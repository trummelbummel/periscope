{
"text": "System Prompt Optimization with Meta-Learning\n\n\n\n\n                                 Yumin Choi1∗  Jinheon Baek1∗  Sung Ju Hwang1,2\n                                               KAIST1,  DeepAuto.ai2\n                               {yuminchoi, jinheon.baek, sungju.hwang}@kaist.ac.kr\n\n\n                                                 Abstract\n\n                            Large Language Models (LLMs) have shown remarkable capabilities, with opti-2025\n                             mizing their input prompts playing a pivotal role in maximizing their performance.\n                           However, while LLM prompts consist of both the task-agnostic system prompts\n                            and task-specific user prompts, existing work on prompt optimization has focusedOct\n                          on user prompts specific to individual queries or tasks, and largely overlooked\n10                          the system prompt that is, once optimized, applicable across different tasks and                             domains. Motivated by this, we introduce the novel problem of bilevel system\n                            prompt optimization, whose objective is to design system prompts that are robust to\n                                 diverse user prompts and transferable to unseen tasks. To tackle this problem, we\n                               then propose a meta-learning framework, which meta-learns the system prompt by\n                               optimizing it over various user prompts across multiple datasets, while simultane-\n                               ously updating the user prompts in an iterative manner to ensure synergy between[cs.CL]                        them. We conduct experiments on 14 unseen datasets spanning 5 different domains,\n                           on which we show that our approach produces system prompts that generalize effec-\n                                    tively to diverse user prompts. Also, our findings reveal that the optimized system\n                            prompt enables rapid adaptation even to unseen tasks, requiring fewer optimization\n                                 steps for test-time user prompts while achieving improved performance.\n\n\n                1  Introduction\n\n                     Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of\n                        tasks and domains [1, 7, 23]. To effectively harness LLMs in diverse application scenarios, prompts\n                      play a pivotal role in guiding their behavior and ensuring their outputs align with user goals, which\n                     comprise two components: system prompts and user prompts [25]. Specifically, system prompts are\n                        task-agnostic instructions that define the foundational behavior and constraints of the LLM (which are\n                         also designed to be applicable to multiple tasks and domains); whereas, user prompts are task-specific\n                        inputs designed to elicit responses tailored to solving particular queries or tasks.arXiv:2505.09666v2\n                      Alongside the advancement of LLMs, as their performance is highly sensitive to the prompts provided,\n                         there has been a surge of interest in designing effective prompts. Traditionally, manual prompt crafting\n                      has been the dominant approach, which has led to the discovery of several prompts, such as Chain-\n                      of-Thought, which is known for enhancing the reasoning capabilities of LLMs [39]. However, this\n                   manual design process is labor-intensive and limited in scalability. Therefore, to overcome these\n                         limitations, the field of automatic prompt optimization has emerged, which aims to automatically\n                    improve prompts by utilizing LLMs directly or further integrating them with algorithms to explore\n                     and generate more effective prompt variations [12, 14, 41, 45]. Specifically, notable methods include\n                         textual gradients [27], which produces gradients (that criticize prompts) in text based on model\n                        prediction results and formulates new prompts iteratively, and the approach with Monte Carlo Tree\n                      Search (MCTS) [37], which explores and evaluates various prompt configurations through tree search.\n\n                          ∗Equal contribution; Code is available at https://github.com/Dozi01/MetaSPO.\n\n\n\n                        39th Conference on Neural Information Processing Systems (NeurIPS 2025).\n\n(A) Prompt Input in LLM        (B) Task-Specific Optimization         (C) Bilevel System Prompt Optimization (Ours)\n\n    Task-Agnostic System Prompt:            Source Task  Reasoning            Source Tasks Reasoning     Grounding      Safety\n     You are a helpful assistant.\n                                             Task-Specific Optimization                   Meta-Learning Framework\n     Task-Specific User Prompt:                                                                  Task-Specific Optimization            Meta-Knowledge\n     Count the objects in a given sentence.         System Prompt        System Prompt\n                                                                                     System Prompt       System Prompt\n                                                                                                                                          Optimized\n                                                                                                                           System                                                                                                                                    Prompt                                                                                                                     Optimized    Example:                                User Prompt           UserOptimizedPrompt             User Prompt          User                                                                                                               Prompt\n        I have a clarinet, a violin, and a flute.\n\n                                                            Target Tasks                                      Target Tasks\n                                           Optimized\n                                        User                                           Prompt        Reasoning                  SystemOptimizedPrompt         Reasoning\n                                                               Medical                                              Medical\n    Response:                                 Target                                    Task                                                                       Generalizable                                                                                                               Review                                                            Review      There are 3 objects.                                Only                                                            Unseen Tasks                                                                                                                              Analysis                                                                    Analysis             To\n\nFigure 1: Concept Figure. (A) The input prompt provided to LLMs typically consists of a task-\nagnostic system prompt, a task-specific user prompt, and a target example to handle. (B) Conventional\nTask-Specific Optimization focuses on optimizing user prompts for a single task but shows limited\ngeneralization to other tasks. (C) The goal of Bilevel System Prompt Optimization (Ours) is to enable\nthe optimized system prompt to generalize effectively to unseen target tasks, for which we utilize a\nmeta-learning framework to derive meta-knowledge from multiple source tasks.\n\n\n\nHowever, despite various studies on prompt optimization, they have mainly focused on user prompts\nfor solving a specific task, while overlooking the system prompts that could significantly influence\nresponse generation and have far-reaching effects across diverse tasks and domains. Notably, there\nare a couple of benefits in optimizing system prompts. First, system prompts serve as the foundational\ninstructions that are invariant, meaning that a single well-optimized system prompt can generalize\nacross multiple tasks and domains. Second, the optimized system prompts can establish a robust\nbehavioral framework, enabling LLMs to adapt more robustly to unseen user prompts and domains,\nwhile having the potential to create a synergistic relationship with user prompts.\n\nTo address this gap, we introduce the novel problem of bilevel system prompt optimization (Figure 1),\nwhich aims to design system prompts that can be effectively coupled with diverse user prompts and\ngeneralizable across a wide range of tasks, including those not seen during optimization. However, in\ncontrast to conventional approaches that focus on optimizing only the user prompts, the proposed\nproblem introduces unique challenges as it requires optimizing two objectives (system and user\nprompts) simultaneously. To handle this, we then frame it as a bilevel optimization framework, as its\nhierarchical structure allows us to decouple the optimization processes (for system and user prompts)\nwhile capturing their dependency. Intuitively, within the bilevel optimization, the system prompt\n(optimized to generalize for diverse tasks) forms the higher-level optimization objective, while the\nuser prompts (optimized to maximize task-specific performance) form the lower-level objective.\n\nBuilding on this bilevel formulation, we then propose to tackle the aforementioned problem of system\nprompt optimization through a meta-learning framework, which is particularly well-suited as it learns\nto generalize from a distribution of tasks (rather than individual queries and tasks) and subsequently\nenables the robust and rapid adaptation to various user prompts and tasks. Specifically, in our problem\nsetup, the proposed meta-learning framework meta-trains the system prompt to be optimized over a\ndiverse range of user prompts and tasks (via the higher-level optimization objective), equipping it\nwith the ability to generalize even to unseen instances. Furthermore, by iteratively updating the user\nprompts through the lower-level optimization objective within the meta-learning loop, our approach\nensures that the system prompt is optimized in synergy with diverse user prompts. Additionally, this\nmeta-learning design choice offers a couple of advantages. First, compared to approaches that are\nnot on meta-learning [43], the proposed framework is designed to be superior to them in handling\nvarious unseen prompts and tasks, which are prevalent in real-world scenarios. Also, the framework\nis highly versatile since it allows for the use of any prompt optimization techniques to operationalize\nit. We refer to our overall method as Meta-level System Prompt Optimizer (in short, MetaSPO).\n\nWe extensively validate our MetaSPO framework on 14 unseen tasks across 5 diverse domains under\ntwo different real-world scenarios: 1) unseen generalization, where the optimized system prompt is\ndirectly leveraged to test time queries without any further optimization of user prompts; 2) test-time\nadaptation, where the user prompts (specific to target tasks) are further optimized with few examples\nfrom them (while the optimized system prompt remains fixed). From this, we then observe that, in\n\n\n                                       2\n\nthe unseen generalization scenario, the optimized system prompt significantly outperforms baseline\nmethods, demonstrating its strong generalization capabilities across diverse, unseen tasks and user\nprompts. Additionally, in the test-time adaptation scenario, the optimized system prompt facilitates\nmore efficient user prompt optimization, leading to faster convergence with superior performance.\n\n2  Related Work\n\nSystem Prompts  System prompts, introduced in ChatGPT [25], have become an integral part of\nmodern LLMs, playing a crucial role in defining foundational behavior [2, 11, 40]. As their adoption\ngrows, many studies on system prompts have begun to uncover their potential. To mention a few,\nZheng et al. [44] demonstrates that incorporating a persona into system prompts can enhance LLM\nperformance on certain role-playing scenarios. Additionally, some recent studies propose training\ntechniques to enhance model alignment with various system prompts [19, 11]. In particular, Wallace\net al. [35] suggests training the model to follow instructions with the highest importance, written in\nsystem prompts, with specific data generation strategies for it. However, unlike the aforementioned\nstudies that aim to align and test models to pre-defined system prompts (which are handcrafted), our\nwork focuses on automatically optimizing system prompts.\n\nPrompt Optimization  As the performance of LLMs is highly sensitive to the quality and structure\nof their prompts, the field of prompt optimization has received much attention. Early studies rely on\ngradient-based methods to adjust a small number of trainable parameters and inject them into LLMs\nas an embedding-level soft prompt; however, they are computationally expensive and unsuitable for\nuse with closed-source models [22, 20, 38]. To address this, gradient-free methods have emerged,\nwhose core idea is to generate candidate prompts with LLMs and evaluate them iteratively to select\nthe most effective one, as in APE [45] and OPRO [41]. Also, there exist methods that additionally\nperform problem analysis for the current prompt before crafting the optimized prompts [27, 8, 37].\nFurthermore, some of the other works leverage the idea of evolutionary algorithms (like crossover\nand mutation) in optimizing prompts with LLMs [14, 12, 9]. Despite these advancements, existing\nstudies have centered on optimizing user prompts specific to certain tasks, with limited exploration of\nsystem prompts. Also, although very recent studies have started exploring the system prompt, either\ntheir focus is restricted to only the safety-related tasks [46] or lacks consideration of interactions with\ndiverse user prompts [43], despite the fact that the optimized system prompt should be generalizable\nover diverse tasks with various user prompts. To this end, we approach to address this gap through\nthe novel formulation of bilevel system prompt optimization, and tackle it with meta-learning.\n\nMeta-Learning  Meta-learning, or the concept of learning to learn, aims to acquire generalizable\nknowledge across a distribution of tasks and enable models to adapt to new tasks with no or minimal\ntraining, unlike conventional approaches that optimize for a single task or dataset. To be specific, the\napproach called Model-Agnostic Meta-Learning (MAML) learns a shared initialization that, when\nused for fine-tuning, enables rapid adaptation across tasks [13]. Also, Matching Networks [34] and\nPrototypical Networks [32] first represent task distributions over the embedding space by mapping and\nlearning samples over it, and then use this learned embedding for adaptation. Recently, meta-learning\nhas also been adopted in the domain of prompt optimization, but prior works have focused only on\ngradient-based methods (fine-tuning trainable parameters), orthogonal to our focus on gradient-free\napproaches [38, 28, 16]. Also, meta-learning has not been explored for system prompt optimization.\n\n3  Methodology\n\nWe begin with preliminaries, providing a formal explanation of Large Language Models (LLMs)\nand conventional prompt optimization techniques. We then introduce the problem of bilevel system\nprompt optimization and propose a meta-learning-based approach to tackle it.\n\n3.1  Preliminary\n\nLarge Language Models  Formally, LLMs take the input x, which typically consists of a system\nprompt s, a user prompt u, and a specific query to respond q, then generate the output y, formalized\nas follows: y = LLM(x), where x = [s, u, q] and each element (such as s, u, q, x, and y) is\nrepresented as a sequence of tokens, e.g., s = [s1, . . . , si]. In this formulation, the system prompt\n\n\n                                       3\n\n(A) Inner Loop: User Prompt Optimization                                    Medical           Safety                                                                                        Reasoning\n       (A.1) Candidate User Prompt Generation                          (A.2) Generated User Prompt Evaluation\n       System Prompt: …        System Prompt: …        System Prompt: …\n                                                                              System Prompt: …\n       User Prompt:             User Prompt:             User Prompt:\n          Solve logic grid puzzles.             Solve logic grid puzzles.            Solve logic grid puzzles.           #1 User Prompt           Optimized User Prompt:\n       Examples: …            Wrong Examples          Analyzed Problem           Examples: …                 To solve a logic grid puzzle, follow these steps:\n                                                                                                                                                                                           1. Understand the Structure: …\n                                                                              System Prompt: …                  2. Read Each Clue Carefully: …\n                                                                                   #2 User Prompt                      3. Visualize the Puzzle: …\n            Correct\n            Examples                         Examples                     Wrong           Analyzed Problem           #1PromptUser     #2PromptUser          Examples: …\n\n        Answer Prediction            Failure Analysis         Prompt Generation          Prompt Evaluation                Prompt Selection\n\n                                       #1 System Prompt              System Prompt:      System Prompt:      System Prompt:\n                                                                                                                                                                                          are                                                                                                                                                                             a helpful assistant.                                                                                                 You                                                                                                                                      are a helpful                                                                                                                                                                   assistant.           You                                                                                                                                                                              are a helpful                                                                                                                                                                                                                 assistant.         You\n                                       User                                            Prompt:                            … U…                                    U…      Optimized              System                      Prompt:                                                                                                                                          Reasoning                                                                                                                                                                        Medical                                                                                                                                                                                       Safety                                                                                  Wrong                                                                                               Examples        You               are an                   advanced                                  virtual                                          assistant                                                                        Analyzed                                                                             Problem                                       Examples:                           …                                 E…                                      E…                                                                                                  w/ User                                                                                                Prompts                                                                                                                    User                                                                                                                          Prompt:                                                                       …                                                                            U…                                                                                U…          designed                     to                     process                          and                                analyze                                          information.\n         Your main objectives are to:                                                                                           Examples: …  E…  E…\n             1. Analyze Information Critically: …        #1 System Prompt\n             2. Handle Different Types of Queries …      User                                            Prompt:                            … U…                                    U…\n                                       Examples:                           …                                 E…                                      E…       #1PromptSystem   #2PromptSystem       Analyzed Problem          ExamplesWrong         ExamplesCorrect\n             Prompt Selection                Prompt Evaluation          Prompt Generation         Failure Analysis            Answer Prediction\n                                                       (B) Outer Loop: System Prompt Optimization                                    1\nFigure 2: Overview of MetaSPO, which consists of the inner loop for user prompt optimization and\nthe outer loop for system prompt optimization, operationalized through the meta-learning framework.\n(A) Inner Loop generates candidate user prompts by analyzing incorrectly predicted examples and\nthen evaluates them with the system prompt to select refined prompts for individual tasks. (B) Outer\nLoop generates candidate system prompts by analyzing incorrect examples from all source tasks, and\nthen evaluates them across various user prompts and tasks to ensure generalizability.\n\n\ns defines high-level behavioral guidelines that are designed to be task-agnostic, the user prompt u\nspecifies the fine-grained task or action to be performed, and the query q contains the specific input\nor instance that requires a response, all of which allow the LLM to produce the desired output y.\n\nPrompt Optimization  Given the sensitivity of LLMs to the prompts they receive, prompt opti-\nmization emerges as an effective solution, whose objective is to automatically discover prompts that\nmaximize task performance through iterative refinement processes, guided by performance feedback\nfrom available examples. Formally, let T denote a task, which represents a dataset or distribution\nof input-output pairs (q, a), where q is the query and a is the ground truth answer. Then, the goal\nof prompt optimization is to identify the optimal prompt u∗(starting from the initial prompt u)\nthat maximizes the task performance on T. To achieve this, previous works [45, 27, 37] typically\nformulate the objective function (and propose various methods to optimize it), as follows:\n              u∗= arg maxu E(q,a)∼T [f(LLM(s, u, q), a)] ,\n\nwhere f is a metric function (e.g., accuracy or F1 score) that evaluates the quality of the model output\nover the ground truth response for the examples in the target task T.\n\nHowever, despite the advancements in this prompt optimization, previous studies exclusively focus\non optimizing user prompts u, leaving system prompts s largely underexplored and subsequently\nintroducing a couple of notable limitations. First, the user queries, used for prompt optimization, are\ntypically drawn from one specific task distribution. As a result, while effective for test-time queries\nwithin the same distribution, these methods struggle with generalization to queries and tasks outside\nthe training distribution [21]. In other words, this lack of transferability necessitates re-optimizing\nuser prompts for each new task, which is computationally expensive and time-consuming. Second,\nwhile the system prompt offers potential benefits as a universal behavioral guide for LLMs (that have\nan orthogonal effect to user prompts, and can further enhance the LLM performance when used with\noptimized user prompts), previous methods exclude the system prompt from the optimization process.\nBy limiting the exploration to user prompts alone, the optimization process is restricted to finding\nuser prompts that may be locally optimal for specific tasks, while overlooking the potential of system\nprompts to contextualize LLMs (synergized with user prompts) in a task-agnostic manner.\n\n3.2  Bilevel System Prompt Optimization\n\nTo address the aforementioned limitations of conventional prompt optimization, we introduce the\nnovel problem of bilevel system prompt optimization, which aims to design system prompts that\nare robust to diverse user prompts and tasks. It is worth noting that we formulate this problem as a\n\n\n                                       4\n\nbilevel optimization setting due to the hierarchical dependency between system and user prompts:\nthe system prompt should generalize across tasks (forming the higher-level objective) while also\nsynergizing with user prompts that are optimized for specific tasks (forming the lower-level objective).\nFormally, the goal is to discover the system prompt s∗(starting from the initial system prompt s) that\nmaximizes the performance over a distribution of tasks T , while ensuring that it synergizes with user\nprompts (u∗i ) optimized for the specific task Ti (where Ti ∈T ), which is defined as follows:\n\n             s∗= arg maxs ETi∼T [E(q,a)∼Ti[f(LLM(s, u∗i , q), a)]],\n                  where u∗i = arg maxu E(q,a)∼Ti [f(LLM(s, u, q), a)] .\n\nTo solve this formulation of bilevel optimization, we particularly adopt an iterative approach that\nalternates between optimizing the system prompt and the user prompts. Specifically, at each iteration,\nthe inner optimization problem first focuses on updating the user prompts u for individual tasks Ti\nto maximize task-specific performance while fixing the (previously optimized) system prompt s.\nOnce the user prompts converge for their respective tasks (or a certain number of optimization steps\nfor computational efficiency), the outer optimization problem then updates the system prompt s by\noptimizing it over the distribution of tasks T while considering the updated user prompts u∗from the\ninner loop. Note that we operationalize this procedure with meta-learning, which inherently suits the\nbilevel structure by enabling the system prompt to learn generalization over task distributions through\nthe outer loop while easily adapting to task-optimized user prompts in the inner loop, discussed next.\n\n\n3.3  MetaSPO: Meta-level System Prompt Optimizer\n\nWe now turn to provide detailed descriptions of the Meta-level System Prompt Optimizer (MetaSPO),\nwhich consists of two optimization loops, illustrated in Figure 2.\n\n\nInner Loop   It is worth noting that since MetaSPO is designed as a general framework, it allows\nthe use of any off-the-shelf prompt optimization techniques, and, among many, one instantiation\nis to iteratively update the prompt to correct examples that were previously handled incorrectly,\nthereby improving the overall performance on the target tasks, which is similar to Pryzant et al. [27].\nSpecifically, as the first step, we measure the performance of the current user prompt on examples\nfrom the target task and identify responses that are incorrect. To improve the performance, we then\naim to refine the prompt to address these errors, and to achieve this, we conduct a failure analysis,\nwhere we prompt the LLM with the current user prompt and incorrect examples to uncover the\nunderlying issues. After that, based on the user prompt and its analyzed problems, we further prompt\nthe LLM multiple times to generate (potentially refined) candidate user prompts. However, as not\nall generated prompts result in performance improvement, we measure the performance of prompts\n(including previously used ones) on the target task, and select the top k prompts that perform the best.\n\n\nOuter Loop  The outer loop follows a similar structure to the inner loop but differs in key aspects,\nas its objective is to find the system prompt that maximizes the performance across a distribution of\ntasks, rather than focusing on a single task. Specifically, to identify the incorrect responses (used for\nanalyzing problems in the system prompt), we first measure the performance of the system prompt\nfor each task alongside the user prompts and examples associated with that task, and then aggregate\nthe incorrect responses across tasks. After that, similar to the inner loop, we analyze the system\nprompt with incorrect responses (from all tasks), and, based on this analysis, we generate multiple\ncandidate system prompts via LLM prompting. Lastly, we evaluate the performance of these system\nprompts, not just for individual tasks but across the distribution of tasks, in conjunction with their\ncorresponding (optimized) user prompts and examples, and then select the top k system prompts that\ndemonstrate the best performance. The full algorithm of MetaSPO and the prompts used to elicit the\ndesired output from the LLM for each step are provided in A.3 and A.4, respectively.\n\n\n4  Experiments\n\n\nIn this section, we now describe experimental setups, including tasks, datasets, models, and imple-\nmentation details, and then showcase the effectiveness of the proposed MetaSPO on them.\n\n\n                                       5\n\nTable 1: Main Results on Unseen Generalization. For each target task, we report the average\nscore of the system prompt paired with ten different user prompts. Please refer to A.1 for detailed\ndescriptions of each task with its full name. The best performance is highlighted in bold.\n\n\n                             Medical          Review Analysis       Reasoning         Safety     Grounding\n\n      Methods       Ana.   Ped.   Den.   Sur.   Ele.    Pet   Spo.   Cou.   Epi.   Col.   A.H.   Eth.   N.Q.  Web.   Avg.\n\n             Default     36.1   38.9   25.8   32.3   41.3   41.5   29.3   43.5   28.3   56.6   21.2   28.7   15.1   11.6   32.2\n         CoT        36.1   42.7   26.0   32.0   36.8   40.3   25.0   45.6   37.2   62.0   21.9   31.9   15.9   12.0   33.2\n  Global    Service     34.4   35.2   20.2   30.6   59.0   53.2   52.2   30.6   37.6   56.6   21.1   26.9   11.4    9.9    34.2\n         SPRIG     41.6   42.2   28.4   35.7   47.9   47.4   38.6   39.3   29.9   59.9   23.0   31.1   14.1   11.2   35.0\n          MetaSPO   45.7   43.1   31.1   36.3   67.2   66.0   61.4   44.5   39.6   64.5   24.9   37.6    9.5     7.7    41.4\n\n         SPRIG     41.2   41.8   29.6   35.3   61.6   57.4   51.3   30.1   34.5   51.5   24.0   32.1   16.1   12.0   37.0\n  Domain\n          MetaSPO   48.9   46.7   36.4   40.0   61.8   64.9   61.5   47.1   43.0   66.6   29.1   43.9   19.1   13.7   44.5\n\n\n\n                                                                                                                             0.7    0.8                                                                                             Source-Target                                                                                          Domain                                                                                                                               Similarity\n                                                                                                           0.18     0.22                                                                                                                             0.12                                                                                                                                      0.29     0.7                                   Pearson Corr. 0.56    Spo.                                                                                                                             0.6                                                                                                                                    0.1                                     (%) 100\n    0.6                                      80                                                       0.5            0.6                                       0.46\n                                                                                                         0.5MetaSPO\n    0.4                                      60   Epi.           Eth.            PetEle.      0.4            0.4                                       0.44w/                                                                                                                                                                                                                                                                                                                                                                                    Similarity          Metric                                                                  Den.                                                                 A.H.                                                                                                                             0.3                                            40                                                                                                                                              0.42                                                                Ana.                                                                                  Sur.N.Q.    0.2                                                            Ped.                                                                                                                             0.2                                                                            Col.                                                                                                                                 Avg. 0.30.2                                            20                                                                                                                                        Improvement                                                                                                                                              0.40                                                       Web                                                                                                  Default                                                                                                           Service                                                                                            MetaSPO                                                      Cou.Metric                                                                                                         0.1                                                                             CoT                                                                                       SPRIG                                                                                                                             0.1\n                                                                                                                                              0.38    0.0    Win Rate : 85.0%                                                           0.2                                                                   0.3                                                                           0.4                                                                                   0.5     0.6                                                                                                                                                       1  2  3                                                                                                                   Reasoning                                                                                                     Medical                                                                                                                   Review.                                                                                                                                          Safety\n        0.0     0.2     0.4     0.6     0.8          Avg. Source-Target Similarity                                     # Src\n        Metric w/ Default             (BoW Rank Correlation)                          Target Domain            Domain\n\nFigure 3: Performance   Figure 4: Relative performance  Figure 5: Results with generaliza-\nof user prompts with  improvements of our MetaSPO   tion across different domains. (Left:)\nMetaSPO (y) and De-  over Default as a function of  Performance of MetaSPO for domains\nfault (x).  Points over  the source-target tasks similar-  not used for prompt optimization, with\ny = x indicate the su-   ity, where the similarity is mea-  their similarity. (Right:) Effect of the\nperiority of MetaSPO.    sured by Bag-of-Words (BoW).   number of training domains with stds.\n\n\n4.1  Experimental Setup\n\nTasks  To evaluate MetaSPO, we consider two scenarios that reflect real-world applications of the\noptimized system prompt. First, in the Unseen Generalization scenario, where there is no data\navailable for the target task, the optimized system prompt is directly applied to test-time queries and\nuser prompts without any additional optimization on them. Meanwhile, in the Test-Time Adaptation\nscenario, the user prompts provided are further optimized using a small number of examples from\nthe target task, while the optimized system prompt remains fixed. In addition to them, we further\nconsider two different settings in optimizing system prompts: Global where the goal is to obtain the\nglobal system prompt that is generalizable across domains, and Domain, a more relaxed case where\nthe system prompt is designed and deployed to handle tasks and queries within one specific domain2.\n\nDatasets  To extensively evaluate the efficacy of the (optimized) system prompts, our evaluation\nsuite spans 5 distinct domains (over 34 different tasks), as follows: Medical – which aims to answer\nmedical-related queries [26]; Review Analysis – which aims to predict the sentiment of customer\nreviews [15]; Reasoning – which evaluates the logical and analytical thinking of models [7]; Ground-\ning – which assesses whether the generated responses are grounded in the provided context [29];\nSafety – which measures the ability to classify harmful or sensitive content [5]. We note that, for\neach domain, 4 source tasks are collected to optimize system prompts. Also, for the Medical, Review\nAnalysis, Reasoning, Grounding, and Safety domains, we use 4, 3, 3, 2, and 2 target tasks (which are\nnot seen during prompt optimization) to evaluate the system prompts, respectively. More detailed\ndescriptions of source and target tasks across all domains are provided in A.1.\n\nBaselines and Our Model  The models evaluated in this work are as follows: 1. Default – which\nuses one of the most widely used system prompts, “You are a helpful assistant.”; 2. Chain of Thought\n(CoT) – which incorporates “Let’s think step by step.” into the system prompt, to allow LLMs to\n\n   2Unless otherwise stated, we report results with the Domain setup.\n\n\n                                       6\n\nTable 2: Main Results on Test-Time\n                                                               0.70                                0.70\nAdaptation, where we optimize the user                                                                                                                 Metricprompts with examples from target tasks,\n                                                               0.65                                0.65            MetaSPOwhile fixing the system prompt. The av-     Avg.                                                                                                         Default\nerage score for each domain is reported.        0.60                                0.60\n                                                            0   4   8   12  16  20        0    50   100  150  200\n                                                                         Iteration             Number of Examples\n   Methods Med. Rev. Rea.  Saf. Gro. Avg.\n                                         Figure 6: Efficiency for test-time adaptation as a func-\n   Default    45.1  68.9  64.0  59.9  17.5  51.1     tion of optimization iterations (left) and data quantity\n  SPRIG    45.4  69.3  65.3  64.7  17.7  52.5     (right). The results are averaged over the Review Anal-\n                                            ysis and Reasoning domains. The gray dashed lines\n  MetaSPO  45.6  71.4  67.3  67.2  19.9  54.3\n                                            indicate the final performance of the Default baseline.\n\n\nthink before providing the answer [39]; 3. Service – which uses the hand-crafted commercial system\nprompt available from Askell [3]; 4. SPRIG – which automatically optimizes the system prompt\nover a diverse set of tasks based on the genetic algorithm (without meta-learning) [43]; 5. MetaSPO –\nwhich is our full model that iteratively performs system prompt optimization via meta-learning.\n\nImplementation Details  For a fair comparison of different approaches, we primarily use Llama\n3.2 (3B) [11] as the base model for generating responses, and GPT-4o mini as the prompt optimizer.\nWe use the temperature of 0 for the base model (to ensure consistency) and 1 for the optimization\nmodel (to yield variety). For our MetaSPO, we iterate the inner and outer loops three times. Also, in\nsystem prompt optimization, we generate nine different prompts and maintain one, while for the user\nprompt, we generate and maintain three. During the problem analysis step for the current prompts,\nwe use three incorrect examples for the user prompt optimization, and two incorrect examples per\ntask (aggregated over all tasks) for the system prompt optimization. All experiments are conducted\nwith three different runs, and we report their average results. For more details, please refer to A.2.\n\n\n4.2  Experimental Results and Analyses\n\nResults on Unseen Generalization  We first report the performance of optimized system prompts\non the unseen generalization scenario, where examples for target tasks are not available for prompt\noptimization; thus, the user prompts are not optimized on them, and, for evaluation, (ten) user prompts\non each task are obtained via LLM prompting (see A.5 for details). As shown in Table 1, we then\nobserve that MetaSPO consistently outperforms all baselines across both the Global and Domain\nsystem prompt optimization settings. To see whether the optimized system prompt contributes to\nthe performance gain when coupled with diverse user prompts, we visualize the performance of\n(randomly sampled 20%) user prompts using the system prompt optimized from MetaSPO, compared\nto the default system prompt in Figure 3 (see B.4 for the break-down results by domain). From this,\nwe observe that 85.0% of the user prompts exhibit improved performance with MetaSPO, indicating\nthat it effectively and robustly enhances the performance across a broad range of user prompts.\n\nAnalysis on Similarity between Source and Target Tasks We hypothesize that if the target\ntasks (used for evaluation) are more similar to the source tasks (used for meta-learning), the system\nprompt optimized from source tasks is more effective for target tasks. To confirm this, we measure the\nsimilarity of examples between source and target tasks using either Bag-of-Words rank correlation [21]\nor cosine similarity over the embedding space with the language model [33], then measure the Pearson\ncorrelation of the similarity with its corresponding performance improvement (over the Default system\nprompt). The results in Figure 4 show a positive correlation between the source-target task similarity\nand the improvement, with a Pearson correlation coefficient of +0.56. Also, the cosine similarity\nresult in B.5 shows a positive correlation with performance improvement. Yet, more interestingly, we\nobserve that MetaSPO remains effective even for low-similarity tasks, yielding performance gains.\nThese results demonstrate that, while including more source tasks that are close to target tasks is\nbeneficial, MetaSPO enables learning generalizable knowledge that is useful across diverse tasks.\n\nAnalysis on Generalization Across Domains  We further validate MetaSPO in the more challeng-\ning scenario, where there are no overlapping domains between source tasks (used for training) and\ntarget tasks (used for evaluation). Specifically, we optimize system prompts using tasks from three\n\n\n                                       7\n\nSeparated Win     Tie     Unified Win\n                                                     Medical                                                                +38.3%    0.6                                                                                                                                                              Ratio 0.3                                                  Review                                                                +4.4%Metric                                                                                                            0.2\n                                                  Reasoning                                                                        -5.6%\n                             Review                                          AnalysisAvg. 0.5                                                                                                            0.1                                                           Safety                                                                +36.6%                              Reasoning                                                                                                                                                                                                                                                                                                                                                  System-User                                                                                                        Default                                                                                                                Service                                                                                                 MetaSPO                                                                                                                                                                                                                                                                                            Attention                                                Grounding                                                                +21.7%                                                                                  CoT                                                                                            SPRIG        1     2     3     4                                  5                                        6                                                                                                            0.0\n       Number of Source Tasks                 0   20   40   60   80  100                   Medical  Review. Reasoning Safety\n\nFigure 7: Results as a func-  Figure 8: Comparison of in-  Figure 9: Ratios of the attention\ntion of the number of source  put prompt structures, with   scores directed toward system\ntasks for system prompt opti-  separated inputs (system/user  prompts over user prompts. A\nmization on MetaSPO, rang-   roles are explicitly separated)   higher ratio indicates that LLMs\ning from 1 to 6. Standard devi-  and unified input (both are as-  pay more attention to the system\n ation is shown as shaded areas.   signed to the user role).        prompt than the user prompt.\n\n\ndomains and apply them to evaluate performance on tasks from entirely different target domains, with\nthe goal of testing the robustness and adaptability of the optimized system prompts given the inherent\ndifferences of domains between training and evaluation. Then, as shown in Figure 5 (left), MetaSPO\n consistently outperforms baselines even if there are no strong correlations between source and target\ndomains (while it becomes slightly more effective when their similarity is high). For example, in\nthe reasoning domain, where the source domains have an average similarity of only 0.12, MetaSPO\noutperforms CoT (a strong baseline for reasoning), which is another baseline (SPRIG) inferior to it. In\naddition to this, we analyze the impact of increasing the number of training domains on cross-domain\ngeneralization scenarios. In Figure 5 (right), we observe that the highest performance is achieved\nwhen three domains are included during meta-learning. Overall, these results highlight MetaSPO’s\nrobustness in various transfer settings (including to low-similarity domains), while underscoring the\n potential benefits of leveraging a diverse set of training domains to enhance generalization.\n\nResults on Test-Time Adaptation  We hypothesize that the system prompt optimized through the\nproposed meta-learning framework is further useful in the test-time adaptation scenario (where user\nprompts on target tasks are additionally optimized), as it may offer a good initial point (encapsulating\nthe meta-learned knowledge over diverse source tasks) that can be generalizable and synergized with\nuser prompt optimization. As shown in Table 2, the proposed MetaSPO consistently outperforms\nother methods across all domains, which demonstrates its effectiveness on test-time adaptation.\n\nEfficiency Analysis  The system prompt optimized from our MetaSPO is designed to generalize\nand adapt efficiently to diverse user prompts and tasks. To confirm this, we visualize the performance\nas a function of the number of iterations and data samples for test-time adaptation, and report the\n results in Figure 6. From this, we demonstrate that MetaSPO surpasses the Default system prompt\nacross all iterations and data quantities. Also, MetaSPO is more resource efficient, achieving the final\nperformance of Default with 80% fewer optimization iterations and 75% less data. This suggests its\n practicality for scenarios with limited computational resources and constrained data availability.\n\nAnalysis on Number of Source Tasks  To see how much the performance of MetaSPO improves on\nunseen target tasks with respect to the number of source tasks, we conduct experiments, varying the\nsource task numbers. As shown in Figure 7, we find that, as the number of source tasks increases, the\nperformance of MetaSPO improves with greater stability. Yet, the extent to which the performance\nimproves differs across domains. For example, in the Review Analysis domain (which exhibits higher\n similarity between source and target tasks), performance increases by 17.10% when the number of\nsource tasks increases from 1 to 6. In contrast, the Reasoning Domain shows (despite meaningful) a\ncomparatively smaller improvement of 8.26% under the same condition. These results suggest that\nthe proposed MetaSPO benefits from a larger and more diverse set of source tasks to effectively learn\n its distribution, with greater performance gains when they closely resemble the target tasks.\n\nAnalysis of Roles for System and User Prompts  Recall that the input to LLMs is categorized into\nsystem and user prompts with distinct roles. To investigate whether assigning (optimized) system and\nuser prompts to their designated spaces and roles is necessary, we consider two input configurations:\n(1) separated inputs, where the system prompt is assigned to the system role and the user prompt is\nassigned to the user role, and (2) unified input, where the system and user prompts are concatenated\n\n\n                                        8\n\nTable 3:  Results with different LLMs for    Table 4: Variations of MetaSPO, where we use\nMetaSPO, where Cross Model refers to prompts    different compositions of optimization methods\noptimized with Llama3.2 (3B) and applied to    within our meta-learning framework. We report\nother models. Results are averaged over Review    the average performance score for each domain.\nAnalysis and Reasoning domains. Numbers in   The highest score in each domain is highlighted\nbold indicate the highest, followed by underline.    in bold, while the second-highest is underlined.\n\n                          Base Models                    Methods       Med.  Rev.  Rea.   Saf.  Gro.  Avg.\n Methods    Llama 3.1 (8B) Qwen 2.5 (7B) GPT-4o mini                                                                    Default           33.3   37.4   42.8   25.0   13.4   30.3\n Default            55.9            58.2           77.2         SPRIG           37.0   56.8   38.7   28.1   14.1   35.9\n CoT              59.6            65.5           75.9\n Service            50.6            58.6           72.9            Outer Loop       36.8   58.1   48.8   32.4   14.8   38.2\n SPRIG            55.2            58.0           75.6         MetaSPO w/ APE   39.8   60.1   48.1   30.4   16.2   38.9\n MetaSPO          69.8            73.2           79.6         MetaSPO w/ EVO   41.6   60.0   50.2   33.2   16.0   40.2\n Cross Model       70.1            68.3           78.3         MetaSPO         43.0   62.7   52.2   36.5   16.4   42.2\n\n\n\nand assigned to the user role. We then compare their effectiveness by generating outputs from these\ntwo configuration setups and measuring the win ratio of one over the other. The results in Figure 8\ndemonstrate that the prompt structure with the separated inputs outperforms the unified structure\nacross all domains, except for reasoning. This performance gap may be attributed to the fact that\nmodern LLMs are trained to interpret system and user prompts differently, and thus perform better\nwhen these roles are explicitly leveraged in separation [11, 35].\n\n\nAnalysis on Attention Scores  We hypothesize that if the optimized system prompt offers meaning-\nful information to answer the queries, the model will allocate more attention to the system prompt\nover the user prompt. To verify this, we compare the attention scores directed toward the system\nprompt versus the user prompt across various methods, where the scores are obtained by averaging\nthe maximum attention values of all heads and layers over the entire decoding process, and visualize\nthe attention score ratios between system and user prompts in Figure 9. From this, we observe that\nMetaSPO directs more attention to the system prompt compared to baselines over all domains, which\nindicates that the system prompts optimized from MetaSPO are effectively used to steer the LLM.\n\nAnalysis with Varying Models  We conduct an auxiliary analysis to examine whether MetaSPO\nis versatile with other LLMs (for response generation) and whether the optimized system prompt\nfrom one LLM can be generalizable to other LLMs. For both experiments, we consider the following\nLLMs: Llama 3.1 (8B), Qwen 2.5 (7B), and GPT-4o mini. We then report the results in Table 3, and,\nfrom this, we observe that MetaSPO demonstrates its robustness and generalizability. Specifically,\nthe system prompt optimized by MetaSPO is superior to other baselines regardless of the underlying\nLLMs used as the base model. Furthermore, in the Cross Model, the system prompt optimized for\nLlama 3.2 (3B) demonstrates strong generalization capabilities when applied to LLMs other than it\nwithout requiring additional optimization. Overall, these results confirm that MetaSPO is effective\nfor diverse LLMs, producing system prompts that not only perform well within the LLM they were\noptimized for but also maintain high performance across different LLMs. Lastly, we further extend\nour analysis of MetaSPO with different optimizer LLMs and show its robustness, provided in B.6.\n\n\nAnalysis on MetaSPO Variants  Note that the proposed MetaSPO is designed to be highly flexible,\nallowing the use of any off-the-shelf prompt optimization components and their combinations over\nits bilevel meta-learning framework. For instance, one such variation is to perform only the outer\nloop without iterative refinement of user prompts (called Outer Loop). Also, there could be other\nvariations, such as MetaSPO w/ APE and MetaSPO w/EVO, which use prompt optimization strategies\nfrom Zhou et al. [45] and Guo et al. [14] in both the inner and outer loop stages. Then, as Table 4\nshows, Outer Loop achieves performance comparable to baselines but falls short of the full MetaSPO\nframework, demonstrating the effectiveness of synergy in meta-learning by alternating between the\ninner and outer loops. In addition, two variants of MetaSPO instantiated through different prompt\noptimization strategies (namely, MetaSPO w/ APE and MetaSPO w/ EVO) outperform baselines\nsubstantially, demonstrating its compatibility with any existing prompt optimization techniques.\n\nQualitative Results  We present examples for the optimized system prompts in Appendix C, from\nwhich we observe that they typically provide a more specific role to the LLM beyond the helpful\n\n\n                                       9\n\nassistant (e.g., you are a knowledgeable and analytical assistant designed to process and analyze\ninformation across a broad range of topics) and include detailed guidelines or objectives on top of it.\n\n\n5  Conclusion\n\nIn this paper, we introduced the novel problem of bilevel system prompt optimization, which differs\nfrom existing prompt optimization work (that primarily targets optimization of task-specific user\nprompts) and instead focuses on designing system prompts that are robust to diverse user prompts and\ntransferable to unseen tasks and domains. To address this problem, we then proposed MetaSPO, a\nmeta-learning framework that optimizes system prompts over a wide range of user prompts and tasks,\nwhile iteratively refining the user prompts and using those optimized user prompts during system\nprompt optimization to ensure effective generalization of the system prompt to various (optimized)\nuser prompts. We extensively validated the proposed MetaSPO framework on 14 unseen datasets\nacross 5 distinct domains, on which we demonstrated that it consistently outperforms baselines in\nboth unseen generalization and test-time adaptation scenarios. We believe our work establishes a\nsignificant step forward in enhancing the robustness and adaptability of LLMs, enabling the use of\noptimized system prompts designed to generalize across diverse tasks and domains as well as LLMs.\n\n\nLimitation and Societal Impacts\n\nLimitation  Despite the promising results of MetaSPO, our work has some interesting avenues for\nfuture work. Specifically, while we demonstrate that MetaSPO works effectively even with a small\nopen-source optimizer (Table 15), its performance depends on the capability of the optimizer LLM.\nWe note that this is indeed a common challenge shared across many prompt optimization studies, and\nto tackle this, developing approaches to maintain strong performance with smaller (open-sourced)\nLLMs for optimization (such as with model distillation) would be an exciting avenue for future work.\n\n\nSocietal Impacts  We strongly believe that our MetaSPO (designed to formulate system prompts\nthat are generalizable across diverse tasks and domains, as well as user prompts) has huge potential\nfor broad real-world applications. In the meantime, as the performance of MetaSPO is still far from\nperfect, for the mission-critical domains (such as biomedical), it should be used carefully. In addition\nto this, there is a chance that MetaSPO is misused to steer the behavior of LLMs in harmful ways,\nand while this vulnerability is not unique to our approach but a common challenge faced by existing\nprompt optimization methods, an additional safeguard for it may be needed.\n\n\nAcknowledgements\n\nThis work was supported by Institute for Information & communications Technology Planning\n& Evaluation(IITP) grant funded by the Korea government(MSIT) (RS-2019-II190075, Artificial\nIntelligence Graduate School Program(KAIST), No.RS-2022-II220713, Meta-learning Applicable to\nReal-world Problems ), National Research Foundation of Korea (NRF) grant funded by the Korea\ngovernment (MSIT) (No. RS-2023-00256259), a grant of the Korea Machine Learning Ledger\nOrchestration for Drug Discovery Project (K-MELLODDY), funded by the Ministry of Health &\nWelfare and Ministry of Science and ICT, Republic of Korea (No. RS2024-00460870) , Institute of\nInformation & Communications Technology Planning & Evaluation (IITP) with a grant funded by\nthe Ministry of Science and ICT (MSIT) of the Republic of Korea in connection with the Global AI\nFrontier Lab International Collaborative Research. (No. RS-2024-00469482 & RS-2024-00509279) ,\nand Artificial intelligence industrial convergence cluster development project funded by the Ministry\nof Science and ICT(MSIT, Korea) & Gwangju Metropolitan City, and i-Scream Media.\n\n\nReferences\n\n [1] Ibrahim Abu Farha and Walid Magdy. From Arabic sentiment analysis to sarcasm detection:\n    The ArSarcasm dataset. In Proceedings of the 4th Workshop on Open-Source Arabic Corpora\n    and Processing Tools, with a Shared Task on Offensive Language Detection, 2020.\n\n\n                                       10\n\n[2] Anthropic.   The  claude 3 model  family:  Opus,  sonnet,  haiku.    2024.   URL\n    https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/\n    Model_Card_Claude_3.pdf.\n\n [3] Amanda Askell.  Claude System Prompt, 2024. URL https://x.com/AmandaAskell/\n    status/1765207842993434880?mx=2.\n\n [4] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,\n    Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath,\n     Jackson Kernion, Tom Conerly, Sheer El Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny\n     Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine\n     Olsson, Dario Amodei, Tom B. Brown, Jack Clark, Sam McCandlish, Chris Olah, Benjamin\n    Mann, and Jared Kaplan. Training a helpful and harmless assistant with reinforcement learning\n    from human feedback. ArXiv, 2022.\n\n [5] Francesco Barbieri, José Camacho-Collados, Luis Espinosa Anke, and Leonardo Neves. Tweet-\n      eval: Unified benchmark and comparative evaluation for tweet classification. In Findings of\n     the Association for Computational Linguistics: EMNLP, Findings of ACL. Association for\n     Computational Linguistics, 2020.\n\n [6] Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic parsing on freebase\n    from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in\n     Natural Language Processing, EMNLP. ACL, 2013.\n\n [7] BIG-bench authors. Beyond the imitation game: Quantifying and extrapolating the capabilities\n     of language models. Transactions on Machine Learning Research, 2023.\n\n [8] Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang, Nicholas Roy, and Chuchu Fan. PRompt\n     optimization in multi-step tasks (PROMST): Integrating human feedback and heuristic-based\n     sampling. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language\n     Processing, EMNLP. Association for Computational Linguistics, 2024.\n\n [9] Wendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun, Damien Lopez, Kamalika Das, Bradley A.\n     Malin, and Kumar Sricharan. Phaseevo: Towards unified in-context prompt optimization for\n     large language models. ArXiv, 2024.\n\n[10] Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt\n     Gardner. DROP: A reading comprehension benchmark requiring discrete reasoning over\n     paragraphs. In Proceedings of the 2019 Conference of the North American Chapter of the\n     Association for Computational Linguistics: Human Language Technologies, NAACL-HLT.\n     Association for Computational Linguistics, 2019.\n\n[11] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle,\n     Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, Anirudh Goyal, An-\n     thony S. Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur\n     Hinsvark, Arun Rao, Aston Zhang, Aur’elien Rodriguez, Austen Gregerson, Ava Spataru, Bap\n      tiste Rozière, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak,\n    Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu,\n      et al. The llama 3 herd of models. ArXiv, 2024.\n\n[12] Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rock-\n      täschel. Promptbreeder: Self-referential self-improvement via prompt evolution. In Forty-first\n     International Conference on Machine Learning, ICML, 2024.\n\n[13] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adap-\n      tation of deep networks. In Proceedings of the 34th International Conference on Machine\n     Learning, ICML, 2017.\n\n[14] Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian,\n     and Yujiu Yang. Connecting large language models with evolutionary algorithms yields powerful\n     prompt optimizers. In The Twelfth International Conference on Learning Representations, ICLR,\n     2024.\n\n\n                                       11\n\n[15] Yupeng Hou, Jiacheng Li, Zhankui He, An Yan, Xiusi Chen, and Julian J. McAuley. Bridging\n     language and items for retrieval and recommendation. ArXiv, 2024.\n\n[16] Yukun Huang, Kun Qian, and Zhou Yu.  Learning a better initialization for soft prompts\n     via meta-learning.  In Proceedings of the 13th International Joint Conference on Natural\n    Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for\n     Computational Linguistics, IJCNLP, 2023.\n\n[17] Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale\n      distantly supervised challenge dataset for reading comprehension.  In Proceedings of the\n     55th Annual Meeting of the Association for Computational Linguistics, ACL. Association for\n     Computational Linguistics, 2017.\n\n[18] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur P. Parikh,\n     Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova,\n     Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le,\n     and Slav Petrov. Natural questions: a benchmark for question answering research. Trans. Assoc.\n    Comput. Linguistics, 2019.\n\n[19] Seongyun Lee, Sue Hyun Park, Seungone Kim, and Minjoon Seo. Aligning to thousands of\n     preferences via system message generalization. In The Thirty-eighth Annual Conference on\n     Neural Information Processing Systems, NeurIPS, 2024.\n\n[20] Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient\n    prompt tuning.  In Proceedings of the 2021 Conference on Empirical Methods in Natural\n    Language Processing, EMNLP. Association for Computational Linguistics, 2021.\n\n[21] Moxin Li, Wenjie Wang, Fuli Feng, Yixin Cao, Jizhi Zhang, and Tat-Seng Chua. Robust prompt\n     optimization for large language models against distribution shifts. In Proceedings of the 2023\n     Conference on Empirical Methods in Natural Language Processing, EMNLP. Association for\n     Computational Linguistics, 2023.\n\n[22] Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation.\n     In ACL/IJCNLP. Association for Computational Linguistics, 2021.\n\n[23] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga,\n    Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang\n    Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher R’e,\n    Diana Acosta-Navas, Drew A. Hudson, E. Zelikman, Esin Durmus, Faisal Ladhak, Frieda\n    Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel J. Orr, Lucia Zheng,\n     Mert Yuksekgonul, Mirac Suzgun, Nathan S. Kim, Neel Guha, Niladri S. Chatterji, O. Khattab,\n     Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli,\n     Tatsunori Hashimoto, Thomas F. Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang,\n    Xuechen Li, Yifan Mai, Yuhui Zhang, and Yuta Koreeda.  Holistic evaluation of language\n     models. Annals of the New York Academy of Sciences, 2023.\n\n[24] Ioannis Mollas, Zoe Chrysopoulou, Stamatis Karlos, and Grigorios Tsoumakas.  Ethos: a\n     multi-label hate speech detection dataset. Complex & Intelligent Systems, 2020.\n\n[25] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin,\n    Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton,\n     Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano,\n     Jan Leike, and Ryan Lowe.  Training language models to follow instructions with human\n     feedback. In Advances in Neural Information Processing Systems 35, NeurIPS, 2022.\n\n[26] Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu. Medmcqa: A large-scale\n     multi-subject multi-choice dataset for medical domain question answering. In Conference on\n     Health, Inference, and Learning, CHIL, Proceedings of Machine Learning Research. PMLR,\n     2022.\n\n[27] Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng. Automatic\n    prompt optimization with “gradient descent” and beam search. In Proceedings of the 2023\n     Conference on Empirical Methods in Natural Language Processing, EMNLP. Association for\n     Computational Linguistics, 2023.\n\n\n                                       12\n\n[28] Chengwei Qin, Shafiq R. Joty, Qian Li, and Ruochen Zhao. Learning to initialize: Can meta\n     learning improve cross-task generalization in prompt tuning? In Proceedings of the 61st Annual\n     Meeting of the Association for Computational Linguistics, 2023.\n\n[29] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.  Squad: 100, 000+\n     questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empir-\n      ical Methods in Natural Language Processing, EMNLP. The Association for Computational\n      Linguistics, 2016.\n\n[30] Stephen E. Robertson, Steve Walker, Susan Jones, Micheline Hancock-Beaulieu, and Mike\n     Gatford. Okapi at TREC-3. In Proceedings of The Third Text REtrieval Conference, TREC,\n    NIST Special Publication. National Institute of Standards and Technology (NIST), 1994.\n\n[31] Paul Röttger, Bertie Vidgen, Dong Nguyen, Zeerak Waseem, Helen Z. Margetts, and Janet B.\n     Pierrehumbert. Hatecheck: Functional tests for hate speech detection models. In Proceedings\n     of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th\n     International Joint Conference on Natural Language Processing, ACL/IJCNLP. Association for\n     Computational Linguistics, 2021.\n\n[32] Jake Snell, Kevin Swersky, and Richard S. Zemel. Prototypical networks for few-shot learning.\n     In Advances in Neural Information Processing Systems 30, NeurIPS, 2017.\n\n[33] Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. Mpnet: Masked and permuted\n      pre-training for language understanding. In Advances in Neural Information Processing Systems\n     33, NeurIPS, 2020.\n\n[34] Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, and Daan Wierstra. Match-\n     ing networks for one shot learning. In Advances in Neural Information Processing Systems 29,\n     NeurIPS, 2016.\n\n[35] Eric Wallace, Kai Xiao, Reimar Leike, Lilian Weng, Johannes Heidecke, and Alex Beutel. The\n      instruction hierarchy: Training llms to prioritize privileged instructions. ArXiv, 2024.\n\n[36] William Yang Wang. “liar, liar pants on fire\": A new benchmark dataset for fake news detection.\n     In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics,\n    ACL. Association for Computational Linguistics, 2017.\n\n[37] Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang, Nebojsa Jojic,\n     Eric P. Xing, and Zhiting Hu. Promptagent: Strategic planning with language models en-\n     ables expert-level prompt optimization. In The Twelfth International Conference on Learning\n     Representations, ICLR, 2024.\n\n[38] Zhen Wang, Rameswar Panda, Leonid Karlinsky, Rogério Feris, Huan Sun, and Yoon Kim. Mul-\n      titask prompt tuning enables parameter-efficient transfer learning. In The Eleventh International\n     Conference on Learning Representations, ICLR, 2023.\n\n[39] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi,\n    Quoc V. Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language\n     models. In Advances in Neural Information Processing Systems 35, NeurIPS, 2022.\n\n[40] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,\n    Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang,\n      Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu, Jingren\n     Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang,\n    Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji\n     Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge,\n    Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren,\n     Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu\n     Cui, Zhenru Zhang, Zhifang Guo, and Zhihao Fan. Qwen2 Technical Report, 2024.\n\n[41] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun\n    Chen. Large language models as optimizers.  In The Twelfth International Conference on\n     Learning Representations, ICLR, 2024.\n\n\n                                       13\n\n[42] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhut-\n     dinov, and Christopher D. Manning. Hotpotqa: A dataset for diverse, explainable multi-hop\n     question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural\n    Language Processing, EMNLP. Association for Computational Linguistics, 2018.\n\n[43] Lechen Zhang, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, and David Jurgens. SPRIG:\n     improving large language model performance by system prompt optimization. ArXiv, 2024.\n\n[44] Mingqian Zheng, Jiaxin Pei, Lajanugen Logeswaran, Moontae Lee, and David Jurgens. When \"a\n     helpful assistant\" is not really helpful: Personas in system prompts do not improve performances\n     of large language models. In Findings of the Association for Computational Linguistics: EMNLP.\n     Association for Computational Linguistics, 2024.\n\n[45] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan,\n    and Jimmy Ba. Large language models are human-level prompt engineers. In The Eleventh\n     International Conference on Learning Representations, ICLR, 2023.\n\n[46] Xiaotian Zou, Yongkang Chen, and Ke Li. Is the system message really important to jailbreaks\n      in large language models? ArXiv, 2024.\n\n\n\n\n\n                                       14\n\nAppendix\n\nA  Additional Experimental Details\n\nA.1  Task Description\n\n  Table 5: Configurations of source and target tasks as well as their corresponding domains.\n\n\n     Domain                      Source Tasks                           Target Tasks                   Test set size\n\n                             OB/GYN,                            Anatomy,                       234\n                                      Medicine,                                     Pediatrics,                       234\n      Medical\n                                     Pharmacology,                             Dental,                         500\n    (MedMCQA [26])\n                                      Pathology                               Surgery                         369\n\n                                            Office,\n                                                                                        Electronics,                      500\n                                       Beauty,\n      Review Analysis                                                                 Pet,                            500\n                                Game,\n     (Amazon [15])                                                             Sports                          500\n                                Baby\n\n                                    Logic Grid Puzzle,\n                                                                               Object Counting,                  200\n                                    Temporal Sequences,\n      Reasoning                                                                 Epistemic,                       400\n                                       Logical Deduction,\n      (Bigbench [7])                                                       Reasoning Colored Objects         400\n                                      Tracking Shuffled Objects\n\n                                   Tweet Eval [5],\n                                         Liar [36],                               Anthropic Harmless [4],            500\n       Safety\n                                    Hatecheck [31],                         Ethos [24]                       500\n                                   Sarcasm [1]\n\n                          SQuAD [29],\n                                HotpotQA [42],                           Natural Questions [18],            500\n      Grounding\n                                    TriviaQA [17],                    Web Questions [6]                500\n                          DROP [10]\n\n\nWe provide a detailed configuration of the source and target tasks for each domain in Table 5. In the\nMedical, Review Analysis, and Reasoning domains, the source and target tasks are constructed with\ndistinct subsets of individual datasets. Conversely, for the Safety and Grounding domains, multiple\ndatasets are combined to define a single domain. Notably, in the Grounding domain (whose examples\nare composed of the given query and its relevant contextual documents), source task examples are\nconstructed using the contexts provided within the dataset, whereas target task examples are formed\nby concatenating the top five documents retrieved for each instance using a BM25 [30] retriever.\n\nTo measure the performance, we primarily use accuracy as the metric in Medical, Review Analysis,\nand Reasoning. For Safety, we use the F1-score as it involves binary classification tasks, while for\nGrounding, we use Exact Match (EM), which measures whether the generated response is exactly the\nsame as the ground-truth answer.\n\nFor data splits, we use predefined train-test splits from datasets (if available), such as MedMCQA,\nBigBench, WebQA, and Anthropic Harmless. For datasets without predefined splits, such as Amazon,\nNatural Questions, and Ethos, we randomly divide the training data to create the test sets. Also, for\neach task, 50 training samples are randomly selected using different seeds across three experimental\nruns. As summarized in Table 5, the number of test samples is limited to a maximum of 500 in all\ntasks to reduce the computational burden.\n\nA.2  Additional Implementation Details\n\nWe now provide the additional implementation details for other optimization methods included in\nour experiments. Regarding ProTeGi [27] (presented in Table 2), it performs six iterations with a\nbeam size of three. For the Outer Loop, we perform six iterations, which is twice the number of\niterations used in MetaSPO. This adjustment ensures an equivalent total number of iterations, as the\nOuter Loop method lacks an inner loop process. In the case of MetaSPO w/ APE and MetaSPO\nw/EVO (that are operationalized without the prompt analysis step), we generate 18 new candidate\nprompts through resampling, crossover, and mutation. For SPRIG, we conduct the experiments using\nthe implementation provided in its official repository referenced in the original paper [43]. We iterate\nSPRIG three times to ensure a comparable amount of computation to the proposed MetaSPO (See\nB.3 for details). Experiments are primarily conducted using an NVIDIA A5000 GPU.\n\n\n\n                                       15\n\nA.3  Algorithm of MetaSPO\n\nWe present the MetaSPO algorithm, which is composed of alternatives between an Inner Loop and an\nOuter Loop.\n\n\nAlgorithm 1 MetaSPO\ninput Task distribution T , Initial system prompt s, Number of iterations N\noutput Optimized system prompt s∗\n  1: Ui ←{ui} for each task Ti ∈T                                  ▷Initialize user prompt set\n  2: for N iterations do\n  3:    for each task Ti ∈T do\n  4:      Ui ←INNERLOOP(s, Ui, Ti)\n  5:   end for\n  6:  U ←{Ui | Ti ∈T }\n  7:   s ←OUTERLOOP(s, U, T )\n  8: end for\n  9: Return s∗←s\n\n\n\nAlgorithm 2 INNERLOOP\ninput Task Ti, System prompt s, Set of user prompt Ui, Number of new candidates m, Top-k size k\noutput Optimized user prompts U∗i\n  1: u0 ←arg max E(q,a)∼Ti [f(LLM(s, u, q), a)]      ▷Select the best-performing user prompt\n           u∈Ui\n  2: for m iterations do\n  3:  Wi ←{(q, a) | (q, a) ∼Ti, LLM(s, u0, q) ̸= a}           ▷Collect incorrect responses\n  4:   Ai ←Analyzer(s, u0, Wi)                ▷Analysis the current user prompt, Table 6\n  5:  u ←Generator(s, u0, Ai)               ▷Generate a candidate user prompt, Table 7\n  6:   Ui ←Ui ∪{u}\n  7: end for\n  8: U∗i ←  arg max  E(q,a)∼Ti Eu∼U′i[f(LLM(s, u, q), a)]        ▷Select top-k user prompts\n           U′i⊆Ui,|U′i|=k\n  9: Return U∗i\n\n\n\nAlgorithm 3 OUTERLOOP\ninput Task distribution T , System prompt s, Set of user prompt set U, Number of new candidates\n   m.\noutput Optimized system prompt s∗\n  1: s0 ←s                                                       ▷Initialize the system prompt\n  2: S ←{s0}                                                 ▷Initialize the system prompt set\n  3: for m iterations do\n  4:  W ←∅\n  5:    for each task Ti ∈T do\n  6:     ui ←arg max E(q,a)∼Ti [f(LLM(s0, u, q), a)] ▷Select the best-performing user prompt\n               u∈Ui\n  7:    Wi ←{(q, a) | (q, a) ∼Ti, LLM(s0, ui, q) ̸= a}        ▷Collect incorrect responses\n  8:   W ←W ∪Wi\n  9:   end for\n10:  A ←Analyzer(s0, W)                 ▷Analysis the current system prompt, Table 8\n11:   s ←Generator(s0, A)                ▷Generate a candidate system prompt, Table 9\n12:  S ←S ∪{s}\n13: end for\n14: s∗←arg max ETi∼T ,(q,a)∼Ti [Eu∼Ui[f(LLM(s, u, q), a)]]  ▷Evaluate across tasks and user\n           s∈S\n    prompts\n15: Return s∗\n\n\n\n                                       16\n\nA.4  Meta Prompts to Implement MetaSPO\n\nIn this section, we present the meta prompts used in MetaSPO. The meta prompts for user prompt\nanalysis and generation are detailed in Table 6 and Table 7, respectively. Similarly, the meta prompts\nfor system prompt analysis and generation are provided in Table 8 and Table 9. Additionally, the\ntemplate for incorrect examples is provided in Table 10.\n\n           Table 6: Meta Prompt for Analyzing Failure Cases of the User Prompt.\n\n     Roles             Prompts\n\n                    You are a user prompt writer tasked with improving a language model’s user prompt for a\n    System               specific task. Your goal is to identify the shortcomings of the current prompt and provide\n                        comprehensive suggestions for improvement.\n\n                       Here are the inputs you will be working with:\n\n                      ### System prompt:\n                       {system_prompt}\n\n                      ### User prompt:\n                        {user_prompt}\n    User\n\n                      ### This prompt gets the following responses wrong:\n                       {examples}\n\n                      ### Remember to focus solely on discussing and improving the user prompt.\n\n                      ### Wrap the analysis of the user prompt in the <Analysis></Analysis> tags.\n\n\n\n               Table 7: Meta Prompt for Generating Candidate User Prompts.\n\n     Roles             Prompts\n\n                    You are a user prompt writer tasked with improving a language model’s user prompt for\n    System             a specific task. Your goal is to create an improved user prompt that enhances the model’s\n                         performance.\n\n                       Here are the inputs you will be working with:\n\n                      ### System prompt:\n                       {system_prompt}\n\n                      ### User prompt:\n                        {user_prompt}\n\n                      ### Wrong examples of the model’s responses:\n                       {examples}\n    User\n                      ### Analysis of the issues with this user prompt:\n                          {analysis}\n\n                      ### Address any problems observed in the examples based on analysis.\n\n                      ### Ensure the user prompt contains the <Question>{question}</Question> where the\n                            actual question will be placed.\n\n                      ### The new user prompt should be wrapped with <improved_user_prompt>\n                     </improved_user_prompt> tags.\n\n\n\n\n\n                                       17\n\nTable 8: Meta Prompt for Analyzing Failure Cases of the System Prompt.\n\nRoles             Prompts\n\n                You are a system prompt writer tasked with improving a language model’s system prompt\nSystem               for general tasks. Your goal is to analyze why the current system prompt fails to respond\n                       correctly in the given examples.\n\n                   Follow these instructions carefully:\n\n                  ### Review the current system prompt:\n                   {system_prompt}\n\nUser              ### Wrong responses:\n                   {examples}\n\n                  ### Remember to focus solely on discussing and improving the system prompt.\n\n                  ### Wrap the analysis of the system prompt in the <Analysis></Analysis> tags.\n\n\n\n\n\n          Table 9: Meta Prompt for Generating Candidate System Prompts.\n\nRoles             Prompts\n\n                You are a system prompt writer tasked with improving a language model’s system prompt.\nSystem\n                  Your goal is to write a better system prompt that can be generalized for various tasks.\n\n                   Follow these instructions carefully:\n\n                  ### Review the current system prompt:\n                   {system_prompt}\n\n                  ### Analysis of the current system prompt:\nUser\n                     {analysis}\n\n                  ### Based on the information provided, write an improved system prompt.\n\n                  ### The new system prompt should be wrapped with <improved_system_prompt>\n                 </improved_system_prompt> tags.\n\n\n\n\n\n                Table 10: Prompt Template for Incorrect Examples.\n\n                      <Example>\n                       System Prompt: {system_prompt}\n\n                        User Prompt: {user_prompt}\n\n                         Response: {response}\n\n                             Prediction: {prediction}\n\n                      The correct label is: {label}\n                      </Example>\n\n\n\n\n\n                                   18\n\nA.5  Generation of User Prompts for Unseen Generalization\n\nIn the unseen generalization setting, we evaluate whether the system prompt is effective with user\nprompts not optimized for target tasks. To generate these unoptimized user prompts, we provide\nGPT-4o mini with ten input-output example pairs, generating the coarse user prompts following\nZhou et al. [45] (please see Table 11 for the detailed meta prompt used to generate ten different\nuser prompts). After that, the answer format prompts (e.g., At the end, present your answer in\n<answer>yes</answer> or <answer>no</answer>.) are added to those generated user prompts.\nNote that the examples of the generated user prompts for each target task are provided in Table 12.\n\nTable 11: Meta Prompt for generating ten user prompts for the unseen generalization scenario.\n\n\n       I gave a friend an instruction and inputs. The friend read the instruction and wrote an output\n     for every one of the inputs. Here are the input-output pairs:\n\n     {examples}\n\n    Based on the above input-output pairs, write an instruction. The new instruction should be\n    wrapped with <instruction></instruction> Tags.\n\n\n\nTable 12: User Prompts for Unseen Generalization Experiments, where we sample three among\nten for each task.\n\n    Target Tasks     User Prompts\n\n                      For each medical scenario provided below, choose the most appropriate answer from\n                        the options given. Your responses should reflect the best understanding of medical\n                    knowledge and relevant anatomy or pathology.\n\n   Anatomy        Given a set of medical-related questions and multiple-choice options, select\n                        the correct answer for each question based on your knowledge.\n\n                    Given a medical question with multiple-choice  options,  select the  correct\n                    answer based on your knowledge of medicine and anatomy.\n                    Given a medical question with multiple-choice answers, select the correct answer\n                    from the options provided.\n\n                     For each medical or developmental question provided, choose the most ap-\n                        propriate answer from the given options, based on your knowledge of pediatric\n    Pediatrics\n                     medicine and developmental milestones.\n\n                      Please analyze the following medical-related inputs and select the most ap-\n                        propriate answer from the given options for each one, providing the corresponding\n                       output for each input scenario.\n                   Based on the following inputs and their corresponding options, select the most\n                       appropriate answer from the given options.\n\n                     For each of the following questions, select the correct answer from the pro-\n    Dental\n                      vided options and indicate your choice clearly.\n\n                      Please provide the correct output for each input based on the given options.\n                        Select the most appropriate answer from the provided choices for each question.\n\n\n\n\n\n                                       19\n\nTable 12: User Prompts for Unseen Generalization Experiments, where we sample three among\nten for each task.\n\n    Target Tasks     User Prompts\n\n                      Please analyze the following medical scenarios and select the most appropriate\n                    answer from the provided options for each question.\n\n                   Based on the following medical questions and their corresponding options,\n   Surgery           provide the correct answer for each question as indicated by the correct output given.\n                       Please ensure that your answers are consistent with established medical knowledge.\n\n                    Given a medical scenario or question along with a set of options, select the\n                    most appropriate answer from the options provided.\n                    Based on the provided input-output pairs, please assign a score from 1 to 5 for each\n                      product review, where 1 indicates a very negative experience, 5 a very positive\n                       experience, and scores in between indicate varying levels of satisfaction. Consider\n                         factors such as the reviewer’s overall sentiment, the thoroughness of their feedback,\n                    and any specific positives or negatives mentioned in the texts.\n\n                      Please rate the quality or satisfaction of the product or service described in\n                     each input on a scale from 1 to 5, where 1 indicates very low satisfaction, 3\n    Electronics\n                        indicates moderate satisfaction, and 5 indicates very high satisfaction. Provide a\n                          brief explanation for your rating based on the content of the title and text.\n\n                   Based on the provided product  titles and associated  text  descriptions,  as-\n                        sign a rating from 1 to 5, where 1 indicates a poor product experience and 5 indicates\n                    an excellent product experience. Consider the sentiment expressed in the text, the\n                          clarity of the title, and how well the product meets the expectations set by the title\n                    and description. Be consistent in your rating based on these factors.\n                     For each input, analyze the title and text of the review and assign a rating from 1\n                        to 5 based on the sentiment expressed in the review. A rating of 1 indicates a very\n                       negative sentiment, 3 indicates a neutral sentiment, and 5 indicates a very positive\n                       sentiment. Provide the rating as an output.\n\n                    Analyze the provided input-title and text, then assign a rating from 1 to 5\n                     based on the overall quality and satisfaction expressed in the content, where 1\n    Pet\n                         indicates very poor satisfaction, 3 indicates average satisfaction, and 5 indicates very\n                      high satisfaction.\n\n                    Given a title and text review of a product, assign a rating from 1 to 5 based\n                   on the sentiment expressed in the review, where 1 indicates a negative sentiment, 5\n                         indicates a very positive sentiment, and ratings in between reflect varying degrees of\n                           positivity.\n                    Given a product review that includes a title and text, rate the overall satisfaction\n                       of the review on a scale from 1 to 5, where 1 indicates very low satisfaction and 5\n                         indicates very high satisfaction. Provide a rating based on the clarity, positivity, and\n                         specifics of the feedback presented in the review.\n\n                      Evaluate the provided product reviews and assign a rating from 1 to 5 based on the\n                        overall sentiment expressed in the review, where 1 indicates a negative experience\n    Sports\n                    and 5 indicates a highly positive experience. Provide ratings that accurately reflect\n                        the review content.\n\n                   Based on the given title and text, evaluate the overall sentiment and quality\n                      expressed in the reviews. Assign a rating from 1 to 5, where 1 indicates a very\n                       negative experience, and 5 indicates a very positive experience. Consider factors\n                      such as product performance, satisfaction level, and any issues mentioned in the text.\n\n\n\n\n\n                                       20\n\nTable 12: User Prompts for Unseen Generalization Experiments, where we sample three among\nten for each task.\n\n    Target Tasks     User Prompts\n\n                      Provide the total count of specific categories of objects, fruits, musical instruments,\n                       animals, or vegetables listed in the given input question.\n\n    Object          Count the total number of objects or items listed in each question provided.\n   Counting\n                   Count the  total number of distinct items based on the provided categories\n                    and specified quantities. Return the total as the output.\n                         Identify the relation between the following premises and hypotheses, choosing from\n                        the options ‘entailment’ or ‘non-entailment’.\n\n                     For the given premises and hypotheses,  identify the relation between them\n                   by determining if the hypothesis necessarily follows from the premise. Choose\n    Epistemic         ‘entailment’ if the hypothesis is a direct conclusion of the premise or ‘non-entailment’\n                                if it does not necessarily follow. Provide the relation as your output.\n\n                    Given a premise and a hypothesis, determine whether the hypothesis can be\n                         logically concluded from the premise. Choose from the options ‘entailment’ if the\n                       hypothesis necessarily follows from the premise, or ‘non-entailment’ if it does not.\n                     For each provided input, analyze the arrangement of objects and their colors, then\n                    answer the question based on the specific characteristics and positions of the items\n                      mentioned.\n\n                    Analyze the arrangement of colored items in each scenario and answer the\n   Reasoning        questions by counting, identifying colors, or evaluating the presence of specific\n   Colored          items based on the provided inputs.\n    Objects\n                      Please answer the following questions based on the descriptions of items\n                    and their attributes provided.  Provide clear and accurate outputs based on the\n                       information given in the inputs.\n                   Based on the dialogue snippets provided, please identify whether the Assistant’s\n                       response to the Human’s queries promotes harmful, illegal, or disrespectful behavior.\n                   Respond with ‘yes’ if the Assistant’s answer promotes such behavior, and ‘no’ if it\n                     does not.\n\n                    Analyze the following input-output pairs and classify the assistant’s responses as\n                       ‘yes’ or ‘no’ based on whether the assistant’s replies encourage harmful or illegal\n   Anthropic         actions. Provide a brief justification for each classification based on the context of\n   Harmless          the dialogue.\n\n                   Based on the given dialogues, determine whether the  assistant’s responses\n                        are appropriate and responsible in relation to the human’s inquiries. If the assistant\n                      provides a helpful, ethical, or supportive answer, mark the output as ‘yes’. If the\n                          assistant’s response encourages harmful, illegal, or unethical behavior, mark the\n                       output as ‘no’.\n                     Determine whether the given input expresses a negative sentiment towards a group\n                       or concept. Output ‘yes’ if it does; otherwise, output ‘no’.\n\n                    Determine whether  the  input statement expresses  hate speech,  derogatory\n   Ethos             language, or violent sentiments. Respond with ‘yes’ for statements that do and ‘no’\n                         for those that do not.\n\n                    Determine whether the input  text expresses a harmful,  derogatory,  or vio-\n                          lent sentiment. Reply with ‘yes’ if it does, and ‘no’ if it does not.\n\n\n\n\n\n                                       21\n\nTable 12: User Prompts for Unseen Generalization Experiments, where we sample three among\nten for each task.\n\n    Target Tasks     User Prompts\n\n                     Provide a concise and accurate answer to the question based on the given context,\n                      ensuring that the response directly addresses the inquiry.\n\n                    Given a context about a specific topic, provide the name of a related char-\n                           acter, actor, or relevant detail mentioned in the text when prompted with a specific    Natural\n                       question related to that context.    Questions\n\n                    Given a context that includes related information, answer the question that\n                      follows with a specific and concise response based on the details provided in the\n                        context.\n                     Provide a concise answer to the question based on the context provided, ensuring\n                          that the output is relevant and directly related to the question asked.\n\n                    Given a context passage, summarize the key information related to the spe-\n                            cific question asked, providing a clear and concise answer based on the content of\n   Web Questions\n                        the context.\n\n                   Based on the provided  context, answer the question  specifically and suc-\n                        cinctly by extracting the relevant information from the context. If the information\n                      cannot be found, provide a response indicating the absence of that information.\n\n\n\n\n\n                                       22\n\nB  Additional Experimental Results\n\nB.1  Unseen Generalization Results with Standard Deviations\n\nWe report standard deviations of SPRIG and MetaSPO in the Unseen Generalization setup in Table 13.\n\n\nTable 13: Unseen Generalization Results with standard deviations over three different runs.\nBold numbers indicate the statistically significant results based on a t-test (p ≤0.05).\n\n\n       Domain                           Medical                             Review Analysis\n\n       Target Task       Anatomy     Pediatrics     Dental      Surgery     Electronics       Pet          Sport\n\n              Default        36.1         38.9         25.8         32.3         41.3         41.5         29.3\n          CoT          36.1         42.7         26.0         32.0         36.8         40.3         25.0\n   Global    Service        34.4         35.2         20.2         30.6         59.0         53.2         52.2\n          SPRIG     41.6 ± 2.4   42.2 ± 0.5   28.4 ± 1.1   35.7 ± 0.9   47.9 ± 3.5   47.4 ± 2.4   38.6 ± 3.5\n          MetaSPO   45.7 ± 4.7   43.1 ± 2.4   31.1 ± 3.5   36.3 ± 3.8   67.2 ± 2.1   66.0 ± 0.8    61.4 ± 1.9\n\n          SPRIG     41.2 ± 2.2   41.8 ± 1.5   29.6 ± 1.4   35.3 ± 1.1   61.6 ± 0.9   57.4 ± 0.6   51.3 ± 2.2\n  Domain\n          MetaSPO   48.9 ± 2.0   46.7 ± 3.6   36.4 ± 3.7   40.0 ± 1.6   61.8 ± 0.6   64.9 ± 2.5    61.5 ± 1.8\n\n       Domain                    Reasoning                        Safety                Grounding\n\n       Target Task         Count      Epistemic   Color Obj.   A.harmless     Ethos        N.Q.     WebQA\n\n              Default        43.5         28.3         56.6         21.2         28.7         15.1         11.6\n          CoT          45.6         37.2         62.0         21.9         31.9         15.9         12.0\n   Global    Service        30.6         37.6         56.6         21.1         26.9         11.4          9.9\n          SPRIG     39.3 ± 1.6   29.9 ± 1.1   59.9 ± 1.9   23.0 ± 1.0   31.1 ± 1.1   14.1 ± 0.9   11.2 ± 0.5\n          MetaSPO   44.5 ± 1.2   39.6 ± 3.9   64.5 ± 1.0   24.9 ± 0.6   37.6 ± 0.7    9.5 ± 0.4     7.7 ± 0.3\n\n          SPRIG     30.1 ± 2.8   34.5 ± 1.4   51.5 ± 3.4   24.0 ± 0.9   32.1 ± 1.7   16.1 ± 0.8   12.0 ± 0.1\n  Domain\n          MetaSPO   47.1 ± 0.7   43.0 ± 0.5   66.6 ± 1.3   29.1 ± 2.8   43.9 ± 0.4   19.1 ± 3.7   13.7 ± 0.06\n\n\n\nB.2  Performance of MetaSPO at Each Iteration\n\n\n\n                               0.42                                                              0.60\n                               0.40                                                              0.55\n                               0.38\n                                                                                                 0.50                                            Metric                                                                                                      Metric\n                               0.36                         MetaSPO                                               MetaSPO\n                              Avg. 0.34                                 DefaultCoT                         Avg. 0.450.40                                 DefaultCoT\n                               0.32                                Service                                                             Service\n                                                        SPRIG                         0.35                          SPRIG                               0.30\n                                 0          1          2          3                         0          1          2          3\n                                         Iteration                                            Iteration\n\n                           (a) Medical                       (b) Review Analysis\n\n\n       0.52                                                      0.36                                                      0.16\n       0.50                                                      0.34                                                      0.15\n       0.48\n                                                                0.32\n                                                                                                                          0.14    Metric 0.46                                                                                                   Metric 0.30                         MetaSPO                Metric                                                                                                                          0.13                         MetaSPO       0.44                         MetaSPO\n                                                                0.28                                 Default   Avg. 0.42                                 DefaultCoT                Avg.                                                                                  CoT                Avg. 0.12                                 DefaultCoT\n                                           Service                0.26                                Service                                                    Service\n       0.40                                   SPRIG                                           SPRIG                0.11                          SPRIG                                                                0.24\n            0          1          2          3                 0          1          2          3                 0          1          2          3\n                     Iteration                                     Iteration                                     Iteration\n\n          (c) Reasoning                      (d) Safety                       (e) Grounding\n\n        Figure 10: Unseen Generalization Performance of MetaSPO for each iteration.\n\n\nWe report the Unseen Generalization performance of the optimized system prompt as a function of\nthe number of iterations for each domain in Figure 10. From this, we observe that the performance\nimproves steadily across iterations, with significant gains observed up to iteration 2, which seems\nsaturated after it, suggesting diminishing returns for further iterations.\n\n\n                                       23\n\nB.3  Comparison of Computational Costs\n\n\nTable 14: Comparison of the number of model requests (or calls) to operationalize optimizer to\nimplement MetaSPO, paraphraser to SPRIG, and base model to both approaches.\n\n\n                                   Optimizer Model Call   Paraphraser Call  Base Model Call\n\n              SPRIG               N/A               300            140k\n              MetaSPO (Ours)          126             N/A             18k\n\nIn Table 14, we compare the computational costs of our system prompt optimization approach against\nSPRIG on four source tasks, based on the number of model requests (or calls) used to operationalize\nthem. Specifically, unlike SPRIG designed to generate a variety of candidate prompts with several\nparaphraser calls and evaluate them (on the training samples) with the base model calls, MetaSPO\nperforms optimization by analyzing the incorrectly predicted examples with the last (few) prompts\nand updating the prompts based on them. As a result, it ultimately yields a far less number of base\nmodel calls, while the resulting optimized prompt can be generalizable to diverse tasks (See Figure 6).\n\nB.4  Relative Performance Gains of MetaSPO over Default with Various User Prompts.\n\n\n\n                                0.6                                                                       0.8\n\n\n\n                                                                                                         0.6\n                                0.4                                                   MetaSPO                                                                                                                                MetaSPO\n              w/                                     w/ 0.4\n                                0.2\n                                                                                                         0.2                                           Metric                                                                                                              Metric\n                          Win Rate : 83.3%\n                                0.0                                                                                                         0.0        Win Rate : 91.1%\n                                    0.0           0.2           0.4           0.6                               0.0       0.2       0.4       0.6       0.8\n                               Metric w/ Default                                   Metric w/ Default\n\n                         (a) Medical                          (b) Review Analysis\n\n\n\n\n                                                                                                                                 0.2                                                                    0.4\n                                                                                                                                                                                                                                   MetaSPO      MetaSPO 0.60.4                                                                                                 MetaSPO\n  w/                             w/                             w/\n                                                                    0.2\n\n        0.2     Metric                                                                                        Metric                                                                                        Metric\n              Win Rate : 85.6%                0.0        Win Rate : 98.3%                0.0         Win Rate : 65.0%        0.0\n            0.0       0.2       0.4       0.6                           0.0            0.2            0.4                              0.0                         0.2\n              Metric w/ Default                         Metric w/ Default                         Metric w/ Default\n\n          (c) Reasoning                      (d) Safety                       (e) Grounding\n\n\nFigure 11: Performance of various user prompts with the system prompt from Default (x) and\nMetaSPO (y) for each domain. Points above y = x indicate the superiority of MetaSPO.\n\nWe provide a detailed visualization of user prompts for each domain to illustrate the performance\nimprovements achieved by MetaSPO over the Default system prompt. The visualization reflects the\nperformance of various user prompts across the Medical, Review Analysis, Reasoning, Safety, and\nGrounding domains. Also, the size of each point represents the density of overlapping prompts with\nsimilar performance scores. Then, as shown in Figure 11, in the Medical domain, 83.3% of user\nprompts perform better with MetaSPO. Also, Review Analysis, Reasoning, Safety, and Grounding\ndomains achieve success rates of 91.1%, 85.6%, 98.3%, and 65.0%, respectively. This highlights the\nconsistent effectiveness of MetaSPO across diverse user prompts and domains.\n\n\n\n\n\n                                       24\n\nB.5  Analysis of Source-Target Task Similarity with Embedding-Level Cosine Similarity\n\n\n                                Pearson Correlation 0.29           Spo.\n                                100\n                          (%)\n                                 80\n                                 60 Epi.                Eth.      Pet      Ele.\n                                                                   Den.                                 40      A.H.                   Ana.\n                                                N.Q.                      Sur.                                                              Ped.  Web                                                                                                 Improvement 20                    Col.\n                                             Cou.\n\n                                                 0.3      0.4      0.5      0.6      0.7      0.8\n                                  Avg. Source-Target Similarity\n                                     (Embedding Cosine Similarity)\n\nFigure 12: Relative improvements of MetaSPO against Default as a function of the similarity\nbetween source and target tasks, where the similarity is measured by the embedding-level cosine\nsimilarity from Song et al. [33].\n\nAs an extension to the results in Figure 4, which uses Bag-of-Words rank correlation to measure\nthe lexical similarity between source and target tasks, we further conduct an additional analysis,\nmeasuring the semantic similarity between them. Specifically, we encode examples for each task\nusing MPNet [33], average their embeddings to obtain a representative vector for each task, and then\ncompute the cosine similarity between vectors across tasks. The results presented in Figure 12 show\na positive correlation between source-target similarity and improvement, with a Pearson correlation\ncoefficient of 0.29. This result further strengthens our hypothesis that the greater similarity between\nsource and target tasks can enhance the impact of the optimized system prompt.\n\nB.6  Results with Different Optimizer LLMs\n\n\nTable 15: Results of MetaSPO with varying optimization models, where the base model for answer\ngeneration is fixed to Llama 3.2 (3B). Default and SPRIG are included as baselines for comparison.\n\n\n                  Methods   Optimizer LLMs  Review.  Reasoning  Avg.\n\n                      Default      -                    37.4       42.8      40.1\n                 SPRIG       -                    56.8       38.7      47.7\n                 MetaSPO  Llama 3.1 (8B)       59.9       45.7      52.8\n                 MetaSPO  Llama 3.1 (70B)      64.2       47.9      56.1\n                 MetaSPO  GPT-4o mini         62.7       52.2      57.5\n                 MetaSPO  GPT-4o              63.7       53.2      58.4\n\n\nTo assess the robustness of MetaSPO across different optimizer LLMs, we fix the base model (for\nanswer generation) to Llama3.2 (3B) and conduct experiments by varying the LLMs for prompt\noptimization. The experiments are performed on Review Analysis and Reasoning domains, and\nresults are averaged over each domain. As shown in Table 15, MetaSPO consistently outperforms\nbaselines regardless of the choice of optimizer LLMs. Also, when using larger optimizer models,\nsuch as GPT-4o, MetaSPO demonstrates strong performance, suggesting its potential to achieve even\nbetter results when combined with more advanced LLMs.\n\n\n\n\n\n                                       25\n\nB.7  Additional Results of MetaSPO on Out-of-Domain Scenario\n\n\n                              0.5\n\n                              0.4                                                                                         Reasoning\n                    on 0.3\n\n                              0.2                                                           Metric\n                                        Avg. 0.1         DefaultCoT           ProTeGiSPRIG\n                                                 Service       MetaSPO\n                              0.0\n                                       Medical    Review.     Safety   Reasoning\n                                            Source Domain\n\nFigure 13: Performance of different prompt optimization methods on the Reasoning domain\nusing prompts trained on different source domains.\n\n\nWe compare MetaSPO with ProTeGi (a user prompt optimization method specific to the target task)\nin a challenging cross-domain scenario. In this setting, prompts are optimized on a source domain\nand evaluated on the unseen Reasoning domain without any further adaptation. As Figure 13 shows,\nMetaSPO consistently outperforms other methods (including ProTeGi) across various source domains,\ndemonstrating superior robustness and generalization capabilities. Notably, both ProTeGi and SPRIG\nexhibit limited performance, performing worse than the Default system prompt even in the case\nwhere the source and target domains are identical. This indicates that they optimize the prompts that\nare tailored to specific tasks and struggle to transfer beyond their training tasks. In contrast, MetaSPO\neffectively optimizes the system prompts with strong cross-domain and cross-task generalization.\n\nB.8  Effect of Scaling the Number of Source Tasks\n\n\n\n                                   0.64\n\n                                   0.62\n\n                                   0.60                                                   Metric\n                                  Avg. 0.58                                   0.56\n\n                                   0.54                                Review Analysis\n\n                                     1 2 3 4 5 6   8       12      16      20\n                            Number of Source Tasks\n\nFigure 14: Results with varying the number of source tasks for system prompt optimization on\nMetaSPO, in the range of 1 to 20.\n\nTo extend the experiment described in Figure 7, we increase the number of source tasks to 20.\nAs shown in Figure 14, while MetaSPO benefits from an increasing number of source tasks, its\nperformance saturates after utilizing six. This suggests that once MetaSPO has sufficiently learned\nthe context and characteristics of the source domains, adding more tasks offers no additional benefit.\n\n\n\n\n\n                                       26\n\nB.9  Combined Optimization Method in MetaSPO\n\nTable 16: Results with different combinations of prompt optimization techniques in MetaSPO.\n\n                Optimization Methods            Domains\n\n              System     User     Medical   Review.   Reasoning   Avg.\n\n            APE     APE        39.7       60.1        48.0      49.3\n            APE     ProTeGi      40.2       58.9        48.9      49.3\n              ProTeGi    APE        41.0       62.5        53.3      52.3\n              ProTeGi    ProTeGi      43.0       62.7        52.2      52.6\n\n\nTo demonstrate the versatility of MetaSPO, we further conduct additional experiments using different\noptimization methods for the system and user prompts. The results in Table 16 show that it remains\nrobust across all combinations, while achieving the best performance when using the most effective\nprompt optimization method (ProTeGi) for both the system and user prompts.\n\nB.10  Effect of Varying the Number of Wrong Examples on System Prompt Optimization\n\n\n\n       0.44\n                                                                             0.60\n       0.42\n       0.40                                                                  0.55\n       0.38                                                                  0.50     Metric                                                                                                            Metric\n       0.36                                 MetaSPO                0.45                                 MetaSPO                                                       Default                                                                  Default   Avg. 0.34                                  CoT                  Avg. 0.40                                  CoT\n       0.32                                          Service                                                                 Service\n                                            SPRIG                   0.35                                   SPRIG       0.30\n            1            2            3            4                    1            2            3            4\n           Number of Wrong Examples                   Number of Wrong Examples\n\n                    (a) Medical                                    (b) Review Analysis\n\nFigure 15: Result with varying the number of wrong examples for system prompt optimization.\n\nTo analyze how the number of incorrect examples affects system prompt optimization, we conduct an\nexperiment by varying the number of examples and report the results in Figure 15. For the Medical\ndomain, a single example is enough, but for the Review Analysis domain, two examples per task are\nnecessary to significantly improve the system prompt, probably due to subjective expressions within\nit that require multiple cases to analyze failures.\n\nB.11  Analysis of Concise System Prompt\n\n                    Table 17: Result of short and concise system prompt.\n\n                                 Medical  Review.  Reasoning  Safety  Grounding  Avg.\n\n                  Default              33.3      37.4       42.8      25.0       13.4      30.3\n                MetaSPO-Concise    37.9      56.8       50.8      30.4       12.8      37.7\n               MetaSPO-Base       43.0      62.7       52.2      36.5       16.4      42.2\n\nTo investigate whether summarized system prompts can serve as effective alternatives, we conduct\nexperiments with more concise system prompts (summarized from the optimized system prompts\nwith GPT-4o-mini), and report their performance in Table 17. From this, we observe a trade-off\nbetween brevity and performance: the more detailed system prompts consistently achieve better\nperformance, suggesting that detailed guidance in the prompt allows the model to respond accurately.\n\n\n\n\n\n                                       27\n\nC  Qualitative Results\n\nC.1  Optimized System Prompts\n\nWe provide the optimized system prompts by MetaSPO for each domain in Table 18, including the\nGlobal setting.\n\n           Table 18: Optimized system prompts for each domain and the global setting.\n\n Domains        Optimized System Prompts\n\n                You are a knowledgeable and analytical assistant specializing in medical topics. Your task is to\n                     accurately respond to medical inquiries by utilizing established medical knowledge, guidelines,\n                  and evidence-based reasoning. When presented with a question, carefully analyze the options\n Medical\n                    provided and select the most appropriate answer. Ensure that your responses are clear, concise,\n                  and well-structured, including a rationale that explains your reasoning and cites relevant medical\n                       principles. Prioritize accuracy and logical coherence in all your responses.\n                You are a versatile language model tasked with analyzing customer reviews to accurately\n                     predict product ratings based on the emotional tone and sentiments expressed. Follow these\n                     guidelines for effective evaluation:\n\n                      1.   Identify Emotional Indicators:  Focus on strong emotional expressions within the\n                     reviews, such as phrases indicating clear satisfaction (“I love it”) and dissatisfaction (“terrible\n                     experience”).  Emphasize these surface-level sentiments as they are essential for quick\n                    assessment.\n\n                       2.  Assess Overall Sentiment: When reviews present mixed sentiments, evaluate the\n                       overall emotion conveyed. Determine whether positive sentiments dominate over negative ones,\n                  and give more weight to dominant sentiments unless significant negative factors are expressed.\n                   Small complaints should generally not overshadow strong positive emotions.\n\n                       3.  Understand Context: Consider the context in which a review is written.  Recognize\n                       that certain statements may have varying implications based on the product’s purpose and the\n                     reviewer’s expectations. Adapt your weighting of sentiments accordingly.\n\n Review\n                       4.   Utilize the Rating Scale:  Assign ratings on a scale from 1 to 5 based on overall\n  Analysis\n                     sentiment:\n                          - 5: Exceptional experience with strong positive sentiments.\n                          - 4: Generally positive with minor negative mentions.\n                          - 3: Neutral with a balance of positive and negative sentiments.\n                          - 2: Predominantly negative experiences with some redeeming qualities.\n                          - 1: Very poor experience with overwhelmingly negative sentiments.\n\n                       5.      Output  Format:     Present  your   predicted   rating   clearly   as   follows:\n                 <answer>{rating}</answer>.  This will maintain consistency and clarity in your re-\n                     sponses.\n\n                       6.  Provide Rationale: When offering predictions, include a brief explanation of how\n                 you arrived at the rating. This will help clarify your reasoning and enhance the trust in your\n                    assessment.\n\n               By following these structured guidelines, you will generate more accurate and contex-\n                       tually relevant predictions that reflect customer satisfaction and experiences.\n                You are a logical reasoning assistant. Your primary objective is to analyze and process in-\n                   formation critically. Focus on understanding the context of events and the implications of\n                     sequential developments while engaging in deductive reasoning. Always strive to provide\n Reasoning\n                      clear and well-structured answers, ensuring that responses are appropriately formatted and\n                     include necessary tags. When faced with complex inquiries, meticulously evaluate relationships\n                  between facts and provide comprehensive, logical conclusions based on the clues provided.\n\n\n\n\n\n                                       28\n\nTable 18: Optimized system prompts for each domain and the global setting.\n\nDomains        Optimized System Prompts\n\n              You are an analytical assistant. Your task is to evaluate statements, questions, and objections\n                  based on contextual understanding, evidence, and relevant criteria. When providing responses,\n                   please adhere to the following guidelines:\n\n                     1.  Factual Accuracy:  Assess the factual correctness and relevance of the statement in\n                    question. Provide context where necessary.\n\n                     2.  Opinion vs.   Fact:  Clearly differentiate between opinion-based claims and factual\n                     assertions. Explain why a statement is considered an opinion or a fact.\n\n                     3.  Emotional Tone Recognition:  Identify and analyze emotional tones, especially in\nSafety            cases involving sarcasm, hate speech, or any emotionally charged language.  Discuss the\n                   implications of tone in your assessment.\n\n                     4.  Balanced Perspective: Explore multiple sides of an argument when applicable.  Of-\n                      fer a well-rounded analysis that considers contrasting viewpoints and broader implications.\n\n                     5.  Clarity and Structure:  Format your final answer using <answer>yes</answer> or\n               <answer>no</answer>, followed by a comprehensive explanation that includes reasoning,\n                   evidence, and relevant context.\n\n             By applying these guidelines, you will provide contextually aware, nuanced, and accu-\n                     rate evaluations in your responses.\n              You are an advanced assistant designed to deliver direct and concise answers tailored to user\n                     inquiries. Focus on providing specific information that directly addresses the question, using\n                keywords or short phrases as your primary response format. Limit additional explanations\nGrounding\n                    to cases where further clarification is explicitly requested. Prioritize accuracy and relevance,\n                   ensuring that your answers are strongly aligned with the context provided. Aim for minimalism\n                    in responses while maintaining clarity and precision.\n              You are an advanced virtual assistant designed to process and analyze information across a\n                 broad range of topics. Your main objectives are to:\n\n                     1.  Analyze Information Critically:  Assess the provided data, considering various per-\n                    spectives and implications. Use logical reasoning to derive conclusions and make connections\n                 between concepts.\n\n                     2.  Handle Different Types of Queries: Be prepared to respond to factual questions,\n                 perform sentiment analysis, and engage in logical deductions. Understand the nuances of each\n                 query type and apply appropriate reasoning.\n\n                     3.  Evaluate Sentiment and Emotional Tone: When dealing with reviews or sentiments,\nGlobal            accurately reflect the emotional tone—consider both positive and negative elements—and\n                  provide a clear overall assessment.\n\n                     4.  Provide Clear and Structured Responses:  Organize your answers in a coherent for-\n                   mat, making it easy for users to understand your reasoning and conclusions. Aim for clarity and\n                    precision in your communication.\n\n                     5.  Adapt to Context:  Adjust your analysis based on the specific context and details\n                  given in each inquiry. Pay attention to nuances and subtleties that may affect the outcome of\n                 your assessment.\n\n             By following these guidelines, you will better serve as a helpful  assistant, enabling\n                   users to receive accurate, relevant, and thoughtful responses to their diverse queries.\n\n\n\n\n\n                                      29\n\nC.2  Example of Failure Analysis and Prompt Generation in MetaSPO\n\nWe provide an example of failure analysis and prompt generation based on the analyzed problem\nwithin the reasoning domain, as shown in Figure 16 and Figure 17, respectively.\n\n\n                                             Failure Analysis Prompt\n\n    You are a system prompt writer tasked with improving a language model’s system prompt for general tasks.\n    Your goal is to analyze why the current system prompt fails to respond correctly in the given examples.\n     Follow these instructions carefully:\n\n    ### Review the current system prompt:\n    You are a helpful assistant.\n\n    ### Wrong responses:\n\n                                    Wrong Example\n\n    System prompt : You are a helpful assistant.\n\n    User prompt : A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of\n     swaps.\n     <Question> Alice, Bob, Claire, Dave, and Eve are playing a game. At the start of the game, they are each holding a ball:\n     Alice has a yellow ball, Bob has a blue ball, Claire has a pink ball, Dave has a white ball, and Eve has a red ball.\n    As the game progresses, pairs of players trade balls. First, Claire and Alice swap balls. Then, Eve and Bob swap balls. Then, Bob and Dave swap\n      balls. Then, Claire and Eve swap balls. Finally, Alice and Dave swap balls. At the end of the game, Alice has the Select the correct option: A.\n     yellow ball. B. blue ball. C. pink ball. D. white ball. E. red ball.\n     </Question> At the end show the answer option bracketed between <answer> and </answer>.\n\n    Response : To determine the final position of Alice's ball, let's analyze the sequence of swaps:\n       Initially, Alice has a yellow ball.\n     Claire and Alice swap balls: Alice now has a pink ball, and Claire has a yellow ball.\n    Eve and Bob swap balls: Eve now has a blue ball, and Bob has a red ball.\n    Bob and Dave swap balls: Bob now has a white ball, and Dave has a blue ball.\n     Claire and Eve swap balls: Claire now has a blue ball, and Eve has a pink ball.\n     Alice and Dave swap balls: Alice now has a blue ball, and Dave has a yellow ball.\n     Therefore, at the end of the game, Alice has a blue ball.\n    <answer>B</answer>\n\n     Prediction : B\n    The correct label is : E\n\n                                    Wrong Example\n\n\n\n\n                                    Wrong Example\n\n    ### Remember to focus solely on discussing and improving the system prompt.\n\n    ### Wrap the analysis of the system prompt in the <Analysis></Analysis> tags.\n\n                                         Analyzed Problem\n\n    The current system prompt, \"You are a helpful assistant.\" is too vague and lacks specificity about the types of tasks or reasoning required. This\n     broad approach may lead to issues in more complex analytical tasks, as shown in the provided examples. Here’s why it's failing:\n\n      1. Clarity and Specificity: The tasks presented often require multi-step reasoning and explicit tracking of information, and the current prompt does\n     not guide the model to employ these specific reasoning strategies. By not specifying that it should follow logical reasoning paths, avoid assumptions,\n     and check contradictory statements, the model can easily make errors in its logic.\n\n      2. Task-Specific Guidance: Each example requires deducing information from clues or statements. The system prompt does not provide any\n     indication of needing to construct logical connections between pieces of information, leading to incorrect conclusions. It could explicitly instruct the\n    model to analyze, deduce, and arrange information based on given constraints.\n\n      3. Focus Areas for Improvement:\n         - The prompt should indicate that the assistant needs to analyze relationships between provided information in a structured way.\n         - It could mention the importance of checking for contradictions and confirming the sequence/order based on the clues.\n         - The prompt should encourage detailed step-by-step reasoning to ensure that any given logical deductions are accurately followed.\n\n      4. Example Contextualization: By including context on handling different types of tasks, such as logical deduction, ordering, and item categorization\n     based on criteria, the model can be better guided to produce more accurate responses.\n\n\n            Figure 16: Example of failure analysis prompt and analyzed problem.\n\n\n\n\n\n                                       30\n\nPrompt Generation Prompt\n\nYou are a system prompt writer tasked with improving a language model’s system prompt.\nYour goal is to write a better system prompt that can be generalized for various tasks.\nFollow these instructions carefully:\n\n### Review the current system prompt:\nYou are a helpful assistant.\n\n### Analysis of the current system prompt:\n                                     Analyzed Problem\n\n  The current system prompt, \"You are a helpful assistant.\" is too vague and lacks specificity about the types of tasks or reasoning required. This\n   broad approach may lead to issues in more complex analytical tasks, as shown in the provided examples. Here’s why it's failing\n    (...)\n\n### Based on the information provided, write an improved system prompt.\n\n### The new system prompt should be wrapped with <improved_system_prompt></improved_system_prompt> tags\n\n                                 Improved System Prompt\n\nYou are a logical reasoning assistant. Your role is to analyze, deduce, and organize information based on provided clues and context. For each task,\nfollow these guidelines:\n\n1. Step-by-Step Analysis: Break down the information into manageable parts. Carefully evaluate each statement or clue in relation to others to\nidentify relationships and implications.\n\n2. Logical Deductions: Apply logical reasoning to make inferences and draw conclusions. Ensure that your conclusions are based solely on the\ninformation given and avoid making unverified assumptions.\n\n3. Check for Contradictions: Continuously verify the consistency of the information. If contradictions arise, address them by reevaluating the clues\nand clarifying any misunderstandings.\n\n4. Present Clear Conclusions: After your analysis, summarize your findings and explicitly state your conclusions. Ensure that your reasoning is\ntransparent and supported by the information provided.\n\nThis approach will enhance your ability to solve complex problems efficiently and accurately across various tasks.\n\n\n    Figure 17: Example of prompt generation prompt and improved system prompt.\n\n\n\n\n\n                                    31",
"headers": [
"arXiv:2505.09666v2  [cs.CL]  10 Oct 2025",
"System Prompt Optimization with Meta-Learning",
"Appendix",
"1",
"Abstract",
"Introduction",
"2",
"Related Work",
"3",
"Methodology",
"4",
"Experiments",
"5",
"Conclusion",
"Limitation and Societal Impacts",
"Acknowledgements",
"References",
"A",
"Additional Experimental Details",
"B",
"Additional Experimental Results",
"C",
"Qualitative Results"
],
"tables": [
"|(A) Prompt Input in LLM<br>Task-Agnostic System Prompt:<br>You are a helpful assistant.<br>Task-Specific User Prompt:<br>Count the objects in a given sentence.<br>Example:<br>I have a clarinet, a violin, and a flute.<br>Response:<br>There are 3 objects.|(B) Task-Specific Optimization (C) Bilevel System Prompt Optimization (Ours)<br>Source Task Reasoning Source Tasks Reasoning Grounding Safety<br>Task-Specific Optimization Meta-Learning Framework<br>Task-Specific Optimization Meta-Knowledge<br>System Prompt System Prompt<br>System Prompt System Prompt<br>User Prompt UO sep rt i Pm ri oz med pt User Prompt UO sep rt i Pm ri oz med pt SysO tp et mim Piz roed mpt<br>Target Tasks Target Tasks<br>Optimized Optimized<br>Reasoning Reasoning<br>User Prompt System Prompt<br>Medical Medical<br>Target Task Generalizable<br>Review Review<br>Only Analysis To Unseen Tasks Analysis|\n|---|---|",
"|Reasoning|Col2|Grounding|Col4|\n|---|---|---|---|",
"|(A) Inner Loop: User Prompt Optimization<br>Medical<br>Reasoning|Col2|Col3|Col4|Col5|Safety|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Examples:** …<br>Correct<br>Examples<br>Wrong<br>Examples<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Wrong Examples**<br>Analyzed Problem<br>**User Prompt:**<br>Solve logic grid puzzles.<br>**System Prompt:** …<br>**Analyzed Problem**<br>#1 User<br>Prompt<br>#2 User<br>Prompt<br>**#1 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**#2 User Prompt**<br>**System Prompt:** …<br>**Examples:** …<br>**Optimized User Prompt:**<br> To solve a logic grid puzzle, follow these steps:<br>   1. Understand the Structure: …<br>   2. Read Each Clue Carefully: …<br>   3. Visualize the Puzzle: …<br>**(A.1) Candidate User Prompt Generation**<br>**(A.2) Generated User Prompt Evaluation**<br>**Answer Prediction**<br>**Failure Analysis**<br>**Prompt Generation**<br>**Prompt Evaluation**<br>**Prompt Selection**<br>|\n|**Optimized System Prompt:**<br> You are an advanced virtual assistant<br> designed to process and analyze information.<br> Your main objectives are to:<br>   1. Analyze Information Critically: …<br>   2. Handle Different Types of Queries …|**System Prompt:**<br>You are a helpful assistant.<br>**Analyzed Problem**<br>#1 System<br>Prompt<br>#2 System<br>Prompt<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>**U…**<br>**E…**<br>**#1 System Prompt**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>**U…**<br>**E…**<br>**#1 System Prompt**|**System Prompt:**<br>You are a helpful assistant.|**System Prompt:**<br>You are a helpful assistant.<br>**Wrong Examples**<br>**w/ User Prompts**|**U…**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>Medical<br>**System Prompt:**<br>You are a helpful assistant.<br>**E…**<br>Safety<br>Reasoning|**U…**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>Medical<br>**System Prompt:**<br>You are a helpful assistant.<br>**E…**<br>Safety<br>Reasoning|**U…**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>Medical<br>**System Prompt:**<br>You are a helpful assistant.<br>**E…**<br>Safety<br>Reasoning|**U…**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>Medical<br>**System Prompt:**<br>You are a helpful assistant.<br>**E…**<br>Safety<br>Reasoning|**U…**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>Medical<br>**System Prompt:**<br>You are a helpful assistant.<br>**E…**<br>Safety<br>Reasoning|\n|**Optimized System Prompt:**<br> You are an advanced virtual assistant<br> designed to process and analyze information.<br> Your main objectives are to:<br>   1. Analyze Information Critically: …<br>   2. Handle Different Types of Queries …|**System Prompt:**<br>You are a helpful assistant.<br>**Analyzed Problem**<br>#1 System<br>Prompt<br>#2 System<br>Prompt<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>**U…**<br>**E…**<br>**#1 System Prompt**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>**U…**<br>**E…**<br>**#1 System Prompt**|**System Prompt:**<br>You are a helpful assistant.|**System Prompt:**<br>You are a helpful assistant.<br>**Wrong Examples**<br>**w/ User Prompts**|**U…**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>Medical<br>**System Prompt:**<br>You are a helpful assistant.<br>**E…**<br>Safety<br>Reasoning|**U…**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>Medical<br>**System Prompt:**<br>You are a helpful assistant.<br>**E…**<br>Safety<br>Reasoning|<br>**U…**<br>**E…**<br>Medical|**U…**<br><br>**E…**<br>Safety|**U…**<br><br>**E…**<br>Safety|\n|**Optimized System Prompt:**<br> You are an advanced virtual assistant<br> designed to process and analyze information.<br> Your main objectives are to:<br>   1. Analyze Information Critically: …<br>   2. Handle Different Types of Queries …|**System Prompt:**<br>You are a helpful assistant.<br>**Analyzed Problem**<br>#1 System<br>Prompt<br>#2 System<br>Prompt<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>**U…**<br>**E…**<br>**#1 System Prompt**<br>**User Prompt:** …<br>**Examples:** …<br>**U…**<br>**E…**<br>**U…**<br>**E…**<br>**#1 System Prompt**|**System Prompt:**<br>You are a helpful assistant.|Analyzed Problem|Wrong<br>Examples<br>|Wrong<br>Examples<br>|Correct<br>Examples<br><br>|Correct<br>Examples<br><br>|Correct<br>Examples<br><br>|\n|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|**Prompt Selection**<br>**Prompt Evaluation**<br>**Prompt Generation**<br>**Failure Analysis**<br>**Answer Prediction**<br><br>|\n|**1**<br>**(B) Outer Loop: System Prompt Optimization**|**1**<br>**(B) Outer Loop: System Prompt Optimization**|**1**<br>**(B) Outer Loop: System Prompt Optimization**|**1**<br>**(B) Outer Loop: System Prompt Optimization**|**1**<br>**(B) Outer Loop: System Prompt Optimization**|**1**<br>**(B) Outer Loop: System Prompt Optimization**|**1**<br>**(B) Outer Loop: System Prompt Optimization**|**1**<br>**(B) Outer Loop: System Prompt Optimization**|**1**<br>**(B) Outer Loop: System Prompt Optimization**|",
"|#1 System Prompt<br>User Prompt: …<br>Examples: …|U…<br>E…|U…<br>E…|\n|---|---|---|",
"|MetaSPO<br>0.6<br>0.4 w/<br>etric<br>0.2|Col2|Col3|Col4|\n|---|---|---|---|",
"|100 P<br>80<br>60 E<br>40<br>20|earson Corr.<br>pi. Eth.<br>A.H.Den.<br>Ped. Ana C. ol. S<br>Web|0.56 Spo.<br>Pet<br>Ele.<br>urN..Q.|0.6<br>0.5 Similarity<br>0.4<br>0.3<br>0.2|\n|---|---|---|---|",
"|0.18 0.22<br>0.6<br>0.5 Metric<br>0.4<br>0.3 Avg.<br>0.2|0.7<br>0.12 0.29<br>0.1<br>0.46<br>0.44<br>0.42<br>0.40|\n|---|---|",
"|0.70 Metric<br>0.65 Avg.<br>0.60<br>0|Col2|Col3|Col4|Col5|Col6|Col7|Col8|\n|---|---|---|---|---|---|---|---|\n|0<br>0.60<br>0.65<br>0.70<br>Avg. Metric||||||||",
"|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|||~~Me~~<br>Def|~~taSPO~~<br>ault||\n||||||\n||50<br>100<br>150<br>200<br>|50<br>100<br>150<br>200<br>|50<br>100<br>150<br>200<br>|50<br>100<br>150<br>200<br>|",
"|Default 45.1 68.9 64.0 59.9 17.5<br>SPRIG 45.4 69.3 65.3 64.7 17.7<br>MetaSPO 45.6 71.4 67.3 67.2 19.9|51.1|\n|---|---|\n|Default<br>45.1<br>68.9 64.0 59.9 17.5<br>SPRIG<br>45.4<br>69.3 65.3 64.7 17.7<br>MetaSPO<br>**45.6**<br>**71.4 67.3 67.2 19.9**|52.5|\n|Default<br>45.1<br>68.9 64.0 59.9 17.5<br>SPRIG<br>45.4<br>69.3 65.3 64.7 17.7<br>MetaSPO<br>**45.6**<br>**71.4 67.3 67.2 19.9**|**    54.3**|",
"|Default 33.3 37.4 42.8 25.0 13.4<br>SPRIG 37.0 56.8 38.7 28.1 14.1<br>Outer Loop 36.8 58.1 48.8 32.4 14.8<br>MetaSPO w/ APE 39.8 60.1 48.1 30.4 16.2<br>MetaSPO w/ EVO 41.6 60.0 50.2 33.2 16.0<br>MetaSPO 43.0 62.7 52.2 36.5 16.4|30.3|\n|---|---|\n|Default<br>33.3<br>37.4<br>42.8<br>25.0<br>13.4<br>SPRIG<br>37.0<br>56.8<br>38.7<br>28.1<br>14.1<br>Outer Loop<br>36.8<br>58.1<br>48.8<br>32.4<br>14.8<br>MetaSPO w/ APE<br>39.8<br>60.1<br>48.1<br>30.4<br>16.2<br>MetaSPO w/ EVO<br>41.6<br>60.0<br>50.2<br>33.2<br>16.0<br>MetaSPO<br>**43.0**<br>**62.7**<br>**52.2**<br>**36.5**<br>**16.4**|35.9|\n|Default<br>33.3<br>37.4<br>42.8<br>25.0<br>13.4<br>SPRIG<br>37.0<br>56.8<br>38.7<br>28.1<br>14.1<br>Outer Loop<br>36.8<br>58.1<br>48.8<br>32.4<br>14.8<br>MetaSPO w/ APE<br>39.8<br>60.1<br>48.1<br>30.4<br>16.2<br>MetaSPO w/ EVO<br>41.6<br>60.0<br>50.2<br>33.2<br>16.0<br>MetaSPO<br>**43.0**<br>**62.7**<br>**52.2**<br>**36.5**<br>**16.4**|38.2|\n|Default<br>33.3<br>37.4<br>42.8<br>25.0<br>13.4<br>SPRIG<br>37.0<br>56.8<br>38.7<br>28.1<br>14.1<br>Outer Loop<br>36.8<br>58.1<br>48.8<br>32.4<br>14.8<br>MetaSPO w/ APE<br>39.8<br>60.1<br>48.1<br>30.4<br>16.2<br>MetaSPO w/ EVO<br>41.6<br>60.0<br>50.2<br>33.2<br>16.0<br>MetaSPO<br>**43.0**<br>**62.7**<br>**52.2**<br>**36.5**<br>**16.4**|38.9|\n|Default<br>33.3<br>37.4<br>42.8<br>25.0<br>13.4<br>SPRIG<br>37.0<br>56.8<br>38.7<br>28.1<br>14.1<br>Outer Loop<br>36.8<br>58.1<br>48.8<br>32.4<br>14.8<br>MetaSPO w/ APE<br>39.8<br>60.1<br>48.1<br>30.4<br>16.2<br>MetaSPO w/ EVO<br>41.6<br>60.0<br>50.2<br>33.2<br>16.0<br>MetaSPO<br>**43.0**<br>**62.7**<br>**52.2**<br>**36.5**<br>**16.4**|40.2|\n|Default<br>33.3<br>37.4<br>42.8<br>25.0<br>13.4<br>SPRIG<br>37.0<br>56.8<br>38.7<br>28.1<br>14.1<br>Outer Loop<br>36.8<br>58.1<br>48.8<br>32.4<br>14.8<br>MetaSPO w/ APE<br>39.8<br>60.1<br>48.1<br>30.4<br>16.2<br>MetaSPO w/ EVO<br>41.6<br>60.0<br>50.2<br>33.2<br>16.0<br>MetaSPO<br>**43.0**<br>**62.7**<br>**52.2**<br>**36.5**<br>**16.4**|**42.2**|",
"|Col1|Col2|Col3|\n|---|---|---|\n|||~~MetaSPO~~<br>~~Dflt~~|",
"|Col1|Col2|Col3|\n|---|---|---|\n|||MetaSPO<br>Dflt|",
"|Col1|Col2|Col3|MetaSPO<br>Default<br>CoT<br>Service|\n|---|---|---|---|",
"|Col1|Col2|MetaSPO<br>Default<br>CoT<br>Service|\n|---|---|---|",
"|Col1|Col2|MetaSPO<br>Default<br>CoT<br>Service|\n|---|---|---|",
"|0.8<br>MetaSPO<br>0.6<br>0.4 w/<br>Metric<br>0.2<br>Win Rate : 91.1%<br>0.0<br>0.0 0.2 0.4 0.6 0.8<br>Metric w/ Default|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>Metric w/ MetaSPO<br>Win Rate : 91.1%|||||\n|0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>Metric w/ MetaSPO<br>Win Rate : 91.1%|||||\n|0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>Metric w/ MetaSPO<br>Win Rate : 91.1%|||||\n|0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>Metric w/ MetaSPO<br>Win Rate : 91.1%||W|n Rate :|11%|",
"|Col1|Col2|\n|---|---|\n|||\n|n Rate :|83.3%|",
"|MetaSPO<br>0.6<br>0.4<br>w/<br>Metric<br>0.2<br>Win Rate : 85.6%<br>0.0<br>0.0 0.2 0.4 0.6<br>Metric w/ Default|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|0.0<br>0.2<br>0.4<br>0.6<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>0.6<br>Metric w/ MetaSPO<br>Win Rate : 85.6%|||||\n|0.0<br>0.2<br>0.4<br>0.6<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>0.6<br>Metric w/ MetaSPO<br>Win Rate : 85.6%|||||\n|0.0<br>0.2<br>0.4<br>0.6<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>0.6<br>Metric w/ MetaSPO<br>Win Rate : 85.6%|||||",
"|MetaSPO<br>0.4<br>w/<br>0.2 Metric<br>Win Rate : 98.3%<br>0.0<br>0.0 0.2 0.4<br>Metric w/ Default|Col2|Col3|Col4|\n|---|---|---|---|\n|0.0<br>0.2<br>0.4<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>Metric w/ MetaSPO<br>Win Rate : 98.3%||||\n|0.0<br>0.2<br>0.4<br>Metric w/ Default<br>0.0<br>0.2<br>0.4<br>Metric w/ MetaSPO<br>Win Rate : 98.3%|Wi|n Rate|983%|",
"|Analysis|alysis|Col3|\n|---|---|---|\n|0.0<br>0.2<br>Metric w/ Default<br>0.0<br>0.2<br>Win Rate : 65.0%|||\n|0.0<br>0.2<br>Metric w/ Default<br>0.0<br>0.2<br>Win Rate : 65.0%|Win Rate|: 65.0%|",
"|Pearson Cor|relation 0.29|Spo.|\n|---|---|---|\n||.|.|\n|pi.|~~Pet~~<br>~~Eth.~~|Ele.|\n|~~A.H.~~<br>N|~~Ana.~~<br>Pd<br><br>.Q.|Den.<br>Sur.<br>|\n|Co|e.<br>u.<br>~~Col.~~|~~Web~~|",
"|Default - 37.4 42.8<br>SPRIG - 56.8 38.7<br>MetaSPO Llama 3.1 (8B) 59.9 45.7<br>MetaSPO Llama 3.1 (70B) 64.2 47.9<br>MetaSPO GPT-4o mini 62.7 52.2<br>MetaSPO GPT-4o 63.7 53.2|40.1|\n|---|---|\n|Default<br>-<br>37.4<br>42.8<br>SPRIG<br>-<br>56.8<br>38.7<br>MetaSPO<br>Llama 3.1 (8B)<br>59.9<br>45.7<br>MetaSPO<br>Llama 3.1 (70B)<br>**64.2**<br>47.9<br>MetaSPO<br>GPT-4o mini<br>62.7<br>52.2<br>MetaSPO<br>GPT-4o<br>63.7<br>**53.2**|47.7|\n|Default<br>-<br>37.4<br>42.8<br>SPRIG<br>-<br>56.8<br>38.7<br>MetaSPO<br>Llama 3.1 (8B)<br>59.9<br>45.7<br>MetaSPO<br>Llama 3.1 (70B)<br>**64.2**<br>47.9<br>MetaSPO<br>GPT-4o mini<br>62.7<br>52.2<br>MetaSPO<br>GPT-4o<br>63.7<br>**53.2**|52.8|\n|Default<br>-<br>37.4<br>42.8<br>SPRIG<br>-<br>56.8<br>38.7<br>MetaSPO<br>Llama 3.1 (8B)<br>59.9<br>45.7<br>MetaSPO<br>Llama 3.1 (70B)<br>**64.2**<br>47.9<br>MetaSPO<br>GPT-4o mini<br>62.7<br>52.2<br>MetaSPO<br>GPT-4o<br>63.7<br>**53.2**|56.1|\n|Default<br>-<br>37.4<br>42.8<br>SPRIG<br>-<br>56.8<br>38.7<br>MetaSPO<br>Llama 3.1 (8B)<br>59.9<br>45.7<br>MetaSPO<br>Llama 3.1 (70B)<br>**64.2**<br>47.9<br>MetaSPO<br>GPT-4o mini<br>62.7<br>52.2<br>MetaSPO<br>GPT-4o<br>63.7<br>**53.2**|57.5|\n|Default<br>-<br>37.4<br>42.8<br>SPRIG<br>-<br>56.8<br>38.7<br>MetaSPO<br>Llama 3.1 (8B)<br>59.9<br>45.7<br>MetaSPO<br>Llama 3.1 (70B)<br>**64.2**<br>47.9<br>MetaSPO<br>GPT-4o mini<br>62.7<br>52.2<br>MetaSPO<br>GPT-4o<br>63.7<br>**53.2**|**58.4**|",
"|Col1|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n||||||||\n||||||||\n||||||||\n||||||||\n|||Defau|lt|ProTeGi|||\n|||CoT<br>Servic|e|SPRIG<br>MetaSPO|||\n||||||||",
"|Col1|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n||||||||\n||||||||\n||||||||\n||||||||\n||||||||\n||||||~~Revie~~|~~ Analys~~|",
"|APE APE 39.7 60.1 48.0<br>APE ProTeGi 40.2 58.9 48.9<br>ProTeGi APE 41.0 62.5 53.3<br>ProTeGi ProTeGi 43.0 62.7 52.2|49.3|\n|---|---|\n|APE<br>APE<br>39.7<br>60.1<br>48.0<br>APE<br>ProTeGi<br>40.2<br>58.9<br>48.9<br>ProTeGi<br>APE<br>41.0<br>62.5<br>**53.3**<br>ProTeGi<br>ProTeGi<br>**43.0**<br>**62.7**<br>52.2|49.3|\n|APE<br>APE<br>39.7<br>60.1<br>48.0<br>APE<br>ProTeGi<br>40.2<br>58.9<br>48.9<br>ProTeGi<br>APE<br>41.0<br>62.5<br>**53.3**<br>ProTeGi<br>ProTeGi<br>**43.0**<br>**62.7**<br>52.2|52.3|\n|APE<br>APE<br>39.7<br>60.1<br>48.0<br>APE<br>ProTeGi<br>40.2<br>58.9<br>48.9<br>ProTeGi<br>APE<br>41.0<br>62.5<br>**53.3**<br>ProTeGi<br>ProTeGi<br>**43.0**<br>**62.7**<br>52.2|**52.6**|",
"|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n||||||\n||||MetaSP<br>Default<br>~~CoT~~|O|",
"|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n||||||\n||||MetaSP<br>Default<br>CoT|O|",
"|efault 33.3 37.4 42.8 25.0 13.4<br>etaSPO-Concise 37.9 56.8 50.8 30.4 12.8<br>etaSPO-Base 43.0 62.7 52.2 36.5 16.4|30.3<br>37.7<br>42.2|\n|---|---|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2505.09666v2.pdf"
}