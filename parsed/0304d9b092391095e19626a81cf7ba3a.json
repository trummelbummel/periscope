{
"text": "Model Performance-Guided Evaluation Data Selection for Effective Prompt\n                                    Optimization\n\n                    Ximing Dong1, Shaowei Wang2*, Dayi Lin1, Ahmed E. Hassan3\n                                1Centre for Software Excellence, Huawei, Canada\n                               2 Department of Computer Science, University of Manitoba, Canada\n                              3School of Computing, Queen’s University, Canada\n       {ximing.dong,dayi.lin}@huawei.com, shaowei.wang@umanitoba.ca, ahmed@cs.queensu.ca\n\n\n                          Abstract                          utilization (Liu et al., 2023). To avoid the process\n                                                                of manually creating prompts, recent work aims\n                 Optimizing Large Language Model (LLM) per-\n                                                                    to automate the process of generating natural lan-                formance requires well-crafted prompts, but\n               manual prompt engineering is labor-intensive      guage prompts that are also interpretable (Zhou2025                and often ineffective. Automated prompt op-        et al., 2022b; Zhang et al., 2023; Guo et al., 2023;\n                   timization techniques address this challenge      Yang et al., 2024; Zhang et al., 2022; Deng et al.,\n                  but the majority of them rely on randomly se-       2022).Aug            lected evaluation subsets, which fail to rep-                                                                 All the proposed approaches require optimiz-\n                   resent the full dataset, leading to unreliable\n18            evaluations and suboptimal prompts. Existing       ing prompts by evaluating them over an evalua-\n                                                                    tion dataset. However, using the entire training\n                   coreset selection methods, designed for LLM\n                                                                   dataset is impractical and cost-prohibitive (Pac-                 benchmarking, are unsuitable for prompt opti-\n                  mization due to challenges in clustering similar        chiardi et al., 2024; Albalak et al., 2024). Conse-\n                 samples, high data collection costs, and the        quently, most approaches randomly select a small\n                   unavailability of performance data for new or       subset of samples from the entire training data to[cs.CL]             private datasets. To overcome these issues, we       evaluate new prompts (Zhou et al., 2022b; Zhang\n                 propose IPOMP, an Iterative evaluation data                                                                         et al., 2023; Guo et al., 2023; Yang et al., 2024;\n                    selection for effective Prompt Optimization us-\n                                                             Pryzant et al., 2023). However, random selection\n                  ing real-time Model Performance. IPOMP is\n                                                                   often fails to produce representative samples of the                 a two-stage approach that selects representa-\n                                                                         entire training dataset, leading to unreliable evalua-                     tive and diverse samples using semantic clus-\n                   tering and boundary analysis, followed by it-        tion results (Zadrozny, 2004) and under-optimized\n                    erative refinement with real-time model per-       prompts. No existing approaches have been pro-\n                formance data to replace redundant samples.      posed to select representative samples for evaluat-\n                  Evaluations on two datasets BIG-bench and       ing prompts for prompt optimization.\n               LIAR, and two models GPT-3.5 and GPT-4o-                                                                Various coreset selection approaches have been\n                   mini, show that IPOMP improves effectiveness\n                                                           developed for benchmarking machine learning\n               by at least 1.6% to 3.1%, and stability by at\n                                                           models, with the core idea being to select repre-                     least 50% to 55.5% compared with the best\n                   baseline across the studied datasets and models,        sentative samples that effectively represent the en-arXiv:2505.10736v3                 with minimal computational overhead below         tire dataset based on different criteria such as se-\n              1%. Furthermore, the results demonstrate that       mantics (Sener and Savarese, 2017; Har-Peled and\n                 our real-time performance-guided refinement      Mazumdar, 2004), model performance indicators\n                 approach can be universally applied to enhance                                                           such as confidence scores (Pacchiardi et al., 2024;\n                    existing coreset selection methods.\n                                                           Vivek et al., 2023; Polo et al., 2024), and training er-\n          1  Introduction                                     rors (Paul et al., 2021). However, these approaches\n                                                                 are not well-suited for prompt optimization.  In\n           Given a task, drafting an effective prompt is a key                                                             semantics-based approaches, samples for certain\n              part of optimizing the Large Language Model’s                                                                     tasks (e.g., Navigation task from BIG-bench (bench\n          (LLM) performance (Kojima et al., 2022; Pryzant                                                                     authors, 2023)) tend to be highly similar, making it\n               et al., 2023; Wei et al., 2022). Minor changes in                                                                 challenging to cluster them effectively solely based\n            prompt can lead to performance gains or losses, ne-                                                      on their semantics. On the other hand, approaches\n              cessitating prompt engineering for effective LLM                                                                        that leverage model performance information rely\n                        * Corresponding author.                        on evaluation results from previously tested mod-\n\nels to predict the performance of new models (Pac-   Let L denote a large language model, T represent\nchiardi et al., 2024; Vivek et al., 2023; Zhou et al.,   a given task, and Devaluation = {xi, yi}Ni=1 be the\n2023, 2022a). However, such approaches have no-   evaluation dataset, where xi are inputs and yi are\ntable limitations. Firstly, model performance data    the corresponding desired outputs for T. A prompt\nfor training samples is not always available, par-  P is a sequence of tokens that guides L to generate\nticularly for new or proprietary datasets. Even if    outputs ˆyi = L(xi, P).\nit is possible, collecting the model performance     The objective of prompt optimization is to find\ninformation prior to the prompt optimization pro-   a prompt P ∗that maximizes the task performance\ncess is expensive. Secondly, using past model per-   over Devaluation. This can be expressed as:\nformance to estimate the capabilities of current\nLLMs often results in sub-optimal predictions, as\nmodel behaviors may vary significantly (which is\n                                     P ∗= arg max M {L(xi, P)yi}Ni=1  ,evidenced by our results in Section 5.1).                                                          P\n  To address the limitations of existing coreset\nselection methods and tailor them for prompt opti-\n                                               where M is a performance metric that quantifies\nmization, we propose a two-stage approach called\n                                                      the alignment between the model-generated outputs\nIPOMP that leverages both semantic and model per-\n                                                                                      ˆyi = L(xi, P) and the ground-truth outputs yi,formance information. In the first stage, we iden-\n                                               such as Accuracy, F1-score, BLEU score, or task-\ntify informative samples by clustering the entire\n                                                         specific measures.\ntraining dataset based on semantic similarity and\n                                           The optimization typically involves iterativeselecting representative samples from each clus-\n                                                  refinement of prompt P  using various  strate-ter. Additionally, to enhance diversity, we incorpo-\n                                                         gies, which typically can be categorized into tworate boundary cases by selecting the most distant\n                                                       families: non-directional and directional. Non-sample pairs in the semantic space. In the second\n                                                       directional approaches sample or generate new in-stage, we iteratively refine the evaluation samples\n                                                    puts randomly and do not explicitly aim to reduceby incorporating their real-time model performance\n                                                       error on a train set over the optimization iterationduring the optimization process. Specifically, we\n                                               based on feedback, such as random search (Zhouidentify redundant samples based on their perfor-\n                                                           et al., 2022b; Zhang et al., 2023) and evolution-mance across the generated prompts and replace\n                                                   ary algorithm (Guo et al., 2023; Yang et al., 2024;them with contrasting samples.\n                                             Fernando et al.). For instance, APE generates se-  We evaluated IPOMP on the BIG-Bench and\n                                                  mantically similar candidate prompts for a taskLIAR datasets, comparing its performance against\n                                               based on their performance on a training subsetseveral SOTA baseline methods. IPOMP outper-\n                                             and iteratively selects the best prompt(Zhou et al.,formed all baselines, achieving effectiveness im-\n                                                2022b). In Directional family, the generation ofprovements in terms of Accuracy ranging from\n                                       new prompts is guided by the error measure on1.6% to 3.1% and significantly enhancing stabil-\n                                                    evaluation data, such as using gradient (Pryzantity by at least 50% in terms of standard deviation,\n                                                            et al., 2023; Juneja et al., 2024) and reinforcementwhile with a computational overhead of less than\n                                                      learning (Zhang et al., 2022; Deng et al., 2022; Yao1%. Furthermore, our evaluation results demon-\n                                                           et al., 2023). For instance, APO uses minibatchesstrate that our real-time model performance-guided\n                                                     of data to form natural language gradients that criti-refinement approach in the second stage can be\n                                                       cize the current prompt (Pryzant et al., 2023) . Theuniversally adapted to existing coreset selection\n                                                    gradients are then propagated into the prompt byapproaches to enhance their effectiveness and sta-\n                                                      editing the prompt in the opposite semantic direc-bility.\n                                                        tion of the gradient.\n2  Background and related work             Most existing prompt optimization approaches\n                                                          either utilize the entire training dataset or randomly\n2.1  Prompt Optimization                                             sample a subset, which can make the evaluation\nPrompt optimization refers to the systematic pro-   process overly expensive or suboptimal. To address\ncess of designing, refining, and evaluating prompts    this challenge, we propose a novel evaluation data\nto improve the performance of large language mod-    selection approach specifically designed for prompt\nels (LLMs) on specific tasks (Zhou et al., 2022b).   optimization.\n\n2.2  Coreset selection for benchmarking          integrated into any prompt optimization method\n    machine learning models                     involving iterative refinement.\n\nWe are the first to propose evaluation data selec-   3  Methodology\ntion in the context of prompt optimization. The\n                                We propose a two-stage approach that leveragesmost related field to our work is coreset selection.\nCoreset selection aims to find the most informa-   both semantic and model performance features to\ntive subset DCore ⊂DTraining with the constraint    select evaluation data for effective prompt optimiza-\n|DCore| ≪|DTraining|, so that the model trained on    tion: 1) Diverse sample selection; and 2) Real-time\nDCore has close generalization performance to the   model performance-guided iterative refinement. In\nmodel trained on the whole training set DTraining.     stage 1, we cluster training samples based on se-\n                                                mantics and select representative samples from  Numerous approaches have been developed for\n                                              each cluster, while incorporating boundary casescoreset selection for evaluating machine learning\n                                           by selecting the most distant pairs in the semanticmodels in recent years. Geometry-based methods\n                                                     space. In stage 2, we iteratively refine the selectedassume that semantically similar data points share\n                                                samples by analyzing real-time model performanceproperties (Chen et al., 2012; Sener and Savarese,\n                                                  during optimization, removing redundant samples,2017; Sinha et al., 2020; Agarwal et al., 2020).\n                                              and replacing them with contrasting ones. For sim-However, solely relying on semantics while over-\n                                                              plicity, we use the terms “coreset selection” andlooking the model performance could lead to sub-\n                                                  “data selection” interchangeably in the followingoptimal performance in identifying the representa-\n                                                              text.tive samples, typically for tasks where the samples\nare naturally semantically close to each other. To                                                    3.1  Stage 1: Diverse sample selection\nimprove accuracy, performance-based approaches\nconsider factors such as confidence (Coleman et al.,\n                                            Algorithm 1 Diverse sample selection\n2019; Margatina et al., 2021; Lin et al., 2023; Kim\net al., 2020), error (Paul et al., 2021; Toneva et al.,   Input: Training set Dtraining, number of selected\n2018; Liu et al., 2021). For instance, approaches       samples N  , number of clustering groups k,\nbased on confidence prioritize uncertain samples,        portion of samples from semantic clustering α\nassuming they have a greater impact on model per-   Output: Devaluation of size N\nformance.  Error-based approaches assume that       1: # Select αN samples based on semantic clus-\ntraining samples are more important if they con-        tering\ntribute more to the error or loss when training mod-      2:  Sclustering ←{}\nels. Decision boundary-based approaches focus on       3: clusters ←KMeans(Dtraining, k)\nsamples near the decision boundary, as they are       4:  Sclustering              ←\nharder to classify and valuable for coreset selec-       sampleProportionly(αN, clusters)\ntion (Ducoffe and Precioso, 2018; Margatina et al.,      5: Dtraining.remove(Sclustering)\n2021; Chai et al., 2023). More recently, methods       6: # Select (1 −α)N boundary samples\nhave leveraged evaluation results from previously       7: n, Sboundary ←0, {}\ntested LLMs to predict the performance of new       8: while n ≤αN do\nmodels (Pacchiardi et al., 2024; Vivek et al., 2023;      9:     d1, d2 ←getLeastSimilarPair(Dtraining)\nZhou et al., 2023, 2022a).                                 10:       if d1 /∈Sclustering then\n                                                              11:         Sboundary.add(d1, d2)  We propose a novel two-stage data selection ap-\n                                                              12:      n ←n + 2proach for prompt optimization that leverages both\n                                                              13:    end ifsemantic and real-time model performance features.\n                                                              14:     Dtraining.remove(d1, d2)Unlike existing model performance-based methods\n                                                              15: end whilethat require a preliminary stage to gather perfor-\n                                                              16: Return Devaluation ←Sclustering + Sboundarymance data or rely on prior model results to predict\nnew outcomes (Vivek et al., 2023; Pacchiardi et al.,\n2024; Zhou et al., 2022a), our approach dynami-      In this stage, we aim to select a small subset from\ncally collects performance data during optimiza-   the entire training set that comprehensively repre-\ntion in real-time, ensuring greater accuracy and    sents all training samples. One common strategy is\ncost-efficiency. Additionally, it can be seamlessly    to first cluster samples of the training set based on\n\ntheir selected properties, such as semantic (Sener   Algorithm 2 Real-time model performance-guided\nand Savarese, 2017; Har-Peled and Mazumdar,    iterative refinement.\n2004). Then it samples representatives from each   Input: Selected samples from stage 1 Devaluation,\nresultant cluster to form a reduced set. However,       Replace rate β, Training set Dtraining, Corre-\nsuch clustering-based approaches probably would        lation threshold CT, Prompt optimization ap-\nmiss boundary cases (Huang et al., 2024). There-       proach PO, LLM L, number of iterations I\nfore, in this stage, we combine semantic clustering   Output: Refined samples Devaluationrefined    , best prompts\nand boundary selection methods to select a small      bestPrompt\nyet comprehensive subset of samples from the train-      1:  i, Si ←0, Devaluation\ning set.                                                            2: while i < I do\n                                                                     3:    candP ←PO.updatePrompts(i, candP)\n                                                                     4:     MPruntime ←recordPerf(Si, L, candP)\n                                                                     5:     #Identify redundant samples in Si based\n  Given the training set Dtraining which contains       on their model performance\nM training samples {D1, D2, . . . , DM}, our algo-      6:    clusters ←Clustering(MPruntime, CT)\nrithm outputs a subset Devaluation with a size of N,      7:     Sredundant            ←\nwhere N ≪M. We demonstrate the algorithm in       sampleRedundant(clusters, β)\nAlgorithm 1, which consists of two steps: 1) Select-      8:    # Find least samples to replace\ning informative samples using semantic clustering.      9:     for ei ∈Sredundant do\nWe first embed each sample in Dtraining into latent     10:       d ←leastSimSample(ei, Dtraining)\nspace. We utilize Sentence-Bert (Reimers, 2019)     11:         Sredundant.replace(ei, d)\nto encode semantic representations. We then use     12:    end for\nK-means to cluster samples into k clusters (Line     13: end while\n3). Note that K-means is selected due to its effec-    14: Return Devaluationrefined  ←Si, bestPrompt ←\ntiveness and efficiency. We do not use methods       identifyBest(candP)\nto determine the value of k since they typically\nrequire additional time. In addition, throughout\nexperiments, we find that the value of k does not                                                    3.2  Stage 2: Real-time model\nimpact our data selection approach significantly                                                 performance-guided iterative refinement\n(see more results in Appendix A.5).  Lastly, we\nrandomly select samples proportionally from each  We obtain a reduced set Devaluation based on their\ncluster based on their size and totally select αN    semantics after applying Algorithm 1. However,\nsamples (i.e., Sclustering), where α is the portion    solely relying on semantics while overlooking the\nof selected samples from semantic clustering (Line   model performance could lead to sub-optimal per-\n4).  2) Identifying boundary cases.  Inspired by   formance, typically for tasks where the samples\nprior study (Huang et al., 2024), we select bound-   are naturally semantically close to each other. To\nary cases by finding samples that are least similar    address this, we design a novel algorithm called\nto each other. To do so, similar to step 1, we em-   Real-time model performance-guided iterative re-\nbed the samples into semantic latent space and find    finement, which updates Devaluation iteratively by\nthe pairs of samples having the furthest distance,    replacing redundant samples with contrasting ones\niteratively (Lines 8 - 14). Note that we only in-   based on their model performance. This process\nclude the samples that are not included in Sclustering.   leverages real-time model performance observed\nCalculating the distance among all samples is ex-   during prompt optimization, eliminating the need\npensive, with a time complexity of O(dN2), where    for pre-collected performance data from existing\nd is the dimension of embeddings and N is the size   models or preliminary evaluations.\nof dataset. To improve the efficiency, we first detect     Our approach is inspired by a key observation\nthe boundary points in the latent space by following    that a significant portion of samples exhibit high\nprevious study (Angiulli and Pizzuti, 2002), and    correlations in their model performance across\nthen find the furthest pairs among those boundary   prompts during prompt optimization.  Figure 1\npoints. Finally, we combine the clustering samples    presents a heatmap where each cell represents the\nSclustering and boundary samples Sboundary together    correlation between two samples based on their\nas the final subset of samples.                        real-time model performance (i.e., logits in this\n\ncase). As we can see, a substantial portion of sam-\nples (20% in this case) exhibit a correlation greater\nthan 0.9 with others. This indicates redundancy\namong these samples and they can be replaced with\nalternative samples from the training set to enhance\nthe diversity of Devaluation.\n\n\n\n We demonstrate our algorithm in Algorithm 2.\nGiven a prompt optimization technique PO, for\neach iteration, our algorithm first identifies the re-\ndundant samples in the Devaluation (Lines 3 - 7)\nand replaces a certain portion of them with the\nopposite (i.e., the most dissimilar) ones retrieved\nfrom the training set. To be specific, for each iter-   Figure 1: Correlation among the samples selected in\nation, we record the performance of each exam-    stage 1 based on their real-time performance across\nple’s performance across candidate prompts on    candidate prompts during the initial iteration of APE.\n                                              Each cell represents the correlation between a pair ofthe LLM L (line 4).  The performance matrix\nMPruntime ∈R|Si|×(|output|×|candP|) where |Si|    samples.\nis the number of samples in Si, |output| is the size\nof output labels, and |candP| is the number of                                       4  Experimental Setting\ncandidate prompts candP generated by prompt op-\ntimization approach PO in each iteration. We use\n                                                    4.1  Datasetslogits as the proxy of the model’s confidence to con-\nstruct the performance matrix. For instance, if the\n                                                   In this paper, we evaluated our approach on twooutput labels of a task are True/False, the matrix\n                                                       datasets BIG-bench dataset (bench authors, 2023)includes two dimensions to represent the perfor-\nmance: {Logit(True), Logit(False)}. If the out-   and LIAR (?). We selected the following five tasks\nput is True, the performance is {Logit(True), 0}.   from Big-bench. Presuppositions as Natural Lan-\n                                           guage Inference (NLI), where to reason whetherIn cases where the output is neither True nor False,\nthe performance is set to {0, 0}. To identify the    a presupposition is embedded in a given statement\n                                            and output entailment, neutral, or contradiction.redundant samples, we use a hierarchical cluster\n                                               Navigation: Given a sequence of navigational in-to build clusters and group samples that share high\n                                                        structions, the objective is to ascertain if an agentcorrelations in the same cluster (Line 6) by follow-\n                                            would return to the original point of departure. Im-ing prior studies (Wang et al., 2018; Rajbahadur\net al., 2017). In our case, we set the threshold CT    plicatures: This task requires models to determine\n                                              whether a response given by one speaker to an-to 0.9 (i.e., highly correlated). We then randomly\n                                                   other constitutes an affirmative or negative reply.select a portion (i.e., β) of samples Sredundant from\n                                        Metaphor Understanding: This task presents aeach cluster with highly correlated samples and re-\nplace them. For replacement, we iteratively select   model with a metaphoric sentence and requires it to\nsamples from Dtraining which have the lowest se-    identify whether a subsequent sentence accurately\n                                                          interprets the initial metaphor. Sports Understand-mantic similarity for examples in Sredundant (Line\n                                                      ing: This task requires models to assess whether a9 - 12). We assume that the pair with the low-\nest semantic similarity is more likely to yield an-    synthetically constructed sentence related to a sport\n                                                                 is plausible or not. We also evaluated LIAR (?), aswers, which leads to different model performances.\n                                               widely used public dataset for Fake News Detec-For efficient search, we use Hierarchical Naviga-\n                                                        tion.ble Small World (HNSW) (Malkov and Yashunin,\n2018) to perform an approximate search by invert-    We measure the Accuracy of those classifica-\ning its similarity function to calculate the dissim-    tion tasks to evaluate the effectiveness of the stud-\nilarity between the query examples and examples    ied coreset selection approaches. In addition, we\nin the training data. HNSW is efficient in high-   use the standard deviation (SD) to measure the\ndimension space.                                         stability of the approaches.\n\n4.2  Prompt optimization approaches and base    4.4  Implementation Details\n   LLMs                                                   In our experiments, the size of Devaluation is set\n                                                      to 20, and the number of clustering groups K is\nAs discussed in Section 2, prompt optimization    set to five by default unless otherwise specified.\ncan primarily be categorized into two families, di-   For IPOMP, we set α to 0.5, meaning that half of\nrectional and non-directional. We selected two    the samples in Devaluation come from the boundary\nstate-of-the-art approaches APO  (Pryzant et al.,   method, while the remaining half comes from the\n2023) and EVOPROMPT (Guo et al., 2023) from    clustering method. The correlation threshold CT\nnon-directional family, and one of the most com-   and the replace rate β are set to 0.9 and 0.5, respec-\nmonly used approaches APE (Zhou et al., 2022b)    tively. We run each task of each method five times\nfrom directional family. We use their default set-   and report the average performance.\nting in our experiments and choose GPT-3.5 and\nGPT-4o-mini.                             5  Results\n\n                                                    5.1  Effectiveness and stability\n\n                                                  All coreset selection approaches enhance the\n4.3  Baselines                                                    effectiveness and stability of prompt optimiza-\n                                                    tion techniques compared to Random selection.\nTo evaluate the effectiveness of our approach, we  Among these, IPOMP demonstrates superior\ncompare our proposed approach with various base-   performance. Table 1 presents the effectiveness\nlines.  Random.  Randomly sample examples   and stability of all studied coreset selection ap-\nfrom the training set. Clustering. Selecting ex-   proaches, across different prompt optimization\namples proportionally from the clusters that are    techniques. Comparing Random with all other data\nconstructed based on samples’ semantics as dis-   sampling approaches, including IPOMP, we ob-\ncussed in Section 3.1. Boundary. We select bound-   serve a significantly superior performance across\nary cases as discussed in Section 3.1 by follow-    all prompt optimization techniques, which indi-\ning prior study (Huang et al., 2024). Our work    cates that selecting representative samples is im-\nis the first to address evaluation data selection for    portant for prompt optimization. IPOMP improves\nprompt optimization, and no existing state-of-the-   the best baseline (Anchor-Point) by at least 1.6%\nart (SOTA) approaches are available. Therefore,    to 3.1% across the studied datasets and models.\nwe benchmark our approach against two SOTA    Typically for APE, the improvement gained from\ncoreset selection methods designed for LLM eval-  IPOMP is larger than other prompt optimization\nuation. Anchor-Point (Vivek et al., 2023). This    techniques, which is probably attributed to its na-\nmethod clusters examples based on the model’s    ture, where in each iteration, the prompt is opti-\nconfidence in the correct class and selects repre-   mized based on the evaluation (e.g., gradient) from\nsentative examples, called “anchor point” as the    the last iteration, the evaluation data’s quality is\ncoreset. To adapt it for prompt optimization, we    typically important for the success of the prompt\ncollect the model’s confidence scores by running    optimization. On the other hand, we summarize\nthe training dataset through a set of 10 prompts    the standard deviation (SD) across all datasets for\ngenerated via prompt optimization in a preliminary   each selected baseline. We find that IPOMP ex-\nstage. Prediction-based (Pacchiardi et al., 2024).    hibits greater stability than other baselines, achiev-\nThis method predicts an instance’s performance on    ing the lowest standard deviation across prompt\nan LLM by training a generic assessor on existing    optimization techniques, with an improvement of\nLLM performance data. We adapt this approach    at least 50%. This is typically attributed to our\nby training the assessor on our dataset, BIG-bench,    real-time model performance-guided iterative re-\nusing GPT-3.5, following (Pacchiardi et al., 2024).   finement strategy (i.e., stage 2 of IPOMP), which\nThe trained assessor predicts performance on a set    dynamically refines the evaluation data during run-\nof initial prompts, and examples are clustered based   time and guarantees the stability of our approach.\non these predictions, similar to Anchor-Point. See   See more ablation analysis in Section 5.2.\nmore details in Appendix A.2. Note that we do not     Boundary and Clustering share similar effec-\nconsider the entire training data as a baseline, since    tiveness across all studied prompt optimization\nit is too expensive and infeasible in practice.         techniques. However, compared with IPOMP, it\n\nTable 1: Comparison of the effectiveness (Accuracy) and stability (SD) of the studied prompt optimization\napproaches with different evaluation data selection approaches.\n\n                                                 GPT-3.5 - BIG-bench                                                                 GPT-4o-mini - BIG-bench\n\n                Random     Boundary      Clustering    Anchor-Point  Prediction-based    IPOMP      Random     Boundary      Clustering    Anchor-Point  Prediction-based    IPOMP\n EVOPROMPT   0.743±0.028   0.757±0.022   0.759±0.031   0.774±0.028     0.758±0.025    0.776↑±0.017↓   0.694 ± 0.047  0.715 ± 0.042  0.706 ± 0.037  0.756 ± 0.026    0.709 ± 0.047    0.758↑±0.011↓\n APO            0.691±0.040   0.718±0.052   0.723±0.025   0.750±0.020     0.743±0.042    0.753↑±0.009↓   0.703 ±0.038   0.72± 0.043   0.701 ± 0.022  0.743± 0.032     0.690 ±0.043    0.780↑±0.012↓\n APE             0.722±0.037   0.708±0.045   0.684±0.032   0.727±0.035     0.707±0.048    0.742↑±0.010↓   0.717 ± 0.040  0.734 ± 0.030  0.770 ± 0.030  0.770 ± 0.023    0.716 ± 0.042    0.794↑±0.012↓\n Average          0.719±0.035   0.727±0.040   0.725±0.029   0.745±0.028     0.725±0.038    0.757↑±0.012↓  0.704± 0.041   0.723 ± 0.038  0.725 ± 0.029  0.756 ± 0.027    0.705 ± 0.044    0.778↑±0.011↓\n\n                                                   GPT-3.5 - LIAR                                                                      GPT-4o-mini - LIAR\n\n                Random     Boundary      Clustering    Anchor-Point  Prediction-based    IPOMP      Random     Boundary      Clustering    Anchor-Point  Prediction-based    IPOMP\n EVOPROMPT   0.753 ± 0.042  0.798 ± 0.037  0.772 ± 0.035  0.810 ± 0.030    0.734 ± 0.043    0.818↑±0.015↓   0.756 ± 0.045  0.806 ± 0.041  0.782 ± 0.037  0.816 ± 0.026    0.754 ± 0.043    0.838↑±0.012↓\n APO             0.732 ± 0.039   0.792 ±0.032   0.731 ± 0.031  0.794 ± 0.028    0.754 ± 0.038    0.812↑±0.014↓   0.746 ± 0.059  0.792 ± 0.061  0.776 ± 0.037  0.806 ± 0.022    0.754 ± 0.048    0.836↑±0.013↓\n APE             0.743 ± 0.043  0.721 ± 0.035  0.753 ± 0.042  0.801 ± 0.023    0.748 ± 0.037    0.832↑±0.011↓   0.746 ± 0.04   0.792 ± 0.039  0.808 ± 0.042    0.8 ± 0.025      0.742 ± 0.04    0.826↑±0.011↓\n Average          0.742 ± 0.041  0.770 ± 0.035  0.752 ± 0.036  0.801 ± 0.027    0.746 ± 0.039    0.820↑±0.012↓   0.748 ± 0.048  0.797 ± 0.047  0.788 ± 0.038  0.807 ± 0.024     0.75 ± 0.043    0.833↑±0.012↓\n\n\ndemonstrates lower effectiveness and suffers lower     (i.e., IPOMPStage1), we construct a variant, namely\nstability, which indicates that relying solely on se-   IPOMPRandom, where we replace stage 1 with\nmantics to obtain samples is insufficient, and in-   random sampling and keep the rest of IPOMP\ncorporating model performance offers a promising   unchanged. As shown in Table 2, the accuracy\napproach to identifying representative examples.   of IPOMPRandom is substantially 2% lower than\nOn the other hand, Prediction-based requires adap-  IPOMP, illustrating the necessity of diverse data\ntation to new datasets and exhibits lower effective-    selection at the beginning. In summary, both stages\nness compared to IPOMP, making it limited com-   of IPOMP make significant contributions to the\npatibility in the context of prompt optimization.      effectiveness and stability of IPOMP.\n  Anchor-Point consistently ranks as the second-\nbest approach across all prompt optimization meth-\nods. Notably, approaches utilizing real-time model\nperformance data (IPOMP and Anchor-Point) out-\n                                                Baseline vs. Baseline+IPOMPStage2 Besides en-\nperform those relying solely on semantics or prior\n                                                 hancing IPOMP, our real-time model performance-\nmodel data, as performance feedback offers more\n                                               guided iterative refinement can serve as a versa-\nprecise insights for distinguishing samples. IPOMP\n                                                                  tile plugin alongside any data sampling approach\nsurpasses Anchor-Point by combining semantic\n                                                      to refine evaluation data during runtime. To as-\nand real-time performance data, meanwhile achiev-\n                                                     sess its effectiveness, we apply it to all selected\ning better efficiency. Unlike Anchor-Point, which\n                                                      baselines.  Figure 2 illustrates the performance\nrequires a costly preliminary stage to collect model\n                                                   of these baselines before and after incorporating\nconfidence, IPOMP gathers performance data in\n                                             IPOMPStage2. The performance of all baselines\nreal-time during the optimization process.\n                                              improves after applying our real-time refinement\n                                             component (i.e., IPOMPStage2), except for Anchor-\n5.2  Ablation Analysis\n                                                  Point in some cases.  For instance, on average,\nIPOMPStage1 vs. IPOMP To evaluate the con-   IPOMPStage2 improves the performance of Ran-\ntribution of model performance-guided iterative   dom, Boundary, Clustering, Anchor-Point, and\nrefinement (i.e., IPOMPStage2), we conduct an ab-   Prediction-based baselines by 2.3%, 1.1%, 1.5%,\nlation analysis. We compare IPOMP with its vari-   0.3% and 1.6% when using GPT-3.5 on BIG-\nant in which sage 2 is removed (i.e., IPOMPStage1).   bench dataset, respectively. More importantly, in-\nAs shown in Table 2, on average, without stage 2,   corporating IPOMPStage2 into the original base-\nthe effectiveness of IPOMP drops 2.4%. In addi-    lines improves the stability significantly. For in-\ntion, the performance becomes unstable without    stance, IPOMPStage2 reduces the standard devia-\nstage 2.  Specifically, the standard deviation in-    tion by 18.8%, 60.0%, 6.9%, 10.8%, and 16.8%\ncreases by a factor of 2.83, indicating that stage 2    for Random, Boundary, Semantic, Anchor-Point,\nsignificantly enhances stability. Actually stage 2   and Prediction-based when using GPT-3.5 on BIG-\nindeed reduce the redundant samples. For instance,   bench, respectively. In summary, IPOMPStage2 not\nin APO, after the first round of refinement of stage   only boosts the performance of baselines but also\n2, the redundancy of examples (correlation > 0.9)   enhances their stability. Our results demonstrate\nare significantly reduced from 19% to 10% (see    that IPOMPStage2 is a practical and adaptable\nAppendix A.8).                              enhancement for various data selection methods,\nIPOMPRandom vs. IPOMP To evaluate the im-    effectively refining evaluation data by leveraging\nportance of the diverse sample selection of IPOMP    real-time model performance insights.\n\nTable 2: Comparison of the effectiveness and stability of the studied prompt optimization approaches with IPOMP\nand its variants.\n\n\n                                  GPT-3.5 - BIG-bench                             GPT-4o-mini - BIG-bench\n                  IPOMPStage1   IPOMPRandom    IPOMP     IPOMPStage1   IPOMPRandom    IPOMP\n   EVOPROMPT     0.745±0.029       0.751±0.021      0.776±0.017     0.737±0.014       0.754±0.012      0.758±0.011\n   APO              0.730±0.031       0.738±0.015     0.753±0.009     0.739±0.012       0.757±0.012     0.780±0.012\n   APE              0.724±0.042       0.723±0.027     0.742±0.010     0.754±0.012       0.705±0.013     0.794±0.012\n     Average           0.733±0.034       0.737±0.021      0.757±0.012     0.743±0.012       0.738±0.012      0.778±0.011\n                                    GPT-3.5 - LIAR                                 GPT-4o-mini - LIAR\n                  IPOMPStage1   IPOMPRandom    IPOMP     IPOMPStage1   IPOMPRandom    IPOMP\n   EVOPROMPT     0.802±0.019       0.807±0.017      0.818±0.015     0.820±0.015       0.809±0.014      0.838±0.011\n   APO              0.801±0.021       0.812±0.018      0.812±0.014     0.797±0.022       0.824±0.015      0.836±0.011\n   APE              0.812±0.018       0.829±0.013      0.832±0.011     0.801±0.014       0.826±0.015      0.827±0.013\n     Average           0.805±0.020       0.816±0.016      0.820±0.013     0.806±0.017       0.820±0.015      0.833±0.012\n\n\n\n\n\nFigure 2: Comparison of the effectiveness of original baselines and Baseline+IPOMPStage2. SD is indicated in\nparentheses.\n\nTable 3: Average execution time (in seconds) of the studied prompt optimization after applying IPOMP (including\ntime required for each stage) and other baselines on BIG-bench when using GPT-3.5. Note that Random can be\nconsidered as the pure execution time of prompt optimization techniques as the execution time of random sampling\nis negligible. For Anchor-Point, we also present the time for the preliminary stage to collect the model confidence\ninformation.\n\n\n                  IPOMPStage1  IPOMPStage2  IPOMP  Random  Boundary  Clustering   Anchor-Point   Prediction-based\n   APO                 0.45            2.74       470.86    469.74     470.34      470.83    469.74+200.36       480.57\n   APE                 0.37            2.31       120.23    109.84     110.67      111.12    113.26+205.32       123.31\n   EVOPROMPT       0.51            3.43       613.75    609.35     611.53      608.38    609.31+207.85       622.61\n    Average              0.45            2.83       401.61    396.31     397.51      396.61    397.43+204.51       405.50\n\n\n5.3  Impact of sample size                     sample size increases from 5 to 20, then stabi-\n                                                          lizes or slightly declines beyond 20, suggesting\nIn this section, we further evaluate the impact of                                                          that 20 samples may represent the optimal balance\nsample size across the prompt optimization tech-                                            between cost and effectiveness for prompt opti-\nniques. Specifically, we conduct experiments with                                                   mization. Across all sample sizes, IPOMP con-\nsample sizes of 5, 10, 15, 20, and 30 on GPT-3.5                                                       sistently outperforms other baselines across all\nwith BIG-bench, as shown in Figure 3. Note that                                        prompt optimization techniques, even with as\nwe observe the same trend on GPT-4o-mini with                                           few as 5 samples. Anchor-Point generally ranks\nLIAR. Overall, the performance improves as the\n\nand prediction can be done locally by deploying\n                                                  small models. The cost for prompt optimization is\n                                                   presented in Table 4. Similar to overhead, Anchor-\n                                                  Point requires evaluating the entire model perfor-\n                                          mance during the preliminary stage, therefore addi-\n                                                         tional cost is required.\nFigure 3: The impact of different sample sizes selected\nby the studied selection approaches on BIG-bench when   6  Conclusion\nusing GPT-3.5.\n                                 We introduced IPOMP, a two-stage approach that\n                                              enhances coreset selection for prompt optimiza-Table 4: The cost analysis of the studied prompt op-\ntimization approaches and warm-up stage for Anchor-    tion by leveraging both semantic and model per-\nPoint. The actual cost (in USD) is in parentheses.       formance information. Our method first selects\n                                                       representative and diverse samples based on seman-\n               Prompt Optimization  Preliminary stage for Anchor-Point    tic clustering and boundary analysis, followed by\n APO                637 (0.20)                   6,124 (0.95)\n APE                231 (0.06)                   2,277 (0.163)         an iterative refinement process that integrates real-\n EVOPROMPT       2,245 (2.75)                  22,349 (6.18)         time model performance information to replace\n Average              1,037 (1.00)                  10,250 (2.43)         redundant samples with more informative ones.\n                                                   Evaluation on the BIG-bench dataset demonstrated\n                                                           that IPOMP consistently outperforms existing base-second, reinforcing our earlier finding (Section 5.1)\n                                                          lines with minimal computational overhead of lessthat approaches leveraging model performance data\n                                                  than 1%. Furthermore, the real-time performance-(IPOMP and Anchor-Point) tend to outperform\n                                               guided refinement approach in IPOMP is univer-those relying solely on semantic or historical per-\n                                                          sally applicable to other coreset selection methods,formance data. In addition, IPOMP is more stable\n                                                enhancing their overall effectiveness and stability.than other approaches across different sample sizes.\nSee more details in Appendix A.6.                                       7  Limitations\n\n5.4  Overhead and cost analysis              One limitation is our findings may not generalize to\n                                                      other large language models with different architec-\nThe overhead of IPOMP is less than 1%, mak-\n                                                           tures, training data, or capabilities. We encourage\ning it comparable to or better than other base-\n                                                     future research to evaluate our approach using a\nlines. Table 3 presents the average execution time\n                                                      diverse set of base models to assess its applicability\nof three prompt optimization techniques, after ap-\n                                                   across different LLMs. We selected three prompt\nplying coreset selection approaches on BIG-bench\n                                                  optimization techniques, from different families.\nusing GPT-3.5. IPOMP has a comparable overhead\n                                 We encourage future research to evaluate on more\nto other baselines. The overhead of IPOMP primar-\n                                                   optimization techniques.\nily comes from stage 2, which iteratively identifies\nand replaces redundant samples based on model\nperformance (2.83 seconds on average). Stage 1   References\nhas a similar overhead as Boundary and Cluster-\n                                                      Sharat Agarwal, Himanshu Arora, Saket Anand, and\ning (0.45 seconds on average). Anchor-Point has                                                    Chetan Arora. 2020. Contextual diversity for active\nthe highest overhead, which requires an additional       learning.  In Computer Vision–ECCV 2020: 16th\npreliminary stage to evaluate training samples on      European Conference, Glasgow, UK, August 23–28,\nprompts, resulting in a significantly higher over-      2020, Proceedings, Part XVI 16, pages 137–153.\n                                                             Springer.\nhead of 51% and an execution time of approxi-\nmately 200 seconds. Note that we observe a similar   Alon Albalak, Yanai Elazar, Sang Michael Xie, Shayne\noverhead when evaluated on LIAR using GPT-4o-      Longpre, Nathan Lambert, Xinyi Wang, Niklas\n                                                     Muennighoff, Bairu Hou, Liangming Pan, Haewon\nmini.\n                                                        Jeong, et al. 2024. A survey on data selection for\n  For Clustering, Boundary, Prediction-based, and      language models. arXiv preprint arXiv:2402.16827.\nIPOMP, since the cost for those approaches only\n                                                        Fabrizio Angiulli and Clara Pizzuti. 2002. Fast outlier\ncomes from LLM’s inference for prompt optimiza-                                                            detection in high dimensional spaces. In European\ntion. For the approach itself, no additional cost      conference on principles of data mining and knowl-\nis required. The calculation related to clustering      edge discovery, pages 15–27. Springer.\n\nBIG bench authors. 2023. Beyond the imitation game:    Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\n   Quantifying and extrapolating the capabilities of lan-      taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\n  guage models. Transactions on Machine Learning      guage models are zero-shot reasoners. Advances in\n  Research.                                             neural information processing systems, 35:22199–\n                                                      22213.\nChengliang Chai, Jiayi Wang, Nan Tang, Ye Yuan, Ji-\n   abin Liu, Yuhao Deng, and Guoren Wang. 2023. Effi-   Yong Lin, Chen Liu, Chenlu Ye, Qing Lian, Yuan Yao,\n   cient coreset selection with cluster-based methods. In      and Tong Zhang. 2023. Optimal sample selection\n  Proceedings of the 29th ACM SIGKDD Conference      through uncertainty estimation and its application in\n  on Knowledge Discovery and Data Mining, pages      deep learning. arXiv preprint arXiv:2309.02476.\n  167–178.\n                                              Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi\n                                                     Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy\nYutian Chen, Max Welling, and Alex Smola. 2012.                                                         Liang, and Chelsea Finn. 2021. Just train twice: Im-\n  Super-samples from kernel herding. arXiv preprint                                                       proving group robustness without training group in-\n  arXiv:1203.3472.                                                           formation. In International Conference on Machine\n                                                         Learning, pages 6781–6792. PMLR.\nCody Coleman, Christopher Yeh, Stephen Mussmann,\n  Baharan Mirzasoleiman, Peter Bailis, Percy Liang,    Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\n   Jure Leskovec, and Matei Zaharia. 2019. Selection      Hiroaki Hayashi, and Graham Neubig. 2023. Pre-\n   via proxy: Efficient data selection for deep learning.       train, prompt, and predict: A systematic survey of\n  arXiv preprint arXiv:1906.11829.                     prompting methods in natural language processing.\n                                    ACM Computing Surveys, 55(9):1–35.\nMingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan\n  Wang, Han Guo, Tianmin Shu, Meng Song, Eric P   Yu A Malkov and Dmitry A Yashunin. 2018. Efficient\n  Xing, and Zhiting Hu. 2022. Rlprompt: Optimizing      and robust approximate nearest neighbor search us-\n   discrete text prompts with reinforcement learning.      ing hierarchical navigable small world graphs. IEEE\n  arXiv preprint arXiv:2205.12548.                         transactions on pattern analysis and machine intelli-\n                                                          gence, 42(4):824–836.\nMelanie Ducoffe and Frederic Precioso. 2018. Adver-\n                                                      Katerina Margatina, Giorgos Vernikos, Loïc Barrault,   sarial active learning for deep networks: a margin\n                                                  and Nikolaos Aletras. 2021.  Active learning by  based approach. arXiv preprint arXiv:1802.09841.\n                                                          acquiring contrastive examples.   arXiv preprint\n                                                        arXiv:2109.03764.Chrisantha Fernando, D Banarse, Henryk Michalewski,\n  Simon Osindero, and Tim Rocktäschel.  Prompt-                                                 Lorenzo  Pacchiardi,  Lucy G  Cheke,  and  José\n   breeder:       Self-referential   self-improvement                                                       Hernández-Orallo. 2024. 100 instances is all you\n   via prompt  evolution  (2023).    arXiv  preprint                                                         need: predicting the success of a new llm on unseen\n  arXiv:2309.16797.                                                          data by testing on a few instances. arXiv preprint\n                                                        arXiv:2409.03563.\nQingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao\n  Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yu-   Mansheej Paul, Surya Ganguli, and Gintare Karolina\n   jiu Yang. 2023. Connecting large language models       Dziugaite. 2021. Deep learning on a data diet: Find-\n  with evolutionary algorithms yields powerful prompt      ing important examples early in training. Advances\n   optimizers. arXiv preprint arXiv:2309.08532.              in neural information processing systems, 34:20596–\n                                                      20607.\nSariel Har-Peled and Soham Mazumdar. 2004. On core-\n   sets for k-means and k-median clustering. In Pro-    Felipe Maia Polo, Lucas Weber, Leshem Choshen,\n  ceedings of the thirty-sixth annual ACM symposium      Yuekai Sun, Gongjun Xu, and Mikhail Yurochkin.\n  on Theory of computing, pages 291–300.                2024. tinybenchmarks: evaluating llms with fewer\n                                                       examples. arXiv preprint arXiv:2402.14992.\nYihao Huang, Chong Wang, Xiaojun Jia, Qing Guo,\n                                                 Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chen-   Felix Juefei-Xu, Jian Zhang, Geguang Pu, and Yang\n                                                  guang Zhu, and Michael Zeng. 2023.  Automatic   Liu. 2024. Semantic-guided prompt organization for\n                                                  prompt optimization with\" gradient descent\" and   universal goal hijacking against llms. arXiv preprint\n                                              beam search. arXiv preprint arXiv:2305.03495.  arXiv:2405.14189.\n                                              Gopi Krishnan Rajbahadur, Shaowei Wang, Yasutaka\nGurusha Juneja, Nagarajan Natarajan, Hua Li, Jian Jiao,     Kamei, and Ahmed E Hassan. 2017. The impact of\n  and Amit Sharma. 2024.  Task facet learning: A       using regression models to build defect classifiers. In\n   structured approach to prompt optimization. arXiv     2017 IEEE/ACM 14th International Conference on\n   preprint arXiv:2406.10504.                           Mining Software Repositories (MSR), pages 135–145.\n                                                   IEEE.\nSeong  Tae Kim,  Farrukh  Mushtaq,  and  Nassir\n  Navab. 2020.  Confident coreset for active learn-  N Reimers. 2019.  Sentence-bert: Sentence embed-\n   ing in medical image analysis.   arXiv preprint      dings using siamese bert-networks. arXiv preprint\n  arXiv:2004.02200.                                    arXiv:1908.10084.\n\nOzan Sener and Silvio Savarese. 2017. Active learn-      pages 9850–9867, Singapore. Association for Com-\n   ing for convolutional neural networks: A core-set       putational Linguistics.\n   approach. arXiv preprint arXiv:1708.00489.\n                                                  Lexin  Zhou,  Fernando  Martínez-Plumed,   José\nSamarth Sinha, Han Zhang, Anirudh Goyal, Yoshua      Hernández-Orallo, Cèsar Ferri, and Wout Schellaert.\n  Bengio, Hugo Larochelle, and Augustus Odena. 2020.      2022a.  Reject before you run:  Small assessors\n   Small-gan: Speeding up gan training using core-sets.       anticipate big language models. In EBeM@ IJCAI.\n   In International Conference on Machine Learning,\n  pages 9005–9015. PMLR.                         Lexin Zhou,  Pablo A Moreno-Casares, Fernando\n                                                       Martínez-Plumed, John Burden, Ryan Burnell, Lucy\nMariya Toneva, Alessandro Sordoni, Remi Tachet des      Cheke, Cèsar Ferri, Alexandru Marcoci, Behzad\n  Combes, Adam Trischler, Yoshua Bengio, and Geof-     Mehrbakhsh, Yael Moros-Daval, et al. 2023.  Pre-\n   frey J Gordon. 2018. An empirical study of exam-       dictable  artificial  intelligence.    arXiv  preprint\n   ple forgetting during deep neural network learning.      arXiv:2310.06167.\n  arXiv preprint arXiv:1812.05159.\n                                              Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\nRajan Vivek, Kawin Ethayarajh, Diyi Yang, and Douwe      Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\n   Kiela. 2023. Anchor points: Benchmarking mod-      Ba. 2022b. Large language models are human-level\n   els with much fewer examples.   arXiv preprint      prompt engineers. arXiv preprint arXiv:2211.01910.\n  arXiv:2309.08638.\n\nRuochen Wang, Sohyun An, Minhao Cheng, Tianyi\n  Zhou, Sung Ju Hwang, and Cho-Jui Hsieh. 2024.\n  One prompt is not enough: Automated construction\n   of a mixture-of-expert prompts.  In International\n  Conference on Machine Learning.\n\nShaowei Wang, Tse-Hsun Chen, and Ahmed E Hassan.\n  2018.  Understanding the factors for fast answers\n   in technical q&a websites: An empirical study of\n   four stack exchange websites. Empirical Software\n  Engineering, 23:1552–1593.\n\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\n  Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\n   et al. 2022. Chain-of-thought prompting elicits rea-\n   soning in large language models. Advances in neural\n   information processing systems, 35:24824–24837.\n\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,\n  Quoc V. Le, Denny Zhou, and Xinyun Chen. 2024.\n  Large language models as optimizers.   Preprint,\n  arXiv:2309.03409.\n\nWeiran Yao, Shelby Heinecke, Juan Carlos Niebles,\n  Zhiwei Liu, Yihao Feng, Le Xue, Rithesh Murthy,\n  Zeyuan Chen, Jianguo Zhang, Devansh Arpit, et al.\n  2023.  Retroformer: Retrospective large language\n   agents with policy gradient optimization.  arXiv\n   preprint arXiv:2308.02151.\n\nBianca Zadrozny. 2004. Learning and evaluating classi-\n   fiers under sample selection bias. In Proceedings of\n   the twenty-first international conference on Machine\n   learning, page 114.\n\nTianjun Zhang, Xuezhi Wang, Denny Zhou, Dale\n  Schuurmans, and Joseph E Gonzalez. 2022. Tem-\n   pera: Test-time prompting via reinforcement learning.\n  arXiv preprint arXiv:2211.11890.\n\nZhihan Zhang, Shuohang Wang, Wenhao Yu, Yichong\n  Xu, Dan Iter, Qingkai Zeng, Yang Liu, Chenguang\n  Zhu, and Meng Jiang. 2023.  Auto-instruct: Auto-\n  matic instruction generation and ranking for black-\n  box language models. In Findings of the Associa-\n   tion for Computational Linguistics: EMNLP 2023,\n\nA  Appendix                                      Table 5: The size of Training dataset and testing in our\n                                                     experiments\nA.1  Experimental setup\n                                                                                               Training Dataset  Testing dataset\nThe temperature is set to 0 for inference. All exper-     Navigation                       800             200\niments are done in Python 3.10. All experiments      Implicatures                     392             100\nwere conducted on a machine equipped with a GPU     Metaphor Understanding          544             136\nof 24GB, a 24-core CPU, and 24 GB of RAM.          Sports Understanding             788             198\n                                                                 Natural Language Inference        588             147\nA.2  Detailed implementation of baselines          Fake News Detection             10240           1267\n\nAnchor-Point (Vivek et al., 2023). To adopt this\napproach in the context of prompt optimization, we\nfirst collect the model’s confidence scores on the\nexamples. Specifically, we run the training dataset\nthrough an initial set of prompts and then clus-\nter the examples based on their confidence scores\nacross these prompts, following (Vivek et al., 2023).\n                                                     Figure 4: The impact of different values of hyper-During this stage, we generate 10 prompts using\n                                                       parameters α , β and cluster size K on the effectiveness\nthe prompt optimization technique as the initial set.\n                                                         of APE, APO, and EVOPROMPT.\nEvaluating confidence on more prompts typically\ncan lead to better clustering results, while infer-\nence is expensive. To balance the quality and cost,   extended our evaluation with one more data LIAR\nwe select 10 prompts. Also, evaluating the con-   and one more model GPT-4o mini, as suggested by\nfidence of the entire training dataset is infeasible    the reviewer. As the results show, boundary case\nand expensive. To expedite the process and save    selection makes significant contribution to IPOMP.\ninference costs, we first select 200 examples from\n                                            A.5  Results of impact of hyper-parametersthe entire training data using the same approach\nof stage 1, and then apply Anchor-Point to select  We examine the impact of key hyper-parameters in\nthe final evaluation data. Prediction-based (Pac-  IPOMP: α which controls the proportion of sam-\nchiardi et al., 2024). This approach predicts the    ples selected based on semantic clustering in stage\nperformance of an instance on an LLM by train-    1, and K which controls the cluster size in stage 1,\ning a generic assessor based on the performance of   and β which determines the proportion of redun-\neach sample in the training set on existing LLMs.   dant samples to be replaced in stage 2. Figure 4\nWe adapt the generic assessor using our dataset,    presents the results of BIG-bench when using GPT-\nBIG-bench, on GPT-3.5, following the approach    3.5.\noutlined by (Pacchiardi et al., 2024). We then use     As α increases from 0.1 to 0.9, the accuracy\nthe trained assessor to predict the performance of    of IPOMP consistently improves across all three\neach example in the training dataset on a set of ini-   prompt optimization techniques. However, when\ntial prompts and subsequently cluster those exam-  α exceeds 0.9, the performance of APE, APE, and\nples based on their predicted performance, similar  EVOPROMPT degrades significantly. This obser-\nto the Anchor-Point.                                vation suggests that while incorporating a small\n                                                     portion of boundary cases can enhance the diversity\nA.3  Dataset statistics                                                     of the evaluation data and improve the performance\nThe sizes of the training and testing datasets used    of IPOMP, relying too heavily on boundary cases\nin our experiments are presented in Table 5.         can negatively impact the overall effectiveness (i.e.,\n                                  α < 0.9). In contrast, selecting samples purely\nA.4  Ablation analysis on boundary cases                                                based on semantic clustering results in suboptimal\n      selection                                               performance (i.e., α = 1).\nIn Stage 1: Diverse sample selection, we select      In terms of β, as it increases from 0.1 to 0.7, the\nboundary cases to diversify our samples. To un-   performance of the three prompt optimization tech-\nderstand the impact of the boundary case, we con-   niques improves gradually, particularly noticeable\nducted an ablation analysis on the boundary case    in the range from 0.1 to 0.3. For APO and EVO-\nand the results are shown in Table 6. Note that we   PROMPT, their performance still gets improved\n\nTable 6: Comparison of IPOMP and IPOMP without boundary cases.\n\n\n                     GPT-4o-mini- Big-Bench          GPT-4o-mini-LIAR              GPT-3.5-LIAR               GPT-3.5-Big-Bench\n\n                IPOMP     w/o Boundary    IPOMP     w/o Boundary    IPOMP     w/o Boundary    IPOMP     w/o Boundary\n\n  EVOPROMPT   0.758±0.011    0.732±0.026    0.838±0.011    0.834±0.035    0.818±0.015    0.785±0.029    0.776±0.017    0.759±0.042\n  APO            0.780±0.012    0.738±0.021    0.836±0.011    0.811±0.027    0.812±0.014    0.746±0.025    0.753±0.009    0.723±0.039\n  APE             0.794±0.012    0.749±0.026    0.827±0.013    0.790±0.037    0.832±0.011    0.766±0.027    0.742±0.010    0.715±0.031\n  Average          0.778±0.011    0.740±0.024    0.833±0.012    0.812±0.033    0.820±0.013    0.765±0.027    0.757±0.012    0.732±0.037\n\n\nTable 7: Comparison of the effectiveness (in terms of accuracy) and stability (in terms of deviation) of the studied\nprompt optimization approaches with different evaluation data sampling approaches on BIG-bench when using\nGPT-3.5.\n\n\n                         Size    Random      Boundary       Clustering     Anchor-Point    Prediction-based     IPOMP\n                      5     0.678±0.013    0.672±0.043    0.674±0.021    0.685↑±0.029     0.675±0.039      0.683±0.017↓\n                      10    0.702±0.031    0.714±0.029    0.708±0.019     0.720±0.015      0.704±0.032     0.722↑±0.010↓\n   APO             15    0.703±0.023    0.718±0.042    0.720±0.022     0.744±0.020      0.732±0.038     0.750↑±0.008↓\n                      20    0.691±0.040    0.718±0.052    0.723±0.025     0.750±0.020      0.743±0.042     0.753↑±0.009↓\n                      30    0.692±0.023    0.714±0.038    0.720±0.028     0.748±0.028      0.740±0.038     0.752↑±0.011↓\n                      5     0.693±0.022    0.677±0.024    0.688±0.023     0.702±0.021      0.698±0.029     0.708↑±0.019↓\n                      10    0.711±0.026    0.712±0.024    0.712±0.020     0.722±0.026      0.712±0.030     0.724↑±0.014↓\n    APE             15    0.727±0.041    0.708±0.042    0.702±0.032     0.728±0.032      0.690±0.042     0.736↑±0.013↓\n                      20    0.722±0.037    0.708±0.045    0.684±0.032     0.727±0.035      0.707±0.048     0.742↑±0.010↓\n                      30    0.719±0.035    0.710±0.040    0.698±0.034     0.727±0.033      0.710±0.032     0.740↑±0.012↓\n                      5     0.704 ±0.034   0.696±0.027    0.708±0.018     0.703±0.027      0.673±0.034     0.712↑±0.020↓\n                      10    0.729±0.029    0.730±0.026   0.740↑±0.032    0.736±0.018      0.712±0.020      0.732±0.017↓\n   EVOPROMPT    15    0.739±0.019    0.738±0.029    0.742±0.019     0.750±0.019      0.739±0.029     0.765↑±0.011↓\n                      20    0.743±0.028    0.757±0.022    0.759±0.031     0.774±0.028      0.758±0.025     0.776↑±0.017↓\n                      30    0.747±0.032    0.754±0.032    0.759±0.034    0.780↑±0.036     0.755±0.030      0.778±0.018↓\n\n\nuntil β reaches 0.7 and gets degraded after 0.7. For    Table 8: Comparison of five-number summary of corre-\n                                                                lation among the samples selected using different strate-APE, its performance degrades from 0.3 to 0.5,\n                                                                gies.\nand improves after 0.5. This enhancement is at-\ntributed to the replacement of redundant examples                     Min    Q1    Median    Q3    Max\nduring each iteration, which effectively increases              Similar       0.623    0.938     0.960     0.978    0.999\nthe diversity of the evaluation samples based on the          Random      0.002    0.418     0.634     0.882    0.943\n                                                                                         Dissimilar    0.002    0.109     0.400     0.480    0.681\nfeedback from the model in real-time.\n  We also investigate the impact of the cluster size\nK. As Figure 4 shows, the size of clusters does not       randomly selected samples from the training\nimpact the effectiveness of IPOMP significantly.           dataset.\n\nA.6  Detailed results of impact of sample size         • Similar: Replacing redundant samples with\nThe accuracy and standard deviation of prompt opti-        the most similar samples from the training\nmization techniques over different sizes of samples         dataset.\nselected by the studied approaches are presented in\n                                   We measured the correlation between the perfor-\nTable 7.\n                                         mance of the original samples and replaced sam-\nA.7  Impact of replacement strategy in Stage 2    ples using the above replacement strategies. The\n                                                         results shown in Table 8 confirm our hypothesis.\n. To verify our hypothesis that selecting dissimilar\n                                                This validates the importance of our replacement\nexamples yields significantly lower performance\n                                                       strategy in influencing model behavior.\ncorrelation compared to both random and similar\nselection, we conducted an ablation study to com-   A.8  Case study\npare three sample replacement strategies:\n                                                 Figure 5 presents the correlation among sam-\n                                                     ples before and after applying real-time model    • Dissimilar:  Replacing redundant samples\n                                               performance-guided refinement in APO. As we    with the most dissimilar samples from the\n                                              can observe, after the refinement, the redundancy     training dataset (our proposed method).\n                                                   of examples (correlation > 0.9) are significantly\n    • Random: Replacing redundant samples with   reduced from 19% to 10%.\n\nFigure 5: Correlation among samples before and after the first round of real-time model performance-guided\nrefinement in APO on the Implicatures dataset. Each cell represents the correlation between a pair of samples.\n\n\n  We present the selected examples in stage 1 and\nafter the first round of refinement in stage 2 below.\n\nSelected Examples by stage 1 of IPOMP\n\n\n• Example 1: Speaker 1: ’This is a costume?’ Speaker 2:  ’Aaaiyyyy... worked on it all night long!’\n\n• Example 2: Speaker 1: ’Do you love me?’ Speaker 2: ’My love for you is as deep as the ocean.’\n\n• Example 3: Speaker 1: ’Did you sleep well last night?’ Speaker 2: ’Last night, I slept like a log.’\n\n• Example 4: Speaker 1: ’Do you think that Dr. Luby will organize a theatre trip to New York this year?’\n  Speaker 2:  ’I have already signed up for  it.’\n\n• Example 5: Speaker 1: ’Did you report Private Barnes to your superiors?’ Speaker 2:  ’I remember\n  thinking very highly of Private Barnes, and not wanting to see his record tarnished by a formal charge.’\n\n• Example 6: Speaker 1:  ’I bought the wrong math book. Here is the receipt. Can I get my money back?’\n  Speaker 2: ’Not after ten days. But you can exchange something for  it.’\n\n• Example 7: Speaker 1: ’Does it bother you that your husband goes away on long business trips?’\n  Speaker 2: ’Absence makes the heart grow fonder.’\n\n• Example 8: Speaker 1: ’Did you order the code red?’ Speaker 2: ’You’re goddamn right.’\n\n• Example 9: Speaker 1: ’My client is taking me to a really fancy restaurant tonight. So I am wearing\n   this new cologne.  I got a sample of it from a magazine. Can you smell it?’ Speaker 2: ’From across the\n  room. But it is not exactly subtle.  Is it?’\n\n• Example 10: Speaker 1: ’Are you a Dodgers fan?’ Speaker 2:  ’I don’t like baseball.’\n\n• Example 11: Speaker 1:  ’Is everyone comfortable?’ Speaker 2: ’Everyone is on pins and needles.’\n\n• Example 12: Speaker 1:  ’I feel horrible. Debbie was furious that I lost her notes. Do you think I\n  should apologize to her again?’ Speaker 2:  ’If I were you, I would cool off for some days before I talk\n  to her again.’\n\n• Example 13: Speaker 1: ’Should I decide now?’ Speaker 2: ’Why don’t you go home and sleep on it?’\n\n• Example 14: Speaker 1: ’Did I do it well?’ Speaker 2: ’You were as brave as a lion.’\n\n• Example 15: Speaker 1: ’Are you coming with me to the exhibition today?’ Speaker 2:  ’I made plans\n  with Susan to go to the exhibition tomorrow afternoon.’\n\n• Example 16: Speaker 1: ’Does it rain here nowadays?’ Speaker 2:  ’It’s been raining for 40 days and\n  40 nights.’\n\n• Example 17: Speaker 1: ’Are you planning to buy a house?’ Speaker 2:  ’I really want a place to call\n  my own.’\n\n• Example 18: Speaker 1:  ’Is it a good product?’ Speaker 2: ’They had put a lot of thought into making\n    it.’\n\n• Example 19: Speaker 1:  ’Is that book about lullabies?’ Speaker 2:  ’It is about symphonies.’\n\n• Example 20: Speaker 1: ’But aren’t you afraid?’ Speaker 2: ’Ma’am, sharks never attack anybody.’\n\nSelected Examples after first round of refinment at stage 2.\n\n                 Here are selected examples from Stage 2 of our tool’s processing:\n\n• Example 1: Speaker 1: ’This is a costume?’ Speaker 2:  ’Aaaiyyyy... worked on it all night long!’\n\n• Example 2: Speaker 1: ’Do you love me?’ Speaker 2: ’My love for you is as deep as the ocean.’\n\n• Example 3: Speaker 1: ’Did you sleep well last night?’ Speaker 2: ’Last night, I slept like a log.’\n\n• Example 4: Speaker 1: ’My client is taking me to a really fancy restaurant tonight. So I am wearing\n   this new cologne.  I got a sample of it from a magazine. Can you smell it?’ Speaker 2: ’From across the\n  room. But it is not exactly subtle.  Is it?’\n\n• Example 5: Speaker 1:  ’I bought the wrong math book. Here is the receipt. Can I get my money back?’\n  Speaker 2: ’Not after ten days. But you can exchange something for  it.’\n\n• Example 6: Speaker 1:  ’I feel horrible. Debbie was furious that I lost her notes. Do you think I should\n  apologize to her again?’ Speaker 2:  ’If I were you, I would cool off for some days before I talk to her\n  again.’\n\n• Example 7: Speaker 1: ’Should I decide now?’ Speaker 2: ’Why don’t you go home and sleep on it?’\n\n• Example 8: Speaker 1: ’Are you planning to buy a house?’ Speaker 2:  ’I really want a place to call my\n  own.’\n\n• Example 9: Speaker 1:  ’Is that book about lullabies?’ Speaker 2:  ’It is about symphonies.’\n\n• Example 10: Speaker 1: ’Are you angry at me?’ Speaker 2: ’To err is human, to forgive divine.’\n\n• Example 11: Speaker 1: ’Does it rain here nowadays?’ Speaker 2:  ’It’s been raining for 40 days and\n  40 nights.’\n\n• Example 12: Speaker 1: ’That cake looks delicious. Aren’t you going to have some with me?’ Speaker\n  2:  ’I am watching my calorie intake.’\n\n• Example 13: Speaker 1: ’Does she know how to play the piano?’ Speaker 2: ’Now it is like second\n  nature to her.’\n\n• Example 14: Speaker 1: ’Do you have these journals?’ Speaker 2:  ’I can have them flown here from\n  Geneva in an hour.’\n\n• Example 15: Speaker 1: ’Do you have any agricultural background?’ Speaker 2:  ’I used to work in an\n   office.’\n\n• Example 16: Speaker 1: ’Do you have field hands that help you?’ Speaker 2: ’We work the land alone.’\n\n• Example 17: Speaker 1:  ’I feel horrible. Debbie was furious that I lost her notes. Do you think I\n  should apologize to her again?’ Speaker 2:  ’If I were you, I would cool off for some days before I talk\n  to her again.’\n\n• Example 18: Speaker 1: ’You have  it, then?’ Speaker 2:  ’I had to slit a few throats to get  it.’\n\n• Example 19: Speaker 1: ’Were you hiding from me?’ Speaker 2:  ’I didn’t want to scare you.’\n\n• Example 20: Speaker 1: ’Are you coming with me to the exhibition today?’ Speaker 2:  ’I made plans\n  with Susan to go to the exhibition tomorrow afternoon.’",
"headers": [
"arXiv:2505.10736v3  [cs.CL]  18 Aug 2025",
"Optimization",
"Model Performance-Guided Evaluation Data Selection for Effective Prompt",
"Ximing Dong",
", Shaowei Wang",
", Dayi Lin",
", Ahmed E. Hassan",
"Centre for Software Excellence, Huawei, Canada",
"Department of Computer Science, University of Manitoba, Canada",
"School of Computing, Queen’s University, Canada",
"{ximing.dong,dayi.lin}@huawei.com, shaowei.wang@umanitoba.ca, ahmed@cs.queensu.ca",
"Abstract",
"1",
"Introduction",
"2",
"Background and related work",
"3",
"Methodology",
"4",
"Experimental Setting",
"5",
"Results",
"6",
"Conclusion",
"7",
"Limitations",
"References",
"A",
"Appendix"
],
"tables": [
"|Col1|GPT-3.5 - BIG-bench|GPT-4o-mini - BIG-bench|\n|---|---|---|\n||**Random**<br>**Boundary**<br>**Clustering**<br>**Anchor-Point**<br>**Prediction-based**<br>**IPOMP**|**Random**<br>**Boundary**<br>**Clustering**<br>**Anchor-Point**<br>**Prediction-based**<br>**IPOMP**|\n|**EVOPROMPT**<br>**APO**<br>**APE**<br>**Average**|0.743_±_0.028<br>0.757_±_0.022<br>0.759_±_0.031<br>0.774_±_0.028<br>0.758_±_0.025<br>**0.776**_↑±_**0.017**_↓_<br>0.691_±_0.040<br>0.718_±_0.052<br>0.723_±_0.025<br>0.750_±_0.020<br>0.743_±_0.042<br>**0.753**_↑±_**0.009**_↓_<br>0.722_±_0.037<br>0.708_±_0.045<br>0.684_±_0.032<br>0.727_±_0.035<br>0.707_±_0.048<br>**0.742**_↑±_**0.010**_↓_<br>0.719_±_0.035<br>0.727_±_0.040<br>0.725_±_0.029<br>0.745_±_0.028<br>0.725_±_0.038<br>**0.757**_↑±_**0.012**_↓_|0.694_ ±_ 0.047<br>0.715_ ±_ 0.042<br>0.706_ ±_ 0.037<br>0.756_ ±_ 0.026<br>0.709_ ±_ 0.047<br>**0.758**_↑±_**0.011**_↓_<br>0.703_ ±_0.038<br>0.72_±_ 0.043<br>0.701_ ±_ 0.022<br>0.743_±_ 0.032<br>0.690_ ±_0.043<br>**0.780**_↑±_**0.012**_↓_<br>0.717_ ±_ 0.040<br>0.734_ ±_ 0.030<br>0.770_ ±_ 0.030<br>0.770_ ±_ 0.023<br>0.716_ ±_ 0.042<br>**0.794**_↑±_**0.012**_↓_<br>0.704_±_ 0.041<br>0.723_ ±_ 0.038<br>0.725_ ±_ 0.029<br>0.756_ ±_ 0.027<br>0.705_ ±_ 0.044<br>**0.778**_↑±_**0.011**_↓_|\n||**GPT-3.5 - LIAR**|**GPT-4o-mini - LIAR**|\n||**Random**<br>**Boundary**<br>**Clustering**<br>**Anchor-Point**<br>**Prediction-based**<br>**IPOMP**|**Random**<br>**Boundary**<br>**Clustering**<br>**Anchor-Point**<br>**Prediction-based**<br>**IPOMP**|\n|**EVOPROMPT**<br>**APO**<br>**APE**<br>**Average**|0.753_ ±_ 0.042<br>0.798_ ±_ 0.037<br>0.772_ ±_ 0.035<br>0.810_ ±_ 0.030<br>0.734_ ±_ 0.043<br>**0.818**_↑±_**0.015**_↓_<br>0.732_ ±_ 0.039<br>0.792_ ±_0.032<br>0.731_ ±_ 0.031<br>0.794_ ±_ 0.028<br>0.754_ ±_ 0.038<br>**0.812**_↑±_**0.014**_↓_<br>0.743_ ±_ 0.043<br>0.721_ ±_ 0.035<br>0.753_ ±_ 0.042<br>0.801_ ±_ 0.023<br>0.748_ ±_ 0.037<br>**0.832**_↑±_**0.011**_↓_<br>0.742_ ±_ 0.041<br>0.770_ ±_ 0.035<br>0.752_ ±_ 0.036<br>0.801_ ±_ 0.027<br>0.746_ ±_ 0.039<br>**0.820**_↑±_**0.012**_↓_|0.756_ ±_ 0.045<br>0.806_ ±_ 0.041<br>0.782_ ±_ 0.037<br>0.816_ ±_ 0.026<br>0.754_ ±_ 0.043<br>**0.838**_↑±_**0.012**_↓_<br>0.746_ ±_ 0.059<br>0.792_ ±_ 0.061<br>0.776_ ±_ 0.037<br>0.806_ ±_ 0.022<br>0.754_ ±_ 0.048<br>**0.836**_↑±_**0.013**_↓_<br>0.746_ ±_ 0.04<br>0.792_ ±_ 0.039<br>0.808_ ±_ 0.042<br>0.8_ ±_ 0.025<br>0.742_ ±_ 0.04<br>**0.826**_↑±_**0.011**_↓_<br>0.748_ ±_ 0.048<br>0.797_ ±_ 0.047<br>0.788_ ±_ 0.038<br>0.807_ ±_ 0.024<br>0.75_ ±_ 0.043<br>**0.833**_↑±_**0.012**_↓_|",
"|Col1|GPT-3.5 - BIG-bench|GPT-4o-mini - BIG-bench|\n|---|---|---|\n||**IPOMP**_Stage_1<br>**IPOMP**_Random_<br>**IPOMP**|**IPOMP**_Stage_1<br>**IPOMP**_Random_<br>**IPOMP**|\n|**EVOPROMPT**<br>**APO**<br>**APE**<br>**Average**|0.745_±_0.029<br>0.751_±_0.021<br>**0.776**_±_**0.017**<br>0.730_±_0.031<br>0.738_±_0.015<br>**0.753**_±_**0.009**<br>0.724_±_0.042<br>0.723_±_0.027<br>**0.742**_±_**0.010**<br>0.733_±_0.034<br>0.737_±_0.021<br>**0.757**_±_**0.012**|0.737_±_0.014<br>0.754_±_0.012<br>**0.758**_±_**0.011**<br>0.739_±_0.012<br>0.757_±_0.012<br>**0.780**_±_**0.012**<br>0.754_±_0.012<br>0.705_±_0.013<br>**0.794**_±_**0.012**<br>0.743_±_0.012<br>0.738_±_0.012<br>**0.778**_±_**0.011**|\n||**GPT-3.5 - LIAR**|**GPT-4o-mini - LIAR**|\n||**IPOMP**_Stage_1<br>**IPOMP**_Random_<br>**IPOMP**|**IPOMP**_Stage_1<br>**IPOMP**_Random_<br>**IPOMP**|\n|**EVOPROMPT**<br>**APO**<br>**APE**<br>**Average**|0.802_±_0.019<br>0.807_±_0.017<br>**0.818**_±_**0.015**<br>0.801_±_0.021<br>0.812_±_0.018<br>**0.812**_±_**0.014**<br>0.812_±_0.018<br>0.829_±_0.013<br>**0.832**_±_**0.011**<br>0.805_±_0.020<br>0.816_±_0.016<br>**0.820**_±_**0.013**|0.820_±_0.015<br>0.809_±_0.014<br>**0.838**_±_**0.011**<br>0.797_±_0.022<br>0.824_±_0.015<br>**0.836**_±_**0.011**<br>0.801_±_0.014<br>0.826_±_0.015<br>**0.827**_±_**0.013**<br>0.806_±_0.017<br>0.820_±_0.015<br>**0.833**_±_**0.012**|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2505.10736v3.pdf"
}