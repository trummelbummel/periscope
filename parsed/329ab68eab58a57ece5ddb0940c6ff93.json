{
"text": "PROMPTWIZARD:\n          TASK-AWARE PROMPT OPTIMIZATION FRAMEWORK\n\n\n                    Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu, Akshay Nambi\n                        Microsoft Research India\n                      Corresponding author: akshayn@microsoft.com\n\n\n\n                                       ABSTRACT\n\n                             Large language models (LLMs) have transformed AI across diverse domains, with\n                             prompting being central to their success in guiding model outputs. However, man-\n                                 ual prompt engineering is both labor-intensive and domain-specific, necessitating2024\n                                the need for automated solutions. We introduce PromptWizard, a novel, fully\n                            automated framework for discrete prompt optimization, utilizing a self-evolving,\n                                 self-adapting mechanism. Through a feedback-driven critique and synthesis pro-Oct\n                                  cess, PromptWizard achieves an effective balance between exploration and ex-\n3                             ploitation, iteratively refining both prompt instructions and in-context examples to\n                               generate human-readable, task-specific prompts. This guided approach systemati-\n                                  cally improves prompt quality, resulting in superior performance across 45 tasks.\n                           PromptWizard excels even with limited training data, smaller LLMs, and various\n                   LLM architectures. Additionally, our cost analysis reveals a substantial reduction in\n                         API calls, token usage, and overall cost, demonstrating PromptWizard’s efficiency,\n                                     scalability, and advantages over existing prompt optimization strategies.[cs.CL]\n\n                1  INTRODUCTION\n\n                     Large language models (LLMs) like GPT-4 (OpenAI et al., 2024) have achieved remarkable per-\n                    formance across diverse tasks (Colombo et al., 2024; Nguyen et al., 2023; Zhang et al., 2024). At\n                       the core of this success is prompting—the process of providing input instructions to guide models\n                     toward desired outputs. Studies have shown that prompting significantly influences LLM perfor-\n                     mance, making prompt engineering—the design and refinement of prompts—critical for maximizing\n                      accuracy (Wang et al., 2023c;b; Nori et al., 2023). However, crafting effective prompts remains a\n                        labor-intensive and domain-specific task, requiring human expertise and subjective judgment. As\n                    models evolve and tasks vary, the need to repeatedly design prompts raises an important question:\n                 Can prompt engineering be automated to streamline this process and enhance scalability?\n\n                      Automatically generating optimal prompts is a key challenge in the era of LLMs (Pryzant et al.,\n                     2023; Zhou et al., 2023). Some approaches, such as gradient-based methods, have been used to\n                      optimize prompts by leveraging token probabilities and model gradients (Deng et al., 2022; ZhangarXiv:2405.18369v2\n                            et al., 2022a). However, these methods are limited to white-box (open-source) models, as they require\n                         direct access to the model’s internal mechanics (Liu et al., 2023). The most powerful LLMs today,\n                          like GPT-4 and Gemini, are typically black-box (closed-source) and accessible only through APIs,\n                   making such techniques impractical and are often resource-intensive.\n\n                      This necessitates gradient-free prompt optimization strategies. Recent methods have focused on enu-\n                      merating diverse prompts or refining existing ones to optimize instructions for black-box LLMs (Zhou\n                          et al., 2023; Lin et al., 2024; Chen et al., 2023; Fernando et al., 2023; Guo et al., 2024). These\n                         strategies can be broadly classified into two types: continuous and discrete prompt optimization.\n                    Continuous approaches, like InstructZero (Chen et al., 2023) and Instinct (Lin et al., 2024), convert\n                    prompt optimization into a continuous problem by using soft prompts. These soft prompts are fed to\n                      open-source LLMs to generate instructions, which are then evaluated by the target black-box LLM.\n                  The feedback is used to train a Bayesian optimizer (BO) or neural network (NN) to predict better\n                          instructions. However, these methods require additional training of NNs and their performance often\n                         varies based on the open-source model and task complexity. For more complex tasks, learning the op-\n                        timal prompt-performance mapping becomes challenging. On the other hand, discrete methods like\n                     PromptBreeder (Fernando et al., 2023) and EvoPrompt (Guo et al., 2024) generate multiple prompt\n\n\n                                                           1\n\nInput                       PromptWizard                                       Final Prompt\n                                                              Sequential                                 Problem\n                 Problem                                      Optimization                                   Description\n                  Description\n\n                                     Iterative     Modified Prompt        Instruction    Optimized                        Optimized\n                           Refinement      Instruction         Optimization    Prompt   Self-generated         Prompt                 Prompt\n                   Instruction       of Prompt                                              Reasoning and         Optimized\n                               Instructions                                                         Validation         Few-shot with\n                                                      Diverse            Synthetic     Synthesized                       reasoning\n                    Training                        Examples         Example      Examples                      Task Intent +\n                Examples                           Selection         Generation                                   Expert Persona\n\n\n                     Figure 1: Overview of PromptWizard framework.\n\nversions using evolutionary or self-referential strategies. While these methods expand exploration by\nscoring prompts, they lack feedback mechanisms, leading to inefficient and suboptimal exploration.\n\nIn this paper, we propose PromptWizard (PW), a discrete prompt optimization framework for\nblack-box LLMs. PromptWizard employs a self-evolving mechanism where the LLM generates,\ncritiques, and refines its own prompts and examples, continuously improving through iterative\nfeedback and synthesis. This self-adaptive approach ensures holistic optimization by evolving both\nthe instructions and in-context learning examples for better task performance. PromptWizard\noperates in two phases: (i) Prompt generation (one-time), where it processes a high-level problem\ndescription and training samples, using LLMs to mutate, score, critique, synthesize, reason, and\nvalidate prompts and examples; (ii) Inference (test-time), where the final optimized prompt and\nexamples are applied to test samples.\nPW’s approach follows a structured strategy (See Figure 1): ➊First, starting with a problem\ndescription and initial prompt instruction, PW generates variations of the instruction by prompting\nLLMs to mutate it. Based on performance, the best prompt is selected. Unlike uncontrolled evolutions\nin prior methods (Fernando et al., 2023; Guo et al., 2024), PW incorporates a critique component\nthat provides feedback, thus guiding and refining the prompt over multiple iterations. ➋Unlike other\ndiscrete approaches, PW also optimizes in-context examples. PW selects a diverse set of examples\nfrom the training data, identifying positive and negative examples based on their performance with\nthe modified prompt. Negative examples help inform further prompt refinements. ➌Examples and\ninstructions are sequentially optimized, using the critique to generate synthetic examples that address\nthe current prompt’s weaknesses. These examples are integrated to further refine the prompt. ➍PW\ngenerates detailed reasoning chains via Chain-of-Thought (CoT), enriching the prompt’s capacity for\nproblem-solving. ➎PW aligns prompts with human reasoning by integrating task intent and expert\npersonas, enhancing both model performance and interpretability.\n\nOur work distinguishes itself from previous approaches in several key aspects:  1. Guided Explo-\nration: PromptWizard introduces a feedback-driven critique-and-synthesis mechanism, refining\nprompts based on performance insights. This guided exploration systematically improves prompt\nquality, overcoming the randomness and inefficiencies in methods like PromptBreeder (Fernando\net al., 2023), OPRO (Yang et al., 2024), and EvoPrompt (Guo et al., 2024)(Section 3.1). 2. Sequen-\ntial Optimization of Instructions and Examples: PromptWizard dynamically and iteratively\noptimizes both prompt instructions and in-context examples in tandem, outperforming methods that\noptimize these components in isolation. This strategy allows deeper exploitation of task-specific\nnuances, leading to superior prompt quality (Section 3.3). 3. Efficient Example Synthesis & Error\nAnalysis: PromptWizard enhances efficiency by utilizing a compact set of diverse examples (up\nto 25) and leveraging error-driven self-reflection to generate synthetic examples. Combined with\nChain-of-Thought reasoning, this approach offers robust and scalable prompt refinement, setting it\napart from existing methods (Section 3.4).\n\nWe evaluate the effectiveness of PromptWizard on the widely-used Big Bench Instruction Induc-\ntion (BBII), Big Bench Hard (BBH), and arithmetic reasoning datasets, covering over 45 tasks\nranging from general reasoning to domain-specific challenges (Section 4). As shown in Fig-\nure 2, PromptWizard consistently outperforms state-of-the-art approaches, including Instinct,\nInstructZero, APE, PromptBreeder, and EvoPrompt on the BBII dataset.\n\nThrough extensive experimentation, we demonstrate that PromptWizard consistently outper-\nforms SOTA baselines in both zero-shot and few-shot scenarios, while maintaining superior ef-\nficiency (Section 5.1). Our comprehensive cost analysis highlights the significant reduction in\n\n\n                                       2\n\nAPI calls, token usage, and overall expenses, showcasing PW’s ability to deliver high-quality\nprompts with minimal computational cost (Section 5.2). Furthermore, we conduct numerous ex-\nperiments to showcase PromptWizard’s efficacy with limited training data and smaller LLMs,\nalong with ablation studies that assess its performance across different base LLMs (Section 6).\nOur  main  contributions  are:     (i)  we  introduce\n                                                                                         1.0\nPromptWizard,  a novel framework for automatic\ndiscrete prompt  optimization  using  a  self-evolving,        0.8\nself-adapting mechanism.   Through feedback-driven\n                           ) 0.6\ncritique and synthesis process, PW strikes an effective  (\nbalance between exploration and exploitation, iteratively         0.4                                  APEInstructZero\nrefining both prompt instructions and in-context examples.                                                   PromptBreederEvoPrompt\n                                                                                         0.2                                      INSTINCTThus generating human-readable, task-specific prompts,\n                                                                                                                                                 PromptWizard\n(ii) we demonstrate PW’s superior performance and                                                                                             0.0        0.1        0.2        0.3\nefficiency across 45 tasks, outperforming SOTA methods.\n                                                      Figure 2: Performance profile curve of\n2  RELATED WORK                      PromptWizard over other baselines\n                                                         (Section 5.1, Appendix 11).\nResearch in prompt optimization has increasingly shifted\ntoward automating prompt creation due to the limitations\nof handcrafted prompts (Moradi & Samwald, 2021; Madaan & Yazdanbakhsh, 2022; Wei et al., 2022).\nRecent work has introduced various techniques for automating prompt generation, broadly classified\ninto continuous and discrete (Yang et al., 2024; Guo et al., 2024). Below, we examine these methods,\ntheir limitations, and how PromptWizard (PW) advances the field.\n\nContinuous Prompt Optimization. Continuous methods, such as InstructZero (Chen et al., 2023)\nand Instinct (Lin et al., 2024), treat prompt optimization as a continuous learning problem using soft\nprompts—trainable vectors that fine-tune responses from open-source LLMs. These soft prompts are\nused to generate responses, with feedback guiding the optimization through models like Bayesian\noptimizers or neural networks. While flexible, these methods face several key limitations: (i) They\nrequire additional neural network training, leading to high computational costs, (ii) Their adaptability\nto complex tasks that need nuanced prompts is limited, as soft prompts are not human-interpretable\nand struggle to capture the depth of task-specific reasoning, (iii) For more intricate tasks, such as\narithmetic reasoning, mapping the relationship between prompt structure and performance becomes\nchallenging, often leading to suboptimal or inconsistent results. Thus, while continuous methods\nimprove prompt generation, their scalability and interpretability in complex tasks remain non-trivial.\n\nDiscrete Prompt Optimization. Discrete methods focus on exploration by generating multiple\nprompt versions and selecting the best among candidates. These methods rely on strategies like Monte\nCarlo searches or evolutionary processes. For example, APE (Zhou et al., 2023) iteratively proposes\nand selects optimal prompts through a Monte Carlo search, while PromptBreeder (Fernando et al.,\n2023) mutates prompts using different thinking styles, evolving prompts in a self-referential manner.\nOther methods, such as OPRO (Yang et al., 2024) and EvoPrompt (Guo et al., 2024), rely on prompt\nmutations, evolutionary algorithms and evaluations on fixed training samples. However, discrete\nmethods have notable drawbacks: (i) They are often query-inefficient due to their reliance on local\nsearch techniques, which fail to balance exploration and exploitation effectively, (ii) These methods\ntend to explore the prompt space randomly or through mutations without a structured mechanism for\nfeedback, resulting in suboptimal and unguided refinement of prompts. Recent methods optimize\nboth instructions and examples in prompting, emphasizing the importance of example selection\nthrough random or diversity-based or adversarial techniques (Do et al., 2024; Wan et al., 2024). In\ncontrast, PW uses a LLM to analyze and synthesize examples, dynamically enhancing prompt quality\nand outperforming traditional fixed-criteria strategies.\n\nComparison and Motivation for PromptWizard. PromptWizard (PW) advances beyond these\nlimitations by introducing a self-evolving and self-adaptive mechanism that better balances explo-\nration and exploitation. Unlike prior methods, PW utilizes a feedback-driven critique-and-synthesis\nprocess, which iteratively refines both prompt instructions and in-context examples. This feedback\nloop, guided by performance insights, leads to more systematic and efficient exploration compared to\nrandom or mutation-based strategies like those employed by PromptBreeder and EvoPrompt. Key\nadvantages of PW include: (i) Deeper Exploitation of Task Nuances: By optimizing prompts and\nexamples together, PW can capture the nuanced requirements of complex tasks that continuous\nand discrete methods often miss, (ii) Human-Interpretable and Scalable: Unlike soft prompts, PW\n\n\n                                       3\n\nThinking                                                                                     SEQUENTIAL OPTIMIZATION OF INSTRUCTION AND EXAMPLES\n             Styles                                     Training        ITERATIVE                                   Negative Examples                                                Synthesized Examples\n          How can I simplify                    Examples\n                the problem ?                            Mini Batch of OPTIMIZATION OF                                                                         Critique /\n         Problem                           K Examples    INSTRUCTION                                                               Feedback\n         Description\n                                                                                                                           Critique          Synthesize\n\n                                                                Top Prompts     Score\n    Prompt Instruction                                                                                                                       0.8                                                                                                            of an                                                                                           approach                                                                                                                                                                                          ....\n                        Mutate                                     N Mutated     Score        Think\n                                                      Instructions                                                                                                                                                                                                             Critique /                                                                                                                 0.75                                                                                   Analyse                                                                                                                      this                                                                                             problem ....\n                                                                                   Solve the given problem..     0.6                                                            Feedback\n                 Improved                                                Critique /                        Lets approach this logically     0.85                 Prompt                Feedback                                                                                                                           Synthesize         Critique\n                   Instruction                                                      Lets think step by step ....     0.4                                Optimized                                                       Modified Instruction\n                       Synthesize              Critique                                                                            Instruction\n\n\n  Figure 3: Iterative Optimization of Prompt Instruction.       Figure 4: Sequential Optimization.\n\ngenerates human-readable prompts that align with task intent, making it more interpretable and\neasier to scale across diverse applications, (iii) Efficiency: PW is significantly cost-efficient, reducing\nthe number of API calls and token usage while delivering superior performance. Evaluated across\nover 45 complex tasks, PW consistently outperforms state-of-the-art approaches, such as Instinct,\nInstructZero, APE, EvoPrompt and PromptBreeder.\n\nIn summary, PW advances prompting by addressing the exploration-exploitation trade-off more\neffectively than prior approaches, delivering higher-quality prompts with less computational overhead.\n\n3  PROMPTWIZARD FRAMEWORK\nWe introduce PromptWizard (PW), a general-purpose framework designed to optimize prompts\nthrough a self-evolving and self-adapting mechanism (see Figure 1). PW harnesses the capabilities of\nLLMs to iteratively synthesize, critique, and refine both prompt instructions and in-context examples,\ntailoring them to specific tasks across diverse domains. The five key steps are described next.\n\nProblem Formulation. In our approach, we start with an initial prompt instruction P e.g., “Let’s\nthink step by step to arrive at the solution of this mathematical problem\"), along with a problem\ndescription and a set of training samples represented as (Q, A) = {(qi, ai)}Ni=1, where qi and ai are\ninput-output pairs (questions and answers). The LLM model L generates outputs with probabilities\npl(ai | qi, P, af, qf), where qf and af are the few-shot examples. The goal of PromptWizard\nis to iteratively optimize both the prompt and the few-shot examples to maximize task accuracy A,\nwhich represents the model’s performance on the target task. The refined prompt ˆP should improve\nthe model’s ability to generate accurate outputs.\n\n3.1  ITERATIVE REFINEMENT OF PROMPT INSTRUCTIONS\n\nThe first step of the PromptWizard framework focuses on refining prompt instructions through a\nsystematic, feedback-driven process. This ensures the prompt evolves in a targeted way, addressing\nspecific task needs while avoiding unnecessary changes (see Figure 3).\n\n1. MutateComponent: PW starts with an initial problem description and generates prompt\n   variations using predefined cognitive heuristics or thinking styles. These heuristics guide the LLM\n   to create diverse perspectives on the problem, ensuring varied and rich prompt instructions. For\n   example, the thinking styles might encourage questions like \"How can I simplify the problem?\" or\n   \"What alternative perspectives exist?\" This targeted generation of mutations improves the diversity\n   of prompt instructions compared to random approaches. By using a single LLM call to generate\n   several mutated prompts, PW ensures computational efficiency. Figure 5 shows examples of\n   mutated prompts for an initial problem description on the GSM8K.\n2. ScoringComponent: Next, PW employs a scoring mechanism to evaluate the performance of\n   the generated mutated prompts. The scoring is based on how well each prompt performs against\n   a mini-batch of 5 training examples with ground truth. The scoring mechanism can be either\n   using traditional metrics like F1 score or an LLM as an evaluator, PW supports both. This helps\n   systematically identify the most effective prompt while filtering out underperforming ones. The\n   use of multiple mini-batches ensures robustness in the evaluation. Examples of mutated prompts\n   with their scores are shown in Figure 3 and 5.\n3. CritiqueComponent: Once the best-performing mutated prompt is selected, PW introduces\n   a unique feedback mechanism through its critique component. The critique reviews where the\n   prompt succeeded and failed by analyzing cases where the LLM struggled, such as interpreting\n\n\n                                       4\n\nEXAMPLES:\n   TOP 3 MUTATED PROMPTS :                                                                     [Question]:large pizzas Albertand 2 issmallwonderingpizzas. Ahowlargemuchpizzapizzahashe16 cansliceseatandin onea smallday.pizzaHe buyshas 28\n     \" Let's devise a step-by-step experiment to reach the solution of this mathematical problem.\"            slices. If he eats it all, how many pieces does he eat that day?\n     \" Let's simplify and tackle this mathematical problem step by step to make it easier to solve. \"         [Answer]: He eats 32 from the largest pizzas because 2 x 16 = <<2*16=32>>32. He\n     \" Let's list out ideas and apply them one by one, thinking step by step, to solve mathematical          eatsbecause16 from32 + 16the= small<<32+16=48>>48.pizza becauseThe2 answerx 8 = is<<2*8=16>>16.48.        He eats 48 pieces\n    problems. \"\n                                                                                     CRITIQUE/FEEDBACK :\n   TOP SCORED PROMPT:                                                                               ThisIt's relevantexampleandis simplerelatableandtostraightforward,students. However,involvingit couldbasicbemultiplicationimproved byandaddingaddition.a bit\n    \"Provide question answering on mathematical school grade questions that require multi-step        more complexity, such as introducing fractions or percentages.\\n\\n\n    reasoning. The problems should take between 2 and 8 steps to solve, and solutions              SYNTHETIC EXAMPLES:\n    primarily involve performing a sequence of elementary calculations using basic arithmetic            [Question]: Albert buys a pizza that is cut into 8 slices. He eats 3 slices and gives 2\n    operations (+ - / *) to reach the final answer.\\nLets think step by step to arrive at the solution           slicesit. Howtomanyhis friend.slicesHeof pizzathen buysdoesanotherAlbert havepizzaleft?that is cut into 12 slices and eats half of\n    of this mathematical problem\",                                                                     [Answer]: From the first pizza, Albert has 8 - 3 - 2 = <<8-3-2=3>>3 slices left. From\n                                                                                                                 the second pizza, Albert eats 12 / 2 = <<12/2=6>>6 slices, so he has 12 - 6 = <<12-\n   CRITIQUE/FEEDBACK :                                                               6=6>>6 slices left.\\nIn total, Albert has 3 + 6 = <<3+6=9>>9 slices of pizza left. The\n     Firstly, the instruction doesn't specify the need for the agent to understand the problem             answer is 9.\n    context, such as interpreting relationships. Secondly, the instruction lacks clarity on the\n    agent's ability to handle percentages and real-world scenarios. Understanding sequences of     Figure 6: Synthetic Example Generation.\n    actions and their impact are crucial. Lastly, the instruction doesn't mention the agent's ability\n    to handle time conversions, such as converting an hourly rate to a per-minute rate.              EXPERT IDENTITY :\n                                                                                           You are a mathematics educator with a deep understanding of elementary and middle\n  REFINED PROMPT:                                                                                schooltechniquesmathematics.and have Youa knackare experiencedfor breaking indownteachingcomplexmulti-stepproblemsproblem-solvinginto manageable\n   Provide question answering on mathematical school grade problems that require multi-step          steps. Your expertise lies in basic arithmetic operations such as addition, subtraction,\n   reasoning and understanding of the problem's context. The problems should take between 2          multiplication,mathematical problemsand division.thatYourequirecan multi-stepprovide clear,reasoning.step-by-stepYou aresolutionspatient toand thorough,\n   and 8 steps to solve, and solutions primarily involve performing a sequence of elementary           ensuring that each step is clearly explained and understood. Your ability to simplify\n    calculations using basic arithmetic operations (+ - / *), handling percentages, and converting        complexan excellentproblemsresourceandforguideansweringstudentsschool-gradethrough themathematicalproblem-solvingquestions.process makes you\n   them into numbers. The agent should be able to interpret real-world scenarios and\n   understand the implications of the problem, including handling time conversions. The agent        INTENT :MathematicalOperations, DataReasoning,Analysis,Multi-stepSolution VerificationProblem Solving, Basic Arithmetic\n   should also be able to follow a sequence of actions and their impact on the final answer. Let's\n    think step by step to arrive at the solution of this mathematical problem.\n                                                    Figure 7: Task Intent and Expert Persona.\n       Figure 5: Iterative Prompt Refinement.\n\n   relationships or time conversions in GSM8k example. This targeted feedback is critical in refining\n   the prompt, as it provides insights into specific weaknesses, allowing for focused improvements\n   rather than general changes. Example of critique feedback on the mutated prompt are in Figure 5.\n4. SynthesizeComponent: Finally, PW synthesize component uses the critique’s feedback to\n   refine the best prompt. It rephrases and enhances the instruction based on the critique, producing\n   a more task-specific and optimized prompt. For example, the feedback indicated issues with\n   interpreting specific relationships, the synthesized prompt would address that directly, leading to a\n   clearer, more effective instruction (see Figure 5).\n\nBy combining these steps—mutation, scoring, critique, and synthesis—PW ensures that the prompts\nare not only diverse and creative but also highly tailored to the specific task at hand, outperforming\nprior methods that lack this guided refinement process.\n\n3.2  IDENTIFICATION OF DIVERSE EXAMPLES\n\nNext, we focus on identifying a diverse set of candidate examples to enhance prompt effectiveness.\nThe choice of examples is critical, as diverse representations allow LLMs to better grasp various\naspects of the information presented (Rubin et al., 2022; Zhang et al., 2022b; Liu et al., 2022; Chen\net al., 2024). We begin by extracting candidate examples from the dataset and employ a scoring\nmechanism to assess the current prompt’s effectiveness against these examples, classifying them into\npositive and negative categories. Positive examples demonstrate where the prompt succeeds, while\nnegative examples highlight areas for improvement. We randomly select 25 examples and iterate\nthrough them to find a targeted number of effective few-shot examples, typically taking five iterations.\nIf this process does not yield the desired count, we randomly select five examples from the initial 25.\nThis targeted approach maximizes efficiency by minimizing the need to evaluate the entire dataset,\nensuring that the chosen examples effectively contribute to refining the prompt. The use of both\npositive and negative examples allows for comprehensive understanding and refinement of prompts.\n\n3.3  SEQUENTIAL OPTIMIZATION OF PROMPT INSTRUCTIONS AND FEW-SHOT EXAMPLES\n\nMost existing prompt optimization methods focus on either prompt instructions or few-shot examples.\nIn contrast, PromptWizard (PW) employs a sequential optimization approach that integrates both,\nenhancing task performance by optimizing them in tandem.\nFew-shot   example   optimization   follows    critique-and-synthesis    process:         (i)\nCritiqueComponent: PW analyzes previously selected examples,  utilizing  critique to\nprovide detailed feedback. This feedback is based on error-driven self-reflection, that determines how\nexamples should evolve to be more diverse and task-relevant. (ii) SynthesizeComponent: This\nincorporates feedback from the Critique to generate new synthetic examples that are more diverse,\nrobust, and task-relevant. Figure 6 demonstrates the critique’s feedback on a example alongside the\nnewly generated synthetic examples.\n\n\n                                       5\n\nPrompt optimization follows  critique-and-synthesis  process:   (i) CritiqueComponent:\nThe newly generated synthetic examples are evaluated alongside the current prompt.  The\nCritiqueComponent identifies weaknesses and gaps that require addressing to further refine\nthe prompt instruction. (ii) SynthesizeComponent: This leverages feedback from the critique\nto synthesize and refine the prompt instruction. This iterative feedback loop facilitates continuous\nrefinement of both the prompt and the synthetic few-shot examples, ensuring they remain aligned\nwith task-specific nuances.\n\n3.4  SELF-GENERATED REASONING AND VALIDATION\n\nWith the optimized prompt and few-shot examples, we further enhance model performance by in-\ncorporating chain-of-thought (CoT) reasoning. Building on the hypothesis that reasoning chains\nimprove problem-solving abilities of the model (Wei et al., 2023; Wang et al., 2023a; Ye et al.,\n2023). Specifically, we automatically generate a detailed reasoning chain for each selected few-shot\nexamples. (i) ReasoningComponent: This takes the selected few-shot examples and generates a\ndetailed reasoning chain for each example to facilitate problem-solving. (ii) ValidateComponent:\nThe validation component uses an LLM to check the coherence and relevance of examples (ques-\ntions,reasoning). This process effectively filters out incorrect examples and/or hallucinated reasoning.\n\n\n3.5  INTEGRATION OF TASK INTENT AND EXPERT PERSONA\n\nTo enhance task performance, PW integrates task intent and an expert persona into prompts (Figure 7).\n(i) Task Intent: This ensures that the model stays aligned with task requirements, particularly\nin specialized domains. By incorporating specific hints or keywords (Sun et al., 2023), derived\nfrom the problem description, PW guides the model to apply relevant approaches. We generate\nthese cues using SynthesizeComponent, informed by initial problem description. (ii) Expert\nPersona: To maintain consistency and relevance in LLM interactions, we incorporate an expert\npersona into prompts (Xu et al., 2023). To maintain consistency, PW introduces an expert persona,\npreventing response variability. This persona is generated based on the problem description and\nensures consistent, domain-relevant outputs. All PW components utilize LLMs, with their prompt\ntemplates provided in Appendix 16 and algorithmic details in Appendix 14.\n\n4  EXPERIMENTS AND IMPLEMENTATION DETAILS\n\nWe evaluate PromptWizard as a tool to generate instructions and examples that steer a black-box\nLLM toward desired behavior for a given target task.\n\nTasks & Datasets. We assess the effectiveness of PromptWizard on the widely-used BIG-Bench\nInstruction Induction (BBII) dataset, a benchmark for prompt optimization in recent works such as\nInstinct (Lin et al., 2024), InstructZero (Chen et al., 2023), and APE (Zhou et al., 2023). The dataset\ncovers a diverse range of language understanding scenarios (Appendix 8).\nIn addition to BBII, we evaluate PromptWizard on three arithmetic reasoning datasets:\nGSM8k(Cobbe et al., 2021), AQUARAT (Ling et al., 2017), and SVAMP (Patel et al., 2021),\nas well as domain-specific tasks from BigBench Hard (BBH) (Suzgun et al., 2022), which includes\n23 challenging tasks. This brings the total to 45 tasks (19 BBII, 23 BBH, 3 math tasks), covering both\ngeneral and domain-specific problem settings. Additional details of all datasets are in Appendix 9.\n\nBaselines. We compare our PromptWizard with five representative SOTA discrete and con-\ntinuous methods: Instinct (Lin et al., 2024), InstructZero (Chen et al., 2023), PromptBreeder\n(PB) (Fernando et al., 2023), EvoPrompt (Guo et al., 2024), and APE (Zhou et al., 2023).\n\nImplementation Details. We experiment with both ChatGPT (GPT3.5Turbo) and GPT-4 as the\nblack-box LLMs for prompt optimization in PromptWizard. All the individual components such as\nmutate, score, critique, reason, synthesize and validate, rely on the same LLM either GPT3.5Turbo\nor GPT-4, accordingly. For all experiments, we use only 25 examples from the training data to\noptimize the prompts and in-context examples, with evaluations conducted on the full test dataset.\nTo ensure robustness, all reported results are averaged over three experimental runs. Details of the\nhyperparameters used in the paper are provided in Appendix 10. Specifically, we restrict the number\nof mutated prompts & mutation rounds to 3, diverse examples to 25, sequential optimization rounds\nto 5. The source code of PromptWizard is available for reproducibility.\n\n\n                                       6\n\nTable 1: Average test accuracy achieved by best instruction generated by different SOTA algorithms.\nInsZero: InstructZero, PB: PromptBreeder, EvoP: EvoPrompt, PW: PromptWizard (ours).\n\n                    Task        APE   InsZero  PB   EvoP   Instinct  PW    Instinct  PW\n        LLM: GPT3.5Turbo                  Zero-shot setting                 One-shot setting\n                 antonyms         0.64    0.83    0.80   0.80     0.85    0.56    0.85     0.78\n                auto-categorization     0.25    0.26    0.22   0.26     0.25    0.28    0.30     0.40\n                cause and effect      0.57    0.81    0.75   0.83     0.59    0.88    0.63     0.92\n            common concept      0.07    0.09    0.10   0.12     0.21    0.10    0.25     0.19\n                           diff            0.67    0.69    1.00   1.00     1.00    1.00    1.00     1.00\n               informal to formal     0.57    0.53    0.58   0.62     0.55    0.62    0.52     0.56\n                        letters list         1.00    0.59    0.99   1.00     1.00    0.95    1.00     1.00\n                    negation          0.75    0.78    0.77   0.79     0.82    0.73    0.86     0.84\n                 object counting       0.36    0.36    0.34   0.12     0.34    0.60    0.36     0.52\n                odd one out        0.63    0.61    0.64   0.65     0.70    0.78    0.63     0.92\n             orthography starts with   0.46    0.51    0.56   0.60     0.67    0.75    0.67     0.92\n                  rhymes          0.16    1.00    0.54   0.61     1.00    0.89    0.75     0.90\n              second word letter     0.75    0.43    0.57   0.41     0.10    0.93    0.24     0.99\n               sentence similarity     0.00    0.00    0.01   0.28     0.14    0.29    0.16     0.30\n                 sum            0.67    1.00    1.00   1.00     1.00    1.00    1.00     1.00\n                synonyms         0.36    0.28    0.36   0.14     0.31    0.37    0.37     0.44\n             taxonomy animal      0.35    0.72    0.72   0.72     0.86    0.92    0.90     0.94\n               word sorting        0.33    0.31    0.56   0.52     0.51    0.56    0.62     0.74\n            word unscrambling     0.44    0.55    0.61   0.60     0.63    0.52    0.58     0.58\n             #best performing tasks    1      2      3     4       8      13      7      16\n\n5  EXPERIMENTAL RESULTS AND ANALYSIS\n\n5.1  PERFORMANCE ANALYSIS AGAINST VARIOUS PROMPTING BASELINES\n\nZero-shot accuracy. We evaluate the zero-shot test accuracy of ChatGPT (GPT3.5Turbo) using\ninstructions generated by five methods: APE, InstructZero, PromptBreeder, EvoPrompt, and Instinct.\nTable 1 presents results on 19 challenging tasks from BIG-Bench Instruction Induction (BBII) dataset,\nselected where the average test accuracy across all methods is below 0.8, following the evaluation pro-\ntocol in Instinct (Lin et al., 2024). All experiments use the same black-box LLM (GPT3.5Turbo)\nunder a zero-shot setting, ensuring a fair and consistent comparison across methods.\nPromptWizard outperforms the baselines, achieving the highest accuracy on 13 out of 19\ntasks (68%), compared to Instinct’s 8 tasks (42%). This significant improvement demonstrates\nPromptWizard ’s strength in tackling complex instruction induction tasks.\n\nOverall Performance. Figure 2 shows the performance profile curve for the instruction induction\ntasks from Table 1. The performance profile curve (Dolan & Moré, 2002) visualizes how frequently\ndifferent approaches’ performance is within a given distance of the best performance. In this curve,\nthe x-axis (τ) represents the performance ratio relative to the best-performing method, and the y-axis\n(p(τ)) reflects the fraction of tasks where a method’s performance is within this ratio. So for a given\nmethod, the curve tells what percentage of the tasks are within τ distance to the best performance\n(among different methods). PromptWizard consistently outperforms other methods across various\nthresholds, maintaining the highest p(τ) values, indicating that it consistently performs near the best\npossible accuracy across all tasks. Additional analysis is available in Appendix 11.\n\nOne-shot Accuracy. To evaluate the effectiveness of PW’s in-context example generation, we\ncompare the one-shot test accuracy of ChatGPT (GPT3.5Turbo) when using instructions gen-\nerated by Instinct and PW. The results, presented in the last two columns of Table 1, show that\nPromptWizard achieves the highest accuracy on 16 out of 19 tasks (84%), while Instinct performs\nbest on only 7 out of 19 tasks (36%). This improvement is largely attributed to the robust in-context\nlearning examples generated by PW, combined with its iterative prompt instruction optimization. By\nrefining both the prompt instructions and examples through multiple iterations, PW ensures that the\ntask-specific knowledge is effectively captured. The optimal prompts are in Appendix 15.\n\nGPT-4 as Base model. Table 1 presents results using GPT3.5Turbo as the base model.  In\nadditional experiments with GPT-4 as the base model on BBII, PW achieved the highest accuracy in\n15 out of 19 tasks (79%), compared to Instinct’s 6 out of 19 (31%), demonstrating PW’s superior\nperformance even with a change in base models (Appendix 12 Table 12 has the detailed results).\n\nArithmetic Datasets. Table 2 compares performance of PW with Instinct and InstructZero on\nthree arithmetic reasoning tasks: GSM8k, AQUARAT, and SVAMP, all using GPT3.5Turbo in\na zero-shot setting. The results clearly show that PromptWizard consistently outperforms all\n\n\n                                       7\n\nTable 3: Perf. on BBH.      Table 4: Cost analysis.\n Table 2: Perf. on arithmetic tasks.                                       API    IO       Total      Cost\n  Dataset   GSM8k  AQUARAT  SVAMP      Dataset   BBH (23)                     calls    Tokens   tokens     ($)\n Approach    Zero-shot with GPT3.5Turbo      Approach   Accuracy         Instinct   1730   67      115910    0.23\n  InsZero      74.2    54.3         79.5      APE       71.85            InsZero\n  Instinct               74.5                       54.7                                81         EvoP       75.03         PBEvoP    186005000   8080      1488000400000    0.82.9              90     58.2                                     82.3 PW\n                         PW        88.1        PW      69     362     24978     0.05\n\nbaselines across these datasets, achieving significant gains in accuracy on arithmetic reasoning tasks.\nThese tasks, often requiring detailed multi-step reasoning, which PW addresses through its iterative\nsynthesis of prompts enriched with intermediate reasoning steps and examples.\n\nComparison with BBH tasks. In Table 3, we report the average accuracy across 23 tasks from\nthe BIG-Bench Hard (BBH) dataset. Due to the high cost and compute requirements involved in\nevaluating all baselines on this extensive set of tasks, we limit the comparison to EvoPrompt and APE.\nPromptWizard achieves a remarkable improvement, increasing the average accuracy by over 13%\ncompared to EvoPrompt and APE, underscoring its effectiveness in handling complex tasks.\n\n5.2  COST ANALYSIS AGAINST VARIOUS PROMPTING BASELINES\n\nWhile high accuracy is crucial, the efficiency of generating prompts is equally important. We present\na detailed cost analysis demonstrating that PW not only outperforms baselines in terms of task\naccuracy but does so with minimal computational overhead. We conduct a comprehensive evaluation\nby computing the total number of API calls, tokens processed, and the corresponding cost (Table 4).\n\nInstinct and InstructZero. Instinct and InstructZero use a mix of white-box and black-box models\nto continuously optimize soft prompts, with the number of API calls linked to the iterative process\nneeded for convergence. According to their respective papers, the best performance is typically\nachieved after a maximum of 165 iterations. On average, across all tasks, we observed 1,730 API\ncalls to the black-box model per task, with approximately 67 input and output (IO) tokens per call\nfor the BBII dataset. Given the token billing structure of the GPT3.5Turbo API ($0.002 per\n1,000 tokens), the total cost per task is estimated to be around $0.23. Detailed API call and token\nbreakdowns per task are provided in Appendix 13.2.\n\nPromptBreeder (PB). PromptBreeder (PB) uses a discrete optimization approach through self-\nreferential improvement, evolving prompts over 20–30 generations with a population size of 20. This\nresults in significant API usage, with an estimated 18,600 API calls per task (30 generations × (20\nmutations + 20×30 evaluations)) (Fernando et al., 2023). With an average of 80 input/output tokens\nper call, the total cost per task for the BBII dataset is approximately $2.9, making PB one of the most\nexpensive methods among the baselines.\n\nEvoPrompt. EvoPrompt, a discrete optimization method, uses evolutionary algorithms to find\noptimal prompts. The number of API calls follows the formula: API calls = N (population size) × T\n(iterations) × (1 + D (development size)). For BBII tasks, with a population size of 10, 10 iterations,\nand a development set size of 50, this results in: API calls = 10×10×(1+50) = 5,000 API calls. With\nan average of 80 input/output tokens per call, EvoPrompt incurs a total cost of $0.8 per task, which\nis lower than PB but still considerable compared to other methods.\n\nPromptWizard (PW). PW employs a discrete optimization, similar to PB and EvoPrompt, but\nintroduces key components- feedback-driven guided exploration, critique and synthesis process, and\nsequential optimization of instruction and examples- that streamline prompt exploration and focus on\nmeaningful evolution. These innovations reduce unnecessary mutations, striking an effective balance\nbetween exploration and exploitation. The API calls in PW are broken down into 48 for prompt\nrefinement, 5 for example selection, 12 for sequential optimizations, and 4 for reasoning, validation,\nintent refinement, and expert identity (Algo. 1). This totals 69 API calls, substantially fewer than\nPB’s 18,600 and EvoPrompt’s 5,000. The average input/output tokens per task is around 360, slightly\nhigher due to the addition of COT reasoning and expert identity during prompt optimization. Despite\nthis, PromptWizard costs just $0.05 per task with 5-60x reduction in overall tokens, significantly\nlower than other techniques. Note that, during inference, PW’s average input tokens are ∼200, which\nis comparable to other approaches. Appendix 13.2 shows the detailed task level computations.\n\nPromptWizard’s efficiency is highlighted by being 5x cheaper than continuous methods like\nInstinct and InstructZero, and 16-60x cheaper compared to discrete methods like EvoPrompt and\nPromptBreeder, while achieving superior performance.\n\n\n                                       8\n\nDatasets     5 (eg)  25 (eg)                                          Datasets  Ll-70B  GPT-4       Models   With PW  w/o PW\n MMLU       80.4    89.5                            GSM8k   94.6     95.4        GPT-4   95.4      92\n GSM8k       94.0    95.4           Ethos     89.2     89.4         GPT3.5   75.6       57.1\n Ethos         86.4    89.4           Average   91.9     92.4          Ll-70B   90.2       56.8\n PubMedQA   68.0    78.2\n MedQA      80.4    82.9\n                                Table 6:  Perf.  with smaller  Table 7: Perf.  with different Average      81.9    87.0\n                    LLM for prompt generation.  Base LLMs on GSM8k.  Ll-\n                               Ll-70B: Llama-70B        70B: Llama-70B Table 5: Perf. with 5 examples.\n6  PROMPTWIZARD ABLATION STUDY\n\n6.1  PROMPTWIZARD EFFICACY WITH FEWER TRAINING EXAMPLES\n\nPromptWizard assesses prompt effectiveness using available training examples while also synthe-\nsizing new few-shot examples. In real-world scenarios, where data may be scarce or tasks evolve\nwithout curated datasets, generating effective prompts with minimal examples becomes essential. To\nevaluate PromptWizard’s performance under data-constrained conditions, we simulate a few-shot\nlearning scenario by randomly selecting only 5 examples from each dataset as the training set (instead\nof 25). PW utilizes these examples for all evaluations, critique feedback, and the generation of\ndiverse synthetic examples. This setup tests the framework’s ability to generalize and create robust,\ntask-relevant prompts with minimal data.\n\nTable 5 showcases PromptWizard’s performance across five diverse datasets (see Appendix 9)\nwhen trained with only 5 examples (5 eg) compared to 25 examples (25 eg). Despite the drastic\nreduction in training data, PromptWizard demonstrates impressive resilience, exhibiting only a\nmarginal 5% drop in accuracy on average. This resilience underscores the model’s adaptability,\ndriven by two key mechanisms: (i) Synthetic Example Generation using critique-and-synthesize,\nwhich produces diverse, high-quality examples from limited inputs, reducing the impact of data\nscarcity; and (ii) Reasoning Chain Guidance, where structured reasoning chains enhance the LLM’s\nability to generate accurate, contextually relevant responses.\n\n6.2  PROMPTWIZARD WITH SMALLER LLMS FOR PROMPT OPTIMIZATION\n\nIn prior experiments, GPT3.5Turbo was used for both prompt generation and optimization. In this\nsection, we explore the feasibility of employing a smaller LLM, such as Llama-70B, for prompt\ngeneration while reserving a more capable model like GPT-4 for inference. This approach reduce\ncomputational costs during prompt optimization by leveraging the efficiency of smaller models\nwhile still maximizing task accuracy with powerful model during inference. This strategy offers\ntwo key advantages: (i) Computational Efficiency: Smaller LLMs like Llama-70B require fewer\nresources, making them ideal for generating prompts in resource-constrained environments. (ii) Task\nPerformance: Despite using a smaller model for prompt generation, inference benefits from the larger\nGPT-4 model’s ability to interpret and execute the optimized prompt, ensuring minimal degradation.\n\nTable 6 compares task accuracy across multiple datasets when Llama-70B is used for prompt\ngeneration versus the default GPT-4. Impressively, the final prompts generated by PromptWizard\nusing Llama-70B show a negligible <1% drop in accuracy compared to those generated with\nGPT-4, highlighting PromptWizard ’s effectiveness even with smaller models. While we ex-\nperimented with smaller models like Llama-3-8B, they struggled to generate complex instructions,\nleading to significant performance degradation. Thus, mid-sized LLMs like Llama-70B are rec-\nommended for prompt optimization, striking a balance between computational efficiency and task\nperformance. These findings demonstrate PromptWizard’s adaptability and its ability to maintain\nhigh performance across different model sizes with minimal loss.\n\n6.3  ASSESSING PERFORMANCE WITH DIFFERENT BASE LLMS\n\nWe perform two types of ablation analysis: (i) evaluating the effect of different base LLMs during\nprompt optimization and inference, and (ii) measuring the contribution of each component within the\nPromptWizard framework to overall performance.\n\nAblation on Different Base LLMs. To assess PromptWizard’s adaptability and efficacy across\nvarious LLMs, we experiment with three settings: using GPT-4, GPT3.5Turbo, and Llama-70B\nas both the base LLM for prompt optimization and during inference. The goal is to understand\nwhether the choice of base model impacts the performance gains achieved through PromptWizard.\n\n\n                                       9\n\nTable 7 summarizes the results for the GSM8k dataset. In case of without PW, we use few-shot\nlearning with Chain-of-Thought (COT) prompting (Touvron et al., 2023) as the baseline. We observe\nsubstantial performance improvements across all models when optimized prompts are generated by\nPW. Specifically, for GPT3.5Turbo, the task accuracy increases by +18%, while for Llama-70B,\nthe improvement is even more pronounced, reaching +33%. In contrast, models when not using PW\nprompt show significant performance degradation, reaffirming the value of prompt optimization.\n\nEffectiveness of different stages of PromptWizard. We\nconducted an ablation study to assess the contribution of each                       GSM8k   Ethos\nstage in the PW pipeline, using the GSM8k and Ethos datasets.    AllNo Mutation and Scoring     95.495.2      89.487.1\n                                                             No Critique and Synthesize   90.9      86.9\nTable 8 presents the results of this ablation study: (i) Mutation   No intent & Expert         95        88.7\nand Scoring: The initial stage of iterative prompt refinement   No Reasoning               45.9      87.6\nalone yields an accuracy boost of 1-2%, demonstrating the\n                                                               Table 8: Abaltion Studybaseline value of exploring prompt variations.  (ii) Critique\nFeedback and Refinement: Adding structured feedback via the\ncritique mechanism improves accuracy by 3-5 highlighting the impact of targeted refinement on\nprompt quality. (iii) Task Intent and Expert Persona Modeling: Tailoring prompts to task-specific\nnuances contributes an additional 0.5-1% improvement. Although smaller, this step plays a crucial\nrole in aligning the prompt with task-specific behavior. (iv) Reasoning on Few-shot Examples: This\nemerges as one of the most significant contributors, indicating that generating detailed reasoning\nchains for few-shot examples is critical for task accuracy. This ablation study underscores the\nsignificance of individual components within the PromptWizard, as they work collectively to\nenhance prompt and model performance.\n\n7  CONCLUSIONS\n\nThis work introduces PromptWizard, a general-purpose framework for automating prompt and\nexample synthesis. By striking a balance between exploration and exploitation through a feedback-\ndriven critique and synthesis process, PW systematically refines prompts and in-context examples\nto enhance task performance.Extensive evaluations across diverse datasets show it consistently out-\nperforms state-of-the-art methods, demonstrating strong efficacy even with limited training data and\nsmaller LLMs, with only a marginal drop in accuracy. Ablation studies highlight the importance\nof each stage in refining prompts, generating diverse examples, and improving reasoning. Our\ncomprehensive cost analysis highlights significant reductions in API calls, token usage, and overall\nexpenses, showcasing PW’s cost-effectiveness—it is 5x cheaper than continuous optimization meth-\nods and 16-60x cheaper than discrete methods, all while delivering superior performance. This work\ndemocratizes access to effective prompt engineering, enabling more efficient and accurate utilization\nof LLMs across various domains and applications. Future work will focus on refining the validation\nof synthetic examples and applying PW to real-world, resource-constrained environments.\nLimitations: While we have conducted extensive experiments across a diverse set of tasks, careful\nvalidation is required for new tasks to ensure adaptability. Prompt response testing is essential before\nreal-world deployment to verify effectiveness. Additionally, while PromptWizard automates prompt\nengineering, human expertise remains indispensable in guiding and refining the optimization process.\n\n\n\n\n\n                                       10\n\nREFERENCES\n\nLichang Chen, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou. Instructzero: Efficient\n   instruction optimization for black-box large language models, 2023. URL https://arxiv.\n  org/abs/2306.03082.\n\nYanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown, and He He. On the relation between\n   sensitivity and accuracy in in-context learning, 2024.\n\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\n  Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John\n  Schulman. Training verifiers to solve math word problems, 2021.\n\nPierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic Culver, Rui Melo, Caio Corro, Andre\n   F. T. Martins, Fabrizio Esposito, Vera Lúcia Raposo, Sofia Morgado, and Michael Desa. Saullm-7b:\n A pioneering large language model for law, 2024.\n\nMingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song,\n  Eric Xing, and Zhiting Hu. RLPrompt: Optimizing discrete text prompts with reinforcement\n   learning. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.), Proceedings of the 2022 Con-\n  ference on Empirical Methods in Natural Language Processing, pp. 3369–3391, Abu Dhabi, United\n  Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/\n  2022.emnlp-main.222. URL https://aclanthology.org/2022.emnlp-main.222.\n\nXuan Long Do, Yiran Zhao, Hannah Brown, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji\n  Kawaguchi, Michael Shieh, and Junxian He. Prompt optimization via adversarial in-context\n   learning, 2024. URL https://arxiv.org/abs/2312.02614.\n\nElizabeth D Dolan and Jorge J Moré. Benchmarking optimization software with performance profiles.\n  Mathematical programming, 91:201–213, 2002.\n\nChrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rocktäschel.\n  Promptbreeder: Self-referential self-improvement via prompt evolution, 2023.\n\nQingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian,\n  and Yujiu Yang. Connecting large language models with evolutionary algorithms yields powerful\n  prompt optimizers, 2024.\n\nXiaoqiang Lin, Zhaoxuan Wu, Zhongxiang Dai, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet,\n  and Bryan Kian Hsiang Low. Use your instinct: Instruction optimization for llms using neural\n  bandits coupled with transformers, 2024. URL https://arxiv.org/abs/2310.02905.\n\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale genera-\n   tion: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146,\n  2017.\n\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. What\n  makes good in-context examples for GPT-3? In Eneko Agirre, Marianna Apidianaki, and Ivan Vuli´c\n   (eds.), Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge\n  Extraction and Integration for Deep Learning Architectures, pp. 100–114, Dublin, Ireland and\n  Online, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.deelio-1.10.\n  URL https://aclanthology.org/2022.deelio-1.10.\n\nXiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt\n  understands, too, 2023.\n\nAman Madaan and Amir Yazdanbakhsh. Text and patterns: For effective chain of thought, it takes\n  two to tango, 2022.\n\nMilad Moradi and Matthias Samwald. Evaluating the robustness of neural language models to input\n  perturbations.  In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau\n  Yih (eds.), Proceedings of the 2021 Conference on Empirical Methods in Natural Language\n  Processing, pp. 1558–1570, Online and Punta Cana, Dominican Republic, November 2021.\n  Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.117. URL https:\n  //aclanthology.org/2021.emnlp-main.117.\n\n\n                                       11\n\nHa-Thanh Nguyen, Randy Goebel, Francesca Toni, Kostas Stathis, and Ken Satoh. How well do sota\n   legal reasoning models support abductive reasoning?, 2023.\n\nHarsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, Richard Edgar, Nicolo Fusi, Nicholas King,\n  Jonathan Larson, Yuanzhi Li, Weishung Liu, Renqian Luo, Scott Mayer McKinney, Robert Os-\n  azuwa Ness, Hoifung Poon, Tao Qin, Naoto Usuyama, Chris White, and Eric Horvitz. Can\n   generalist foundation models outcompete special-purpose tuning? case study in medicine, 2023.\n\nOpenAI, R, and other et. al. Gpt-4 technical report, 2024.\n\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. Are nlp models really able to solve simple math\n  word problems? arXiv preprint arXiv:2103.07191, 2021.\n\nReid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng. Automatic prompt\n  optimization with \"gradient descent\" and beam search, 2023.\n\nOhad Rubin, Jonathan Herzig, and Jonathan Berant. Learning to retrieve prompts for in-context\n   learning, 2022.\n\nHong Sun, Xue Li, Yinchuan Xu, Youkow Homma, Qi Cao, Min Wu, Jian Jiao, and Denis Charles.\n  Autohint: Automatic prompt optimization with hint generation, 2023.\n\nMirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung,\n  Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei.  Challenging\n  big-bench tasks and whether chain-of-thought can solve them, 2022.\n\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée\n  Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand\n   Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language\n  models, 2023.\n\nXingchen Wan, Ruoxi Sun, Hootan Nakhost, and Sercan O. Arik. Teach better or show smarter?\n  on instructions and exemplars in automatic prompt optimization, 2024. URL https://arxiv.\n  org/abs/2406.15708.\n\nBoshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, and Huan Sun.\n  Towards understanding chain-of-thought prompting: An empirical study of what matters, 2023a.\n\nLei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim.\n  Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language\n  models, 2023b.\n\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\n   ery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models,\n  2023c.\n\nJason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\n  Andrew M. Dai, and Quoc V. Le. Finetuned language models are zero-shot learners, 2022.\n\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le,\n  and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models, 2023.\n\nBenfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong Zhang, and Zhendong\n  Mao. Expertprompting: Instructing large language models to be distinguished experts, 2023.\n\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen.\n  Large language models as optimizers, 2024.\n\nXi Ye, Srinivasan Iyer, Asli Celikyilmaz, Ves Stoyanov, Greg Durrett, and Ramakanth Pasunuru.\n  Complementary explanations for effective in-context learning, 2023.\n\nTianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schuurmans, and Joseph E. Gonzalez. Tempera:\n  Test-time prompting via reinforcement learning, 2022a.\n\n\n                                       12\n\nXinlu Zhang, Chenxin Tian, Xianjun Yang, Lichang Chen, Zekun Li, and Linda Ruth Petzold.\n  Alpacare:instruction-tuned large language models for medical application, 2024.\n\nYiming Zhang, Shi Feng, and Chenhao Tan. Active example selection for in-context learning. In\n  Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.), Proceedings of the 2022 Conference on\n  Empirical Methods in Natural Language Processing, pp. 9134–9148, Abu Dhabi, United Arab\n  Emirates, December 2022b. Association for Computational Linguistics. doi: 10.18653/v1/2022.\n  emnlp-main.622. URL https://aclanthology.org/2022.emnlp-main.622.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and\n  Jimmy Ba. Large language models are human-level prompt engineers, 2023.\n\n\nAPPENDIX\n\n8  BIG BENCH INSTRUCTION INDUCTION (BBII) DATASET DETAILS\n\nTable 9 describes the numerous tasks in BBII dataset along with the description of the task. This is\na popular dataset and the selected tasks cover many facets of language understanding and includes\nall nine such problems from the BigBench-Hard Subset. In particular, it includes emotional under-\nstanding, context-free question answering, reading comprehension, summarization, algorithms, and\nvarious reasoning tasks (e.g., arithmetic, commonsense, symbolic, and other logical reasoning tasks).\nWe selected tasks for which the data was publicly available.\n\n                       Table 9: Big Bench Instruction Induction Dataset\n\n Task                    Description\n antonyms            Make the pairs of words opposite.\n  auto categorization      Create a list of things that the input could be associated with, and the\n                          output would be the category that the input belongs to\n cause and effect          identify the sentence that is the cause of the effect in the input sentence\n                             pair\n common concept        ”involve” the objects mentioned in the input, so the answer would be\n                          ”involve oscillations” for the input ”guitars, pendulums”\n  diff                    Find the difference between the two numbers\n  informal to formal       convert the input sentence into an output sentence that is grammatically\n                            correct and idiomatic in English\n  letters list               output the input with a space after each letter\n  negation             make the output false by adding the word ”not” to the input\n  object counting          output the number of objects in the input list\n odd one out               find the word that is most dissimilar to the others in the group\n orthography starts with   output the word that starts with the letter that was inputted\n rhymes                  output the first word that appeared in the input text\n second word letter        takes a string as input and returns the first character that is a vowel.\n  sentence similarity      Find the difference between the two sentences and the output was 4 -\n                         almost perfectly\n sum                  add the numbers of the two input numbers\n synonyms                create a list of words that could be used in the same way as the original\n                       words\n taxonomy animal        output the name of an animal that starts with the letter\n word sorting              sort the input words alphabetically\n word unscrambling      output the word that is formed by rearranging the letters of the given\n                      word\n\n\n9  DATASET DETAILS: TRAIN/TEST SPLIT FOR DATASETS & FEW-SHOT COUNT\n\nBelow are the details of the datasets used for evaluation.\n\n\n                                       13\n\nDatasets                                                      Test dataset size            Few-shot count\n\n                                   GSM8k                                             1319                    5\n\n                                AQUARAT                                            254                     0\n\n                                 SVAMP                                             254                     0\n\n                                                 Ethos                                              799                     3\n\n                                   PubMedQA                                           500                     5\n\n                                 MedQA                                             1273                    5\n\n                                 CSQA                                              1140                    5\n\n                                  SQA                                              224                     5\n\n                  BBH [’snarks’, ’penguins in a table’, ’causal judgement’]                             153, 121, 162             3\n\n               BBH all except [’snarks’, ’penguins in a table’, ’causal judgement’]                     225                     3\n\n MMLU [clinical knowledge, college biology, college medicine, anatomy, medical genetics, professional medicine]   65, 144, 173, 135, 100, 272  5\n\n                    Table 10: Train/Test split for datasets & Few-shot count\n\n\nGSM8K: This dataset contains 8.5K high-quality, linguistically diverse grade school math word\nproblems created by human problem writers. The final answer is an integer value.\n\nAQUARAT: A large-scale dataset consisting of approximately 100,000 algebraic word problems. The\nsolution to each question is explained step-by-step using natural language. The test data includes 254\nquestions.\n\nSVAMP: SVAMP (Simple Variations on Arithmetic Math word Problems) dataset is a one-unknown\narithmetic word problems with grade level up to 4 by applying simple variations over word problems\nin an existing dataset.\n\nEthos: This hate speech detection dataset is built from YouTube and Reddit comments. It includes\ntwo tasks: binary classification and multi-label classification. We evaluate our approach on the binary\nclassification task, which consists of 998 questions. The final answer is either \"yes\" or \"no.\"\n\nMedQA: This dataset includes multiple-choice questions similar to those in the Medical Licensing\nExamination. We use the English subset with 11,450 training and 1,273 test questions, styled like the\nUnited States Medical Licensing Exam (USMLE). The final answer is the correct option from the\navailable choices.\n\nMMLU: Measuring Massive Multitask Language Understanding (MMLU) includes multiple-choice\nexam questions from 57 domains. We use 6 medical datasets, viz., Clinical knowledge, Medical\ngenetics, Anatomy, Professional Medicine, College Biology, and College Medicine.\n\nBBH: BIG-Bench Hard (BBH) includes 23 tasks from different domains. Answers can be in the form\nof multiple-choice questions, boolean, or string responses.\n\nFor all the datasets, in PromptWizard we randomly select only 25 samples from available training\ndata. We do not use entire training dataset in training-phase. Test dataset size for each dataset is\nspecified below. However for the baseline approaches, we follow their train/test splits. Table 10\nprovides details of the test set along with the few-shots used in each dataset.\n\n10  HYPER PARAMETERS\n\nPW relies on several parameters to control the level of exploration and evolution at each stage. We\nnow provide comprehensive details of all parameters and associated values (see Table 11).\n\n11  PERFORMANCE PROFILE CURVE - ADDITIONAL DETAILS\n\nIn Section 5.1 we presented the Performance Profile Curve comparing PromptWizard’s perfor-\nmance against all baselines across all tasks in BBII dataset.\n\nThe performance profile curve Dolan & Moré (2002) visualizes how frequently different approaches’\nperformance is within a given distance of the best performance. In this curve, the x-axis (τ) represents\nthe performance ratio relative to the best-performing method, and the y-axis (p(τ)) reflects the\nfraction of tasks where a method’s performance is within this ratio. PromptWizard consistently\n\n\n                                       14\n\nHyper-          Description                                              Default Value\n   parameter\n   mutate_refine   Number of rounds of call to MutateComponent fol-  3\n   rounds         lowed by refinement over best prompt among generated\n                 by MutateComponent in previous step.\n   mutate_rounds  Number of times MutateComponent would be called.   3\n    style_variation  Number of variations MutateComponent generates in   3\n                   a single call.  i.e. one variation corresponding to each\n                    thinking style provided.\n   min_example   Minimum     number      of      questions      the   3\n   correct_count   ScoringComponent   should   answer   correctly\n                      for a prompt to get qualified for next stage.\n   max_example  Maximum   number   of   attempts/questions   the   6\n   count        ScoringComponent  would  be  asked  asked  to\n                    answer.\n   max_seq_iter   Number of rounds of call to CritiqueComponent fol-  5\n                  lowed by call to SynthesizeComponent\n   few_shot_count  Total number of few shot examples to be provided in   Defined in Ta-\n                   prompt.                                                    ble 10\n    ex_critique     Number of LLM calls made by CritiqueComponent   1\n                      for getting critique for improving examples passed as few-\n                      shots.\n    synthesize     Number     of   LLM      calls    made    by   1\n              SynthesizeComponent   to   generate   synthetic\n                   examples.\n    inst_critique    Number of LLM calls made by CritiqueComponent   1\n                      for getting critique for improving instruction passed as\n                     few-shots.\n    synthesize     Number     of   LLM      calls    made    by   1\n              SynthesizeComponent   to   created   improved\n                    version of instruction.\n   reasoning  +  Number       of    LLM        calls      made   2\n    validation      by        ReasoningComponent          and\n              ValidateComponent respectively.\n    intent + per-  Number of LLM calls made to get keywords that express   2\n   sona             the intent and to generate expert persona respectively.\n\n               Table 11: Description for hyper parameters and their default values\n\n\noutperforms other methods across various thresholds, maintaining the highest p(τ) values, indicating\nthat it consistently performs near the best possible accuracy across all tasks.\n\nIn this curve, the x-axis (τ) represents the performance ratio relative to the best-performing method,\nand the y-axis (p(τ)) reflects the fraction of tasks where a method’s performance is within this ratio.\nIt is a suitable measure for the performance of methods over a large number of tasks. To draw the\nperformance profile curve for a method, for each task i, we check whether the performance of this\nmethod in task i is within τ distance to the best performance (among different methods) in task i, and\ndefine an indicator function I(). Next, we average this indicator function across all np tasks, which\nyields a value p(τ) (equation 1). Finally, the performance profile curve for this method is obtained by\nvarying the value of τ and calculating the corresponding p(τ).\n\n       Pnpi=1 I (Best performance of task i −Performance of the approach on task i ≤τ)   ρ(τ) =                                                                                         (1)\n                                        np\n\nFor example at τ = 0.0, the values of p(τ) are approximately 0.05 (APE), 0.105 (InstructZero), 0.157\n(PromptBreeder), 0.210 (EvoPrompt), 0.421 (INSTINCT), 0.68 (PromptWizard). This shows that\nPromptWizard is the best performing method, betting all the other methods at 68% of the tasks.\n\n\n                                       15\n\nTable 12: Average test accuracy achieved by best instruction generated by Instinct and PW using\nGPT4 as base model on BBII dataset.\n\n                     Task                       Instinct  PromptWizard\n               LLM: GPT4            Zero-shot setting\n                    antonyms                 0.79         0.77\n                      auto categorization         0.3         0.38\n                      cause and effect           0.96         0.88\n                common concept           0.2         0.15\n                           diff                     1          1\n                      informal to formal          0.6         0.75\n                            letters list                1          1\n                      negation                   0.7         0.85\n                        object counting             0.6         0.82\n                   odd one out               0.54         0.87\n                      orthography starts with    0.75         0.92\n                    rhymes                  1          0.88\n                     second word letter         0.57         0.97\n                      sentence similarity         0.3         0.43\n                 sum                      0.99         1\n                   synonyms                  0.3         0.42\n                   taxonomy animal           0.9         1\n                   word sorting               0.5         0.65\n                   word unscrambling        0.54         0.77\n                   # best performing tasks     6          15\n\n\nAlgorithm 1 Total LLM Calls Calculation\n\n  1: Calculation: Input: Hyperparameters, Result: Total LLM Calls\n  2: refine_instructions_component  ←     mutate_refine_rounds ×  (mutate_rounds ×\n    style_variations + min_example_correct_count + critique + synthesize)\n  3: seq_iter_component ←  max_seq_iter × (ex_critique + ex_synthesize + inst_critique +\n    inst_synthesize)\n  4: other_components ←max_example_count + reasoning + validation + intent + persona\n  5: Total LLM Calls  ←      refine_instructions_component +  seq_iter_component +\n    other_components\n  6: Total LLM calls =  3 ×  (3 × 3) + 5 + 1 + 1 + 5 + 3 ×  (1 + 1) + (1 + 1)   + 1 +\n   1 + 1 + 1 = 48 + 5 + 12 + 2 + 2\n  7: Prompt_refinement = 48; example_selection = 5; seq_opt = 12;\n  8: reason+validate = 2; intent+expert = 2\n  9: Total LLM calls = 69\n\n\n12  ADDITIONAL RESULTS: BBII DATASET\n\nTable 12 shows additional experiments with GPT-4 as the base model, PW achieved the highest\naccuracy in 15 out of 19 tasks, compared to Instinct’s 6 out of 19, demonstrating PW’s superior\nperformance even with a change in base models.\n\n\n13  COST ANALYSIS: ADDITIONAL DETAILS\n\n13.1  PROMPTWIZARD LLM API CALLS CALCULATION\n\nWe compute the total LLM calls made by PromptWizard during prompt generation (one-time),\nwhich derives the most effective prompt and few-shot examples. The algorithm provides more\ndetails: Algorithm 1 describes the total LLM calls made by PromptWizard during preprocessing\n(one-time), which derives the most effective prompt and few-shot examples (see Appendix 10.for\nparameter description). Note that during inference, each query uses only the default one LLM call.\n\n\n                                       16\n\nTable 13: Cost analysis of Instinct and PromptWizard on BBII dataset with GPT3.5Turbo as the\nbase model.\n\n                                                                  Instinct            PromptWizard\n                          Dataset              API Calls  IO Tokens  API Calls  IO Tokens\n                       antonyms             2200      39         69        334\n                           auto-categorization      1740      86         69        341\n                         cause and effect        1352      61         69        390\n                   common concept       639       94         69        386\n                               diff                  1820      58         69        381\n                          informal to formal      880       90         69        271\n                                letters list             2240      58         69        256\n                          negation              2180      60         69        305\n                           object counting         1340      69         69        470\n                      odd one out           840       50         69        372\n                         orthography starts with  1800      82         69        339\n                       rhymes               1920      41         69        391\n                        second word letter      1840      48         69        257\n                          sentence similarity      2140      78         69        626\n                    sum                  2180      66         69        367\n                      synonyms             2100      51         69        452\n                      taxonomy animal       1900      72         69        225\n                      word sorting           1680      110        69        426\n                      word unscrambling     2060      58         69        306\n                        Average              1729      67         69        362\n\n\n\n13.2  COMPARISON OF API CALLS, NUMBER OF TOKENS FOR BBII DATASET\n\n\nTable 13 shows the comparison of API calls, number of tokens for BBII dataset for both Instinct and\nPromptWizard using GPT3.5Turbo model. We can see that PW has significant lower number\nof API calls compared to Instinct, thus resulting in 5x reduction in overall tokens per task. Similar\ntrends with the API calls, number of tokens used, were seen when the base model in Instinct and PW\nwas changed to GPT-4.\n\n\n14  PR O M P TWI Z A R D ALGORITHM\n\n\nAlgorithm 2 provides pseudo code for entire PromptWizard framework. Algorithm 3 provides\npseudo code for mutating prompt instruction and further refining the best prompt instruction among\nall the mutated prompt instructions. i.e. Section 3.1. Algorithm 4 and 5 provide pseudo code for\nSections 3.2 and 3.3 respectively.\n\n\nAlgorithm 2 PromptWizard Framework\n  1: Input:  L:  large language model; D:  problem description; S:  set of training samples\n    {(qi, ai)}Ni=1; T:  thinking styles; N:  mutate_refine_rounds;  k:  few-shot count  ; N1:\n    max_seq_iter\n  2: Output: Optimized prompt ˆPopt and few-shot examples {(qfi, afi)}ki=1\n  3: procedure PROMPTWIZARD(L, D, S, T, k, N, N1)\n  4:      Initialize P ←initial prompt instruction\n  5:      ˆP ←RefineInstructions(L, D, S, T, N)\n  6:      Ediverse = {(qdi, adi)}ki=1 ←DiverseExampleSelection(L, D, S, ˆP)\n  7:      ˆPopt, Esyn = {(qsi, asi)}ki=1 ←SequentialOptimization(L, ˆP, Ediverse, N1)\n  8:      Esyn,r ←ReasoningComponent (Esyn)                   ▷generate reasoning chains\n  9:     {(qfi, afi)}ki=1 ←ValidateComponent (Esyn,r)                   ▷validate examples\n10:       τintent ←SynthesizeComponent (D)                         ▷generate task intent\n11:      πexpert ←SynthesizeComponent (D)                    ▷generate expert persona\n12:    return πexpert, ˆPopt, {(qfi, afi)}ki=1, τintent\n13: end procedure\n\n\n\n                                       17\n\nAlgorithm 3 RefineInstructions Procedure\n  1: Input:  L:  large language model; D:  problem description; S:  set of training samples\n    {(qi, ai)}Ni=1; T: thinking styles; N: mutate_refine_rounds; b: batch size (default:  5); v:\n   number of thinking styles to select; M: mutate_rounds\n  2: Output: Optimized prompt ˆP\n  3: procedure REFINEINSTRUCTIONS(L, D, S, T, N, b, v, M)\n  4:      Initialize P ←initial prompt instruction\n  5:    Optimized prompt ˆP ←P\n  6:     for refinement_round = 1 to N do\n  7:       T1 ←RandomlySelect(v, T)                      ▷Select v thinking styles from T\n  8:     F ←∅\n  9:        for m = 1 to M do\n10:    M ←MutateComponent(D,P, T1)\n11:            for p ∈M do\n12:              s ←ScoringComponent(p, S, b)\n13:                     if s > 0.5 then\n14:           F ←F ∪{(p, s)}\n15:             end if\n16:          end for\n17:       end for\n18:        top_scored_prompt ←arg maxp∈F{s(p)}\n19:        feedback ←CritiqueComponent(top_scored_prompt)\n20:          ˆP ←SynthesizeComponent(top_scored_prompt, feedback)\n21:    end for\n22:    return ˆP\n23: end procedure\n\n\n\n\n\nAlgorithm 4 DiverseExampleSelection Procedure\n  1: Input: L: large language model; D: problem description; S: training dataset {(qi, ai)}Ni=1; k:\n    few-shot count\n  2: Output: Selected diverse examples Ediverse = {(qdi, adi)}ki=1\n  3: procedure DIVERSEEXAMPLESELECTION(L, D, S, k)\n  4:    S′ ←RandomSample(S, 25)\n  5:      Ediverse ←∅\n  6:     count ←0\n  7:     for (q, a) ∈S′ do\n  8:          apred ←L(q)                                    ▷LLM’s answer for q\n  9:\n10:           if apred ̸= a then\n11:                Ediverse ←Ediverse ∪{(q, a)}\n12:           count ←count + 1\n13:       end if\n14:           if count = k then\n15:          break\n16:       end if\n17:    end for\n18:       if count < k then                           ▷Sample Random Correct Examples\n19:           Ediverse ←Ediverse ∪random.sample(S, k −count)\n20:    end if\n21:    return Ediverse\n22: end procedure\n\n\n\n                                       18\n\nAlgorithm 5 SequentialOptimization Procedure\n  1: Input: L: large language model; D: problem description; ˆP: optimized prompt; Ediverse =\n    {(qdi, adi)}ki=1: diverse examples; n: max_seq_iter\n  2: Output:  Final optimized task instruction  ˆPopt and synthetic few-shot examples Esyn =\n    {(qsi, asi)}ki=1\n  3: procedure SEQUENTIALOPTIMIZATION(L, ˆP, Ediverse, n)\n  4:     Esyn ←Ediverse\n  5:     for round = 1 to n do\n  6:        feedback ←CritiqueComponent (ˆP, Esyn)        ▷Examples optimization step\n  7:         Esyn = {(qsi, asi)}ki=1 ←SynthesizeComponent (Ediverse, feedback)\n  8:\n  9:        feedback ←CritiqueComponent (ˆP, Esyn)          ▷Prompt optimization step\n10:          ˆP ←SynthesizeComponent (ˆP, Esyn, feedback)\n11:    end for\n12:    return ˆPopt ←ˆP, Esyn\n13: end procedure\n\n15  BEST PROMPTS FOR BBII TASKS\n\nBelow are the best prompt obtained using PromptWizard for some of the tasks in BBII dataset.\n\nantonyms  Your task is to provide an antonym for each word presented to you, keeping in mind\nthat the opposite word can often be formed by using prefixes or suffixes. If it’s not possible to do\nso without altering the root word, choose a standalone antonym that widely resonates the opposite\nmeaning in common contexts. The aim here is not to rule out standard methods of forming antonyms\nor to seek context-free opposites, but rather to find straightforward, widely accepted opposites based\non every day usage and understanding. Regarding adverbs, note that some can have more than\none antithesis depending on context, so provide the most generally applicable one. Ensure that the\nantonyms offered reflect commonly understood oppositions, without venturing into less accepted or\ncontextually delicate nuances. Remember, the focus here is on providing clear, generally suitable\nopposites rather than unusual or highly situational counterparts.\n\nFor each input word present the reasoning followed by the correct word. Wrap only your final answer,\nwithout reason for each question separately between <ANS_START> and <ANS_END>.\n\nnegation   Initiate text inversion by transforming the sentiment of the input sentence to its exact\nreverse, while maintaining syntactic and grammatical accuracy and ensuring the output clearly\ncommunicates the opposing sentiment. Stick to input sentences that express opinions, feelings, or\nsubjective judgments instead of factual, real-world information or historical events.\n\nIf the sentence contains an auxiliary verb, add the negation ’not’ immediately after it. For sentences\nwithout an auxiliary, add ’not’ before the main verb. If the input sentence includes a negative term,\neliminate it to achieve the reverse sentiment.\n\nExamine any clauses with modal verbs closely, keeping in mind to switch ’can’ to ’can’t’ and so\nforth to reverse meaning. Be cautious while altering relative clauses, indirect speech, or idiomatic\nexpressions. Their sentiment inversion should be handled carefully while still preserving linguistic\ncoherence.\n\nConsider implicit sentiments such as rhetorical questions, forms of irony, or sarcasm. Remember,\naltering these doesn’t merely mean skewing negative to positive or vice versa. The key is to ensure\nclarity and comprehension of the reversed sentiment.\n\nAvoid changing the truth value of objective facts or historical events, and if the main verb of a sentence\ndoesn’t carry the sentiment, consider implementing changes to other parts of the sentence—like\nthe subject or object—to successfully reverse the meaning. Regularly assess the result of your\nmodifications for precision and understanding.\"\n\nFor each input sentence, negate the meaning by adding ’not’ to the input sentence. Wrap only your\nfinal answer, without reason for each question separately between <ANS_START> and <ANS_END>.\n\n\n                                       19\n\nsecond word letter  For the provided word, your task is to specifically output the second letter.\n\nFor each input word, output only the extracted letter (only single letter) wrapped between\n<ANS_START> and <ANS_END> tags.\n\n\nsentence similarity  For each input, you will find two sentences (Sentence 1 and Sentence 2). Your\ntask is to evaluate their similarity based on two elements: overall meaning and specific numerical or\nfactual details.\n\nThe importance of each element is weighted as follows: 70% overall meaning and 30% numerical/-\nfactual details.\n\nThe evaluation scale is now:\n\n0 - Definitely not: The sentences not only differ in overall meaning but also show significant\ndiscrepancies in factual details. 1 - Probably not: There are minor similarities in meaning, but\nsignificant differences in factual details are prevalent. 2 - Possibly: The sentences share some\nelements of meaning but show differences in certain details or numerical data. 3 - Probably: The\nsentences express largely similar meanings but have noticeable differences or discrepancies in specific\ndetails or numerical data. 4 - Almost perfectly: The sentences are very similar in meaning with only\nslight discrepancies in factual or numerical details. 5 - Perfectly: The sentences are identical in terms\nof overall meaning and factual/numerical details.\n\nIn case of conflicts between overall meaning and factual details, the weighting system will guide your\nevaluation. Resultant rating should be separated with \" - \" for clarity, and should be accompanied by\na brief textual description of your rating.\n\nProvide your rating and brief textual description for each pair of sentences from the 6 options. (0 -\nDefinitely not, 1 - Probably not, 2 - Possibly, 3 - Probably, 4 - Almost perfectly, 5 - Perfectly) Wrap\nonly your final answer, without reason for each question separately between <ANS_START> and\n<ANS_END> tags.\n\n\nsynonyms  Your assignment involves identifying a list of synonyms for a provided word. These\nsynonym should not only share the same basic meaning with the given word, but should also be able\nto replace the original word in most of its use cases without resulting in loss of meaning or causing\nthe sentence to sound strange. For example, \"report\" could be a synonym for \"account\" as both can\nbe used in similar business and financial situations while preserving the essence of the original use.\nPay attention to the part of speech; a suitable synonym for a noun should also be a noun. Beware of\nfalse friends that evoke similar themes but are not true synonyms; \"rest\" seems related to \"pillow,\" but\none is a tangible object and the other an action or state, making them non-interchangeable. Prioritize\nsynonyms that maintain the semantic richness of the original term, employ them regularly in similar\ncontexts, and ensure they have the same connotation. Simplify your task by rejecting words that have\nonly a minor relationship or those that are broader in meaning.\n\nFor each input word, output a list of synonym words. Wrap only your final answer, without reason\nfor each question separately between <ANS_START> and <ANS_END> tags.\n\n\nword sorting  Given a series of words in the task, your assignment is to reorder them in alphabetical\norder, prioritizing by the first letter of every word. Think step-by-step and consider the most efficient\nway to sort the words. Wrap the list of sorted words between <ANS_START> and <ANS_END>.\n\n16  PROMPT TEMPLATES\n\nThe prompt template for MutateComponent is: <problem description> <thinking\nstyle pool> <#style_variation_number> < instruction>, where < instruction>\nguides MutateComponent to generate new mutated prompts by combining the problem description\nwith thinking styles.\n\nThe prompt  template  for ScoringComponent  is:  <mutated/improved prompts>\n<mini batch examples> < instruction>,    where   <    instruction>    guides\nScoringComponent to evaluate all mutated prompts against the examples in the mini-batch.\n\n\n                                       20\n\nThe prompt template for CritiqueComponent to get critique over prompt instruction is: <best\n mutated prompt> <selected mini batch examples> < instruction>, where\n < instruction> guides CritiqueComponent to provide feedback on how to improve the prompt\n  instruction based on the selected examples.\n\n The prompt template for SynthesizeComponent to refine prompt instruction is: <best\n mutated prompt> <critique feedback> < instruction>, where < instruction>\n  guides SynthesizeComponent to generate an improved prompt using the critique feedback.\n\n The prompt template for CritiqueComponent to get critique over few-shot examples is: The\n  prompt template for CritiqueComponent is structured as follows: <negative examples> <im-\n  proved prompt> < instruction>. This guides the CritiqueComponent to provide detailed feed-\n  back for improving examples. For SynthesizeComponent, the prompt template is <synthesized\n  examples> <improved prompt> < instruction>, aiding in the synthesis and refinement of new exam-\n  ples.\n\n The prompt template for CritiqueComponent follows this structure: <synthesized examples>\n <improved prompt> < instruction>, guiding the CritiqueComponent to provide detailed feed-\n  back for prompt improvement. For SynthesizeComponent, the prompt template is <synthesized\n  examples> <improved prompt> < instruction>, assisting in the synthesis and refinement of new\n  optimized prompts for the synthetic examples. Figure 6 demonstrates the critique feedback on the\n  prompt alongside the refined optimized prompt. Prompt Templates used by different components are\n  shown in Fig. 8\n\n 17  BEST PROMPTS\n\n  Best prompt found for each dataset are shown below:\n\n  17.1  GSM8K PROMPT\n\n1 <the optimized prompt instruction>\n\n2\n3 Analyze the given real-world mathematical problem step-by-step,\n     identifying key information, relationships between different pieces\n     of data, and the context. Understand the structure of the problem,\n     whether it involves a sequence of events or a comparison between\n     different quantities. Keep track of all variables and quantities\n     mentioned in the problem. Use appropriate mathematical operations and\n      formulas, including addition, subtraction, multiplication, division,\n      and more complex operations if required. Understand and handle\n     indirect relationships and different units of measurement. Apply\n     specific rules or conditions given in the problem. Make assumptions\n     when information is not explicitly provided. Consider the order of\n     operations when performing calculations. Understand the structure and\n      properties of the data in the problem. Finally, verify your answer\n     against the original problem to ensure it is logical and accurate.\n\n\n1 <synthesized examples + reasoning chain>\n\n2\n3 [Question] Tim rides his bike back and forth to work for each of his 5\n     workdays.  His work is 20 miles away.  He also goes for a weekend\n     bike ride of 200 miles.    If he can bike at 25 mph how much time\n     does he spend biking a week?\n4 [Answer] 1. Identify the key pieces of information: Tim bikes to work and\n      back for 5 days, his work is 20 miles away, he goes for a 200-mile\n     bike ride on the weekend, and his biking speed is 25 mph.\n5 2. Understand that the problem involves a sequence of events: Tim’s daily\n      commute to work and back, and his weekend bike ride.\n6 3. Calculate the total distance Tim bikes to work and back in a week: 20\n     miles to work * 2 (for the return trip) = 40 miles per day. Multiply\n     this by 5 days: 40 miles/day * 5 days = 200 miles.\n7 4. Add the distance of Tim’s weekend bike ride to the total distance he\n     bikes to work: 200 miles (work) + 200 miles (weekend) = 400 miles.\n\n\n                                        21\n\nFigure 8: Prompt Templates for different components of PromptWizard.\n\n\n\n\n\n                             22\n\n8 5. Understand that the problem asks for the total time Tim spends biking\n      in a week, and that time can be calculated by dividing distance by\n      speed.\n 9 6. Calculate the total time Tim spends biking in a week: 400 miles / 25\n      mph = 16 hours.\n10 7. Verify that the answer is logical: Tim spends 16 hours biking in a\n      week, which is reasonable given the distances and speed provided.\n11 8. The final answer is 16 hours. <ANS_START>16<ANS_END>\n\n12\n\n13\n14 [Question] Tobias is buying a new pair of shoes that costs $95. He has\n      been saving up his money each month for the past three months. He\n      gets a $5 allowance a month. He also mows lawns and shovels driveways\n      . He charges $15 to mow a lawn and $7 to shovel. After buying the\n      shoes, he has $15 in change. If he mows 4 lawns, how many driveways\n      did he shovel?\n15 [Answer] 1. Identify the total amount of money Tobias had before buying\n      the shoes. This is given by the cost of the shoes plus the change he\n      has left, which is $95 + $15 = $110.\n16 2. Calculate the total amount of money Tobias earned from his allowance.\n      He gets $5 a month and has been saving for three months, so he earned\n       $5 * 3 = $15 from his allowance.\n17 3. Calculate the total amount of money Tobias earned from mowing lawns.\n      He charges $15 to mow a lawn and he mowed 4 lawns, so he earned $15 *\n       4 = $60 from mowing lawns.\n18 4. Subtract the money Tobias earned from his allowance and mowing lawns\n      from the total amount of money he had before buying the shoes. This\n      will give us the amount of money he earned from shoveling driveways.\n      So, $110 - $15 - $60 = $35 is the amount he earned from shoveling\n      driveways.\n19 5. Finally, divide the total amount of money Tobias earned from shoveling\n       driveways by the amount he charges to shovel one driveway. This will\n       give us the number of driveways he shoveled. So, $35 / $7 = 5\n      driveways. <ANS_START>5<ANS_END>\n\n20\n21 [Question] Bella bought stamps at the post office. Some of the stamps had\n       a snowflake design, some had a truck design, and some had a rose\n      design. Bella bought 11 snowflake stamps. She bought 9 more truck\n      stamps than snowflake stamps, and 13 fewer rose stamps than truck\n      stamps. How many stamps did Bella buy in all?\n22 [Answer] 1. Identify the quantities given in the problem: Bella bought 11\n       snowflake stamps.\n23 2. Understand the relationships between the different types of stamps:\n      She bought 9 more truck stamps than snowflake stamps, and 13 fewer\n      rose stamps than truck stamps.\n24 3. Calculate the number of truck stamps: The number of truck stamps is 11\n       (snowflake stamps) + 9 = 20.\n25 4. Calculate the number of rose stamps: The number of rose stamps is 20 (\n      truck stamps) - 13 = 7.\n26 5. Add up all the stamps: The total number of stamps Bella bought is 11 (\n      snowflake stamps) + 20 (truck stamps) + 7 (rose stamps) = 38.\n27 6. Verify the answer: Check that the total number of stamps (38) matches\n      the sum of the individual quantities of each type of stamp (11\n      snowflake stamps, 20 truck stamps, 7 rose stamps). The answer is\n      correct. <ANS_START>38<ANS_END>\n\n28\n29 [Question] Tina makes $18.00 an hour.  If she works more than 8 hours per\n       shift, she is eligible for overtime, which is paid by your hourly\n      wage + 1/2 your hourly wage.  If she works 10 hours every day for 5\n      days, how much money does she make?\n30 [Answer] 1. Identify the key information: Tina’s hourly wage is \\$18.00,\n      she works 10 hours a day for 5 days, and overtime is calculated as\n      the hourly wage plus half the hourly wage for hours worked over 8\n      hours in a shift.\n\n\n\n                                         23\n\n31 2. Calculate the regular pay: Tina works 10 hours a day, but only 8 hours\n       are considered regular hours. So, for 5 days, she works 8 hours/day\n      * 5 days = 40 hours.\n32 3. Multiply the regular hours by the hourly wage to get the regular pay:\n      40 hours * $18.00/hour = $720.00.\n33 4. Calculate the overtime hours: Tina works 10 hours a day, so she has 10\n       hours/day - 8 hours/day = 2 hours/day of overtime. Over 5 days, this\n       is 2 hours/day * 5 days = 10 hours of overtime.\n34 5. Calculate the overtime wage: The overtime wage is the hourly wage plus\n       half the hourly wage, so $18.00/hour + 0.5 * $18.00/hour = $27.00/\n      hour.\n35 6. Multiply the overtime hours by the overtime wage to get the overtime\n      pay: 10 hours * $27.00/hour = $270.00.\n36 7. Add the regular pay and the overtime pay to get the total pay: $720.00\n       + $270.00 = $990.00.\n37 8. Verify the answer: Tina makes $990.00 if she works 10 hours a day for\n      5 days, with overtime pay for hours worked over 8 hours in a shift.\n      This is logical and matches the original problem. <ANS_START>990<\n      ANS_END>\n\n38\n39 [Question] Samantha’s last name has three fewer letters than Bobbie’s\n      last name. If Bobbie took two letters off her last name, she would\n      have a last name twice the length of Jamie’s. Jamie’s full name is\n      Jamie Grey. How many letters are in Samantha’s last name?\n40 [Answer] 1. Start by identifying the key pieces of information from the\n      problem: Samantha’s last name has three fewer letters than Bobbie’s\n      last name, and if Bobbie took two letters off her last name, she\n      would have a last name twice the length of Jamie’s. Jamie’s full name\n       is Jamie Grey.\n41 2. From the information given, we know that Jamie’s last name is Grey,\n      which has 4 letters.\n42 3. Since Bobbie’s last name, after removing two letters, is twice the\n      length of Jamie’s last name, we can set up the equation: (Bobbie’s\n      last name length - 2) = 2 * Jamie’s last name length.\n43 4. Substituting the known value of Jamie’s last name length (4) into the\n      equation gives: (Bobbie’s last name length - 2) = 2 * 4, which\n      simplifies to Bobbie’s last name length - 2 = 8.\n44 5. Solving for Bobbie’s last name length gives: Bobbie’s last name length\n       = 8 + 2 = 10.\n45 6. We know that Samantha’s last name has three fewer letters than Bobbie’\n      s last name. So, we can set up the equation: Samantha’s last name\n      length = Bobbie’s last name length - 3.\n46 7. Substituting the known value of Bobbie’s last name length (10) into\n      the equation gives: Samantha’s last name length = 10 - 3.\n47 8. Solving for Samantha’s last name length gives: Samantha’s last name\n      length = 7.\n48 9. Therefore, Samantha’s last name has 7 letters. <ANS_START>7<ANS_END>\n\n\n 1 <human intent>\n\n 2\n 3 Mathematical Reasoning, Multi-step Problem Solving, Basic Arithmetic\n      Operations, Data Analysis, Solution Verification\n\n 4\n 5 <expert persona>\n\n 6\n 7 You are a mathematics educator with a deep understanding of elementary\n      and middle school mathematics. You are experienced in teaching multi-\n      step problem-solving techniques and have a knack for breaking down\n      complex problems into manageable steps. Your expertise lies in basic\n      arithmetic operations such as addition, subtraction, multiplication,\n      and division. You can provide clear, step-by-step solutions to\n      mathematical problems that require multi-step reasoning. You are\n      patient and thorough, ensuring that each step is clearly explained\n      and understood. Your ability to simplify complex problems and guide\n\n\n                                         24\n\nstudents through the problem-solving process makes you an excellent\n      resource for answering school-grade mathematical questions.\n\n 8\n 9 <prompt guidelines for desired output format>\n\n10\n11 You need to answer each of the questions separately. Arabic numeral\n      should be at the end in the format Wrap your only the final answer,\n      without reason for each question separately between <ANS_START> and <\n      ANS_END> tags.\n\n\n\n  17.2  ETHOS PROMPT\n\n\n 1 <the optimized prompt instruction>\n\n 2\n 3 Carefully examine the provided text and determine if it constitutes hate\n      speech. Hate speech is defined as language that is derogatory,\n      offensive, or discriminatory towards a specific group of people based\n       on their race, gender, or other characteristics, with the intent to\n      harm or degrade. Even if the statement appears factual or sarcastic,\n      if it uses aggressive language or personal attacks aimed at a\n      specific group, it should be classified as hate speech.\n\n\n 1 <synthesized examples + reasoning chain>\n\n 2\n 3 [Question] While I appreciate the hard work of some immigrants, others\n      are just here to exploit our system and take our jobs.\n 4 [Answer] 1. Start by reading the provided text to understand its content.\n 5 2. The task requires identifying if the text contains hate speech.\n      According to the task description, hate speech is language that is\n      derogatory, offensive, or discriminatory towards a specific group of\n      people based on their race, gender, or other characteristics, with\n      the intent to harm or degrade.\n 6 3. The text states, \"While I appreciate the hard work of some immigrants,\n       others are just here to exploit our system and take our jobs.\"\n 7 4. This statement is making a generalization about a specific group of\n      people, in this case, immigrants. It suggests that some immigrants\n      are exploiting the system and taking jobs, which is a negative\n      stereotype.\n 8 5. Even though the text acknowledges the hard work of some immigrants, it\n       still uses derogatory language towards others, implying they are\n      here to exploit the system.\n 9 6. This statement can be seen as offensive and discriminatory towards\n      immigrants, as it negatively stereotypes them and can potentially\n      harm or degrade them.\n10 7. Therefore, according to the task description and instruction, this\n      text can be classified as hate speech.\\newline\n11 8. As per the task instruction, if the text contains hate speech, the\n      output should be 1.\n12 9. Hence, the final answer is 1. <ANS_START>1<ANS_END>\n\n13\n14 [Question] I’ve noticed that female politicians are more corrupt and only\n       care about their own interests.\\newline\n15 [Answer] 1. Start by reading the provided text: \"I’ve noticed that female\n       politicians are more corrupt and only care about their own interests\n      .\"\n16 2. Identify the subject of the text: The subject is \"female politicians.\"\n17 3. Analyze the language used in the text: The language used is derogatory\n       and offensive, as it generalizes all female politicians as being \"\n      more corrupt\" and only caring about their own interests.\n18 4. Determine if the language is discriminatory: The language\n      discriminates against a specific group, in this case, female\n      politicians, by making a negative generalization about them.\n\n\n                                         25\n\n19 5. Check if the language has the intent to harm or degrade: The language\n      used seems to degrade the reputation of female politicians by\n      portraying them as corrupt and self-interested.\n20 6. Based on the task description and instruction, the text is considered\n      hate speech if it is derogatory, offensive, or discriminatory towards\n       a specific group of people with the intent to harm or degrade.\n21 7. Since the text meets all these criteria, it is classified as hate\n      speech.\n22 8. According to the task instruction, if the text contains hate speech,\n      the output should be 1.\n23 9. Therefore, the final answer is 1. <ANS_START>1<ANS_END>\n\n24\n25 [Question] I don’t get why we have to accept people who choose to be\n      transgender. It’s unnatural and against our values.\n26 [Answer] 1. Start by reading the provided text.\n27 2. Identify the subject of the text. In this case, the subject is \"people\n       who choose to be transgender.\"\n28 3. Analyze the language used in the text. The text uses phrases like \"It’\n      s unnatural\" and \"against our values,\" which are derogatory and\n      offensive.\n29 4. Determine if the language is aimed at a specific group. Here, the\n      language is targeted towards transgender people, a specific group.\n30 5. Check if the language is intended to harm or degrade the specific\n      group. The text implies that being transgender is unnatural and\n      against societal values, which can be seen as an attempt to degrade\n      or harm the transgender community.\\newline\n31 6. Since the text uses offensive language against a specific group with\n      the intent to harm or degrade, it can be classified as hate speech.\n32 7. Therefore, the correct answer is 1, indicating that the text contains\n      hate speech. <ANS_START>1<ANS_END>\n\n\n 1 <human intent>\n\n 2\n 3 Text Analysis, Hate Speech Identification, Discriminatory Language\n      Detection, Offensive Content Recognition, Derogatory Language\n      Classification\n\n 4\n 5 <expert persona>\n\n 6\n 7 You are a machine learning engineer with a specialization in natural\n      language processing and text analysis. You have developed and trained\n       algorithms to detect and classify different types of text, including\n       hate speech. Your algorithm can analyze the given text, identify\n      patterns, and determine whether it contains hate speech or not. You\n      are equipped with a deep understanding of the nuances of language,\n      and you can differentiate between offensive language, strong\n      criticism, and actual hate speech. Your algorithm is designed to be\n      fair and unbiased, and it respects the principles of freedom of\n      speech while also recognizing the harm caused by hate speech. Your\n      expertise in text analysis and machine learning is highly valuable in\n       moderating online content and creating a safer digital environment.\n\n 8\n 9 <prompt guidelines for desired output format>\n10 You need to answer each of the questions separately with 1 if its a hate\n      speech and 0 if its not a hate speech.  Wrap your only the final\n      answer, without reason for each question separately between <\n      ANS_START> and <ANS_END> tags.\n\n\n  17.3  PUBMEDQA PROMPT\n\n 1 <the optimized prompt instruction>\n\n 2\n 3 Carefully read the abstract and identify the key points that directly\n      address the biomedical research question. Based on these key points,\n\n\n                                         26\n\nprovide a clear and concise answer in a \"Yes\" or \"No\" format,\n      followed by a brief explanation that correlates the research question\n       with the findings in the abstract.\n\n 1 <synthesized examples + reasoning chain>\n\n 2\n 3 [Question] Does the process of photosynthesis under varying light\n      intensities and temperature play a significant role in the growth of\n      different species of algae?\\newline\n 4 [Abstract] : Photosynthesis is a process used by plants and other\n      organisms to convert light energy into chemical energy that can later\n       be released to fuel the organisms’ activities. This study\n      investigates the impact of varying light intensities and temperature\n      on the photosynthetic process in different species of algae. The\n      algae were exposed to different light intensities and temperatures,\n      and their growth rate was monitored over a period of time. The\n      results showed a direct correlation between light intensity,\n      temperature and the growth rate of algae.\n 5 [Answer] 1. The question asks whether the process of photosynthesis under\n       varying light intensities and temperature plays a significant role\n      in the growth of different species of algae.\n 6 2. The abstract provides information about a study that investigates the\n      impact of varying light intensities and temperature on the\n      photosynthetic process in different species of algae.\n 7 3. The abstract mentions that the algae were exposed to different light\n      intensities and temperatures, and their growth rate was monitored\n      over a period of time.\\newline\n 8 4. The results of the study, as mentioned in the abstract, showed a\n      direct correlation between light intensity, temperature and the\n      growth rate of algae.\n 9 5. This direct correlation indicates that the process of photosynthesis\n      under varying light intensities and temperature does indeed play a\n      significant role in the growth of different species of algae.\n10 6. Therefore, based on the information provided in the abstract, the\n      answer to the question is \"Yes\". <ANS_START>yes<ANS_END>\n\n11\n\n12\n13 [Question] Is the use of antiviral drugs effective in treating influenza,\n       a common viral infection?\n14 [Abstract] : Antiviral drugs are medicines used to prevent and treat\n      viral infections. Influenza, on the other hand, is a viral infection.\n       This study investigates the effectiveness of antiviral drugs in\n      treating influenza. The study involved patients suffering from\n      influenza who were treated with antiviral drugs. The results showed\n      significant improvement in the condition of the patients.\n15 [Answer] 1. The question asks about the effectiveness of antiviral drugs\n      in treating influenza, a common viral infection.\n16 2. The abstract provides information about a study that investigates the\n      effectiveness of antiviral drugs in treating influenza.\n17 3. The study involved patients suffering from influenza who were treated\n      with antiviral drugs.\\newline\n18 4. The results of the study showed significant improvement in the\n      condition of the patients after they were treated with antiviral\n      drugs.\n19 5. Therefore, based on the results of the study mentioned in the abstract\n      , it can be concluded that the use of antiviral drugs is effective in\n       treating influenza.\n20 6. Hence, the answer to the question is \"Yes\". <ANS_START>yes<ANS_END>\n\n21\n\n22\n23 [Question] Are intensive care units more beneficial than general wards\n      for the treatment of severe pneumonia in children with underlying\n      health conditions?\n24 [Abstract] : Pneumonia is a common illness in children that can become\n      severe if not properly treated. Intensive care units (ICUs) provide\n\n\n                                         27\n\nspecialized care for patients with severe or life-threatening\n      illnesses. This study examines the impact of ICU treatment on\n      children with severe pneumonia and underlying health conditions. The\n      study compared the recovery rates of children treated in ICUs with\n      those treated in general wards. The results showed a higher recovery\n      rate in children with underlying health conditions treated in ICUs.\\\n      newline\n25 [Answer] 1. The question asks whether intensive care units (ICUs) are\n      more beneficial than general wards for the treatment of severe\n      pneumonia in children with underlying health conditions.\n26 2. The abstract provides information about a study that examined the\n      impact of ICU treatment on children with severe pneumonia and\n      underlying health conditions.\\newline\n27 3. The study compared the recovery rates of children treated in ICUs with\n       those treated in general wards.\n28 4. The results of the study showed a higher recovery rate in children\n      with underlying health conditions treated in ICUs.\n29 5. Therefore, based on the results of the study presented in the abstract\n      , the answer to the question is \"Yes\". ICUs are more beneficial than\n      general wards for the treatment of severe pneumonia in children with\n      underlying health conditions. <ANS_START>yes<ANS_END>\n\n30\n31 [Question] Is the blood glucose level a more reliable marker than HbA1c\n      for diagnosing Diabetes?\n32 [Abstract] : Diabetes is a chronic disease that affects the body’s\n      ability to process sugar. Blood glucose levels and HbA1c are commonly\n       used markers for diagnosing diabetes. This study investigates the\n      reliability of blood glucose levels and HbA1c as markers for\n      diagnosing Diabetes. The study involved patients diagnosed with\n      Diabetes and their blood glucose and HbA1c levels were measured. The\n      results showed a significant correlation between high blood glucose\n      levels and Diabetes diagnosis, but not with HbA1c levels.\n33 [Answer] 1. The question asks whether blood glucose level is a more\n      reliable marker than HbA1c for diagnosing Diabetes.\\newline\n34 2. The abstract provides information about a study that investigates the\n      reliability of blood glucose levels and HbA1c as markers for\n      diagnosing Diabetes.\n35 3. The abstract mentions that the study involved patients diagnosed with\n      Diabetes and their blood glucose and HbA1c levels were measured.\n36 4. The key point in the abstract is the results of the study, which\n      showed a significant correlation between high blood glucose levels\n      and Diabetes diagnosis, but not with HbA1c levels.\n37 5. This indicates that blood glucose levels are a more reliable marker\n      for diagnosing Diabetes than HbA1c levels, according to the study.\n38 6. Therefore, based on the information provided in the abstract, the\n      answer to the question is \"Yes\". <ANS_START>yes<ANS_END>\n\n39\n\n40\n41 [Question] Can regular strength training reduce the risk of osteoporosis\n      in adults over 60?\n42 [Abstract] : Osteoporosis is a major health issue globally, especially in\n       adults over 60. Regular strength training is known to have various\n      health benefits, including improving bone health. This study\n      investigates the impact of regular strength training on the risk of\n      osteoporosis in adults over 60. The study involved participants who\n      engaged in regular strength training and their bone health was\n      monitored over a period of time. The results showed a lower incidence\n       of osteoporosis in participants who engaged in regular strength\n      training.\n43 [Answer] 1. The question asks whether regular strength training can\n      reduce the risk of osteoporosis in adults over 60.\n44 2. The abstract provides information about a study that investigates the\n      impact of regular strength training on the risk of osteoporosis in\n      adults over 60.\n\n\n\n                                         28\n\n45 3. The abstract mentions that regular strength training is known to have\n      various health benefits, including improving bone health.\n46 4. The study involved participants who engaged in regular strength\n      training and their bone health was monitored over a period of time.\n47 5. The results of the study, as mentioned in the abstract, showed a lower\n       incidence of osteoporosis in participants who engaged in regular\n      strength training.\n48 6. Therefore, based on the results of the study mentioned in the abstract\n      , it can be concluded that regular strength training can reduce the\n      risk of osteoporosis in adults over 60.\n49 7. Hence, the answer to the question is \"Yes\". <ANS_START>yes<ANS_END>\n\n 1 <human intent>\n 2 Biomedical Research Understanding, Abstract Analysis, Key Point\n      Identification, Concise Answering, Explanation Correlation\n\n 3\n 4 <expert persona>\n\n 5\n 6 You are a biomedical researcher with a deep understanding of medical and\n      scientific literature. You have a strong background in reading and\n      interpreting scientific abstracts, and you are skilled at extracting\n      key information from complex texts. You can accurately answer\n      biomedical research questions based on the information provided in\n      the corresponding abstracts. Your expertise in biomedical research\n      allows you to understand the nuances and implications of the findings\n       presented in the abstracts, and you can provide clear, concise, and\n      accurate answers to the questions. Your ability to critically analyze\n       and interpret scientific literature makes you an invaluable resource\n       in the field of biomedical research.\n\n 7\n 8 <prompt guidelines for desired output format>\n\n 9\n10 You need to answer each of the questions separately with yes/ no/ maybe.\n      Wrap your only the final answer, without reason for each question\n      separately between <ANS_START> and <ANS_END> tags.\n\n\n  17.4 MEDQA PROMPT\n\n 1 <the optimized prompt instruction>\n\n 2\n 3 Analyze the patient’s age, symptoms, duration and onset of symptoms,\n      history of present illness, lifestyle factors, physical examination\n      findings, and any diagnostic test results presented in the Medical\n      Licensing Examination question. Use your knowledge of medicine to\n      identify the most likely diagnosis or appropriate treatment. Consider\n       the progression, severity, and duration of the patient’s symptoms in\n       relation to the answer options. Eliminate incorrect answer options\n      based on your medical knowledge and ensure your final choice is the\n      most appropriate given the specifics of the question. Validate your\n      answer by ensuring it aligns with all the information provided in the\n       question, including the patient’s age, lifestyle factors, and\n      specific diagnostic test results.\n\n 1 <synthesized examples + reasoning chain>\n\n 2\n 3 [Question] A 50-year-old man with a history of hypertension and type 2\n      diabetes presents with a 3-day history of chest pain radiating to the\n       left arm. He also reports shortness of breath and fatigue. Physical\n      examination reveals a blood pressure of 150/90 mmHg, heart rate of\n      90/min, and an irregular pulse. An ECG shows ST-segment elevation in\n      leads II, III, and aVF. Which of the following is the most\n      appropriate initial treatment?\n 4     Options:\n 5     A: Aspirin and clopidogrel\n\n\n                                         29\n\n6     B: Metformin\n 7     C: Lisinopril\n 8     D: Atorvastatin\n\n 9\n10 [Answer] 1. Start by analyzing the patient’s age, symptoms, and medical\n      history. The patient is a 50-year-old man with a history of\n      hypertension and type 2 diabetes. He presents with chest pain\n      radiating to the left arm, shortness of breath, and fatigue. These\n      symptoms are indicative of a cardiovascular event.\n11 2. Consider the physical examination findings. The patient has a blood\n      pressure of 150/90 mmHg, heart rate of 90/min, and an irregular pulse\n      . These findings further support the likelihood of a cardiovascular\n      event.\n12 3. Review the diagnostic test results. The ECG shows ST-segment elevation\n       in leads II, III, and aVF. This is a classic sign of an ST-segment\n      elevation myocardial infarction (STEMI), a type of heart attack.\n13 4. Given the diagnosis of STEMI, consider the most appropriate initial\n      treatment. The options are Aspirin and clopidogrel (A), Metformin (B)\n      , Lisinopril (C), and Atorvastatin (D).\n14 5. Eliminate incorrect answer options based on medical knowledge.\n      Metformin (B) is a medication for diabetes, Lisinopril (C) is an\n      antihypertensive medication, and Atorvastatin (D) is a cholesterol-\n      lowering medication. While these medications may be part of the\n      patient’s long-term management, they are not the most appropriate\n      initial treatment for a STEMI.\n15 6. Aspirin and clopidogrel (A) are antiplatelet medications. They work by\n       preventing blood clots, which is crucial in the initial management\n      of a STEMI to restore blood flow to the heart muscle.\n16 7. Therefore, the most appropriate initial treatment for this patient,\n      given his symptoms, physical examination findings, and ECG results,\n      is Aspirin and clopidogrel (A). This aligns with all the information\n      provided in the question and is the most appropriate given the\n      specifics of the question.\n17 8. Validate the final choice (A) as it is the most appropriate initial\n      treatment for a patient presenting with a STEMI. <ANS_START>A<ANS_END\n      >\n\n18\n\n19\n20 [Question] A 6-month-old girl is brought to the physician by her mother\n      because of a 2-day history of fever and irritability. She also has a\n      rash on her cheeks. Physical examination reveals a temperature of\n      38.5C (101.3F), a heart rate of 120/min, and a respiratory rate of\n      30/min. Examination of the skin shows erythema of the cheeks with\n      sparing of the nasal bridge and perioral area. Which of the following\n       is the most likely diagnosis?\n21     Options:\n22     A: Measles\n23     B: Fifth disease\n24     C: Roseola\n25     D: Scarlet fever\n\n26\n27 [Answer] 1. Start by analyzing the patient’s age, symptoms, duration and\n      onset of symptoms, and physical examination findings. The patient is\n      a 6-month-old girl with a 2-day history of fever and irritability.\n      She also has a rash on her cheeks. Her temperature is 38.5C (101.3F),\n       a heart rate of 120/min, and a respiratory rate of 30/min. The skin\n      examination shows erythema of the cheeks with sparing of the nasal\n      bridge and perioral area.\n28 2. Use your medical knowledge to identify the most likely diagnosis. The\n      symptoms presented are indicative of a viral exanthem, a rash that\n      appears due to a viral infection.\n29 3. Consider the answer options. The options are Measles, Fifth disease,\n      Roseola, and Scarlet fever. All of these are diseases that can\n      present with a rash.\n\n\n\n                                         30\n\n30 4. Eliminate incorrect answer options based on your medical knowledge.\n      Measles typically presents with a rash that starts at the hairline\n      and moves down, along with Koplik spots in the mouth, which are not\n      mentioned in the question. Scarlet fever typically presents with a\n      sandpaper-like rash and a strawberry tongue, which are also not\n      mentioned. Roseola typically presents with a high fever that suddenly\n       drops as a rash appears, which does not match the patient’s symptoms\n      .\n31 5. The remaining option is Fifth disease, also known as erythema\n      infectiosum. This disease is common in children and presents with a \"\n      slapped cheek\" rash, fever, and irritability, which aligns with the\n      patient’s symptoms.\n32 6. Validate your answer by ensuring it aligns with all the information\n      provided in the question. The patient’s age, symptoms, and physical\n      examination findings all align with a diagnosis of Fifth disease.\n33 7. Therefore, the correct answer is B: Fifth disease. <ANS_START>B<\n      ANS_END>\n\n34\n\n35\n36 [Question] A 70-year-old man presents with a 1-year history of\n      progressive memory loss, difficulty finding words, and getting lost\n      in familiar places. Neurologic examination shows impaired recall and\n      disorientation to time and place. MRI of the brain shows cortical\n      atrophy and enlarged ventricles. Which of the following is the most\n      likely diagnosis?\n37     Options:\n38     A: Alzheimer’s disease\n39     B: Vascular dementia\n40     C: Lewy body dementia\n41     D: Frontotemporal dementia\n\n42\n43 [Answer] 1. Start by analyzing the patient’s age, symptoms, duration and\n      onset of symptoms, and the results of the physical examination and\n      diagnostic tests. The patient is a 70-year-old man with a 1-year\n      history of progressive memory loss, difficulty finding words, and\n      getting lost in familiar places. The neurologic examination shows\n      impaired recall and disorientation to time and place. The MRI of the\n      brain shows cortical atrophy and enlarged ventricles.\n44 2. Consider the progression, severity, and duration of the patient’s\n      symptoms. The symptoms have been progressing over a year, which\n      indicates a chronic condition.\n45 3. Use your medical knowledge to identify the most likely diagnosis. The\n      symptoms of progressive memory loss, difficulty finding words, and\n      getting lost in familiar places, along with impaired recall and\n      disorientation to time and place, are characteristic of a\n      neurodegenerative disease.\n46 4. Look at the answer options and eliminate incorrect ones based on your\n      medical knowledge. Vascular dementia (Option B) typically presents\n      with stepwise deterioration of cognitive function, which is not the\n      case here. Lewy body dementia (Option C) is usually accompanied by\n      visual hallucinations, parkinsonism, or fluctuating cognition, none\n      of which are mentioned in the question. Frontotemporal dementia (\n      Option D) often presents with changes in personality and behavior,\n      which is also not mentioned in the question.\n47 5. The remaining option is Alzheimer’s disease (Option A), which is a\n      neurodegenerative disease that commonly presents with progressive\n      memory loss, difficulty finding words, and getting lost in familiar\n      places, especially in older adults. The MRI findings of cortical\n      atrophy and enlarged ventricles are also consistent with Alzheimer’s\n      disease.\n48 6. Validate your answer by ensuring it aligns with all the information\n      provided in the question. Alzheimer’s disease fits with the patient’s\n       age, the chronic and progressive nature of the symptoms, the\n      neurologic examination findings, and the MRI results.\n\n\n\n                                         31\n\n49 7. Therefore, the correct answer is A: Alzheimer’s disease. <ANS_START>A<\n      ANS_END>\n\n50\n\n51\n52 [Question] A 35-year-old woman presents with a 2-week history of severe\n      headache, fever, and photophobia. She also reports a rash on her\n      lower extremities. Physical examination reveals a temperature of 38.2\n      C (100.8F), a heart rate of 110/min, and a petechial rash on her\n      lower extremities. Lumbar puncture shows increased white blood cells\n      with a predominance of lymphocytes, increased protein, and normal\n      glucose. Which of the following is the most appropriate\n      pharmacotherapy?\n53     Options:\n54     A: Ceftriaxone and vancomycin\n55     B: Acyclovir\n56     C: Amphotericin B\n57     D: Doxycycline\n\n58\n59 [Answer] 1. Start by analyzing the patient’s symptoms: severe headache,\n      fever, photophobia, and a petechial rash on her lower extremities.\n      These symptoms suggest a systemic infection, possibly involving the\n      central nervous system given the presence of headache and photophobia\n      .\n60 2. Consider the patient’s age and duration of symptoms. A 35-year-old\n      woman with a 2-week history of these symptoms suggests an acute\n      infection rather than a chronic condition.\n61 3. Review the physical examination findings and diagnostic test results.\n      The patient has a fever and tachycardia, further supporting the\n      presence of a systemic infection. The lumbar puncture results show\n      increased white blood cells with a predominance of lymphocytes,\n      increased protein, and normal glucose. These findings are indicative\n      of viral meningitis.\n62 4. Evaluate the answer options in relation to the most likely diagnosis.\n      Viral meningitis is typically caused by enteroviruses, herpes simplex\n       virus, or arboviruses.\n63 5. Option A (Ceftriaxone and vancomycin) is used to treat bacterial\n      meningitis, which is not consistent with the lumbar puncture results.\n       Eliminate this option.\n64 6. Option B (Acyclovir) is an antiviral medication used to treat\n      infections caused by herpes viruses, including herpes simplex virus\n      meningitis. This option aligns with the diagnosis.\n65 7. Option C (Amphotericin B) is an antifungal medication, which is not\n      consistent with the diagnosis of viral meningitis. Eliminate this\n      option.\n66 8. Option D (Doxycycline) is an antibiotic used to treat bacterial\n      infections, including certain types of bacterial meningitis, but it\n      is not the first-line treatment for viral meningitis. Eliminate this\n      option.\n67 9. Validate the final choice (Option B: Acyclovir) by ensuring it aligns\n      with all the information provided in the question, including the\n      patient’s age, symptoms, physical examination findings, and specific\n      diagnostic test results.\n68 10. Therefore, the correct answer is B: Acyclovir. <ANS_START>B<ANS_END>\n\n69\n\n70\n71 [Question] A 40-year-old man with a history of alcohol abuse presents\n      with a 1-day history of severe abdominal pain, nausea, and vomiting.\n      Physical examination reveals a distended abdomen, decreased bowel\n      sounds, and tenderness to palpation in the upper abdomen. Laboratory\n      tests show an elevated serum amylase and lipase. Which of the\n      following is the most likely diagnosis?\n72     Options:\n73     A: Acute pancreatitis\n74     B: Peptic ulcer disease\n75     C: Gastric cancer\n\n\n                                         32\n\n76     D: Gastroenteritis\n\n77\n78 [Answer] 1. Start by analyzing the patient’s age, symptoms, duration and\n      onset of symptoms, history of present illness, lifestyle factors,\n      physical examination findings, and any diagnostic test results\n      presented in the question. The patient is a 40-year-old man with a\n      history of alcohol abuse. He has been experiencing severe abdominal\n      pain, nausea, and vomiting for 1 day. His abdomen is distended, bowel\n       sounds are decreased, and there is tenderness in the upper abdomen.\n      His serum amylase and lipase levels are elevated.\n79 2. Use your knowledge of medicine to identify the most likely diagnosis.\n      The patient’s history of alcohol abuse, the sudden onset and severity\n       of his symptoms, and his physical examination findings are all\n      indicative of a pancreatic condition. The elevated serum amylase and\n      lipase levels further support this, as these enzymes are produced by\n      the pancreas and their levels increase in the blood when the pancreas\n       is inflamed or damaged.\n80 3. Consider the answer options in relation to the patient’s symptoms and\n      test results. Acute pancreatitis, peptic ulcer disease, gastric\n      cancer, and gastroenteritis are all potential diagnoses.\n81 4. Eliminate incorrect answer options based on your medical knowledge.\n      Peptic ulcer disease typically presents with a burning pain in the\n      middle or upper stomach between meals or at night, not with a\n      distended abdomen and decreased bowel sounds. Gastric cancer usually\n      develops slowly over many years, and its symptoms often only appear\n      in the advanced stages of the disease. Gastroenteritis, while it can\n      cause abdominal pain, nausea, and vomiting, does not typically result\n       in a distended abdomen, decreased bowel sounds, or elevated serum\n      amylase and lipase levels.\n82 5. The remaining option, acute pancreatitis, aligns with all the\n      information provided in the question. The patient’s history of\n      alcohol abuse is a common risk factor for acute pancreatitis. The\n      sudden onset and severity of his symptoms, his physical examination\n      findings, and his elevated serum amylase and lipase levels are all\n      characteristic of this condition.\n83 6. Therefore, the most likely diagnosis for this patient is acute\n      pancreatitis, making option A the correct answer. <ANS_START>A<\n      ANS_END>\n\n\n\n 1\n 2 <human intent>\n 3 Medical Knowledge, Analytical Skills, English Proficiency, Reasoning\n      Skills, Attention to Detail\n\n 4\n 5 <expert persona>\n 6 You are a medical professional with extensive experience in the field and\n       a deep understanding of the United States Medical Licensing Exam (\n      USMLE). You have successfully passed the USMLE and have a thorough\n      understanding of the format and style of the questions. You are well-\n      versed in a wide range of medical topics, from anatomy and physiology\n       to pathology and pharmacology. You have the ability to analyze\n      complex medical scenarios, apply your knowledge, and make informed\n      decisions. You can accurately interpret the questions and the\n      provided options, and select the correct answer based on your medical\n       knowledge and reasoning. Your expertise and experience make you\n      highly capable of answering these questions correctly and efficiently\n\n 7\n 8 <prompt guidelines for desired output format>\n 9 You need to output the correct option among [A/B/C/D] for each question\n      separately using your medical knowledge and reasoning. Wrap your only\n       the final answer, without reason for each question separately\n      between <ANS_START> and <ANS_END> tags.\n\n\n\n\n\n                                         33",
"headers": [
"arXiv:2405.18369v2  [cs.CL]  3 Oct 2024",
"P",
"W",
":",
"T",
"-A",
"O",
"F",
"ROMPT",
"IZARD",
"ASK",
"WARE",
"PTIMIZATION",
"RAMEWORK",
"A",
"1",
"I",
"2",
"R",
"3",
"4",
"E",
"D",
"5",
"6",
"S",
"7",
"C",
"8",
"B",
"(BBII) D",
"9",
"10",
"H",
"11",
"- A",
"12",
": BBII D",
"13",
": A",
"14",
"15",
"BBII",
"16",
"17",
": T",
"/T",
"& F",
"-"
],
"tables": [
"|Col1|Col2|Input|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||**Iterative**<br>**Refinement**<br>**of Prompt**<br>**Instructions**|**Modified Prompt**<br>**Instruction**|\n|||||||\n||**Prompt**<br>**Instruction**|**Prompt**<br>**Instruction**|**Prompt**<br>**Instruction**|**Prompt**<br>**Instruction**|**Prompt**<br>**Instruction**|\n||**Prompt**<br>**Instruction**|**Prompt**<br>**Instruction**||||",
"|Sequential<br>Optimization|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|**Sequential**<br>**Optimization**|**Sequential**<br>**Optimization**|**Optimized**<br>**Prompt**|**Optimized**<br>**Prompt**|**Optimized**<br>**Prompt**|\n|**Sequential**<br>**Optimization**|**Sequential**<br>**Optimization**|**Optimized**<br>**Prompt**||**Self-generated**<br>**Reasoning and**<br>**Validation**|\n|**Sequential**<br>**Optimization**|||||\n|**Sequential**<br>**Optimization**||**Synthesized**<br>**Examples**|**e**||",
"|Task APE InsZero PB EvoP Instinct PW|Instinct PW|\n|---|---|\n|**LLM: GPT3.5Turbo**<br>Zero-shot setting|One-shot setting|\n|antonyms<br>0.64<br>0.83<br>0.80<br>0.80<br>**0.85**<br>0.56<br>auto-categorization<br>0.25<br>0.26<br>0.22<br>0.26<br>0.25<br>**0.28**<br>cause and effect<br>0.57<br>0.81<br>0.75<br>0.83<br>0.59<br>**0.88**<br>common concept<br>0.07<br>0.09<br>0.10<br>0.12<br>**0.21**<br>0.10<br>diff<br>0.67<br>0.69<br>**1.00**<br>**1.00**<br>**1.00**<br>**1.00**<br>informal to formal<br>0.57<br>0.53<br>0.58<br>**0.62**<br>0.55<br>**0.62**<br>letters list<br>**1.00**<br>0.59<br>0.99<br>**1.00**<br>**1.00**<br>0.95<br>negation<br>0.75<br>0.78<br>0.77<br>0.79<br>**0.82**<br>0.73<br>object counting<br>0.36<br>0.36<br>0.34<br>0.12<br>0.34<br>**0.60**<br>odd one out<br>0.63<br>0.61<br>0.64<br>0.65<br>0.70<br>**0.78**<br>orthography starts with<br>0.46<br>0.51<br>0.56<br>0.60<br>0.67<br>**0.75**<br>rhymes<br>0.16<br>**1.00**<br>0.54<br>0.61<br>**1.00**<br>0.89<br>second word letter<br>0.75<br>0.43<br>0.57<br>0.41<br>0.10<br>**0.93**<br>sentence similarity<br>0.00<br>0.00<br>0.01<br>0.28<br>0.14<br>**0.29**<br>sum<br>0.67<br>**1.00**<br>**1.00**<br>**1.00**<br>**1.00**<br>**1.00**<br>synonyms<br>0.36<br>0.28<br>0.36<br>0.14<br>0.31<br>**0.37**<br>taxonomy animal<br>0.35<br>0.72<br>0.72<br>0.72<br>0.86<br>**0.92**<br>word sorting<br>0.33<br>0.31<br>**0.56**<br>0.52<br>0.51<br>**0.56**<br>word unscrambling<br>0.44<br>0.55<br>0.61<br>0.60<br>**0.63**<br>0.52|**0.85**<br>0.78<br>0.30<br>**0.40**<br>0.63<br>**0.92**<br>**0.25**<br>0.19<br>**1.00**<br>**1.00**<br>0.52<br>**0.56**<br>**1.00**<br>**1.00**<br>**0.86**<br>0.84<br>0.36<br>**0.52**<br>0.63<br>**0.92**<br>0.67<br>**0.92**<br>0.75<br>**0.90**<br>0.24<br>**0.99**<br>0.16<br>**0.30**<br>**1.00**<br>**1.00**<br>0.37<br>**0.44**<br>0.90<br>**0.94**<br>0.62<br>**0.74**<br>**0.58**<br>**0.58**|\n|#bestperforming tasks<br>1<br>2<br>3<br>4<br>8<br>**13**|7<br>**16**|",
"|Task|Description|\n|---|---|\n|antonyms<br>auto categorization<br>cause and effect<br>common concept<br>diff<br>informal to formal<br>letters list<br>negation<br>object counting<br>odd one out<br>orthography starts with<br>rhymes<br>second word letter<br>sentence similarity<br>sum<br>synonyms<br>taxonomy animal<br>word sorting<br>word unscrambling|Make the pairs of words opposite.<br>Create a list of things that the input could be associated with, and the<br>output would be the category that the input belongs to<br>identify the sentence that is the cause of the effect in the input sentence<br>pair<br>”involve” the objects mentioned in the input, so the answer would be<br>”involve oscillations” for the input ”guitars, pendulums”<br>Find the difference between the two numbers<br>convert the input sentence into an output sentence that is grammatically<br>correct and idiomatic in English<br>output the input with a space after each letter<br>make the output false by adding the word ”not” to the input<br>output the number of objects in the input list<br>find the word that is most dissimilar to the others in the group<br>output the word that starts with the letter that was inputted<br>output the first word that appeared in the input text<br>takes a string as input and returns the first character that is a vowel.<br>Find the difference between the two sentences and the output was 4 -<br>almost perfectly<br>add the numbers of the two input numbers<br>create a list of words that could be used in the same way as the original<br>words<br>output the name of an animal that starts with the letter<br>sort the input words alphabetically<br>output the word that is formed by rearranging the letters of the given<br>word|",
"|Hyper-<br>parameter|Description|Default Value|\n|---|---|---|\n|_mutate_refine_<br>_rounds_<br>_mutate_rounds_<br>_style_variation_<br>_min_example_<br>_correct_count_<br>_max_example_<br>_count_<br>_max_seq_iter_<br>_few_shot_count_<br>_ex_critique_<br>_synthesize_<br>_inst_critique_<br>_synthesize_<br>_reasoning_<br>_+_<br>_validation_<br>_intent + per-_<br>_sona_|Number of rounds of call to MutateComponent fol-<br>lowed by refinement over best prompt among generated<br>by MutateComponent in previous step.<br>Number of times MutateComponent would be called.<br>Number of variations MutateComponent generates in<br>a single call. i.e. one variation corresponding to each<br>thinking style provided.<br>Minimum<br>number<br>of<br>questions<br>the<br>ScoringComponent<br>should<br>answer<br>correctly<br>for a prompt to get qualified for next stage.<br>Maximum<br>number<br>of<br>attempts/questions<br>the<br>ScoringComponent<br>would<br>be<br>asked<br>asked<br>to<br>answer.<br>Number of rounds of call to CritiqueComponent fol-<br>lowed by call to SynthesizeComponent<br>Total number of few shot examples to be provided in<br>prompt.<br>Number of LLM calls made by CritiqueComponent<br>for getting critique for improving examples passed as few-<br>shots.<br>Number<br>of<br>LLM<br>calls<br>made<br>by<br>SynthesizeComponent<br>to<br>generate<br>synthetic<br>examples.<br>Number of LLM calls made by CritiqueComponent<br>for getting critique for improving instruction passed as<br>few-shots.<br>Number<br>of<br>LLM<br>calls<br>made<br>by<br>SynthesizeComponent<br>to<br>created<br>improved<br>version of instruction.<br>Number<br>of<br>LLM<br>calls<br>made<br>by<br>ReasoningComponent<br>and<br>ValidateComponent respectively.<br>Number of LLM calls made to get keywords that express<br>the intent and togenerate expertpersona respectively.|3<br>3<br>3<br>3<br>6<br>5<br>Defined in Ta-<br>ble 10<br>1<br>1<br>1<br>1<br>2<br>2|",
"|Task|Instinct PromptWizard|\n|---|---|\n|**LLM: GPT4**|Zero-shot setting|\n|antonyms<br>auto categorization<br>cause and effect<br>common concept<br>diff<br>informal to formal<br>letters list<br>negation<br>object counting<br>odd one out<br>orthography starts with<br>rhymes<br>second word letter<br>sentence similarity<br>sum<br>synonyms<br>taxonomy animal<br>word sorting<br>word unscrambling|**0.79**<br>0.77<br>0.3<br>**0.38**<br>**0.96**<br>0.88<br>**0.2**<br>0.15<br>**1**<br>**1**<br>0.6<br>**0.75**<br>**1**<br>**1**<br>0.7<br>**0.85**<br>0.6<br>**0.82**<br>0.54<br>**0.87**<br>0.75<br>**0.92**<br>**1**<br>0.88<br>0.57<br>**0.97**<br>0.3<br>**0.43**<br>0.99<br>**1**<br>0.3<br>**0.42**<br>0.9<br>**1**<br>0.5<br>**0.65**<br>0.54<br>**0.77**|\n|# bestperforming tasks|6<br>**15**|",
"|Col1|Instinct|PromptWizard|\n|---|---|---|\n|Dataset|API Calls<br>IO Tokens|API Calls<br>IO Tokens|\n|antonyms<br>auto-categorization<br>cause and effect<br>common concept<br>diff<br>informal to formal<br>letters list<br>negation<br>object counting<br>odd one out<br>orthography starts with<br>rhymes<br>second word letter<br>sentence similarity<br>sum<br>synonyms<br>taxonomy animal<br>word sorting<br>word unscrambling|2200<br>39<br>1740<br>86<br>1352<br>61<br>639<br>94<br>1820<br>58<br>880<br>90<br>2240<br>58<br>2180<br>60<br>1340<br>69<br>840<br>50<br>1800<br>82<br>1920<br>41<br>1840<br>48<br>2140<br>78<br>2180<br>66<br>2100<br>51<br>1900<br>72<br>1680<br>110<br>2060<br>58|69<br>334<br>69<br>341<br>69<br>390<br>69<br>386<br>69<br>381<br>69<br>271<br>69<br>256<br>69<br>305<br>69<br>470<br>69<br>372<br>69<br>339<br>69<br>391<br>69<br>257<br>69<br>626<br>69<br>367<br>69<br>452<br>69<br>225<br>69<br>426<br>69<br>306|\n|Average|1729<br>67|69<br>362|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/test/2405.18369v2.pdf"
}