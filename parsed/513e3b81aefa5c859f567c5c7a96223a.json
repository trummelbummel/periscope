{
"text": "Prompt Optimization and Evaluation for LLM Automated Red Teaming\n\n                    Michael Freenor1∗†, Lauren Alvarez12†, Milton Leal1†, Lily Smith1†\n                            Joel Garrett1, Yelyzaveta Husieva1, Madeline Woodruff1\n               Ryan Miller1, Erich Kummerfeld3, Rafael Medeiros4, Sander Schulhoff5\n                                 1Fuel iX Applied Research, Charlottesville, USA\n                                2North Carolina State University, Raleigh, USA\n                                    3University of Minnesota, Minneapolis, USA\n                              4TELUS Digital, Vancouver, CA\n                                   5Learn Prompting, San Francisco, USA\n\n                          Abstract                       Ribeiro, 2022). In this practice, adversarial inputs\n                                                                 are automatically generated by a prompted LLM                  Applications that use Large Language Mod-\n                                                               (an attack generator) and systematically evaluated.                     els (LLMs) are becoming widespread, making\n                   the identification of system vulnerabilities in-     Common examples of attacks include prompt in-2025            creasingly important. Automated Red Team-        jections and data exfiltration attempts (Dong et al.,\n                  ing accelerates this effort by using an LLM       2024). These attacks are deployed against a target\n                   to generate and execute attacks against target       and assigned a binary success feature (0 for failure,Jul                  systems. Attack generators are evaluated us-                                                      1 for success), and the generator’s Attack Success\n29            ing the Attack Success Rate (ASR) – the sam-      Rate (ASR) is calculated as the sample mean of                   ple mean calculated over the judgment of suc-\n                                                                  these features (Yang and Wang, 2023).                  cess for each attack. In this paper, we intro-\n                duce a method for optimizing attack generator                                                  One of our contributions (see Figure 1) is the appli-\n                 prompts that applies ASR to individual attacks.\n                                                                 cation of ASR to individual attacks, replacing bi-\n              By repeating each attack multiple times against\n                                                              nary success with a numeric feature calculated over                 a randomly seeded target, we measure an at-[cs.CR]                   tack’s discoverability – the expectation of the       repeated trials of each attack against a randomly\n                   individual attack success. This approach re-      seeded target. This new set of features forms an\n                  veals exploitable patterns that inform prompt     ASR distribution that captures more information\n                   optimization, ultimately enabling more robust       about a given attack generator. Our main contri-\n                   evaluation and refinement of generators.            bution is providing a method to optimize the at-\n                                                                tack generator through Optimization by PROmpt-\n          1  Introduction\n                                                                 ing (OPRO) (Yang et al., 2024). The in-context data\n           Systems  that apply Large Language Models    for our OPRO procedure is formed by selecting se-\n           (LLMs), collectively referred to as LLM applica-   mantically similar attacks that have a difference in\n               tions, have demonstrated remarkable capabilities  ASR above a set threshold. These contrastive pairs\n             across various domains (Brown et al., 2020). How-   exhibit subtle differences that can guide an LLM\n              ever, like other forms of deep learning, these sys-    to produce more successful attack generators.\n            tems (targets) are susceptible to adversarial inputs\n                                                                In the following sections we detail our methodol-arXiv:2507.22133v1        (attacks). To address this, Red Teaming identifies\n                                                               ogy, present experimental results, and discuss the\n                critical vulnerabilities that malicious actors might\n                                                                   implications of our findings for the broader field of\n              exploit in real-world scenarios. This process re-\n                                      LLM safety and robustness.\n              veals potential weaknesses and risks of LLM appli-\n              cation misuse leading to liability for organizations\n                                                 2  Related Work\n            encompassing social, moral, and legal dimensions\n           (Yao et al., 2024). Consequently, addressing these    2.1  Automated Red Teaming for LLM\n              issues at scale through rigorous evaluation and opti-        Applications\n             mization is paramount to ensuring scalability, align-\n                                                      Automated red teaming for Large Language Mod-\n            ment, safety, and security (Vashney, 2022).\n                                                                        els (LLMs) has emerged as a critical area of re-\n           Automated Red Teaming has emerged as a scal-   search, with recent work establishing methods for\n             able approach to tackle this challenge (Perez and    systematically testing model safety and robustness.\n                  ∗Corresponding author: michael.freenor@fuelix.ai        Early approaches focused primarily on gradient-\n                  †These authors contributed equally to this work.          based attack optimization (Bai et al., 2022), but the\n\n\n                                                    1\n\nFigure 1: Flowchart depicting the calculation of an empirical ASR distribution\n\n\nfield has rapidly evolved to encompass a broader    adaptive mutation rates, while balancing effective-\nrange of techniques including automated discrete    ness with attack diversity (Lin et al., 2024).\nprompt-based methods (Perez et al., 2022; Ganguli\net al., 2022), evolutionary algorithms (Choulde-\nchova et al., 2023), and hybrid approaches (Lin    2.2  Attack Success Rate\net al., 2024).\n                                         The evaluation of red teaming effectiveness hasRecent taxonomies help organize these diverse ap-\n                                                  coalesced around Attack Success Rate (ASR) as aproaches. Perez et al. (2022) introduced a method\n                                               primary metric, though its definition and applica-for using one LLM to generate test cases for an-\n                                                      tion may vary across studies. ASR typically mea-other demonstrating the potential of automated red\n                                                    sures the proportion of attempts that successfullyteaming. Ganguli et al. (2022) expanded on this\n                                                  breach a model’s safeguards (Hui, 2023), but recentwork, providing insights into scaling behaviors and\n                                         work has highlighted the need for more nuancedlessons learned from extensive red teaming efforts.\n                                                         interpretations.These studies laid the groundwork for more sophis-\nticated approaches.                         Dong et al. (2024) propose a multi-dimensional\n                                              view of ASR that considers not only the binary suc-In terms of implementation strategies, continuous\n                                                    cess outcome but also the severity of the violationoptimization in embedding space has shown par-\n                                            and the naturalness of the attack. This approachticular promise for generating nuanced adversarial\n                                                 has been further refined by incorporating semanticinputs (Bai et al., 2022). These gradient-based ap-\n                                                      preservation scores to ensure that successful attacksproaches operate in token embedding, hidden state,\n                                                maintain their intended meaning while achievingand output logit spaces, offering different trade-\n                                                           their objectives (Lin et al., 2024).offs between attack power and computational com-\nplexity. However, discrete prompt-based methods   The importance of considering ASR in the context\nremain dominant due to their universal applicabil-   of attack diversity has been emphasized in recent\nity and interpretability (Perez et al., 2022; Ganguli    literature. Some researchers have demonstrated\net al., 2022). Furthermore, gradient-based exploits    that high ASR values may mask a lack of diversity\nrely on access to powerful computational resources;    in successful attacks, leading to potential overesti-\nfor those using third-party services (e.g. OpenAI),   mation of vulnerability (Chouldechova et al., 2023).\nthese methods are off the table.                    This has led to the introduction of metrics like the\n                                                  Attack Diversity Index (ADI) that should be consid-A significant advancement in automated red team-\n                                                  ered alongside ASR when evaluating red teaminging has been the development of mutation-based\n                                                        effectiveness.approaches. These methods employ evolutionary\nalgorithms where successful prompts are iteratively   As the field of LLM red teaming continues to\nmodified and selected based on their effectiveness    evolve, there is a growing recognition of the need\n(Chouldechova et al., 2023). Advanced mutation    for standardized benchmarks and evaluation frame-\ntechniques incorporate linguistic knowledge and   works (Mazeika et al., 2024).\n\n\n                                         2\n\n2.3  Optimization by Prompting (OPRO)        an automated judge serving as the cost function.\n\nRecent research has explored the potential of LLMs   3  ASR Applied to Individual Attacks and\nnot just as generators of text or solvers of specific         its Distribution\ntasks, but as general-purpose optimizers. Yang et al.\n                                              Recent work by Chouldechova et al. (2023) has(2024) introduced the concept of \"Optimization by\n                                                     highlighted important theoretical considerations inPROmpting\" (OPRO), a novel approach that lever-\n                                        AI Red Teaming, particularly regarding the inter-ages the reasoning capabilities of LLMs to solve\n                                                      pretation and comparison of ASR across differentoptimization problems across various domains.\n                                                     contexts. Building upon this foundation, we pro-\nOPRO represents a significant shift in how we uti-   pose an approach to address the specific challenges\nlize LLMs, moving beyond manual prompt engi-   posed by non-deterministic LLM responses in Red\nneering to employ these models as iterative opti-   Teaming scenarios. Our contribution complements\nmizers. The core idea is to frame optimization prob-   existing work by offering a statistical method tai-\nlems as natural language tasks, allowing the LLM    lored to the unique characteristics of LLM-based\nto propose, evaluate, and refine solutions through a    systems.\nseries of prompted interactions.\n                                                    3.1  Applying ASR to Individual AttacksThe OPRO framework consists of several key com-\nponents:                                              Traditional approaches to measuring attack success\n                                                    often rely on what we call single-try ASR, which\n  1. Problem Formulation: The optimization task\n                                                 uses binary success on a single try of the attack\n      is expressed in natural language, including the\n                                                   as the feature for ASR calculations. This method\n     objective function and any constraints.\n                                                 provides a point estimate that serves as a basis\n  2. Solution Generation: The LLM proposes can-   of comparison between attack generators, bench-\n     didate solutions based on the problem descrip-   mark datasets, and target systems (Chakraborty\n     tion and previous iterations.                       et al., 2021). However, as pointed out by Choulde-\n                                               chova et al. (2023), this approach can be misleading\n  3. Evaluation: The proposed solutions are eval-\n                                                       in practice, particularly when dealing with non-\n     uated using the specified objective function,\n                                                      deterministic LLM applications. Applying ASR to\n     often by an external system or LLM judges.\n                                                     individual attacks provides additional information\n  4. Feedback and Iteration: The evaluation results    about the consistency and reliability of each attack\n     are fed back to the LLM, which then reasons    across different target seeds, revealing important\n     about how to improve the solution in the next    patterns that single-try measurements cannot cap-\n      iteration.                                            ture.\n\nYang et al.  demonstrated the effectiveness of  We claim that attack quality is at least partially\nOPRO on a diverse set of problems, including lin-   characterized by this reapplied ASR calculation.\near regression, traveling salesman problems, and   Our primary justification follows from attacker eco-\nprompt optimization for other AI tasks. Notably,   nomics: attackers operate under constraints of lim-\nOPRO showed competitive performance against    ited time and resources (or equivalently, limited\ntraditional optimization algorithms and specialized    tokens), making discoverability of success an im-\nneural network approaches, highlighting the versa-    portant part of overall quality (Chouldechova et al.,\ntility of LLMs as general-purpose problem solvers.   2023). When attempting to uncover vulnerabili-\n                                                                 ties, any repetition of previously executed attacks\nOne of the key advantages of OPRO is its ability to\n                                                      necessarily reduces the set of unique attacks tested\nuse the broad knowledge and reasoning capabilities\n                                                  within a fixed budget of trials. Consequently, at-\nembedded in LLMs. This allows the method to\n                                                      tackers must balance between breadth and depth.\npotentially discover novel optimization strategies\nthat might not be apparent to human experts or    Targets typically operate with a random seed to\neasily encoded in traditional algorithms, especially   maintain flexible and dynamic responses. Conse-\nfor natural language inputs like adversarial prompts.    quently, an identical attack executed multiple times\nFor the purposes of this paper we employ OPRO to   may produce target outputs that vary, yielding some\noptimize attack generator prompts on the basis of    proportion of successes and failures that are not\n\n\n                                         3\n\naccounted for in single-try ASR. This observation\naligns with the measurement theory concerns raised\nin previous work (Chouldechova et al.) and moti-\nvates the application of ASR to individual attacks.\n\nWe suggest the following pipeline:\n\n  1. Generate n attacks from the attack generator.\n\n  2. For each unique attack, run the attack against\n     the target (with no chat history) m times.\n\n  3. Collate the binary vector of m successes and\n     failures produced by the judge with its corre-\n    sponding attack and calculate the ASR (sam-\n     ple mean) of this vector.\n\nThis approach replaces the typical binary qual-\nity metric with a numeric one, enabling a more\ninformed assessment of generator quality based            Figure 2: Example ASR Distribution\non the proportion of successes an attack achieved\nagainst a target (Yang and Wang, 2023).\n                                                           late realistic non-deterministic behavior. We gen-\nGiven these considerations, our primary research\n                                                     erated n = 384 unique attacks and evaluated each\ngoal is to demonstrate the utility of applying ASR\n                         m = 50 times against the target (see Appendix A\nto individual attacks and to show that its distribu-\n                                                        for sample size justification).\ntion provides valuable information about generator\nquality. We address this by exploiting the ASR   For the examined generator, we calculate an em-\ndistribution for generator prompt optimization.        pirical distribution (Figure 2). This distribution\n                                                                is characterized by one mode near the origin, re-\n3.2  The ASR Distribution and Its Implications    flecting the effectiveness of the target’s security\n                                                 measures, and additional mass higher on the ASR\nThe ASR distribution provides critical information\n                                                           scale, representing a sample of relatively successful\nfor evaluating and improving attack generators by\n                                                         attacks.\nrevealing patterns that are invisible to single-try\nASR. Specifically, this distribution:              To model this distribution, we suggest the use of\n                                                a Beta mixture where the number of Beta distri-\n    • Captures attack success discoverability across\n                                                   butions is equal to the number of modes present\n    random target seeds\n                                                      in the empirical distribution. This modeling ap-\n    • Reveals clusters of particularly successful or   proach serves several purposes: it provides a com-\n     unsuccessful attacks                           pact mathematical representation of the complex\n                                 ASR patterns, enables statistical comparison be-\n    • Enables identification of minimal linguistic\n                                            tween different attack generators, and facilitates\n     differences between high and low-performing\n                                                    simulation of attack success scenarios. Most impor-\n     attacks\n                                                             tantly, it helps bridge empirical observations with\n    • Provides a statistical foundation for more ro-    theoretical understanding of attack quality, allow-\n     bust generator optimization                     ing researchers to make more informed predictions\n                                                 about generator performance in various contexts.\nTo empirically compute the ASR distribution, we\nuse GPT-4o (2024-05-13) for all three components   The ASR distribution provides richer information\nof our pipeline: (1) the attack generator that creates    for comparing generators than the traditional single-\nadversarial prompts, (2) the target system that sim-    try ASR. While single-try ASR compares genera-\nulates an LLM-based application being attacked,    tors based on the probability that a randomly gen-\nand (3) the judge that evaluates whether each at-   erated attack will succeed against the target on a\ntack attempt succeeded. Each component oper-    single attempt, the ASR distribution is sensitive to\nated with temperature=1 and random seeds to emu-    settings where multiple tries are afforded to each\n\n\n                                         4\n\nattack. This distinction is crucial in practical red   This approach is formalized in Algorithm 1 which\nteaming scenarios as it integrates attack success   employs a technique we term ASR-delta pair min-\ndiscoverability.                                        ing. This procedure selects similar attacks based\n                                            on a chosen similarity measure (S). For S we apply\nMathematically, the ASR distribution represents a\n                                                  cosine similarity to attack embeddings produced\ndistribution over Bernoulli parameters, with each\n                                          by OpenAI’s text-embedding-3-large. We select\nattack’s ASR serving as the θ parameter for its cor-\n                                                     attack pairs with an ASR difference exceeding a\nresponding Bernoulli distribution. Thus, a set of\n                                                     threshold ∆. By setting an appropriate ∆, this pro-\nsingle-try attempts across multiple attacks effec-\n                                                cedure can reveal critical and minimal contrasts\ntively samples from a mixture of these Bernoullis.\n                                            between high and low-ASR attacks which prove\nAccordingly, the mean of the ASR distribution con-\n                                                        effective for improving attack generator prompts\nverges to the single-try ASR due to the fact that\n                                                     against a given target.\nthe ASR distribution ranges over a set of attack\nexpectations. While two ASR distributions with   The core idea behind this approach is to provide\nequal means are equivalent on this basis, the one   semantic nearest neighbors with differing ASRs\nwith more mass concentrated higher on the ASR    to an OPRO prompt, thereby highlighting which\nscale would produce attacks whose success is more    characteristics to emulate. The optimizer prompt\ndiscoverable on the whole. This makes the ASR     is designed to produce text that, when added to\ndistribution a valuable tool for comparison when-   our generator’s system prompt, transforms it into a\never attack success discoverability is important.     more effective generator against the target.\n\nIn settings where the goal is exploiting a specific    In our experiments, we use GPT-4o (2024-05-13)\nvulnerability, repeated trials of a set of attacks may   with temperature=1 for both the generator and the\nbe more desirable than trying a larger set of distinct    optimizer. We produce 10 possible prompt addi-\nattacks a single time each. The ASR distribution    tions to the original generator and keep the one that\ncaptures the nuance required for this assessment.   yields the highest ASR distribution mean. This ap-\nMoreover, it highlights the noisy nature of binary   proach was chosen due to specific constraints in the\nsuccess as a feature—low-ASR attacks may occa-   prompt that are required to get attack generation to\nsionally succeed on a single attempt while high-   work, which can unintentionally be written out of\nASR attacks may fail, leading to potentially mis-   a generator during optimization.\nleading classifications when using single-try met-\n                                          The result is demonstrated in Figure 4 and Figure 5,\nrics alone.\n                                             which compares ASR distributions before and after\nBy leveraging this distributional understanding of    the application of this method. The improvement\ngenerator quality, we can develop more effective    in attack performance is evident in the rightward\nstrategies for both evaluating and improving attack    shift of density in the distribution, accompanied\ngenerators. In the following section, we demon-   by a corresponding increase in the distribution’s\nstrate how this information can be exploited to op-   mean. This shift indicates that the optimized gen-\ntimize generator prompts.                            erator produces a higher proportion of high-ASR\n                                                       attacks using information from the original genera-\n4  Application: Attack Generator               tor’s ASR distribution. This approach:\n   Optimization                                                                 • Utilizes information about attack success dis-\n                                                            coverability from the ASR distribution\n4.1  ASR-Delta Pair Mining\n                                                                 • Provides a systematic method for identifying\nThe ASR distribution reveals a diversity of attack\n                                                and emulating successful attack characteris-\nquality that is not captured by single-try ASR. With-\n                                                                    tics\nout considering the ASR distribution, it is possible\nto overlook prompt patterns that correlate with the        • Enables the continuous improvement of gen-\nsuccess of an attack. To demonstrate the practical         erators through iterative application\nutility of the ASR distribution, we explore an appli-\n                                                                 • Offers insights into the factors that contribute\ncation to Automated Red Teaming using Optimiza-\n                                                             to attack success\ntion by PROmpting (OPRO), which is summarized\nin Figure 3.                                   However, it is crucial to consider potential limita-\n\n\n                                         5\n\nFigure 3: Flowchart depicting ASR delta pair mining\n\nAlgorithm 1 ASR-Delta Pair Mining and Generator OPRO\nRequire: Set of distinct attacks A generated by GA with ASR(A) ∼DA, similarity metric S, threshold\n  ∆> 0, optimizer prompt O\n  1: Form set P of semantically similar pairs (a, b) where a, b ∈A, a ̸= b, and\n        ∀a′ ∈A : S(a, b) ≥S(a′, b)\n  2: Filter to pairs with significant ASR difference:\n     P ′ = {(a, b) ∈P | |ASR(a)−ASR(b)| ≥∆}\n                                                                                                                                ′  3: Order each pair such that ASR(a) > ASR(b) for all (a, b) ∈P\n  4: Produce optimized generator G′A = O(GA, P ′), where O prompts for an addition\n         to GA that favors completions similar to high-ASR attacks a rather than low-ASR\n         attacks b\n\n\ntions and areas for future research:            We compare ASR-delta pair mining OPRO against\n                                            what we term single-try OPRO (ST-OPRO).\n    • The generalizability of this method across dif-\n     ferent target systems needs further investiga-  ST-OPRO replaces the use of individual attack\n     tion                           ASR with the  single-try binary success met-\n                                                  ric—selecting semantic nearest neighbors so long\n    • The choice of similarity measure (S) and\n                                                    as one is successful and the other unsuccessful on\n     threshold (∆) may significantly impact results\n                                                a single try.  This modification was specifically\n    and thus require careful tuning\n                                                designed to provide the closest possible compari-\n    • The long-term effectiveness of this approach   son to ASR-delta pair mining, differing only in the\n     in the face of evolving defenses remains to be   mechanism for distinguishing between high and\n     studied                                        low-quality attacks.\n\nBy demonstrating the value of the ASR distribu-  As in ASR-delta OPRO, we use GPT-4o (2024-\ntion as a source of information about attack quality,   05-13) with temperature=1 for both the generator\nthis work opens new avenues for research in auto-   and optimizer. We produce 10 possible prompt\nmated red-teaming and LLM security. Future work    additions to the original generator and select the\ncould explore more sophisticated optimization tech-   generator with the highest ASR distribution mean.\nniques, investigate the transferability of learned im-\n                                             While ST-OPRO does yield improvements over the\nprovements across different types of LLM-based\n                                                      original unoptimized generator (see Figure 4 and\nsystems, and develop methods to anticipate and\n                                                 Figure 5), these improvements are demonstrably\ncounteract these optimized attack strategies.\n                                                    smaller than those achieved through the ASR-delta\n                                               method.\n4.2  Method Comparison: Single-Try Attack\n     Pair Mining                           The superior performance of ASR-delta pair min-\n                                                  ing suggests that the ASR distribution providesTo validate that the improvements observed in our\n                                                a better source of information for the optimiza-optimized generator’s ASR distribution stem from\n                                                      tion process than single-try success. This findingthe information contained within the original gen-\n                                                  supports our hypothesis that the ASR distributionerator’s ASR distribution rather than from the act\n                                                   contains valuable information about attack qual-of OPRO itself, we conduct a comparative analysis.\n\n\n                                         6\n\ntimization procedures, and evaluation of genera-\n                                                              tors.\n\n                                         Our results demonstrate that the ASR distribution\n                                                     serves as a reliable guide for identifying contrastive\n                                                      pairs for use with OPRO. By selecting semantic\n                                                     nearest neighbors with large ASR differences, we\n                                              can isolate near-minimal contrasts in attack lan-\n                                              guage that have disproportionate impacts on attack\n                                                          efficacy. This approach provides a method for un-\n                                                  derstanding and improving attack generator per-\n                                               formance, as evidenced by the superior results of\n                                              ASR-delta pair mining compared to ST-OPRO.\n\n                                              These findings open several promising avenues for\n                                                      future research:\n\n                                                            1. Optimization of system prompts for more ef-\n                                                              fective red teaming\nFigure 4: ASR Distributions: Unoptimized Generator vs\nST-OPRO                                                  2. Generation of new insights about prompt en-\n                                                        gineering in security contexts\n\n                                                            3. Study of attack robustness across different\n                                             LLM-based systems\n\n                                                            4. Development of more sophisticated defense\n                                                 mechanisms based on ASR distribution analy-\n                                                                   sis\n\n                                                  Furthermore, this work suggests that the evaluation\n                                            and optimization of LLM-based security systems\n                                                         benefit from more nuanced metrics of attack quality.\n                                          The ASR distribution offers a more comprehensive\n                                             view of attack success, enables more accurate pre-\n                                                       dictions when attacks are repeated, and provides a\n                                          method for evaluating and optimizing generators\n                                                          that is sensitive to attack success discoverability.\n\n                                            Limitations\nFigure 5: ASR Distributions: ST-OPRO vs ASR Delta\nPair Mining                                             While our approach demonstrates promising results\n                                                         for optimizing attack generators, several limitations\nity that can be effectively leveraged for generator   should be acknowledged:\nimprovement.                                                           1. Our experiments were conducted using a specific\n                                            model (GPT-4o) and may not generalize to all LLM\n5  Conclusion\n                                                        architectures.\nThis work demonstrates that single-try ASR, while\n                                                         2. The effectiveness of ASR-delta pair mining de-\nuseful as a point estimate for comparing attack\n                                             pends on the quality and diversity of the initial\ngenerators, fails to capture potentially exploitable\n                                                      attack generator output.\ndistributional information. We argue that binary\nsuccess does not align as effectively with attack    3. The computational cost of repeatedly testing\nquality—defined through the lens of attacker eco-   each attack multiple times may be prohibitive in\nnomics—as our proposed application of ASR. This   some contexts, especially with limited API access\nfinding has implications for classification tasks, op-   or computational resources.\n\n\n                                         7\n\n4. The proposed method focuses on optimizing for    Lizhi Lin, Honglin Mu, Zenan Zhai, Minghan Wang,\nattack success rate but doesn’t necessarily account   Yuxia Wang, Renxi Wang, Junjie Gao, Yixuan Zhang,\n                                              Wanxiang Che, Timothy Baldwin, Xudong Han, andfor other important aspects such as attack stealth,\n                                             Haonan Li. 2024. Against the achilles’ heel: A survey\nnaturalness, or transferability.                     on red teaming for generative models. arXiv preprint\n                                                     arXiv:2404.00629v2. V2.\n5. As defense mechanisms evolve, the effectiveness\nof optimized attack generators may diminish over   Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou,\n                                                      Zifan Wang, Norman Mu, Elham Sakhaee, Nathanieltime, necessitating continuous refinement.\n                                                             Li, Steven Basart, Bo Li, David Forsyth, and Dan\n                                                   Hendrycks. 2024. Harmbench: A standardized eval-\nAcknowledgments                                   uation framework for automated red teaming and robust\n                                                                refusal. arXiv preprint arXiv:2402.04249v2. V2.\nWe thank our colleagues Christopher Frenchi and\n                                                      E.  Perez,  S. Huang,  F. Song,  T.  Cai,  R. Ring,Nish Tahir for their helpful feedback throughout\n                                                                         J. Aslanides, et al. 2022. Red teaming language mod-\nthis process. Funding for this work was provided     els with language models. In Proceedings of the 2022\nby Fuel iX, a TELUS Digital product.                Conference on Empirical Methods in Natural Language\n                                                        Processing, pages 3419–3448.\n\n                                                                F. Perez and I. Ribeiro. 2022. Attack techniques for\nReferences                                        language models. In NeurIPS ML Safety Workshop.\n\nYuntao  Bai,  Saurav  Kadavath,  Sandipan Kundu,   Kush R Vashney. 2022. Trustworthy machine learning.\nAmanda Askell, Jackson Kernion, Andy Jones, Anna    Independently published.\nChen, Anna Goldie, Azalia Mirhoseini, Cameron Mc-\nKee, et al. 2022. Constitutional ai: Harmlessness from   Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao\n ai feedback. arXiv preprint arXiv:2212.08073.            Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. 2024.\n                                                   Large language models as optimizers.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-\n biah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakan-   Fangqun Yang and Yisong Wang. 2023. Analyzing the\n tan, Pranav Shyam, Girish Sastry, Amanda Askell, Sand-    robustness of complex networks with attack success rate.\n hini Agarwal, Ariel Herbert-Voss, Gretchen Krueger,    Entropy, 25(11):1508.\nTom Henighan, Rewon Child, Aditya Ramesh, Daniel                                                       Y. Yao, J. Duan, K. Xu, Y. Cai, Z. Sun, and Y. Zhang.\n Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse,                                                     2024. A survey on large language model (llm) security\nMark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,                                                 and privacy: The good, the bad, and the ugly. High-\nBenjamin Chess, Jack Clark, Christopher Berner, Sam                                                     Confidence Computing, page 100211.\nMcCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language models are few-shot learners.\nAdvances in Neural Information Processing Systems,\n33.\n\nAnirban Chakraborty, Manaar Alam, Vishal Dey, Anu-\npam Chattopadhyay, and Debdeep Mukhopadhyay.\n2021. A survey on adversarial attacks and defences.\nCAAI Transactions on Intelligence Technology, 6(1):25–\n45.\n\nAlexandra Chouldechova, Daniel Zhang, and Jennifer\nWortman Vaughan. 2023. Ai red teaming through the\nlens of measurement theory. In OpenReview.\n\nZhihan Dong, Yifan Liu, Zihao Zhang, Zhenyu Wang,\nXujiang Yao, Chenghua Zhou, Dongxiao Wang, and\nHui Xiong. 2024. Attacks, defenses and evaluations for\nllm conversation safety: A survey. In Proceedings of\nthe 2024 Conference of the North American Chapter of\nthe Association for Computational Linguistics.\n\nDeep Ganguli, Amanda Askell, Nicholas Schiefer, Long\n Li, Danny Hernandez, Dylan Drain, Saurav Kadavath,\nJared Kaplan, Laura Weidinger, Anna Jones, et al. 2022.\nRed teaming language models to reduce harms: Meth-\nods, scaling behaviors, and lessons learned.  arXiv\npreprint arXiv:2209.07858.\n\nKaver Edwin Hui. 2023. Language models red teaming\n— attack and defense evaluation. Medium.\n\n\n                                         8\n\nA  Computational Considerations for\n   Sample Sizes\n\nIn this study, we employed n = 384 unique at-\ntacks, each evaluated m = 50 times against the\ntarget. These sample sizes were selected based on\nboth statistical considerations and computational\nfeasibility.\n\nA.1  Determining the Number of Attacks (n)\n\nFor the number of unique attacks n, we applied\nthe standard sample size formula for estimating a\npopulation proportion with a specified margin of\nerror:\n\n                  z2 · p · (1 −p)\n          n =\n                         e2\n\nWhere:\n\n    • z is the z-score corresponding to the desired\n     confidence level (1.96 for 95% confidence)\n\n    • p is the estimated proportion (we used p = 0.5\n     to maximize the required sample size)\n\n    • e is the desired margin of error (0.05 or 5%)\n\nSubstituting these values:\n\n\n         1.962 · 0.5 · 0.5   0.9604\n   n =         =     = 384.16\n             0.052        0.0025\n\nThis calculation yields n ≈384, ensuring that our\nestimate of the overall ASR has a margin of error\nno greater than 5% with 95% confidence.\n\nA.2  Determining the Number of Repetitions\n     (m)\n\nFor the number of repetitions m per attack, we\nselected m = 50 primarily for computational effi-\nciency. A full evaluation would require n × n =\n384 × 384 = 147, 456 total attack evaluations,\nwhich would be computationally prohibitive. Our\napproach with m = 50 required only 384 × 50 =\n19, 200 evaluations, representing an 87% reduction\nin computational load.\n\nImportantly, we observed convergence in our ASR\nestimates at m = 50. Additional repetitions be-\nyond this point produced negligible changes in the\nestimated ASR values for individual attacks, sug-\ngesting that 50 repetitions adequately captured the\nsuccess probability distribution while maintaining\ncomputational tractability.\n\n\n                                         9",
"headers": [
"arXiv:2507.22133v1  [cs.CR]  29 Jul 2025",
"Prompt Optimization and Evaluation for LLM Automated Red Teaming"
],
"tables": [],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2507.22133v1.pdf"
}