{
"text": "MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative\n                      Prompt Optimization\n\n                  Yichen Han                 Yuhang Han                   Bojun Liu\n              South China Normal University         Northwestern Polytechnical               University of Sydney\n                   Guangzhou, China                         University                       Sydney, Australia\n                2024024502@m.scnu.edu.cn                    Xiâ€™an, China                  liubojun9999@gmail.com\n                                                  hanyh@mail.nwpu.edu.cn\n\n              Zhengpeng Zhou              Guanyu Liu                 Zeng Zhang\n               Shanghai Jiaotong University               University of Macau            South China Normal University\n                      Shanghai, China                     Macau, China                    Guangzhou, China\n                   alex_chou@sjtu.edu.cn              dc32352@um.edu.mo              2024024588@m.scnu.edu.cn\n2025             Yang Yang                   Wenli Wang                      Isaac N Shi\n                       Silicon Sapiens LLC                     Silicon Sapiens LLC                     Silicon Sapiens LLC\n                           Jinan, China                             Jinan, China                             Jinan, ChinaOct               yang@esapiens.ai                    wenli@esapiens.ai                isaac@goldensection.com\n7\n               Yunyan Zhang                  Lewei Heâˆ—                   Tianyu Shiâ€ \n                       Silicon Sapiens LLC             South China Normal University             University of Toronto\n                           Jinan, China                     Guangzhou, China                     Toronto, Canada\n              yunyan@fangyingmobile.com           helewei@m.scnu.edu.cn                 tys@cs.toronto.edu[cs.AI]  ABSTRACT                              CCS CONCEPTS\n          Prompt engineering is essential for fully leveraging large language        â€¢ Computing methodologies â†’Discourse, dialogue and prag-\n          models (LLMs), yet existing optimization methods often follow a sin-     matics.\n            gle trajectory, leading to limited adaptability, gradient conflicts, and\n          high computational overhead. We propose MAPGD (Multi-Agent   KEYWORDS\n         Prompt Gradient Descent), a novel framework that reconceptual-                                                                    Prompt Optimization, Multi-Agent Systems, Large Language Mod-\n            izes prompt optimization as a collaborative multi-agent process.                                                                                                        els, Gradient Descent\n       MAPGD incorporates specialized agents focusing on orthogonal\n           refinement dimensionsâ€”such as instruction clarity, example selec-\n             tion, format structuring, and stylistic adaptationâ€”and coordinates    1  INTRODUCTION\n            their contributions through semantic gradient embedding, conflict      Large Language Models (LLMs), trained on vast webscale corpora,\n            detection, and fusion. To further enhance robustness and stability,     have recently demonstrated remarkable generalization capabilities\n       MAPGD proposes two new mechanisms: Hypersphere-Constrained      across diverse natural language processing (NLP) tasks [1, 4]. A cen-\n           Gradient Clustering (HCGC), which enforces angular margin con-       tral factor influencing their performance is the design of prompts,\n            straints to ensure intra-cluster compactness and inter-cluster sep-     which serve as the primary interface for guiding model behavior.\n            aration, and Channel-Adaptive Agent Weighting (CAAW), which      However, prompt construction remains largely a manual, trial-and-arXiv:2509.11361v2    dynamically reweights agent contributions based on validation per-      error process that demands substantial human labor [15] and do-\n           formance. Experiments on classification and reasoning benchmarks     main expertise [27, 35]. This inefficiency highlights the urgent need\n          demonstrate that MAPGD consistently outperforms single-agent       for automatic or semi-automatic strategies to systematically gener-\n         and random baselines in both accuracy and efficiency. Ablation       ate or refine prompts. Such approaches can reduce manual burden,\n            studies validate the effectiveness of gradient fusion, agent spe-     improve task performance, and provide interpretable optimization\n             cialization, and conflict resolution. Together, these contributions      pathways.\n            establish MAPGD as a unified, gradient-inspired, and interpretable        Recent research has explored this problem through two primary\n          framework for robust prompt optimization with theoretical conver-      directions. One line of work introduces auxiliary models or dif-\n          gence guarantees.                                                        ferentiable prompt embeddings to approximate gradient-based op-\n                                                                                 timization [9, 26]. Yet, these methods often assume access to the\n                                                                                       internal states or parameters of LLMs [16, 30], which is impractical\n                                                                                   in real-world API-only scenarios. Another line of work employs\n             âˆ—Corresponding author.                                                 reinforcement learning or feedback-driven editing to discretely\n             â€ Corresponding author.                                               manipulate prompts [36, 37]. While effective in some cases, these\n\nInit Prompt                                                  the unit hypersphere to ensure compact intra-cluster coherence\n               Classify the customer review as Positive or Negative            and inter-cluster separation, and Channel-Adaptive Agent Weight-\n                                                                  ing (CAAW), which dynamically reweights agent contributions\n         Minibatch                                                    according to validation performance, amplifying effective optimiza-\n                    \"I bought this phone yesterday, and the            Prediction: Positive           tion channels while suppressing noisy ones. Together, these inno-\n                   battery already drains too fast.\"                 Label: Negative            vations endow MAPGD with improved robustness, stability, and\n       LLM                                                                 interpretability, enabling it to consistently outperform single-agent\n                                                                        baselines such as ProTeGi across diverse optimization scenarios.          Agent Gradients\n                                                            Beyond empirical improvements, MAPGD also provides a theo-\n                TheTheThepromptpromptpromptdoesdoesdoesnotnotnotspecifyspecifyspecifyfocusingfocusingfocusingonononsentimentsentimentsentimentpolaritypolaritypolarity                retical foundation for convergence. Under mild stochastic approxi-\n  Instruction Specialist                                                mation assumptions, we prove that the multi-agent gradient coordi-\n                    AddAddAddclearclearclearexamplesexamplesexamplestototoguideguideguidethethethemodelmodelmodel                     nation and fusion mechanisms preserve the convergence properties\n                                                                        of classical gradient descent, yielding almost sure convergence to\n  Example Curator                                                           âˆš\n                                                                a local optimum at a sublinear rate of O(1/ ğ‘‡), where ğ‘‡denotes\n                          TheTheTheoutputoutputoutputformatformatformatisisisambiguousambiguousambiguous                       the number of iterations. This result establishes that, despite oper-\n  Format Designer                                                          ating in a discrete, textual prompt space and coordinating multiple\n                        TheTheTheinstructioninstructioninstructionlackslackslacksprofessionalprofessionalprofessionaltonetonetone                   heterogeneous agents, MAPGD maintains stable and predictable\n  Style Optimizer                                                         optimization dynamics, bridging practical prompt refinement with\n                                                                     rigorous theoretical guarantees.\n                    Fused prompt    Hypersphere-Constrained Gradient Clustering\n   Decide whether the review expresses Positive or Negative sentiment, focusing on polarity.    2  RELATED WORK\n                                      If uncertain, choose the most likely label.\n                     Examples: â€œThe product is excellent.â€ â†’ Positive;                    Prompt Learning and Optimization. Early efforts relied on manual\n                     â€œThe product broke after a day.â€ â†’ Negative.                    engineering, which lacks scalability. Automated methods include\n              Respond strictly with one word: POSITIVE à “ or NEGATIVEâ˜¹ï¸.\n                            Maintain concise and formal tone.                        reinforcement learning [9], evolutionary search [12], and Bayesian\n                                                                   optimization [28]. Continuous prompt tuning (e.g., prefix tuning\n                                                                               [17], soft prompts [16]) optimizes embeddings but sacrifices inter-\nFigure 1: Overview of the Multi-Agent Prompt Gradient De-       pretability. MAPGD instead pursues interpretable natural language\nscent for Collaborative Prompt Optimization.                     optimization with structured feedback.\n\n                                                                       Multi-Agent Collaboration. Multi-agent systems are well-studied\nalgorithms may produce incoherent prompts, incur high compu-      in RL, distributed AI, and game theory. In NLP, multi-agent de-\ntational costs, or rely on unguided Monte Carlo search over the      bate [10, 18], cooperative reasoning, and collaborative generation\nsemantic space. Collectively, these limitations highlight the need       [13] show that role specialization outperforms monolithic optimiza-\nfor more robust, interpretable, and scalable frameworks for prompt       tion. MAPGD applies this principle by assigning agents to distinct\noptimization.                                                prompt dimensions and coordinating them via gradient fusion.\n   Addressing this gap, Pryzant et al. [25] proposed ProTeGi, a non-\n                                                                         Gradient-Inspired Optimization. ProTeGi [25] and similar ap-parametric approach that mirrors gradient descent in textual space.\n                                                               proaches approximate prompt gradients through self-feedback.\nProTeGi generates natural language â€œgradientsâ€ from model errors\n                                                          While effective, single-agent descent struggles with limited sig-\nand iteratively edits prompts in semantically opposite directions.\n                                                                     nal diversity and inherent conflict resolution challenges [34]. A\nTo balance exploration and exploitation, it further integrates beam\n                                                                    monolithic agent can generate self-contradictory pseudo-gradients,\nsearch and bandit-based candidate selection, achieving significant\n                                                                      as different refinement dimensions are not explicitly disentangled.\ngains over earlier baselines. Nevertheless, ProTeGi operates under a\n                                                                For instance, to correct a misclassification, a single agent might\nsingle-agent paradigm, which restricts the diversity of optimization\n                                                                propose a gradient to add more illustrative examples, while an im-\nsignals and leaves unresolved conflicts among competing refine-\n                                                                                       plicit counter-gradient aims to make the instructions more concise.\nment directions.\n                                                                   This creates a direct conflict in prompt length and structure, poten-\n  To overcome these limitations, we propose MAPGD (Multi-Agent        tially leading to suboptimal or oscillating optimization trajectories.\nPrompt Gradient Descent), a novel framework that reconceptual-    MAPGD extends this paradigm by embedding gradients semanti-\nizes prompt optimization as a collaborative multi-agent process(Figure 1).\n                                                                                      cally, explicitly detecting such conflicts, and fusing them coherently\nMAPGD introduces a set of specialized agents, each dedicated to dis-\n                                                               through LLM-driven synthesis.\ntinct refinement dimensionsâ€”such as instruction clarity, example\nselection, format structuring, and stylistic adaptation. To reconcile        Geometric and Adaptive Mechanisms. Contrastive learning and\nheterogeneous improvement signals, MAPGD employs a semantic      angular margin constraints are effective in representation learning.\ngradient coordinator that embeds textual gradients into a shared    Wang and Isola formalize how contrastive losses enforce alignment\nvector space, enabling conflict detection, clustering, and fusion. In     and uniformity, providing a theoretical lens [32]. This principle of\naddition, we propose two novel mechanisms to further enhance      hyperspherical separation to enhance discriminability spans do-\nrobustness and stability: Hypersphere-Constrained Gradient Clus-      mains. In face recognition, margin-based softmax losses such as\ntering (HCGC), which introduces angular margin constraints on      SphereFace [21], CosFace [31], and ArcFace [8] enforce angular\n\ncomplemented by Channel-Adaptive Agent Weighting (CAAW)\n                                                                     adjusting agent contributions. Together, these modules enhance\n                                                                    multi-agent gradient descent with geometry-aware clustering and\n                                                                    adaptive coordination.\n                                                               In summary, MAPGD unifies prompt learning, multi-agent col-\n                                                                         laboration, gradient descent, and geometry-inspired optimization\n                                                                        into a scalable and interpretable framework.\n\n                                               3 METHODOLOGY\n                                                         3.1  Framework Overview\n                                           MAPGD formulates prompt optimization as a hybrid discreteâ€“continuous\n                                                                       gradient descent process in the natural language space. Unlike con-\n                                                                  tinuous embeddingâ€“based methods such as prefix or soft prompt\n                                                                   tuning [16, 17], MAPGD explicitly manipulates interpretable textual\n                                                            prompts while leveraging gradient-inspired feedback for iterative\n                                                                  refinement (Figure 2).\n                                                           At each iteration, specialized agents analyze misclassified or\n                                                                  suboptimal examples and produce pseudo-gradients in natural lan-\n                                                                   guage. These gradients are semantically embedded, clustered, and\n                                                                    adaptively fused to mitigate conflicts and ensure coherent opti-\n                                                                    mization. The resulting fused gradients are applied to generate\n                                                                   successor prompts, which are then evaluated and filtered under\n                                                                        limited budgets. Iterative repetition yields a dynamically evolving\n                                                          prompt trajectory that balances exploration of diverse directions\n                                                               with exploitation of promising refinements.\n                                                                        Formally, the optimization objective is defined as:\n\n                                                                             ğ¹(ğ‘) = E(ğ‘¥,ğ‘¦)âˆ¼D [â„“(ğ‘€(ğ‘¥;ğ‘),ğ‘¦)] ,                (1)\n                                                          where â„“(Â·, Â·) denotes a task-specific loss function. The goal is:\n                                                               ğ‘âˆ—= arg min ğ¹(ğ‘).                        (2)\n                                                                                                                ğ‘\n\n                                                                  Unlike stochastic gradient descent (SGD), where gradients are con-\n                                                                       tinuous, MAPGD constructs textual pseudo-gradients:\n                                                                                        âˆ‡ğ¹(ğ‘(ğ‘¡)) â‰ˆğ‘”(ğ‘¡),                          (3)\n\n                                                          which act as semantic analogues of numerical gradients.\n\n                                                         3.2  Specialized Prompt Agents\nFigure  2: Workflow of MAPGD. Starting from an ini-     Each agent specializes in a distinct dimension of prompt optimiza-\ntial prompt ğ‘, specialized agents propose diverse pseudo-       tion, analogous to orthogonal gradient directions. For example: ğ´1:\ngradients {ğ‘”,ğ‘”â€²,ğ‘”â€²â€²,ğ‘”â€²â€²â€², . . .} (top). These gradients are seman-      instruction clarity (ğ‘”1), ğ´2: example selection (ğ‘”2), ğ´3: format speci-\ntically embedded and projected onto the unit hypersphere,       fication (ğ‘”3), ğ´4: stylistic refinement (ğ‘”4), and optionally a generic\nthen clustered with angular-margin constraints to form co-     agent for broad improvements. At iteration ğ‘¡, the gradient set is:\nherent groups (middle). Clustered directions are fused via\n                                                                                         ğº(ğ‘¡) = {ğ‘”(ğ‘¡)1  ,ğ‘”(ğ‘¡)2   , . . . ,ğ‘”(ğ‘¡)ğ¾}.LLM-driven synthesis into composite gradients ğº, which gen-\nerate refined candidate prompts {ğ‘ƒ1, ğ‘ƒ2, . . . , ğ‘ƒğ‘›} (bottom). The      This decomposition supports parallel exploration of diverse re-\nbest candidates are iteratively selected and fed back to con-      finements, alleviating local minima issues inherent in single-agent\ntinue the prompt optimization loop.                              approaches.\n\n                                                         3.3  Hypersphere-Constrained Gradient\nmargins between identities. Chen et al. [6] introduce a distance         Clustering\npolarization regularizer for large-margin contrastive learning, push-      Inspired by hyperspherical contrastive learning [21, 31], our HCGC\ning inter-cluster samples apart while keeping intra-cluster rep-     mechanism is designed to enhance the semantic consistency of\nresentations tight. Inspired by these advances, our Hypersphere-      multi-agent gradients by enforcing intra-cluster compactness and\nConstrained Gradient Clustering (HCGC) enforces intra-cluster       inter-cluster separation in a normalized hypersphere space. This\ncompactness and inter-cluster separation for semantic gradients,     approach addresses the challenge of conflicting pseudo-gradients\n\ngenerated by heterogeneous agents, ensuring that semantically                                                             Î½k\ncoherent optimization directions are emphasized while contradic-\ntory ones are disentangled. The overall process and the geometric\nintuition of our method are illustrated in Figure 3.\n\n                                                                              Push   Gradient Embedding on Hypersphere. Given a set of agent-generated                                                                                                                                                                        i        Î” Ì˜Ï¦, Ì˜Ï¤          Î” Ì˜Ï¦, Ì˜Ï¥            j\ngradients ğº(ğ‘¡) = {ğ‘”(ğ‘¡)1  ,ğ‘”(ğ‘¡)2   , . . . ,ğ‘”(ğ‘¡)ğ¾}, each gradient is encoded\ninto a d-dimensional vector ğ‘£(ğ‘¡)                                ğ‘˜  = ğœ™(ğ‘”(ğ‘¡)ğ‘˜), where ğœ™denotes a pre-\ntrained language encoder. For this purpose, we utilize a Sentence                          Push                    (b) Original BoundaryTransformer model, such as all-MiniLM-L6-v2, which provides           Push\n                                                                                                                            Î½k                       Î½kcompact and semantically informative embeddings. To eliminate\nscale variance, we normalize each embedding onto the unit hyper-\nsphere:\n                               ğ‘£(ğ‘¡)                                                                                          (a)                                                                                             Intra-cluster                                                                                   Compactness                                                                                                                                                                       i        Î” Ì˜Ï¦, Ì˜Ï¤          Î” Ì˜Ï¦, Ì˜Ï¥            j                              ğ‘˜      ,    Ë†ğ‘£(ğ‘¡)                            Ë†ğ‘£(ğ‘¡)                                                                      and                                                                                              Inter-cluster                                                                                          Repulsion                                       ğ‘˜  âˆˆSğ‘‘âˆ’1.                   (4)                     ğ‘˜  =\n                             âˆ¥ğ‘£(ğ‘¡)ğ‘˜âˆ¥\nThe similarity between two gradients is then computed as the cosine                                                        (c) Angular Margin\nsimilarity. Gradients are considered to be in conflict if their angular\ndistance exceeds a predefined threshold, ğœƒğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡:                    Figure 3: Details of Hypersphere-Constrained Gradient Clus-\n                                                                 tering\n                   sim(Ë†ğ‘£ğ‘–, Ë†ğ‘£ğ‘—) = Ë†ğ‘£âŠ¤ğ‘–Ë†ğ‘£ğ‘—= cos(Î”(Ë†ğ‘£ğ‘–, Ë†ğ‘£ğ‘—)),               (5)\n\nwhere Î”(Â·, Â·) denotes the angular distance on the hypersphere.\n   Figure 4 illustrates a concrete example in the sentiment clas-                                                                       Optimization Objective. Analogous to hyperspherical contrastive\nsification task, where different agents generate multiple pseudo-      learning, the clustering objective combines intra-cluster compact-\ngradients. While some gradients form semantically coherent clus-      ness and inter-cluster repulsion:\nters (intra-cluster compactness), others introduce conflicts that\nmust be separated through angular margin constraints.                                                exp(cos(Î”(Ë†ğ‘£ğ‘–, Ë†ğ‘£ğ‘—))/ğœ)\n                                                             LHCGC = âˆ’log                                                          ,        (7)\n                                                 Ãğ‘˜âˆˆN(ğ‘–) exp(cos(Î”(Ë†ğ‘£ğ‘–, Ë†ğ‘£ğ‘˜))/ğœ)\n   Angular Margin Constraint. To mitigate conflicts and ensure clear\nseparation between semantic clusters, HCGC enforces an angular     where (Ë†ğ‘£ğ‘–, Ë†ğ‘£ğ‘—) is a positive pair from the same cluster, N (ğ‘–) denotes\nmargin constraint on the unit hypersphere. Let Ë†ğ‘£ğ‘˜denote a normal-      negatives from other clusters, and ğœis a temperature factor. By\nized gradient vector, ğ‘¢ğ‘–the centroid of its assigned cluster ğ‘–, and ğ‘¢ğ‘—      optimizing LHCGC, we obtain semantically well-aligned clusters of\nthe centroid of any other cluster ğ‘—. We define the corresponding       gradients, ensuring coherent downstream fusion.\nangles as                                                              After clustering, gradients within each semantically coherent\n          ğ›¼= Î”(Ë†ğ‘£ğ‘˜,ğ‘¢ğ‘–),  ğ›½= Î”(Ë†ğ‘£ğ‘˜,ğ‘¢ğ‘—).                    group are fused into a single representative gradient. This fusion\n                                                                                        is typically performed by an LLM, guided by the original sugges-\nA standard clustering assignment only requires ğ›¼< ğ›½. However, to       tions. To maintain diversity and avoid redundancy among the fused\nenforce stronger separation, we introduce a margin scaling factor                                                                         gradients, a semantic diversity filter is applied, discarding sugges-\nğ‘›â‰¥1:                                                                  tions that are too similar to already selected ones, controlled by a\n                      ğ‘›Â· ğ›¼< ğ›½.                                    diversity threshold ğœƒğ‘‘ğ‘–ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘–ğ‘¡ğ‘¦.\n\nSince cos(ğœƒ) is monotonically decreasing for ğœƒâˆˆ[0, ğœ‹], this condi-\ntion is equivalently expressed in terms of cosine similarity:           3.4  Channel-Adaptive Agent Weighting\n                                                             While HCGC ensures structural consistency across gradients, gradi-\n                 cos(ğ‘›Â· ğ›¼) > cos(ğ›½),  ğ‘›â‰¥1.                   (6)      ents within the same cluster may still differ in reliability due to het-\n                                                               erogeneous agent expertise. To address this, we propose Channel-\nThis constraint ensures that Ë†ğ‘£ğ‘˜is not only closer to its own centroid      Adaptive Agent Weighting (CAAW), which dynamically calibrates\nğ‘¢ğ‘–, but also significantly more aligned with it than with any other      agent contributions according to their historical effectiveness, akin\ncentroidğ‘¢ğ‘—. Geometrically, as illustrated in Figure 3 (c), this confines       to channel-wise recalibration in neural representations [14].\nË†ğ‘£ğ‘˜to a scaled angular neighborhood aroundğ‘¢ğ‘–, effectively creating a\nâ€œcone of acceptanceâ€ narrower than the standard Voronoi region on                                                                     Adaptive Weight Assignment. Let ğ‘ (ğ‘¡)ğ‘˜  denote the validation per-\nthe hypersphere. By enforcing this margin, HCGC simultaneously\n                                                             formance gain associated with gradient ğ‘”(ğ‘¡)ğ‘˜. The adaptive weightenhances inter-cluster separation and intra-cluster compactness,\n                                                                         of each gradient is computed via a softmax normalization:\nyielding more stable and reliable gradient fusion. During clustering,\nany gradient Ë†ğ‘£ğ‘˜violating this condition with respect to some ğ‘¢ğ‘—is\n                                                                                                       exp(ğœ†ğ‘ (ğ‘¡)ğ‘˜)considered for reassignment to a cluster where the margin holds;                          ğ‘¤(ğ‘¡)                                                                                                                                                                                                                         ,                     (8)                                                                                                      ğ‘˜  =\notherwise, it remains in its original cluster.                             Ã ğ‘—âˆˆğ¶exp(ğœ†ğ‘ (ğ‘¡)ğ‘—  )\n\nInit Prompt                                             3.6  Theoretical Convergence (Informal)\n               Classify the sentiment of the following review as          We provide a convergence analysis of MAPGD in Appendix C. Here\n                          Positive, Negative, or Neutral                we summarize the key assumptions: (i) bounded variance of agent\n                                                                      pseudo-gradients, (ii) Lipschitz continuity of the loss function, and\n      Instruction Specialist Gradients\n                                                                                                         (iii) unbiased sampling from bandit-based candidate selection. Un-\n     g1ï¼šExplicitly state that only one sentiment label should be chosen        der these conditions, MAPGD inherits the convergence properties\n                                                                       of stochastic gradient descent and achieves almost sure conver-\n    g2ï¼šAsk the model to provide a one-sentence justification for its                                   âˆš\n         choice                                                   gence to a local optimum at a sublinear rate of O(1/ ğ‘‡). Intuitively,\n                                            HCGC reduces variance by enforcing geometric separation, CAAW\n     g3ï¼šExplicitly instruct the model to output only one category            emphasizes historically reliable agents, and bandit selection main-\n     Example Curator Gradients                                           tains unbiased exploration, together ensuring stable optimization\n                                                                dynamics.\n    g1ï¼šAdd a Positive example describing product satisfaction\n\n    g1ï¼šAdd a Negative example focusing on delivery issues           4  EXPERIMENTS\n                                              We design comprehensive experiments to evaluate the effectiveness,\n     g1ï¼šEnsure that Neutral examples include mixed or ambiguous             efficiency, and robustness of the proposed MAPGD framework.\n          reviews                                                        To ensure comparability, we reproduce the experimental setup of\n                                                                ProTeGi under identical conditions and extend the evaluation with\nFigure 4: Illustration of agent-generated pseudo-gradients      ablation studies and token consumption analysis. In addition, we\nin a sentiment classification task. Blue gradients form a co-      include a real-world case study on prompt optimization for text\nherent cluster under the Instruction Specialist, while the red      generation (see Appendix D), which highlights the applicability of\ngradient represents a conflicting update. Green gradients    MAPGD beyond controlled benchmarks.\nfrom the Example Curator constitute another semantically\ncompact cluster. This motivates the need for hypersphere-     4.1  Datasets\nconstrained clustering to enforce intra-cluster compactness                                                          To ensure comparability with ProTeGi, we evaluate MAPGD on the\nand inter-cluster separation.                                                        same four benchmark NLP classification tasks that span diverse\n                                                            domains and languages:\n                                                                â€¢ Jailbreak [29]: a novel task to determine whether a user\nwhere ğ¶is the current cluster, and ğœ†controls the sharpness of             input to an LLM continuation API constitutes a jailbreak\nweighting. This formulation emphasizes historically effective agents              attempt. Jailbreak attacks are defined as user strategies that\nwhile down-weighting less reliable ones.                                aim to make the model violate its own safety policies, such\n                                                                              as generating harmful content or exposing hidden instruc-\n   Gradient Fusion. The final fused gradient is expressed as:                       tions. The dataset contains 1306 multilingual examples with\n                                                                   human-annotated jailbreak labels.\n                                               !                           â€¢ Ethos [22]: an English hate speech detection dataset with\n                       ğ‘”(ğ‘¡)                           fused = Î¨ âˆ‘ï¸ ğ‘¤(ğ‘¡)ğ‘˜ğ‘”(ğ‘¡)ğ‘˜      ,                    (9)            997 online comments annotated as hateful or non-hateful.\n                            ğ‘˜âˆˆğ¶                                   â€¢ LIAR [33]: a large-scale dataset for fake news detection,\n                                                                             consisting of 4,000 short statements labeled with ground-\nwhere Î¨(Â·) denotes an LLM-driven synthesis function that inte-                                                                               truth veracity, along with context information.\ngrates multiple textual directions into a coherent refinement.\n                                                                â€¢ Sarcasm [11]: an Arabic sarcasm detection dataset with\n                                                                               10,000 online comments, labeled for the presence or absence   Robustness and Stability. By recalibrating agent contributions\n                                                                                of sarcasm.at the channel level, CAAW suppresses redundant or conflicting\nupdates while amplifying stable and discriminative directions. The-       Beyond classification, we further evaluate on three arithmetic\noretically, this reduces variance in the optimization trajectory and      reasoning datasets that require multi-step logical inference and\nprevents over-amplification of noisy gradients, thereby ensuring      symbolic manipulation:\nconvergence to semantically robust prompt candidates.                                                                â€¢ GSM8k [7]: a widely used benchmark of 8,500 grade-school\n                                                              math problems that require step-by-step reasoning.\n3.5  Candidate Generation and Selection                  â€¢ AQUARAT [20]: a dataset of algebraic word problems de-\n                                                                          signed to test symbolic reasoning and program induction.Fused gradients generate successor prompts {ğ‘â€²1, . . . , ğ‘â€²ğ‘›}. MAPGD\napplies lightweight filtering and optional bandit-based evaluation          â€¢ SVAMP [23]: a benchmark focusing on simple arithmetic\n                                                             word problems with diverse linguistic variations, serving[3] to control computational overhead. However, unlike prior work\n                                                                             as a testbed for robustness to paraphrasing.that heavily relies on bandit selection, our framework emphasizes\ngeometry-aware clustering (HCGC) and adaptive agent weight-         In addition, we include a real-world text generation case study\ning (CAAW) as the primary mechanisms ensuring robustness and      in the Appendix to highlight MAPGDâ€™s applicability beyond con-\ninterpretability.                                                             trolled benchmarks.\n\n4.2  Experimental Setup                                    â€¢ InsZero [5]: a zero-shot prompting method with instruc-\nFor each dataset, we randomly sample 50 examples for development              tion tuning.\nand 150 for testing. All reported results are averaged over three          â€¢ Instinct [19]: an instruction-following baseline that im-\nindependent runs to mitigate variance. The evaluation metric is             proves prompting robustness.\nbinary F1 score on the test set, computed by max-pooling over the          â€¢ PromptWizard [2]: a state-of-the-art prompt synthesis\nfinal beam of candidate prompts.                                       framework that iteratively enriches prompts with interme-\n   Unless otherwise stated, all experiments are conducted with the               diate reasoning steps and examples.\nJanuary 2023 version of gpt-3.5-turbo through the Azure OpenAI\nAPI. The temperature is set to 0.0 for classification tasks to ensure\n                                                                   This collection of baselines allows us to evaluate MAPGD notdeterministic predictions.\n                                                               only against single-agent gradient-based optimization, but also  To ensure a fair comparison, all methodsâ€”including baselines\n                                                                      against strong arithmetic reasoning methods optimized for chain-and MAPGDâ€”use the same initial prompts, training data, and ran-\n                                                                   of-thought style prompting.dom seeds. The iteration budget is fixed at ğ‘‡= 10 across all ex-\nperiments. We adopt default parameter values without additional\nhyperparameter search, to ensure that performance differences are\nattributable to algorithmic design rather than parameter tuning.\n   For our MAPGD implementation, we instantiate the framework     4.4  Experimental Results\nwith specific hyperparameters introduced in Section 3.3. We use the      Figure 5 summarizes the overall performance across the four bench-\nall-MiniLM-L6-v2 Sentence Transformer as the gradient encoder     mark classification datasets. Our results demonstrate that MAPGD\nğœ™. The conflict threshold ğœƒğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡is set to 0.3, and we use a cluster      consistently achieves the best performance under varying evalua-\nsimilarity threshold of 0.7 for grouping gradients. The diversity      tion budgets, outperforming all baselines by a notable margin.\nthreshold ğœƒğ‘‘ğ‘–ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘–ğ‘¡ğ‘¦is set to 0.7 to ensure varied candidate prompts.      On the Jailbreak dataset, MAPGD attains an average F1 of 0.86,\nBandit-based selection adopts a UCB strategy with a budget of      surpassing ProTeGi (0.82) and MC (0.76), while substantially improv-\n80 evaluations.We set the CAAW weighting parameter ğœ†to 1 (see      ing over RL (0.67) and AutoGPT (0.62). The improvement margin\nAppendix A for a sensitivity analysis on different values).             remains stable across different budgets, reaching up to +5.5% over\n   Accordingly, all experiments reported in Section 4.4 were con-     ProTeGi and +10.9% over MC at 30 evaluations.\nducted with these modules enabled, unless explicitly ablated.             For Ethos, MAPGD pushes performance from the strong baseline\n                                                                          of 0.93 (ğ‘0) to 0.98, showing a consistent +1.5% advantage over Pro-\n                                                              TeGi and +4.0% over MC. These improvements highlight MAPGDâ€™s\n4.3  Baselines                                                           ability to leverage gradient fusion even in relatively saturated tasks.\nTo evaluate the effectiveness of MAPGD, we compare it against a      On the more challenging LIAR dataset, MAPGD achieves 0.71,\nset of non-parametric prompt optimization methods, following the      representing the largest relative gains: +8.0% over ProTeGi, +11.0%\nsetup of ProTeGi [25], and additionally include ProTeGi itself as a      over MC, and a substantial +17.0% over the initial prompt. This\nstrong baseline. Specifically, we consider:                              suggests that multi-agent collaboration and semantic clustering are\n                                                                          particularly beneficial in noisy, fact-checking tasks.\n    â€¢ ProTeGi: the original prompt gradient descent framework,\n                                                                  For Sarcasm, MAPGD steadily improves from 0.84 (ğ‘0) to 0.91,      where a single agent iteratively generates pseudo-gradients\n                                                                 outperforming ProTeGi (0.87) and MC (0.85). Interestingly, AutoGPT\n      and candidate prompts, with bandit-based selection. This\n                                                            sometimes reduces performance below the initial prompt, echo-\n        serves as our primary baseline for comparison.\n                                                                   ing earlier findings that unguided agent feedback may destabilize\n    â€¢ Monte-Carlo (MC) [37]: an iterative but directionless                                                                       optimization.\n      Monte Carlo search over the prompt space. For fairness, we\n                                                             Beyond classification, we further evaluate MAPGD on arithmetic\n      match the number of samples per candidate to the succes-\n                                                                   reasoning benchmarks, which require detailed multi-step inference.\n        sors generated by MAPGD.\n                                                                    Table 1 compares MAPGD against three strong baselinesâ€”InsZero,\n    â€¢ Reinforcement Learning (RL) Recent approaches such as                                                                               Instinct, and PromptWizardâ€”on GSM8k, AQUARAT, and SVAMP.\n       GrIPS [24] and TEMPERA [36] formulate prompt optimiza-\n                                           MAPGD achieves consistent improvements across all datasets, with\n        tion as a reinforcement learning problem. In these methods,\n                                                                           particularly notable gains on GSM8k (93.5%), surpassing the previ-\n       the prompt text is first segmented into phrases, and the\n                                                               ous best by +3.5 points. On AQUARAT and SVAMP, MAPGD reaches\n       search space is explored via phrase-level edit operations,\n                                                                60.3% and 84.1%, respectively, representing stable improvements\n        including addition, paraphrasing, swapping, and deletion.\n                                                                over the strongest baselines. These results confirm that MAPGD\n    â€¢ AutoGPT: an open-source autonomous agent system that                                                                not only excels in classification but also transfers effectively to\n       improves prompts through self-directed feedback loops.\n                                                                    challenging reasoning tasks.\n     We configure AutoGPT with the same number of examples\n                                                                          Overall, MAPGD improves over ProTeGi and MC by 3â€“7% on\n      and errors as MAPGD, running for the same number of\n                                                                  average for classification, while maintaining strong gains on arith-\n       optimization steps.\n                                                                   metic reasoning datasets. These results validate our hypothesis that\n   For arithmetic reasoning, we additionally compare against three      multi-agent specialization and hypersphere-constrained cluster-\ncompetitive baselines, all reported with GPT-3.5-Turbo in a zero-      ing provide more robust and adaptive optimization compared to\nshot setting:                                                           single-agent or rule-based approaches.\n\nTable 1: Arithmetic reasoning accuracy (%) on GSM8k,     Table 2: Ablation study: classification performance (F1 score,\nAQUARAT, and SVAMP. Best results in bold.               mean Â± std over 3 runs). Best results in bold.\n\n Method      GSM8k  AQUARAT  SVAMP         Method              Jailbreak     Ethos      LIAR     Sarcasm\n                                                      MAPGD (full)         0.88 Â± 0.01  0.98 Â± 0.02  0.71 Â± 0.01  0.91 Â± 0.01\n  InsZero            74.2         54.3         79.5           No Gradient Fusion    0.83 Â± 0.02    0.92 Â± 0.02    0.67 Â± 0.02    0.86 Â± 0.02\n  Instinct            74.5         54.7         81.0                Single Agent Only     0.80 Â± 0.03    0.87 Â± 0.03    0.62 Â± 0.02    0.82 Â± 0.03\n                                                              No Specialization      0.80 Â± 0.02    0.90 Â± 0.02    0.65 Â± 0.02    0.84 Â± 0.02\n  PromptWizard     90.0         58.2         82.3             w/o HCGC             0.84 Â± 0.02    0.94 Â± 0.02    0.68 Â± 0.02    0.87 Â± 0.02\n MAPGD          93.5        60.3        84.1            w/ow/o CAAWHCGC + CAAW   0.850.82 Â±Â± 0.020.03    0.950.91 Â±Â± 0.020.03    0.690.66 Â±Â± 0.020.02    0.880.83 Â±Â± 0.020.02\n\n\n\n                         Jailbreak                                      Ethos\n                                                      0.98                          Table 3: Token consumption comparison between ProTeGi\n    0.85                                                      0.97                        and MAPGD (averaged over 3 runs). MAPGD achieves lower\n    0.80                                                    token usage and higher efficiency.\n                                                      0.96\n F1 0.75                              F1\n                                                      0.95\n    0.70                                                              Metric           ProTeGi MAPGD (full)\n                                                      0.94    0.65\n                                                                                Total Tokens         256k       236k                                                      0.93\n                             Liar                                   Sarcasm                        Calls                 962         643\n   0.700                                                                           ProTeGiMC                           Avg F1                 0.83          0.87\n                                                      0.90       RL                                                                     F1 / Token (Ã—10âˆ’6)     3.24          3.69   0.675                                                                          AutoGPT\n   0.650                                              0.88      MAPGD\nF1                                  F1\n   0.625                                              0.86\n   0.600\n                                                      0.84                                          (7) w/o HCGC+CAAW: use standard K-means clustering with\n   0.575\n                                                                             cosine similarity (no angular margin) and replace adaptive\n         10      20      30      40      50         10      20      30      40      50\n                           p0                                             p0                      weighting with uniform fusion.\n\nFigure 5: Test performance (F1 score) vs. API query budget\nper prompt candidate across four benchmark tasks.            4.6  Token Consumption Analysis\n                                                        To further assess the efficiency of MAPGD, we conducted a ded-\n                                                                       icated token consumption experiment, following the same setup\n4.5  Ablation Study                                           as in Section 4.2. In this experiment, we recorded the number of\n                                                                  tokens used in every API call, where the token cost of a single call\nTo precisely attribute the performance gains of MAPGD, we per-\n                                                                                         is defined as the sum of input tokens and output tokens. For each\nform a comprehensive ablation study (see Table 2 for the detailed\n                                                               method, we accumulated token usage across all iterations and runs,\nconfigurations and results). Beyond standard ablation variants (e.g.,\n                                                           and report the total tokens, average tokens per iteration, and total\nNo Gradient Fusion, Single-Agent Only, No Specialization), we de-\n                                                         number of LLM calls. In addition, we report performance efficiency\nsign targeted experiments specifically to isolate the contributions of\n                                                                      as the ratio of average F1 score to total token usage.\nthe two proposed modules HCGC and CAAW, as well as to evaluate\n                                                                    Table 3 presents the results, comparing MAPGD with the Pro-\nresource efficiency and robustness.\n                                                                      TeGi. MAPGD not only achieves higher F1 scores, but also requires\n   Ablation configurations. We evaluate the following variants:        fewer tokens and API calls overall. Specifically, MAPGD reduces\n                                                                   the average token cost per iteration from roughly 25.6k to 23.6k,\n     (1) MAPGD (full): our full method with HCGC and CAAW.\n                                                                corresponding to a âˆ¼8% saving in token usage. At the same time,     (2) No Gradient Fusion: disable the fusion stage; agents act\n                                          MAPGD improves the performance-per-token efficiency by more\n       independently and their suggestions are applied without\n                                                              than 10%. These findings indicate that multi-agent collaboration\n       semantic clustering.\n                                                                with HCGC and CAAW enables more effective use of query budgets,\n     (3) Single-Agent Only: only one specialized agent (instruction\n                                                                  reducing redundancy while preserving accuracy.\n         specialist) is used.\n     (4) No Specialization: agent roles are randomized each iteration\n       (no fixed expertise).                                   4.7  Agent Number Sensitivity\n     (5) w/o HCGC: keep clustering but remove the hypersphere     To better justify the design choice of using four specialized agents,\n       angular-margin constraint. This reduces to standard K-    we conduct a sensitivity analysis by varying the number of agents\n      means clustering with cosine similarity, which acts as an    ğ‘âˆˆ{2, 4, 6}. For ğ‘= 2, we retain only the Instruction Specialist\n        off-the-shelf baseline for comparison.                      and Example Curator; for ğ‘= 6, we extend the framework with two\n     (6) w/o CAAW: replace Channel-Adaptive Agent Weighting      additional stylistic and format-focused agents. All other settings\n       with simple uniform averaging of agent gradients.             follow Section 4.2.\n\nFigure 6 shows the average F1 score across the four datasets.                efficiency, indicating that it not only improves accuracy but\nWe observe that performance improves substantially when mov-              also makes more economical use of query budgets.\ning from ğ‘= 2 to ğ‘= 4, confirming the benefit of multi-agent          â€¢ Robustness across tasks. The improvements are consis-\nspecialization. Increasing to ğ‘= 6 yields only marginal gains               tent across datasets of varying size, domain, and language,\nwhile incurring higher token cost, suggesting diminishing returns.             suggesting that MAPGD generalizes well to heterogeneous\nThese results indicate that four agents provide a favorable balance          NLP tasks. Furthermore, the case study in the Appendix\nbetween effectiveness and efficiency, validating our default config-               illustrates its applicability to open-ended generation, ex-\nuration.                                                                  tending beyond controlled classification benchmarks.\n   Overall, these findings suggest that an excessively small agent          â€¢ Transferability to reasoning tasks. MAPGD also demon-\nset cannot comprehensively capture different prompt dimensions,               strates strong performance on arithmetic reasoning datasets,\nwhereas an overly large set introduces redundancy and potential             surpassing competitive baselines such as PromptWizard.\nconflicts. A moderate number of agents, four in our case, provides                 Its consistent improvements on GSM8k, AQUARAT, and\nthe best trade-off.                                          SVAMP highlight that the proposed gradient-inspired multi-\n                                                                        agent optimization is not limited to classification, but can\n       1.00\n                                                Agents num                                    effectively enhance chain-of-thought style reasoning as\n       0.95                                             2                                      well.                                                       4\n                                                       6\n       0.90\n                                                                          In summary, these insights show that MAPGD achieves a favor-\n       0.85                                                                 able balance between performance and efficiency, while its modular\n                                                                    design (HCGC + CAAW) provides both effectiveness and robustness\n F1 0.80\n                                                                         in diverse prompt optimization scenarios.\n       0.75\n\n       0.70\n                                               5  DISCUSSION\n       0.65                                     MAPGD advances prompt optimization by combining gradient-\n       0.60                                                               inspired reasoning with multi-agent collaboration. Its two key\n                    Jailbreak           Ethos                Liar           Sarcasm\n                                                             mechanismsâ€”Hypersphere-Constrained Gradient Clustering and\n                                                                Channel-Adaptive Agent Weighting enable more structured, inter-\nFigure 6: Agent number sensitivity analysis. Increasing\n                                                                            pretable, and efficient optimization.\nagents from 2 to 4 yields clear improvements, while further\n                                                                 Modularity. By separating gradient generation, clustering, weight-increasing to 6 brings diminishing returns.\n                                                                             ing, and candidate selection, MAPGD clarifies which components\n                                                                        drive performance, supporting transparent analysis and principled\n                                                                       extensions.\n4.8  Experimental Insights                                                                    Conflict resolution. HCGC enforces angular margin constraints\nOur experimental evaluation provides several key insights:           on the hypersphere, promoting intra-cluster compactness and inter-\n    â€¢ Effectiveness of multi-agent collaboration. Across all       cluster separation. This directly addresses conflicts among agent-\n       four benchmark tasks, MAPGD consistently outperforms      generated gradients, common in tasks such as fake news detection\n        single-agent ProTeGi and other baselines. The largest gains      or jailbreak classification, and parallels gradient surgery in multi-\n        are observed on LIAR and Jailbreak, where conflicting gra-      task learning but for discrete prompts.\n        dient signals are common. This demonstrates that multi-       Adaptive collaboration. CAAW allocates influence based on\n       agent specialization, combined with semantic clustering,      agent reliability, reducing noise from weaker gradients while am-\n       can effectively resolve gradient conflicts and guide prompt       plifying consistent signals. This is useful when tasks emphasize\n        optimization toward more robust improvements.                 different reasoning dimensions (e.g., semantic consistency vs. con-\n    â€¢ Contributions of HCGC and CAAW. The ablation study       textual grounding).\n       confirms that both proposed modules are indispensable.       Budget-awareness. With lightweight bandit-based selection,\n      Removing HCGC reduces the ability to enforce semantic    MAPGD improves performance-per-token efficiency, achieving\n       compactness and separation, leading to less stable opti-      higher accuracy with fewer redundant API calls.\n        mization. Disabling CAAW degrades robustness by failing        Limitations. MAPGD depends on embedding quality and agent\n        to downweight weaker agents. When both modules are        reliability; under strong domain shifts, clustering may be unstable\n       removed, MAPGD collapses close to single-agent perfor-     and weighting may amplify spurious signals. Future work may\n       mance, highlighting their complementary roles.                strengthen semantic representations and improve agent calibration.\n    â€¢ Efficiency in token usage. Despite employing multiple        Future directions. Promising avenues include:\n        agents, MAPGD achieves lower overall token consumption\n       and fewer API calls than ProTeGi. This efficiency stems from            (1) Cross-task generalization: training reusable agents with\n        clustering redundant gradients and adaptively weighting              transferable clustering and weighting behaviors.\n        agents, which reduce unnecessary evaluations. As a result,            (2) Human-in-the-loop fusion: leveraging expert oversight to\n     MAPGD achieves over 10% higher performance-per-token             guide clustering and validate weighting.\n\n(3) Hybrid optimization: integrating MAPGD with differen-\n        tiable prompt tuning to balance interpretability and effi-\n        ciency.\n\n6  CONCLUSION\nWe presented MAPGD: Multi-Agent Prompt Gradient Descent, a\nnovel framework for optimizing prompts in large language mod-\nels. The key innovations of MAPGD are HCGC, which resolves\nconflicts through hypersphere-constrained clustering, and CAAW,\nwhich adaptively balances the contributions of specialized agents.\nTogether, these mechanisms enable diverse agents to collaborate\neffectively while maintaining semantic alignment.\n   Empirically, MAPGD achieves consistent improvements over\nstrong baselines such as ProTeGi, Monte Carlo search, reinforce-\nment learningâ€“based methods, and recent arithmetic reasoning\nframeworks. On four benchmark classification tasks, MAPGD im-\nproves F1 scores by 3â€“7% on average while reducing token consump-\ntion by âˆ¼8%, leading to better performance-per-token efficiency.\nBeyond classification, MAPGD also demonstrates strong transfer-\nability to arithmetic reasoning datasets such as GSM8k, AQUARAT,\nand SVAMP, where it surpasses competitive baselines including\nPromptWizard. These results confirm that gradient-inspired multi-\nagent collaboration is broadly applicable across both discriminative\nand reasoning tasks.\n   Theoretically, we show that MAPGD achieves a sublinear con-\n            âˆš\nvergence rate of ğ‘‚(1/ ğ‘‡) under standard stochastic approximation\nassumptions (see Appendix C for details). This result indicates\nthat even in a discrete prompt space, the semantic gradient mech-\nanismâ€”stabilized by HCGC and CAAWâ€”retains the efficiency of\nclassical stochastic gradient descent.\n  While challenges remain, particularly regarding embedding ro-\nbustness and LLM feedback reliability, MAPGD provides both a\npractical toolkit for efficient prompt optimization and a theoreti-\ncal foundation linking discrete semantic updates with continuous\noptimization theory. Future work may extend HCGC and CAAW\nto multimodal prompts, incorporate human preference alignment,\nand develop cross-domain reusable agents.\n   In summary, MAPGD demonstrates that multi-agent collabo-\nration, when combined with principled clustering and adaptive\nweighting, leads to more robust, interpretable, and resource-efficient\nprompt optimization, with demonstrated effectiveness across clas-\nsification, reasoning, and beyond.\n\nREFERENCES                                                                    [23]  Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP models really\n [1]  Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-              able to solve simple math word problems? arXiv preprint arXiv:2103.07191 (2021).\n      cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal        [24]  Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal. 2022. Grips: Gradient-\n     Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774                free, edit-based instruction search for prompting large language models. arXiv\n      (2023).                                                                                        preprint arXiv:2203.07281 (2022).\n [2] Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu,        [25]  Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng.\n     and Akshay Nambi. 2024. PromptWizard: Task-Aware Prompt Optimization              2023. Automatic prompt optimization with\" gradient descent\" and beam search.\n     Framework. arXiv:2405.18369 [cs.CL] https://arxiv.org/abs/2405.18369                    arXiv preprint arXiv:2305.03495 (2023).\n [3]  Jean-Yves Audibert and SÃ©bastien Bubeck. 2010. Best arm identification in multi-        [26] Guanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying LMs with\n     armed bandits. In COLT-23th Conference on learning theory-2010. 13â€“p.                    mixtures of soft prompts. arXiv preprint arXiv:2104.06599 (2021).\n [4]  SÃ©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric        [27]  Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language\n      Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.            models: Beyond the few-shot paradigm. In Extended abstracts of the 2021 CHI\n      2023. Sparks of artificial general intelligence: Early experiments with gpt-4.              conference on human factors in computing systems. 1â€“7.\n     arXiv preprint arXiv:2303.12712 (2023).                                                 [28] Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal,\n [5]  Lichang Chen, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou. 2023.           and Aman Chadha. 2025. A Systematic Survey of Prompt Engineering in Large\n      InstructZero: Efficient Instruction Optimization for Black-Box Large Language            Language Models: Techniques and Applications. arXiv:2402.07927 [cs.AI] https:\n     Models. arXiv:2306.03082 [cs.AI] https://arxiv.org/abs/2306.03082                          //arxiv.org/abs/2402.07927\n [6] Shuo Chen, Gang Niu, Chen Gong, Jun Li, Jian Yang, and Masashi Sugiyama.        [29] Xinyue Shen, Zeyuan Chen, Michael Backes, Yun Shen, and Yang Zhang. 2024. \"\n      2021. Large-margin contrastive learning with distance polarization regularizer.           do anything now\": Characterizing and evaluating in-the-wild jailbreak prompts\n      In International conference on machine learning. PMLR, 1673â€“1683.                     on large language models. In Proceedings of the 2024 on ACM SIGSAC Conference\n [7]  Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun,            on Computer and Communications Security. 1671â€“1685.\n     Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,        [30]  Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, and Sameer\n      et al. 2021. Training verifiers to solve math word problems. arXiv preprint             Singh. 2020.  Autoprompt: Eliciting knowledge from language models with\n      arXiv:2110.14168 (2021).                                                                  automatically generated prompts. arXiv preprint arXiv:2010.15980 (2020).\n [8]  Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. 2019. Arcface:        [31] Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou,\n     Additive angular margin loss for deep face recognition. In Proceedings of the             Zhifeng Li, and Wei Liu. 2018. Cosface: Large margin cosine loss for deep face\n     IEEE/CVF conference on computer vision and pattern recognition. 4690â€“4699.                  recognition. In Proceedings of the IEEE conference on computer vision and pattern\n [9]  Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin               recognition. 5265â€“5274.\n     Shu, Meng Song, Eric P Xing, and Zhiting Hu. 2022. Rlprompt: Optimizing dis-        [32] Tongzhou Wang and Phillip Isola. 2020. Understanding contrastive representa-\n      crete text prompts with reinforcement learning. arXiv preprint arXiv:2205.12548              tion learning through alignment and uniformity on the hypersphere. In Interna-\n      (2022).                                                                                            tional conference on machine learning. PMLR, 9929â€“9939.\n[10]  Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch.        [33] W Wang. 2021. A new benchmark dataset for fake news detection. In Proceedings\n      2023. Improving factuality and reasoning in language models through multiagent                of the 55th Annual Meeting of the Association for Computational Linguistics, Vol. 2.\n      debate. In Forty-first International Conference on Machine Learning.                     [34]  Jinyu Xiang, Jiayi Zhang, Zhaoyang Yu, Xinbing Liang, Fengwei Teng, Jinhao\n[11]  Ibrahim Abu Farha and Walid Magdy. 2020. From arabic sentiment analysis to             Tu, Fashen Ren, Xiangru Tang, Sirui Hong, Chenglin Wu, and Yuyu Luo. 2025.\n     sarcasm detection: The arsarcasm dataset. In The 4th Workshop on Open-Source             Self-Supervised Prompt Optimization. arXiv:2502.06855 [cs.CL] https://arxiv.\n     Arabic Corpora and Processing Tools. European Language Resources Association             org/abs/2502.06855\n     (ELRA), 32â€“39.                                                                        [35]  J Diego Zamfirescu-Pereira, Richmond Y Wong, Bjoern Hartmann, and Qian\n[12]  Chrisantha Fernando, Dylan Banarse, Charles Blundell, Tim RocktÃ¤schel, and             Yang. 2023. Why Johnny canâ€™t prompt: how non-AI experts try (and fail) to\n    Simon Osindero. 2023. PromptBreeder: Self-Referential Self-Improvement Via             design LLM prompts. In Proceedings of the 2023 CHI conference on human factors\n     Prompt Evolution. arXiv preprint arXiv:2309.16797 (2023).                                    in computing systems. 1â€“21.\n[13]  Sirui Hong, Mingchen Zhuge, Jiaqi Chen, Xiawu Zheng, Yuheng Cheng, Ceyao        [36]  Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schuurmans, and Joseph E\n     Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou,             Gonzalez. 2022. Tempera: Test-time prompting via reinforcement learning. arXiv\n    Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and JÃ¼rgen Schmidhuber. 2024.              preprint arXiv:2211.11890 (2022).\n    MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework.        [37] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis,\n     arXiv:2308.00352 [cs.AI] https://arxiv.org/abs/2308.00352                                  Harris Chan, and Jimmy Ba. 2022. Large language models are human-level prompt\n[14]  Jie Hu, Li Shen, and Gang Sun. 2018.  Squeeze-and-excitation networks. In              engineers. In The eleventh international conference on learning representations.\n      Proceedings of the IEEE conference on computer vision and pattern recognition.\n     7132â€“7141.\n[15]  Ellen            Jiang,                 Kristen                         Olson,                          Edwin                                     Toh,                                          Alejandra Molina,                                                    Aaron                                                              Donsbach,   A CAAW PARAMETER SENSITIVITY     Michael               Terry,                 and Carrie                                         J Cai.                                     2022.                                     Promptmaker:                                                   Prompt-based                                                                    prototyping\n     with large language models. In CHI Conference on Human Factors in Computing     The Channel-Adaptive Agent Weighting module uses a temperature\n     Systems Extended Abstracts. 1â€“8.                                      parameter ğœ†to control the emphasis on historically effective agents\n[16]  Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for\n                                                                  during gradient fusion. To evaluate the robustness of MAPGD with      parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691 (2021).\n[17] Xiang Lisa Li and Percy Liang. 2021. Prefix-Tuning: Optimizing Continuous      respect to ğœ†, we conducted experiments on two representative\n     Prompts               for Generation.                              Proceedings                                              of the                                              59th                                            Annual Meeting                                                                          of the                                                                           Association                                                                           datasets: LIAR(binary) and GSM8K (mathematical reasoning).      for Computational                          Linguistics                              and the                                          11th                                                   International                                                                  Joint                                                                 Conference                                                                    on\n     Natural Language Processing (Volume 1: Long Papers) (2021), 4582â€“4597.  https:      We tested three values of ğœ†: 0.5, 1, and 2. Table 4 summarizes the\n     //api.semanticscholar.org/CorpusID:230433941                                   test accuracy for each setting. The results indicate that moderate\n[18] Weizhe Liang, Yizhong Wu, Mina Lee, Ed Chi, Denny Zhou, Yiming Song, and\n     Xiang Lisa Li. 2023. Encouraging Divergent Thinking in Large Language Models      variations of ğœ†do not significantly affect the overall performance,\n     through Multi-Agent Debate. arXiv preprint arXiv:2305.19118 (2023).              supporting the choice of ğœ†= 1 in the main experiments.\n[19]  Xiaoqiang Lin, Zhaoxuan Wu, Zhongxiang Dai, Wenyang Hu, Yao Shu, See-\n     Kiong Ng, Patrick Jaillet, and Bryan Kian Hsiang Low. 2024. Use Your INSTINCT:\n     INSTruction optimization for LLMs usIng Neural bandits Coupled with Trans-\n      formers. arXiv:2310.02905 [cs.LG] https://arxiv.org/abs/2310.02905            Table 4: Test accuracy of MAPGD under different CAAW[20] Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program\n      induction by rationale generation: Learning to solve and explain algebraic word     weighting parameter ğœ†. Performance differences are minor,\n     problems. arXiv preprint arXiv:1705.04146 (2017).                        demonstrating robustness to ğœ†.\n[21] Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song. 2017.\n      Sphereface: Deep hypersphere embedding for face recognition. In Proceedings of\n      the IEEE conference on computer vision and pattern recognition. 212â€“220.                     ğœ†   LIAR Accuracy  GSM8K Accuracy\n[22]  Ioannis Mollas, Zoe Chrysopoulou, Stamatis Karlos, and Grigorios Tsoumakas.                    0.5        0.709              0.927\n      2022. ETHOS: a multi-label hate speech detection dataset. Complex & Intelligent\n                                                                           1        0.717              0.935     Systems 8, 6 (2022), 4663â€“4678.\n                                                                           2        0.711              0.933\n\nAs shown in Table 4, the test accuracy exhibits only minor varia-     Algorithm 1 MAPGD with HCGC and CAAW\ntions across the three ğœ†values, with a maximum difference of 0.008                                                             Require: Initial prompt ğ‘0, train data ğ·train, dev data ğ·dev, agents\non LIAR and 0.008 on GSM8K. These variations are small relative         {ğ´ğ‘–}ğ‘ğ‘–=1, iterations ğ‘…, beam width ğ‘˜to the overall performance gains achieved by multi-agent gradient\n                                                                                                               1: Initialize best prompt ğ‘(0)â˜…  â†ğ‘0, beam ğµ0 â†{ğ‘0}; initializefusion, indicating that while ğœ†influences the sharpness of agent\n                                                                   each agent prompt ğ´ğ‘–.ğ‘â†ğ‘0\nweighting, MAPGDâ€™s performance remains stable for reasonable\n                                                                                                               2: for ğ‘¡= 1 to ğ‘…do\nchoices around the default setting of ğœ†= 1.                                              3:    ğ‘€ğ‘¡â†SampleMiniBatch(ğ·train,ğ‘)\n                                                                                                               4:    Gğ‘¡â†GenerateAgentGradients({ğ´ğ‘–}, ğ‘€ğ‘¡)    âŠ²Alg. 2\nB  COMPLEXITY AND PARALLELISM                                                                                                               5:   ËœGğ‘¡â†HCGC(Gğ‘¡)                            âŠ²Alg. 3\nThe computational bottleneck of MAPGD with HCGC and CAAW                                                                                                               6:   ğ¹ğ‘¡â†CAAWFuse( ËœGğ‘¡, ğ·dev)                    âŠ²Alg. 4\n(see Algorithm 1) lies in LLM calls for gradient generation, clus-\n                                                                                                               7:    Cğ‘¡â†ExpandPrompts(ğ‘(ğ‘¡âˆ’1)â˜…      , ğ¹ğ‘¡)ter fusion, and prompt expansion, whereas embedding, clustering,\nsimilarity checks, and adaptive weighting involve comparatively            8:     ğµğ‘¡, ğ‘(ğ‘¡)â˜…  â†BanditSelect(Cğ‘¡, ğ·dev,ğ‘˜)\nlightweight vector operations. Multi-agent parallelization signifi-            9:    SynchronizeAgents({ğ´ğ‘–}, ğ‘(ğ‘¡)â˜…)               âŠ²Alg. 5\ncantly reduces wall time, making the framework scalable for prac-         10:      if Converged(ğ‘(ğ‘¡)â˜…) then break\ntical deployment. In the following, we analyze the per-iteration          11:    end if\ncomputational and memory costs, providing a detailed breakdown          12: end for\nof the dominant operations and their respective complexities.                13: return Best prompt over {ğ‘(1)â˜…, . . . , ğ‘(ğ‘¡)â˜…}\n\n   Notation. Let ğ‘be the number of agents, ğ‘šthe number of rea-\nsons per agent, givingğº= ğ‘ğ‘šatomic gradients. Embedding dimen-     Algorithm 2 Multi-Agent Textual Gradient Generation\nsion ğ‘‘, clusters ğ¾â‰¤ğº, fused gradients | ËœG|, expansion variants per\n                                                             Require: Agents {ğ´ğ‘–}, mini-batch ğ‘€ğ‘¡, task ğ‘‡, predictor Î , per-gradient ğ‘ , MC paraphrases per variant ğ‘›mc, candidate prompts |C|,                                                                     agent error cap ğ‘’, feedback count ğ‘š\nbeam width ğ‘˜, bandit roundsğ‘‡ğ‘with ğ¾eval arms and dev mini-batch\n                                                                                                               1: for all agent ğ´ğ‘–in parallel dosize ğ‘.\n                                                                                                               2:      (Ë†ğ‘¦,ğ‘¦) pairs â†ğ‘‡.InferAndLabel(ğ´ğ‘–.ğ‘, ğ‘€ğ‘¡, Î )\n   Stage costs (time).                                                                                3:    ğ¸ğ‘–â†SelectErrors(Ë†ğ‘¦,ğ‘¦,ğ‘’)\n     (1) Agent gradient generation: Each of the ğ‘agents gen-            4:      if |ğ¸ğ‘–| = 0 then ğ¸ğ‘–â†DiverseSamples(ğ‘€ğ‘¡,ğ‘’)\n        erates ğ‘šgradients using LLMs, giving ğ‘‚(ğ‘) LLM calls.            5:    end if\n        Parallelization reduces wall time to â‰ˆmaxğ‘¡LLM.                            6:    ğ‘Ÿğ‘ğ‘¤ğ‘–â†LLMGradientPrompt(ğ´ğ‘–.ğ‘Ÿğ‘œğ‘™ğ‘’,ğ´ğ‘–.ğ‘, ğ¸ğ‘–,ğ‘š)\n     (2) HCGC embedding + conflict detection: Embedding each            7:    ğ‘”ğ‘–â†ParseGradientBlocks(ğ‘Ÿğ‘ğ‘¤ğ‘–)  âŠ²Split by delimiters\n        gradient costs ğ‘‚(ğºğ‘‘); computing pairwise angular conflicts            8: end for\n        costs ğ‘‚(ğº2ğ‘‘). For small ğº(e.g., ğºâˆ¼16), this is negligible            9: return Gğ‘¡= {(ğ´ğ‘–.ğ‘Ÿğ‘œğ‘™ğ‘’,ğ‘”ğ‘–)}ğ‘ğ‘–=1\n      compared with LLM calls.\n     (3) HCGC clustering: KMeans clustering over ğºgradients\n        into ğ¾clusters with ğ¼iterations costsğ‘‚(ğºğ¾ğ¼ğ‘‘), again minor     Algorithm 3 Hypersphere-Constrained Gradient Clustering\n       due to small ğº.                                          Require: Agent gradients Gğ‘¡\n     (4) HCGC fusion (LLM): Clusters with multiple gradients            1: Embed and normalize: Ë†ğ‘£ğ‘˜= ğœ™(ğ‘”ğ‘˜)/âˆ¥ğœ™(ğ‘”ğ‘˜)âˆ¥\n        require one LLM call per cluster to fuse into a coherent            2: Detect conflicts: Cconf â†{(ğ‘–, ğ‘—) : cosâˆ’1(Ë†ğ‘£âŠ¤ğ‘–Ë†ğ‘£ğ‘—) > ğœƒ}\n        gradient. Total LLM calls up to ğ‘‚(ğ¾merge), parallelizable            3: Cluster gradients: {ğ‘†ğ‘˜}ğ¾  â†KMeans({Ë†ğ‘£ğ‘˜}, ğ¾max)                                                                                                    ğ‘˜=1\n        across clusters.                                                                            4: for ğ‘˜= 1 to ğ¾do\n     (5) CAAW weighting and fusion: Per-cluster adaptive weight-          5:    Apply angular margin: reassign gradients violating cos(ğ‘›Â·\n        ing is ğ‘‚(ğº) vector operations, negligible compared to LLM            Î”(Ë†ğ‘£ğ‘–,ğ‘ğ‘˜)) > cos(Î”(Ë†ğ‘£ğ‘–,ğ‘ğ‘—))\n        fusion.                                                                                         6:    Fuse cluster ğ‘†ğ‘˜via LLM: ğ‘“ğ‘˜â†LLMFuse(ğ‘†ğ‘˜, Cconf)\n     (6) Prompt expansion + MC paraphrasing: Applying each            7: end for\n        fused gradient:ğ‘‚(| ËœG|) gradient applications. MC paraphras-            8: return Fused clusters: ËœGğ‘¡= {ğ‘“1, . . . , ğ‘“ğ¾}\n       ing for each variant: ğ‘‚(| ËœG|ğ‘ ğ‘›mc) LLM calls.\n     (7) Diversity filtering: Computing embeddings:ğ‘‚(|C|ğ‘‘); naive\n        pairwise similarities:ğ‘‚(|C|2). For tens of candidate prompts,                                  C  THEORETICAL ANALYSIS\n         this remains negligible.\n                                                                     In this section, we provide convergence guarantees for MAPGD\n     (8) Bandit evaluation: Probing ğ¾eval arms over mini-batches     under mild assumptions, following the stochastic approximation\n        of size ğ‘for ğ‘‡ğ‘rounds: ğ‘‚(ğ¾evalğ‘ğ‘‡ğ‘), significantly cheaper                                                              framework. Our goal is to bridge the gap between the continuous\n       than exhaustive evaluation ğ‘‚(|C| |ğ·dev|).                                                                   optimization theory of stochastic gradient descent (SGD) and the\n   Space complexity. Text storage: ğ‘‚(|C|ğ¿avg). Embeddings: ğ‘‚((ğº+       discrete prompt optimization carried out in MAPGD. We show that,\n|C|)ğ‘‘), typically a few MB. Optional caches (unique prompts or in-      despite operating in a structured and discrete search space, MAPGD                                                                         âˆš\ntermediate LLM outputs) scale linearly with the number of prompts      achieves the same sublinear convergence rate of ğ‘‚(1/ ğ‘‡) in both\nand clusters.                                                  convex and non-convex settings.\n\nAlgorithm 4 Channel-Adaptive Agent Weighting and Fusion         Lemma 2 (Non-Convex Descent Lemma). If ğ¹is ğ¿-smooth, then\n                                                                           for update ğ‘(ğ‘¡+1) = ğ‘(ğ‘¡) âˆ’ğœ‚ğ‘”(ğ‘¡), we haveRequire: Clustered gradients ËœGğ‘¡, dev data ğ·dev, temperature ğœ†\n   1: for all cluster ËœGğ‘¡do                                                                           ğ¿                                                                             ğ¹(ğ‘(ğ‘¡+1)) â‰¤ğ¹(ğ‘(ğ‘¡)) âˆ’ğœ‚âŸ¨âˆ‡ğ¹(ğ‘(ğ‘¡)),ğ‘”(ğ‘¡)âŸ©+           âˆ¥2.   2:    Compute per-gradient validation gain ğ‘ ğ‘–on ğ·dev                                                              2ğœ‚2âˆ¥ğ‘”(ğ‘¡)\n                                                  exp(ğœ†ğ‘ ğ‘–)\n   3:    Assign adaptive weight: ğ‘¤ğ‘–= Ã ğ‘—âˆˆğ‘†ğ‘˜exp(ğœ†ğ‘ ğ‘—)               C.3  Main Results\n   4:    Fuse cluster gradients: ğ‘“ğ‘˜= Î¨ Ãğ‘–âˆˆğ‘†ğ‘˜ğ‘¤ğ‘–ğ‘”ğ‘–                     Convex Convergence. Suppose ğ¹is convex, ğº-Lipschitz, and P\n   5: end for                                                    has diameter ğ·. Let Â¯ğ‘ğ‘‡= ğ‘‡1 Ãğ‘‡ğ‘¡=1 ğ‘(ğ‘¡). Under (A1)â€“(A2) and step\n   6: return ğ¹ğ‘¡= {ğ‘“1, . . . , ğ‘“ğ¾}                                               size ğœ‚= ğºğ·                                                                 âˆšğ‘‡, we obtain:\n\n                                                                                                      1\nAlgorithm 5 SynchronizeAgents                                              E[ğ¹( Â¯ğ‘ğ‘‡)] âˆ’ğ¹(ğ‘âˆ—) = ğ‘‚ âˆš      .\n                                                                                       ğ‘‡\nRequire: Agents {ğ´ğ‘–}ğ‘ğ‘–=1, current best prompt ğ‘(ğ‘¡)â˜…                         Proof sketch. By Lemma 1 and convexity:\n   1: for each agent ğ´ğ‘–do\n   2:    ğ´ğ‘–.ğ‘â†ğ‘(ğ‘¡)â˜…  âŠ²Set the agentâ€™s current prompt to the global                      ğ¹(ğ‘(ğ‘¡)) âˆ’ğ¹(ğ‘âˆ—) â‰¤âŸ¨ğ‘”(ğ‘¡), ğ‘(ğ‘¡) âˆ’ğ‘âˆ—âŸ©.\n    best\n                                                     Summing over ğ‘¡= 1, . . . ,ğ‘‡and applying (A1)â€“(A2), we bound the\n   3:    ResetGradientHistory(ğ´ğ‘–)   âŠ²Optional: clear outdated                                                                             regret:\n    gradient history\n   4:    UpdatePerformanceMemory(ğ´ğ‘–, ğ‘(ğ‘¡)â˜…)        âŠ²Record                  ğ‘‡âˆ‘ï¸ E[ğ¹(ğ‘(ğ‘¡)) âˆ’ğ¹(ğ‘âˆ—)] â‰¤ğ·2   ğœ‚ğº2ğ‘‡ .    performance feedback for the new prompt                                        2ğœ‚+   2\n                                                                                               ğ‘¡=1\n   5: end for                                                     Using Jensenâ€™s inequality for Â¯ğ‘ğ‘‡and optimizing ğœ‚, we conclude the\n   6: return Updated agents {ğ´ğ‘–}                          âˆš                                                        ğ‘‚(1/ ğ‘‡) rate.\n\n                                                                Non-Convex Convergence. Suppose ğ¹is ğ¿-smooth and (A1)â€“(A2)                                                                âˆš\nC.1  Assumptions                                               hold. With constant step size ğœ‚= Î˜(1/ ğ‘‡), we have\nWe begin with a set of assumptions standard in stochastic opti-\nmization but reinterpreted in the context of multi-agent prompt                    1 ğ‘‡âˆ‘ï¸ E âˆ¥âˆ‡ğ¹(ğ‘(ğ‘¡))âˆ¥2 = ğ‘‚ âˆš1     .\noptimization.                                                        ğ‘‡                     ğ‘‡                                                                                                     ğ‘¡=1\n    â€¢ (A1) Alignment (Unbiasedness). For some ğœ‡> 0, the                                                                           Proof sketch. Applying Lemma 2 and taking conditional expecta-        stochastic semantic gradient ğ‘”(ğ‘¡) maintains alignment with                                                                               tion:\n       the true gradient:\n                                                                             E[ğ¹(ğ‘(ğ‘¡+1))] â‰¤E[ğ¹(ğ‘(ğ‘¡))] âˆ’ğœ‚ğœ‡E[âˆ¥âˆ‡ğ¹(ğ‘(ğ‘¡))âˆ¥2]\n        E âŸ¨ğ‘”(ğ‘¡), âˆ‡ğ¹(ğ‘(ğ‘¡))âŸ©  ğ‘(ğ‘¡)  â‰¥ğœ‡âˆ¥âˆ‡ğ¹(ğ‘(ğ‘¡))âˆ¥2.\n                                                              + ğ¿2ğœ‚2 ğœŒE[âˆ¥âˆ‡ğ¹(ğ‘(ğ‘¡))âˆ¥2] + ğœ2   .      (10)       This reflects the role of semantic fusion: multi-agent aggre-\n       gation reduces the chance of adversarial or noisy updates,       Summing over ğ‘¡= 1 . . .ğ‘‡gives\n       ensuring progress along descent directions.\n    â€¢ (A2) Bounded Second Moment. For constants ğœŒ, ğœ2 â‰¥0,            1 ğ‘‡âˆ‘ï¸ E âˆ¥âˆ‡ğ¹(ğ‘(ğ‘¡))âˆ¥2  â‰¤2(ğ¹(ğ‘(1)) âˆ’ğ¹inf) + ğ¿ğœ2                                                           ğ‘‡                         ğœ‡ğ‘‡ğœ‚       ğœ‡ğœ‚.\n         E âˆ¥ğ‘”(ğ‘¡) âˆ¥2  ğ‘(ğ‘¡)  â‰¤ğœŒâˆ¥âˆ‡ğ¹(ğ‘(ğ‘¡))âˆ¥2 + ğœ2.                                ğ‘¡=1\n                                                            âˆš\n       This captures the variance-control effect of the bandit-based      Balancing terms with ğœ‚= Î˜(1/ ğ‘‡) yields the claimed rate.\n        selection mechanism, which prevents uncontrolled explo-\n        sion of gradient magnitude.                         C.4  Summary of Theoretical Guarantees\n    â€¢ (A3) Smoothness or Lipschitzness. For convex tasks, ğ¹       In this work, we bridge the gap between classical stochastic op-\n          is ğº-Lipschitz with domain diameter ğ·. For non-convex       timization, which assumes continuous parameter spaces, and the\n         tasks, ğ¹is ğ¿-smooth: âˆ¥âˆ‡ğ¹(ğ‘¢) âˆ’âˆ‡ğ¹(ğ‘£)âˆ¥â‰¤ğ¿âˆ¥ğ‘¢âˆ’ğ‘£âˆ¥.             inherently discrete, structured nature of prompt optimization. Our\n                                                              convergence analysis for MAPGD does not require the discrete\nC.2  Supporting Lemmas                              prompt space to be continuous. Instead, we show that the frame-\nWe restate two standard lemmas, adapted to the MAPGD setting.      workâ€™s core mechanisms ensure that the optimization process satis-\n                                                                                    fies the key conditions of stochastic approximation theory.\n  Lemma 1 (Convex Projection Inequality). For convex ğ¹with feasi-       The argument unfolds along three main dimensions:\nble set P, the projected subgradient update\n                                                                â€¢ Directional Alignment (A1): Although textual pseudo-\n                     ğ‘(ğ‘¡+1) = Î P ğ‘(ğ‘¡) âˆ’ğœ‚ğ‘”(ğ‘¡)                                   gradients are not true mathematical gradients, Hypersphere-\n                                                                       Constrained Gradient Clustering aggregates semantically\nsatisfies                                                                          coherent suggestions from multiple agents into a fused gra-\n âˆ¥ğ‘(ğ‘¡+1) âˆ’ğ‘âˆ—âˆ¥2 â‰¤âˆ¥ğ‘(ğ‘¡) âˆ’ğ‘âˆ—âˆ¥2 âˆ’2ğœ‚âŸ¨ğ‘”(ğ‘¡), ğ‘(ğ‘¡) âˆ’ğ‘âˆ—âŸ©+ ğœ‚2âˆ¥ğ‘”(ğ‘¡) âˆ¥2.               dient that statistically aligns with the true descent direction.\n\nâ€¢ Variance Control (A2): Discrete prompt edits are prone          â€¢ Identifying and resolving inconsistencies, ambiguities, or\n        to high variance, but the bandit-based candidate selection              potential misinformation through systematic checks.\n      mechanism filters out unreliable or detrimental candidates.         â€¢ Ensuring all risk assessments and conclusions are based\n       This effectively bounds the second moment of stochastic              solely on validated and accurate inputs to maintain the\n        updates.                                                                  integrity of your outputs.\n    â€¢ Smoothness Justification (A3): We assume the empirical       Data Authenticity and Completeness Verification\n        loss function is Lipschitz or smooth in the semantic em-\n                                                                â€¢ Scrutinize contextual cues (e.g., â€œContext: Section: Payback\n       bedding space, even though the prompts themselves are\n                                                                                    Period:â€) to ensure alignment with expected data types and\n         discrete.\n                                                                                    structures.\n  Given that these conditions are met, MAPGD inherits the con-         â€¢ Check for numerical or factual inconsistencies, such as\nvergence guarantees of classical stochastic gradient descent. Con-            typos (e.g., â€œ11975â€ instead of â€œ1975â€), exaggerations (e.g.,\nsequently, despite operating in a discrete textual space, MAPGD            â€œ$22.0Mâ€ without supporting context), or missing critical\n                               âˆš\nachieves a robust sublinear convergence rate of ğ‘‚(1/ ğ‘‡), provid-             information.\ning a solid theoretical foundation for the observed empirical effec-         â€¢ Validate that all referenced data points are present, logically\ntiveness of our multi-agent, geometry-aware approach to prompt               consistent, and contextually appropriate.\noptimization.                                                     â€¢ Flag and document any anomalies for further investigation\n                                                                            before proceeding with classification or analysis.\n\nD  CASE STUDY: SYSTEM PROMPT                    Context Interpretation and Parsing Guidelines\n                                                                â€¢ Carefully interpret and utilize contextual cues, especially   OPTIMIZATION\n                                                                               in nested or ambiguous contexts (e.g., â€œContext: Section:\nTo further illustrate the applicability of MAPGD, we present a case\n                                                       Name & Headquarters:â€).\nstudy where our method is applied to optimize the system prompt\n                                                                â€¢ Accurately parse section headers and contextual clues toof a large language model assistant. The original prompt is designed\n                                                                        prevent misclassification or incomplete analysis in multi-\nto support multi-source analysis and financial data interpretation\n                                                                               section reports.\nfor decision-making tasks. Using MAPGD, we refine the prompt to\n                                                                â€¢ Anchor analysis to the documentâ€™s structure by adheringenhance robustness, accuracy, and interpretability by embedding ex-\n                                                                                to hierarchical or sequential organization.\nplicit verification protocols, structured analysis guidelines, and risk\n                                                                â€¢ Resolve discrepancies in contextual labeling or structure toprioritization frameworks. This example highlights how MAPGD\n                                                                        maintain coherence.\ncan be deployed in practical LLM applications beyond benchmark\ndatasets, particularly in domains where data authenticity, reliability,        Structured Classification and Risk Prioritization Frame-\nand interpretability are critical.                            work\n  Original System Prompt. You are an AI assistant designed to            (1) Factual Reporting and Descriptive Analysis: Present\nprocess, analyze, and synthesize information from multiple sources               verified information such as corporate history, operational\nin order to answer user questions, generate insights, and prepare              metrics, and financial data neutrally, before transitioning\ndetailed reports. You have specialized capabilities in financial data              to evaluative content.\ninterpretation, knowledge retrieval, and multi-source analysis. You            (2) Business Analysis: Evaluate performance, market posi-\nsupport both operational and strategic decision-making for Golden               tioning, and strategic initiatives; assess risks by severity,\nSectionâ€™s portfolio companies.                                                    likelihood, and propose contextualized mitigation.\n  Optimized System Prompt via MAPGD. You are an AI assis-            (3) Legal Risk Analysis: Examine compliance, regulatory,\ntant specialized in processing, analyzing, and synthesizing infor-            and contractual risks; assess impact and propose mitigation\nmation from multiple sources to answer user questions, generate              actions aligned with legal context.\ninsights, and prepare detailed reports. Your core capabilities in-            (4) Cross-Domain Analysis: For overlapping elements, clas-\nclude financial data interpretation, knowledge retrieval, and multi-                sify by primary context and document dual-category cases\nsource analysis, with a focus on supporting operational and strate-            with rationale.\ngic decision-making for Golden Sectionâ€™s portfolio companies.                                                                 Validation Mechanisms for Cross-References\n   In performing your duties, you must ensure that all input data\n                                                                â€¢ Distinguish between source types (e.g., governance vs. iden-\nundergoes rigorous verification for authenticity, accuracy, and com-                                                                                            tity records).\npleteness before any analysis is conducted. This includes imple-\n                                                                â€¢ For each statement, explicitly identify the source type and\nmenting protocols to validate financial figures, legal terms, and                                                                        ensure contextual alignment.\nother critical information for alignment with established norms\nand credible sources. Your process must involve:                      Empirical Observation. After applying MAPGD, we observe\n                                                               a notable increase in the comprehensiveness of the generated fi-\n    â€¢ Cross-referencing information from diverse, credible sources     nancial analysis reports. Specifically, the average report length\n        to detect and mitigate false, exaggerated, or incomplete      increased from 1616 words under the original system prompt to\n        data.                                                     1965 words with the optimized prompt. This indicates that the opti-\n    â€¢ Assessing the reliability of each source, prioritizing primary     mized prompt encourages the model to produce more detailed and\n       sources where available.                                        contextually grounded content. While the per-report output length\n\nbecomes longer, the improved accuracy and completeness reduce         example_curator Selects and formats diverse examples that\nthe need for repeated generations or manual corrections, thereby            demonstrate truthful report generation and false data re-\nlowering the overall token consumption in practical workflows.               jection, including both positive (realistic) and negative (ex-\nThese findings further support that MAPGD enhances the robust-             aggerated) samples.\nness and effectiveness of system prompts in real-world generation         format_designer Specializes in designing clear, structured\ntasks.                                                                    output templates for reports (e.g., using <Business Analysis>,\n                                                                 <Financial Report> tags) and error messages (e.g., <Error>).\n                                                               style_optimizer Optimizes language style and tone for gen-E AGENT SPECIALIZATION FOR DIFFERENT\n                                                                                erating professional reports in business, financial, and legal\n   TASKS                                                                                 contexts, while ensuring error messages are direct and un-\nTo adapt MAPGD to different domains, we define specialized agent                                                                      ambiguous.\nroles tailored to the unique requirements of each task. Below are\nthe agent configurations used for the classification, mathematical\n                                            F EXAMPLE PROMPTS BEFORE AND AFTERreasoning, and financial analysis tasks in our experiments.\n                                          OPTIMIZATION\n                                                                  This appendix provides the initial prompts and the final optimized\nE.1  Agent Roles for Classification Tasks                                                              prompts generated by MAPGD for each of the benchmark datasets\nFor general classification tasks, the agents focus on the core compo-                                                               used in our experiments.\nnents of a good prompt: instructions, examples, format, and style.\n\n    instruction_specialist Analyzes and improves task in-     F.1  LIAR Dataset\n        structions, ensuring clarity, completeness, and executabil-                                                                                       Initial Prompt.\n          ity.\n                                                           # Task\n    example_curator Focuses on selecting representative, diverse\n                                                           Determine whether the Statement is a lie (Yes) or not (No)       examples and ensuring consistent formatting.\n                                                           based on the Context and other information.\n    format_designer Designs clear output templates and struc-\n                                                           # Output format       tured formats for better model understanding.\n                                                           Answer Yes or No as labels\n    style_optimizer Optimizes language expression for profes-\n                                                           # Prediction       sionalism and task-specific adaptation.\n                                                           Text: {text}\n                                                           label:\nE.2  Agent Roles for Mathematical Reasoning\n     Tasks                                                   Optimized Prompt.\nFor mathematical reasoning, the agent roles are adapted to focus     # Task\non logical decomposition, calculation, and problem interpretation.     Your task is to evaluate the given Statement in the context\n                                                           of the provided information. If the Statement is found to be\n    reasoning_specialist Specializes in enhancing mathemat-                                                           intentionally false or misleading, it should be classified\n         ical reasoning processes, ensuring clear step-by-step logic\n                                                           as a lie. In this case, your response should be 'Yes'.\n      and proper problem decomposition.\n                                                           If the Statement is true or unintentionally false due to a\n    calculation_optimizer Focuses on improving calculation                                                           mistake or lack of knowledge, it should not be classified\n        accuracy, suggesting better computational methods, and\n                                                           as a lie. In this case, your response should be 'No'.\n       ensuring numerical correctness.\n                                                           # Output format\n    problem_interpreter Specializes in interpreting math word                                                           Provide your answer as 'Yes' or 'No' labels. 'Yes' indicates\n       problems, extracting relevant information, and identifying\n                                                           that the statement is a lie, while 'No' indicates that the\n       mathematical relationships.\n                                                           statement is not a lie.\n    solution_formatter Optimizes mathematical solution pre-                                                           # Prediction\n        sentation, ensures clear formatting and proper answer no-\n                                                           Text: {text}\n        tation (e.g., #### [final_answer]).                                                           label:\n\nE.3  Agent Roles for Financial Report Analysis      F.2  Ethos Dataset\nFor the complex task of business and financial analysis, agents                                                                                       Initial Prompt.\nare given highly specialized roles focusing on data verification,\n                                                           # Taskstructured report generation, and professional tone.\n                                                           Is the following text hate speech?\n    instruction_specialist Crafts clear, executable instruc-     # Output format\n        tions for generating truthful, structured reports and reject-     Answer Yes or No as labels\n       ing false or exaggerated inputs. Instructions must include     # Prediction\n        steps to verify input data authenticity (e.g., checking finan-     Text: {text}\n         cial metrics for realism).                                 Label:\n\nOptimized Prompt.                                            3. Show your work step by step\n# Task                                                     4. Provide the final numerical answer\nYour task is to analyze the following text and determine if   # Output Format\nit contains hate speech. For the purpose of this task, hate   Show your reasoning process and end with: #### [final_answer]\nspeech is defined as any speech, gesture, conduct, writing,   # Problem\nor display that may incite violence or prejudicial actions    {text}\nagainst or by a protected individual or group, or because it                                                                Optimized Prompt.\ndisparages or intimidates a protected individual or group.\n                                                           # Task\nPlease base your judgment on the explicit content of the text,\n                                                           Solve the math word problem step by step.\nrather than personal interpretations or assumptions.\n                                                           # Instructions\n# Output format\n                                                           1. Read the problem carefully\nProvide your answer in a clear format as either\n                                                           2. Identify what needs to be calculated\n'Contains Hate Speech' or 'Does Not Contain Hate Speech'\n                                                           3. If there are ambiguous situations in the problem, make\n# Prediction\n                                                              reasonable assumptions and state them clearly\nText: {text}\n                                                           4. Show your work step by step\nLabel:\n                                                           5. Provide the final numerical answer\n                                                           # Output Format\nF.3  Jailbreak Dataset\n                                                           Show your reasoning process, including any assumptions made,\nInitial Prompt.                                               and end with: #### [final_answer]\n# Task                                                     # Problem\nDetect if the message is a jailbreak attack,               {text}\ni.e. an attempt by a user to break through an\nAI system's protections                                   F.5 AQUARAT Dataset\n# Output format                                                                                       Initial Prompt.\nAnswer Yes or No as labels\n                                                           # Task\n# Prediction\n                                                           Solve the math word problem and choose the correct answer\nText: {text}\n                                                           from the given options.\nLabel:\n\nOptimized Prompt.                                            # Instructions\n                                                           1. Read the problem carefully# Task\n                                                           2. Analyze each optionClassify the message as one of the following labels based on\n                                                           3. Show your reasoning step by stepits potential to be a jailbreak attack, i.e., an attempt to\n                                                           4. Select the correct answer (A, B, C, D, or E)bypass an AI system's protections:\n- \"OvertAttack\": The message contains clear, direct attempts\n                                                           # Output Format  to break through system safeguards.\n                                                           Show your reasoning and end with: Answer: [LETTER]- \"SuspiciousContext\": The message shows indirect or\n                                                           (For example: \"Answer: A\" or \"Answer: B\")  contextual cues that may indicate a multi-stage or\n  sophisticated attack attempt.\n                                                           # Problem- \"Benign\": The message poses no apparent risk and does not\n                                                           {text}  attempt to circumvent protections.\n\n                                                           # Options# Output format\n                                                           {options}Select and output exactly one label from the options above.\n\n                                                                Optimized Prompt.\n# Prediction\n                                                           # Task\nText: {text}\n                                                           Solve the provided problem by systematically classifying its\nLabel:\n                                                           type, analyzing all constraints, applying formal mathematical\n                                                           reasoning, and verifying the solution against all conditions\nF.4 GSM8K Dataset                                                           before selecting the correct answer.\nInitial Prompt.\n# Task                                                     # Instructions\nSolve the math word problem step by step.                  Adhere strictly to the following structured framework:\n# Instructions\n1. Read the problem carefully                              1. **Problem Classification:**\n2. Identify what needs to be calculated                      * Explicitly identify the core problem domain (e.g.,\n\n\"Combinatorial Selection,\" \"Constraint Satisfaction,\"    # Task\n     \"Partnership Profit-Sharing,\" \"Work Rate\").           Solve the math word problem step by step.\n   * Justify the classification with a brief rationale     # Instructions\n     based on the problem statement.                       1. Read the problem carefully\n                                                           2. Identify what needs to be calculated\n2. **Constraint Analysis:**                                3. Show your work step by step\n  * Enumerate all explicit constraints from the problem text. 4. Provide the final numerical answer\n   * Infer and list any implicit constraints or logical     # Output Format\n     dependencies.                                         Show your reasoning process and end with: #### [final_answer]\n  * Categorize each constraint (e.g., Hard/Must-Fulfill,     # Problem\n     Soft/Optimization) and specify their logical          {text}\n     relationships (e.g., AND, OR).\n                                                                Optimized Prompt.\n\n3. **Mathematical Formalization & Numerical Context\n                                                         F.7 SVAMP Dataset     Resolution:**\n  * Identify and resolve any ambiguous numerical references  Optimized Prompt.\n     (e.g., \"monthly\" vs. \"annual\", \"together\" vs.         # Task\n     \"individual\").                                        Solve the math word problem through structured, hierarchical\n  * Infer and incorporate any implicit numerical variables   reasoning. Your primary goal is to correctly parse and compute\n    (e.g., initial quantities, unstated rates, starting     multi-step problems involving distinct object categories and\n     points).                                              their quantitative relationships.\n  * Normalize all units to a consistent basis for calculation.\n  * Define all variables, sets, and parameters using clear    # Instructions\n     notation (e.g., C_total, P_A, S_eligible, nCr).       1. **Parse and Categorize:**\n  * Structure the problem using appropriate formalisms:       Read the problem and question carefully. Identify and list\n    timelines, sets, equations, or logical statements.       all distinct object types or categories (e.g., 'packages\n   * For combinatorial problems, explicitly state            of gum', 'boxes of candy'). For each category, extract:\n     the formula used.                                        - The number of units (e.g., 5 packages).\n                                                             - The quantity per unit, if specified (e.g., 8 pieces\n4. **Solution Execution:**                                      per package).\n   * Perform all calculations step-by-step, showing\n     substitutions and operations.                         2. **Structure the Solution Hierarchically:**\n   * For combinatorial scenarios, enumerate valid             - **Step 1: Calculate Intra-Category Totals.**\n     combinations or calculate cardinalities.                 For each identified category, calculate its total quantity.\n  * Derive the target value (e.g., profit share, number of        If a unit rate is given, perform the multiplication\n     committees, optimal value).                              (e.g., `5 packages * 8 pieces/package = 40 pieces of gum`).\n                                                              If no unit rate exists, use the given quantity directly.\n5. **Verification & Solution Finalization:**                  - **Step 2: Perform Inter-Category Operations.**\n   * Systematically verify that the proposed solution         Using the totals from Step 1, now perform the final operation\n     satisfies every constraint from Step 2.                  as required by the question (e.g., sum all category totals\n   * For combinatorial answers, confirm counts against         for a grand total, or find the difference between two\n     constraints using direct checks or complementary           category totals for a comparison).\n     counting.\n   * Match the final, verified result to the provided      3. **Show Your Work:**\n     options to select the correct answer.                   Present your reasoning clearly, reflecting this two-step\n                                                             hierarchical process. First, show all calculations within\n# Output Format                                              categories. Then, show the final combination of these\nYour final output must follow this structure precisely:        category totals.\n\n**Problem Classification:**                                4. **Final Answer:**\n[Your classification and rationale]                           Box your final numerical result.\n\n**Constraint                                               # Output Format\n                                                           Reasoning: [Your step-by-step reasoning here]\n                                                           #### [final_answer]\nF.6 SVAMP Dataset\nInitial Prompt.                                               # Problem\n\n{text}                                                     # Question\n                                                           {question}",
"headers": [
"arXiv:2509.11361v2  [cs.AI]  7 Oct 2025",
"Prompt Optimization",
"MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative",
"Yichen Han",
"Bojun Liu",
"Yuhang Han",
"Zhengpeng Zhou",
"Guanyu Liu",
"Zeng Zhang",
"Yang Yang",
"Wenli Wang",
"Isaac N Shi",
"Lewei He",
"Tianyu Shi",
"Yunyan Zhang",
"CCS CONCEPTS",
"ABSTRACT",
"KEYWORDS",
"1",
"INTRODUCTION",
"2",
"RELATED WORK",
"3",
"METHODOLOGY",
"3.1",
"Framework Overview",
"3.2",
"Specialized Prompt Agents",
"3.3",
"Hypersphere-Constrained Gradient",
"Clustering",
"3.4",
"Channel-Adaptive Agent Weighting",
"3.6",
"Theoretical Convergence (Informal)",
"4",
"EXPERIMENTS",
"4.1",
"Datasets",
"3.5",
"Candidate Generation and Selection",
"4.2",
"Experimental Setup",
"4.4",
"Experimental Results",
"4.3",
"Baselines",
"4.6",
"Token Consumption Analysis",
"4.5",
"Ablation Study",
"4.7",
"Agent Number Sensitivity",
"5",
"DISCUSSION",
"4.8",
"Experimental Insights",
"6",
"CONCLUSION",
"REFERENCES",
"A",
"CAAW PARAMETER SENSITIVITY",
"B",
"COMPLEXITY AND PARALLELISM",
"C",
"THEORETICAL ANALYSIS",
"C.3",
"Main Results",
"C.1",
"Assumptions",
"C.4",
"Summary of Theoretical Guarantees",
"C.2",
"Supporting Lemmas",
"D",
"CASE STUDY: SYSTEM PROMPT",
"OPTIMIZATION",
"E",
"AGENT SPECIALIZATION FOR DIFFERENT",
"TASKS",
"F",
"EXAMPLE PROMPTS BEFORE AND AFTER",
"E.1",
"Agent Roles for Classification Tasks",
"F.1",
"LIAR Dataset",
"E.2",
"Agent Roles for Mathematical Reasoning",
"Tasks",
"E.3",
"Agent Roles for Financial Report Analysis",
"F.2",
"Ethos Dataset",
"F.3",
"Jailbreak Dataset",
"F.5",
"AQUARAT Dataset",
"F.4",
"GSM8K Dataset",
"F.7",
"SVAMP Dataset",
"F.6",
"Method",
"GSM8k",
"AQUARAT",
"SVAMP",
"InsZero",
"74.2",
"54.3",
"79.5",
"Instinct",
"74.5",
"54.7",
"81.0",
"PromptWizard",
"90.0",
"58.2",
"82.3",
"MAPGD",
"93.5",
"60.3",
"84.1"
],
"tables": [
"|Jailbreak Ethos<br>0.98<br>0.85<br>0.97<br>0.80<br>0.96<br>0.75 F1 F1<br>0.95<br>0.70<br>0.94<br>0.65<br>0.93<br>Liar Sarcasm<br>0.700 P Mr CoTeGi<br>0.90 RL<br>0.675 AutoGPT<br>MAPGD<br>0.650 0.88<br>F1 F1<br>0.625 0.86<br>0.600<br>0.84<br>0.575<br>10 20 30 40 50 10 20 30 40 50<br>p0 p0|Col2|Col3|Col4|hos|Col6|Col7|\n|---|---|---|---|---|---|---|\n|0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>F1<br><br>0.93<br>0.94<br>0.95<br>0.96<br>0.97<br>0.98<br>F1<br><br>10<br>20<br>30<br>40<br>50<br>p0<br>0.575<br>0.600<br>0.625<br>0.650<br>0.675<br>0.700<br><br>Liar<br>10<br>20<br>30<br>40<br>50<br>p0<br>0.84<br>0.86<br>0.88<br>0.90<br>F1<br>Sarcasm<br>ProTeGi<br>MC<br>RL<br>AutoGPT<br>MAPGD|||||||\n|0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>F1<br><br>0.93<br>0.94<br>0.95<br>0.96<br>0.97<br>0.98<br>F1<br><br>10<br>20<br>30<br>40<br>50<br>p0<br>0.575<br>0.600<br>0.625<br>0.650<br>0.675<br>0.700<br><br>Liar<br>10<br>20<br>30<br>40<br>50<br>p0<br>0.84<br>0.86<br>0.88<br>0.90<br>F1<br>Sarcasm<br>ProTeGi<br>MC<br>RL<br>AutoGPT<br>MAPGD|||||||\n|0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>F1<br><br>0.93<br>0.94<br>0.95<br>0.96<br>0.97<br>0.98<br>F1<br><br>10<br>20<br>30<br>40<br>50<br>p0<br>0.575<br>0.600<br>0.625<br>0.650<br>0.675<br>0.700<br><br>Liar<br>10<br>20<br>30<br>40<br>50<br>p0<br>0.84<br>0.86<br>0.88<br>0.90<br>F1<br>Sarcasm<br>ProTeGi<br>MC<br>RL<br>AutoGPT<br>MAPGD|||||||\n|0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>F1<br><br>0.93<br>0.94<br>0.95<br>0.96<br>0.97<br>0.98<br>F1<br><br>10<br>20<br>30<br>40<br>50<br>p0<br>0.575<br>0.600<br>0.625<br>0.650<br>0.675<br>0.700<br><br>Liar<br>10<br>20<br>30<br>40<br>50<br>p0<br>0.84<br>0.86<br>0.88<br>0.90<br>F1<br>Sarcasm<br>ProTeGi<br>MC<br>RL<br>AutoGPT<br>MAPGD|||||||\n|0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>F1<br><br>0.93<br>0.94<br>0.95<br>0.96<br>0.97<br>0.98<br>F1<br><br>10<br>20<br>30<br>40<br>50<br>p0<br>0.575<br>0.600<br>0.625<br>0.650<br>0.675<br>0.700<br><br>Liar<br>10<br>20<br>30<br>40<br>50<br>p0<br>0.84<br>0.86<br>0.88<br>0.90<br>F1<br>Sarcasm<br>ProTeGi<br>MC<br>RL<br>AutoGPT<br>MAPGD|||||||",
"|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||",
"|Col1|ProTeGi<br>MC<br>RL|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n||A<br>M|utoGP<br>APGD|T||||\n||||||||\n||||||||\n||||||||",
"|1.00<br>Agents num<br>0.95 2<br>4<br>6<br>0.90<br>0.85<br>0.80 F1<br>0.75<br>0.70<br>0.65<br>0.60<br>Jailbreak Ethos Liar Sarcasm|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6||||||||||Agents|num<br>2<br>4|num<br>2<br>4|num<br>2<br>4|num<br>2<br>4|num<br>2<br>4|num<br>2<br>4|\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6|||||||||||||||||\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6|||||||||6|6|6|6|6|6|6|6|\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6|||||||||||||||||\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6|||||||||||||||||\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6|||||||||||||||||\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6|||||||||||||||||\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6|||||||||||||||||\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6|||||||||||||||||\n|Jailbreak<br>Ethos<br>Liar<br>Sarcasm<br>0.60<br>0.65<br>0.70<br>0.75<br>0.80<br>0.85<br>0.90<br>0.95<br>1.00<br>F1<br>Agents num<br>2<br>4<br>6||Jail|brea|k||E|thos|||Li|ar||Sa|rcas|m|m|\n|**igure 6:**<br>**gents fro**<br>**ncreasin**<br>**.8**<br>**Ex**<br>ur experi<br>â€¢** Ef**<br>fou<br>sin<br>are<br>die<br>ag<br>can<br>opt|**igure 6:**<br>**gents fro**<br>**ncreasin**<br>**.8**<br>**Ex**<br>ur experi<br>â€¢** Ef**<br>fou<br>sin<br>are<br>die<br>ag<br>can<br>opt|**  Ag**<br>** m 2**<br>**g to**<br>**per**<br> men<br>** fecti**<br>r be<br>gle-<br> obs<br>nt s<br>ent s<br> eff<br>imi|**  ent**<br>**   to**<br>**  6 b**<br>**im**<br> tal<br>** ve**<br> nc<br>age<br> erv<br> ign<br> pe<br> ecti<br>zati|**   n**<br>**    4**<br>**   rin**<br>**en**<br>  ev<br>** ne**<br> hm<br>nt<br> ed<br> als<br> cia<br> vel<br>on|**   um**<br>**     yie**<br>**   gs**<br>**ta**<br>  alu<br>** ss o**<br> ark<br> Pro<br>  on<br>  are<br> liza<br> y re<br> tow|**   ber**<br>**     lds c**<br>**    dim**<br>**l In**<br>  ation<br>**  f m**<br>  task<br> TeGi<br>   LIA<br>   co<br> tion<br>  solv<br> ard|**    s**<br>**      le**<br>**    in**<br>** si**<br>   p<br>**   ul**<br>  s,<br>  an<br>   R a<br>   mm<br> , c<br>  e<br>  m|**    ens**<br>**      ar i**<br>**    ish**<br>** gh**<br>   rov<br>**   ti-a**<br>   MA<br>  d o<br>    nd<br>   on<br>  om<br>   grad<br>  ore|**    iti**<br>**       mp**<br>**    ing**<br>** ts**<br>   ides<br>**   gen**<br>   PG<br>   the<br>     Jail<br>   . Th<br>  bine<br>   ien<br>   rob|**    vity**<br>**       rove**<br>**     retu**<br>    seve<br>**   t col**<br>   D co<br>   r base<br>     break<br>    is de<br>  d wi<br>   t con<br>   ust i|**     anal**<br>**       men**<br>**     rns.**<br>    ral k<br>**    labo**<br>    nsist<br>    lines<br>     , wh<br>     mon<br>   th se<br>    flicts<br>    mpro|**     ysi**<br>**       ts,**<br>     ey i<br>**    rat**<br>    entl<br>    . Th<br>      ere<br>     stra<br>    ma<br>     an<br>    vem|**     s. I**<br>**        whi**<br>      nsig<br>**    ion**<br>    y o<br>     e la<br>       con<br>     tes<br>    ntic<br>     d gu<br>    ent|**      ncr**<br>**        le f**<br>      hts<br>**    .** Ac<br>     utp<br>      rge<br>       flict<br>      tha<br>     clu<br>      ide<br>    s.|**      ea**<br>**         ur**<br>      :<br> ro<br>     erf<br>      st<br>       ing<br>      t m<br>     ste<br>       pr|**      sin**<br>**         the**<br> ss a<br>     orm<br>       gain<br>        gr<br>       ult<br>     rin<br>       omp|",
"|ğœ†|LIAR Accuracy GSM8K Accuracy|\n|---|---|\n|0.5<br>1<br>2|0.709<br>0.927<br>0.717<br>0.935<br>0.711<br>0.933|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2509.11361v2.pdf"
}