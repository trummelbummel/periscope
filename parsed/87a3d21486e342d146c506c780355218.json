{
"text": "Local Prompt Optimization\n\n\n\n                                 Yash Jain     Vishal Chowdhary\n\n                                                Microsoft\n\n\n\n\n\n                          Abstract\n\n                                                                                                                  Prompt: Let's evaluate                                    Prompt: Let’s think step-by-step\n                                                                                                            whether the argument is          Prompt\n                  In recent years, the use of prompts to guide                 logically valid by checking                                                                                                                                                                                                       if the conclusion follows         Candidates\n                   the output of Large Language Models have in-            from the premises step by\n                  creased dramatically. However, even the best of               step.\n                   experts struggle to choose the correct words to2025                                                                Prompt                                                                                                            Evaluation                      stitch up a prompt for the desired task. To solve\n                                                                             Proposal         Traditional Global\n                       this, LLM driven prompt optimization emerged                                                     Optimization                       Best Prompt\n                   as an important problem. Existing prompt opti-Apr                                                                                                              Edit tokens: Let’s think                                                      Identify tokens for                 mization methods optimize a prompt globally,\n                where in all the prompt tokens have to be opti-29                                                                                                step-by-step                 Local                        optimization                mized over a large vocabulary while solving a                              Optimization\n               complex task. The large optimization space\n                  (tokens) leads to insufficient guidance for a\n                    better prompt. In this work, we introduce Lo-       Figure 1: Local Prompt Optimization integrated in a\n                    cal Prompt Optimization (LPO) that integrates        general automatic prompt engineering framework.\n                  with any general automatic prompt engineering[cs.CL]                method. We identify the optimization tokens\n                                                                 are used to modify prompts in a process called                    in a prompt and nudge the LLM to focus only\n                on those tokens in its optimization step. We ob-      Prompt Optimization (Zhou et al., 2023a).\n                  serve remarkable performance improvements        Prompt optimization techniques follow a two-\n               on Math Reasoning (GSM8k and MultiArith)        step process as shown in Fig. 1. First, the prompt is\n                and BIG-bench Hard benchmarks across var-                                                                   validated against a training set where the incorrect\n                  ious automatic prompt engineering methods.\n                                                                  predictions are identified. Optionally, a feedback\n                   Further, we show that LPO converges to the\n                                                                  step is added where a natural language feedback,                  optimal prompt faster than global methods.\n                                                         termed ‘textual gradients’, is obtained by query-\n                                                              ing the LLM (Ye et al., 2024; Tang et al., 2024).          1  Introduction\n                                                                      Finally, the prompt is optimized using the textual\n            Large Language Models (LLMs) are everywhere.   gradients (incorrect examples or natural language\n         LLMs are automating all the tasks that required spe-   feedback) to obtain an optimized prompt. The cy-arXiv:2504.20355v1        cialized models a few years ago (Dubey et al., 2024;    cle is repeated for a fixed number of steps.\n           OpenAI, 2023). The easiest and cheapest way to      Traditional prompt  optimization  techniques\n              control an LLM’s output is to do prompt engineer-   (Pryzant et al., 2023; Zhou et al., 2023b; Ye et al.,\n             ing (Zhou et al., 2023a; Zhao et al., 2021; Yang   2024; Tang et al., 2024) optimize prompts globally\n                et al., 2023; Lu et al., 2022). Unfortunately, writing      ,i.e., mutate all tokens in the prompt. However, op-\n            a prompt is extremely tricky (Pryzant et al., 2022).   timizing all the tokens in a prompt while searching\n           Although the prompts are in English, the choice   over the vocabulary to solve a complex problem,\n             of words that effectively have the same meaning   makes the prompt optimization very challenging.\n           makes a huge difference in the prompt’s perfor-    Further, for many production applications, it is de-\n          mance on a task (Kojima et al., 2022; Wei et al.,    sirable to optimize only subsections of the prompt\n            2022; Amatriain, 2024). Furthermore, an LLM is   while keeping the other parts static. Doing so re-\n              inherently biased towards its own vocabulary, mak-   quires us to limit the scope of the ‘prompt proposal’\n             ing the task even more challenging. Thus, LLMs   on subsection of the prompt, hence, the need of Lo-\n\ncal Prompt Optimization (LPO). Thus, we reduce   prompt along with additional information which\nthe optimization space (tokens) for the LLM to sim-   vary between automatic prompt engineering tech-\nplify the problem and control the edit direction of    niques. These include incorrect examples (Zhou\na prompt.                                                  et al., 2023b), or a natural language LLM feedback\n   In this work, we evaluate the efficacy and pitfalls    of the incorrect examples (Pryzant et al., 2023) to\nof doing local prompt optimization compared to    a combination of both along with previous prompts\nglobal prompt optimization. We incorporate local    p(t−1) and their scores (Ye et al., 2024).\noptimization in three automatic prompt optimiza-\n                                                                  p(t+1) = Mproposal(pt, gt).         (2)tion algorithms and evaluate on GSM8k (Cobbe\net al., 2021), MultiArith (Roy and Roth, 2015), and\n                                            However, the edits in prompt p(t) can take place\nBIG-bench hard (Suzgun et al., 2023) benchmarks.\n                                             anywhere inside the prompt including complete re-\nWe highlight that local optimization leads to faster\n                                                    writing the prompt at every timestep causing slow\nconvergence of optimal prompt while improving\n                                                  update towards the optimal prompt. Further, it does\nprompt performance. Finally, we test local opti-\n                                                  not provide any control required in a typical pro-\nmization on a real-world application by evaluating\n                                                 duction prompt engineering where a professional\nit on a production prompt.\n                                          would want prompt edits to take place within a\n2  Background and Method                     specific scope of the prompt. Thus, the global op-\n                                                    timization leads to slow prompt convergence and\nIn this section, we will describe a general frame-   provides no control over direction of prompt opti-\nwork of automatic prompt engineering (Zhou et al.,   mization.\n2023a) and highlight the gap in the framework.\n                                                       (3)  Search:   Finally,  among  the  candidateBuilding on this, we will introduce local prompt\n                                             prompts across all timesteps p0 ∪p1 ∪... ∪pt, aoptimization.\n                                                    subset of the best performing prompts are retained\n2.1  Automatic Prompt Engineering            and the process is repeated.\nGiven a dataset D = (x, y), a prompt engineering\n                                                    2.2  Local Prompt Optimization\nsystem aims to find a prompt p∗that maximizes the\n                                         The basic function of ‘textual gradients‘ gt is toscore on an evaluator function f. Specifically,\n                                                inform how the optimization process (gradient val-\n  p∗= arg max X  f(Mtask(x; p), y)   (1)    ues) should adjust according to model’s perfor-\n             p                  (x,y)∈D                      mance (Tang et al., 2024). However, it does not\n                                                     specify where the optimization should take place or\nwhere Mtask(x; p) is the output generated by   analogously in deep learning on which parameters\nthe task model Mtask when conditioning on the    should the gradient descent should take place. We\nprompt p.                                           incorporate this intuition of parameter selection to\n A general automatic prompt engineering system    reduce the optimization space through local prompt\nhas three parts: Prompt Initialization, Prompt Pro-   optimization.\nposal, and Search Procedure.                        Following the intuition of Chain-of-Thought\n                                                     logic (Wei et al., 2022), we first identify the po-\n(1) Prompt Initialization:  An initial prompt is\n                                                              tential tokens in the prompts which are responsible\nprovided to an automatic prompt system that needs\n                                                         for incorrect predictions by adding an instruction in\nto be optimized. Prompt Initialization can be done\n                                                    the meta-prompt before the Prompt Proposal step\nby a manual human-written instruction or it can be\n                                                   as depicted in Fig. 1. We use <edit> tags to high-\nfew shot examples from the dataset D (Zhao et al.,\n                                                            light the edit tokens, the meta-instruction is shown\n2021).\n                                                       in Fig. 2. The goal is to identify tokens within the\n(2) Prompt Proposal:  In this step new prompt   prompt that the proposal LLM Mproposal should\ngeneration takes place. At any timestep t, a new    optimize.\nset of prompts p(t+1) are generated from a set of     Once the prompt edit tokens are identified, we\ncandidate prompts pt. A proposal LLM Mproposal   proceed with the Prompt Proposal step. The in-\nis used to propose new prompts, grounded on ‘tex-    struction ‘Reply with the new instruction\ntual gradients’ gt obtained on the current prompt   without the <edit>, </edit> tags.’ is pro-\npt. These ‘textual gradients’ consists of a meta   vided to Mproposal to output the updated prompt\n\np(t+1). Tab 1 shows the complete prompt evolution      Initial Prompt    Let’s think step by step.\nwith local and global optimization.                       Global Optimization\n\n                                                                               Ensure all given initial values and specific contexts\n                                                                                                             (e.g., rounding rules, phrase interpretation) are con-\nFirst, identify the scope of tokens within the    Optimum                                                                                             sidered, and explain the arithmetic operations logi-\nprompt where edits should take place.                                                                                                cally and clearly, step-by-step.\nPrompt   edits   include   adding,   deleting   or\nmodifying tokens.                                            Local Optimization\nMark the scope of the prompt that needs editing                        Let’s <edit> think </edit> <edit> step by step\nby putting <edit>, </edit> tags.                            Identifying edit  </edit>.\nYou can have multiple <edit> tags and each <edit>\n                                                                                             Let’s carefully read and clearly understand the prob-\ntag should not entail more than 5 words.\n                                                       Optimum        lem. Next, let’s think through each step and verify\nDo not cover the whole sentence with multiple\n                                                                                  each calculation carefully.\n<edit> tags.\nReply with the prompt with <edit>, </edit> tags.\nDo not include any other text.                      Table 1: MultiArith prompts found by comparing tra-\n                                                             ditional global optimization approach against our pro-\n                                                   posed local optimization.\nFigure 2: Illustration of the Prompt for identifying po-\ntential optimization tokens.\n                                                    3.2  Prompt Optimization methods\n\n3  Experiments                               For fair comparison, we select three representative\n                                            prompt optimization techniques and modify their\nThe goal of this section is to highlight the efficacy    global optimization step with our local optimiza-\nof local optimization over existing global optimiza-    tion step as explained in Sec. 2 and Fig. 1. (1) APE\ntion across different automatic prompt engineering   (Zhou et al., 2023b) leverages LLMs to come up\nmethods.                                        with variants of the input prompt, given few exam-\n                                                     ples and then select the best performing prompt.\n3.1  Datasets                          An improved variant of APE called Iterative APE,\n                                                      repeats this process a few times to get a better opti-\nFollowing PE2 (Ye et al., 2024) closely, we perform\n                                            mized prompt. We use Iterative APE for compari-evaluation on three set of tasks varying in their\n                                               son in the paper. (2) APO (Pryzant et al., 2023) is\nobjectives and domain. We use the same train-dev-\n                                                       builds over Iterative APE and adds an incorrect pre-\ntest split as provided by (Ye et al., 2024).\n                                                        diction feedback in its prompt optimization process.\n                                                 This feedback is often termed as ‘textual gradients’(1) BIG-bench Hard  or BBH (Suzgun et al.,\n                                              and is used to make edits in correct direction on the2023) is a set of 23 tasks (27 subtasks) which can\n                                                  candidate prompt. APO is named as ProTeGi inbe categorized as algorithmic, natural language\n                                                            their recent draft. (3) PE2 (Ye et al., 2024) furtherunderstanding, world knowledge, and multlingual\n                                                    innovates in the ‘textual gradients’ and make themreasoning tasks.\n                                                       rich by adding old prompt and their feedback his-\n                                                     tory to guide the edit process. They also limit the(2) Math Reasoning  consists of two datasets\n                                          number of edits in the prompt.MultiArith (Roy and Roth, 2015) and GSM8K\n(Cobbe et al., 2021). Both contains grade school\n                                                    3.3  Implementation Details\nmath problems requiring 2 to 8 steps of algebraic\nreasoning to reach the final answer.                Across  all  experiments, we  consistently  use\n                                           gpt-3.5-turbo as the task solving model and\n(3) Production Prompt   is an internal classifica-   gpt-4o as the prompt optimizer. The remaining\ntion prompt, developed to orchestrate the correct    design details follow those of PE2 (Ye et al., 2024).\ntool for further LLM calls. The prompt would take  We limit the search budget to 3 optimization steps,\nin a user query and would identify the ‘intent’ of    using a beam size of 4 and generating 4 prompts\nthe query. It would then output a function call with    at each step. Further, we initialize the prompts for\nappropriate arguments. It has been developed by in-  BBH and Math Reasoning datasets with the stan-\ndomain experts and is 8k tokens long. The prompt   dard prompt “Let’s think step by step” (Kojima\ncontains sections of skill definitions, specific clas-    et al., 2022; Wei et al., 2022). We keep the hyperpa-\nsification instruction, safety instructions and so on,   rameters for all the prompt optimization methods\nmaking it an ideal candidate for evaluation.        same across global and local optimization.\n\n64\n   5                                                                         Global Opt.                                                                                       Global Opt.         95                 Global Opt.\n                                                                                Local Opt.                                                                                        Local Opt.                              Local Opt.\n                                                            62                                                                                                   +2.1%\n   4                                                                                                   +6.0%  Timestep                                                         60                                                                 90\n   3                                                                                                                                                                                                                                                                                            Accuracy                                                                                                                                                                                                                     Accuracy                                                            58                        +3.2% Prompt 2                                                                                                                                                                                                                                                                                                                                (Average) 56                                                                                                                                                                                                                                     (Average)\n   1                                                                 +1.7%                                                85 Optimal                                                         54\n   0                                                            52\n         APE          APO           PE2                   APE         APO          PE2               80       Production Prompt\n\n(a) Optimal Prompt Timestep in the 27 subtasks  (b) Average Accuracy on BBH. Local Opt. con- (c) Production Prompt\nof BBH benchmark. Local Opt. achieves faster  sistently outperforms global opt. across various  performance  after em-\nconvergence.                                  methods.                                       ploying local opt.\n\nFigure 3: Experiments on BBH and Production Prompt, showcasing LPO benefits in both performance and efficiency.\n\n\n Method  LPO  GSM8k (↑)   MultiArith (↑)  # steps (↓)    BIG-bench Hard benchmark. The number of iter-\n                 -        77.7          93.2           2.5        ations were kept to 3 and we assign a timestep of\n APE\n      ✓       78.0           96.2          4       4 when the initialization prompt is found to be the\n                 -        77.7          96.0          4         best performing prompt. Fig. 3a depicts the violin\n APO\n      ✓       79.7          97.5          2        curves of optimal prompt timestep. Notably, we\n                 -        78.7          97.0           2.5       observe majority of tasks reaching earlier conver-\n PE2      ✓       80.6          97.5          2                                               gence than global optimization approaches, saving\n                                                a lot of LLM compute and time. Global optimiza-\nTable 2: Results of Local Prompt Optimization (LPO)\n                                                      tion often leads to rewriting the complete prompt\non Math Reasoning benchmark.\n                                            from scratch for the LLM, making the task more\n                                                  challenging and complex. On the other hand, we\n4  Results and Analysis                          believe reducing the optimization space through lo-\n                                                         cal optimization keeps the gradient updates aligned\nLocal Prompt Optimization improves existing   towards the minima.\nautomatic prompting techniques.  We evaluate\n                                            Local Prompt Optimization can allow control\nAPE, APO and PE2 algorithms with and without\n                                             over prompt editing.  Perhaps, the biggest ben-\nLocal Optimization on GSM8K and MultiArith\n                                                                  efit of LPO is to control the scope of editing. In\ndatasets as depicted in Tab. 2. We observe that\n                                                    the production prompt written by domain expert,\nLocal Prompt Optimization is able to improve\n                                                    the prompt has specific sections where the differ-\nprompts for Math Reasoning tasks by an average\n                                                    ent tools are defined followed by instructions on\nof 1.5% while decreasing the number of optimiza-\n                                                     individual tools and their use. Using LPO, we can\ntion steps required. Additionally, we demonstrate\n                                                     specify which tool’s instruction needs to be updated\nthe wide applicability of Local optimization on\n                                                  without affecting the other tools. Further, it ensures\nBIG-bench Hard benchmark (27 subtasks).  In\n                                                        that there is no regression in performance of the\nFig. 3b, we show that local optimization supports\n                                              prompt in other classes due to the optimization pro-\nvarious automatic prompting techniques over a\n                                                       cess. In our evaluation, we gained a significant\nlarge variety of tasks. We outperform traditional\n                                          jump of 6% on the production prompt as shown in\nglobal optimization approach by an average of\n                                                       Fig. 3c.\n2.3% across methods. We hypothesize that since\nLocal Optimization reduces the optimization to-                                       5  Conclusion\nkens for the proposal LLM Mproposal and intro-\nduces a Chain-of-Thought approach in the opti-   In this work, we identify the gap in the optimiza-\nmization step, Mproposal is able to more efficiently    tion step of the existing automatic prompt engi-\nsolve the task and provide better prompt outputs.     neering techniques. Traditionally, prompts are mu-\n                                                      tated globally in each step. However, this global\nLocal Prompt Optimization results in faster con-   optimization increases the task complexity as the\nvergence. We estimate the timestep where the    optimizer (LLM) has to work on a larger num-\noptimal prompt is produced over the 27 subtasks in    ber of parameters (tokens) to find the optimal up-\n\ndate. Furthermore, many production prompts re-      Akhil Mathur, Alan Schelten, Amy Yang, Angela\nquire optimizing only a section of the prompt and       Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang,\n                                                     Archi Mitra, Archie Sravankumar, Artem Korenev,not rewriting the complete prompt from scratch.\n                                                       Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien\nAs a fix, we introduce Local Prompt Optimization      Rodriguez, Austen Gregerson, Ava Spataru, Bap-\n(LPO) where we identify the optimization tokens        tiste Roziere, Bethany Biron, Binh Tang, Bobbie\nand nudge the optimizer to focus only on those to-      Chern, Charlotte Caucheteux, Chaya Nayak, Chloe\n                                                              Bi, Chris Marra, Chris McConnell, Christian Keller,kens. We observe consistent performance improve-\n                                                       Christophe Touret, Chunyang Wu, Corinne Wong,\nments over Math Reasoning and BIG-bench Hard                                                                Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Al-\nbenchmark. Notably, we observe that local opti-       lonsius, Daniel Song, Danielle Pintz, Danny Livshits,\nmization searches the optimal prompt significantly      David Esiobu, Dhruv Choudhary, Dhruv Mahajan,\n                                                    Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes,quicker than the traditional approach. Further, LPO\n                                                  Egor Lakomkin, Ehab AlBadawy, Elina Lobanova,\ncan be integrated well with long prompts, which are                                                  Emily Dinan, Eric Michael Smith, Filip Radenovic,\nmore common in practical settings, further show-      Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Geor-\ncasing the ubiquity of our method. Looking ahead,      gia Lewis Anderson, Graeme Nail, Gregoire Mi-\nwe are optimistic about prompt optimization tech-       alon, Guan Pang, Guillem Cucurell, Hailey Nguyen,\n                                               Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan\nniques built from the perspective of local optimiza-                                                           Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan\ntion to benefit from the gains in performance and      Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan\nefficiency.                                                   Geffert, Jana Vranes, Jason Park, Jay Mahadeokar,\n                                                              Jeet Shah, Jelmer van der Linde, Jennifer Billock,\n6  Limitations                                    Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi,\n                                                        Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu,\nWe believe our study has three limitations which      Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph\n                                                     Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia,we believe can be overcome in future works. (1)\n                                                  Kalyan Vasuden Alwala, Kartikeya Upasani, Kate\nMultilinguality: We primarily focused on English                                                        Plawiak, Ke Li, Kenneth Heafield, Kevin Stone,\nlanguage as the base in this work, from prompts to      Khalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuen-\ndatasets to LLMs. However, we believe the ideas       ley Chiu, Kunal Bhalla, Lauren Rantala-Yeary, Lau-\nintroduced in the paper are extendable to other lan-      rens van der Maaten, Lawrence Chen, Liang Tan, Liz\n                                                            Jenkins, Louis Martin, Lovish Madaan, Lubo Malo,\nguages as well and implore the community to build                                                  Lukas Blecher, Lukas Landzaat, Luke de Oliveira,\nover our work. (2) Local Optimization sometimes      Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh,\nleads to overfitting the prompt with dev score reach-     Manohar Paluri, Marcin Kardas, Mathew Oldham,\ning close to 99%. We believe that a better search      Mathieu Rita, Maya Pavlova, Melanie Kambadur,\n                                              Mike Lewis, Min Si, Mitesh Kumar Singh, Mona\nstrategy can solve this problem and hope to see fu-\n                                                        Hassan, Naman Goyal, Narjes Torabi, Nikolay Bash-\nture works addressing it. (3) Closed-source models:       lykov, Nikolay Bogoychev, Niladri Chatterji, Olivier\nWe have used GPT-4o as the optimizer to bench-      Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan\nmark large datasets in this work.  This poses a      Zhang, Pengwei Li, Petar Vasic, Peter Weng, Pra-\n                                                             jjwal Bhargava, Pratik Dubal, Praveen Krishnan,challenge to the reproducibility of this work. How-\n                                                         Punit Singh Koura, Puxin Xu, Qing He, Qingxiao\never, we believe that showcasing local optimization                                                 Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon\ncapabilities on proprietary models is a good signal       Calderer, Ricardo Silveira Cabral, Robert Stojnic,\nfor both academic and industry to incorporate the      Roberta Raileanu, Rohit Girdhar, Rohit Patel, Ro-\n                                                 main Sauvestre, Ronnie Polidoro, Roshan Sumbaly,ideas in their prompt engineering methods.\n                                                    Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar\n                                                          Hosseini, Sahana Chennabasappa, Sanjay Singh,\n                                                  Sean Bell, Seohyun Sonia Kim, Sergey Edunov,\nReferences                                          Shaoliang Nie, Sharan Narang, Sharath Raparthy,\n                                                 Sheng Shen, Shengye Wan, Shruti Bhosale, ShunXavier Amatriain. 2024. Prompt design and engineer-\n                                                      Zhang, Simon Vandenhende, Soumya Batra, Spencer   ing:  Introduction and advanced methods.  arXiv\n                                                 Whitman, Sten Sootla, Stephane Collot, Suchin Gu-   preprint arXiv:2401.14423.\n                                                          rurangan, Sydney Borodinsky, Tamar Herman, Tara\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,      Fowler, Tarek Sheasha, Thomas Georgiou, Thomas\n  Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias      Scialom, Tobias Speckbacher, Todor Mihaylov, Tong\n   Plappert, Jerry Tworek, Jacob Hilton, Reiichiro      Xiao, Ujjwal Karn, Vedanuj Goswami, Vibhor\n  Nakano, et al. 2021. Training verifiers to solve math      Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent\n  word problems. arXiv preprint arXiv:2110.14168.       Gonguet, Virginie Do, Vish Vogeti, Vladan Petro-\n                                                                   vic, Weiwei Chu, Wenhan Xiong, Wenyin Fu, Whit-\nAbhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,      ney Meers, Xavier Martinet, Xiaodong Wang, Xiao-\n  Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,      qing Ellen Tan, Xinfeng Xie, Xuchao Jia, Xuewei\n\nWang, Yaelle Goldschlag, Yashesh Gaur, Yasmine     Ning Dong, Ning Zhang, Norman Cheng, Oleg\nBabaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue      Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem\nLi, Yuning Mao, Zacharie Delpierre Coudert, Zheng       Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pa-\nYan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh,     van Balaji, Pedro Rittner, Philip Bontrager, Pierre\nAaron Grattafiori, Abha Jain, Adam Kelsey, Adam      Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratan-\nShajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva      chandani, Pritish Yuvraj, Qian Liang, Rachad Alao,\nGoldstand, Ajay Menon, Ajay Sharma, Alex Boesen-      Rachel Rodriguez, Rafi Ayub, Raghotham Murthy,\nberg, Alex Vaughan, Alexei Baevski, Allie Feinstein,     Raghu Nayani, Rahul Mitra, Raymond Li, Rebekkah\nAmanda Kallet, Amit Sangani, Anam Yunus, An-     Hogan, Robin Battey, Rocky Wang, Rohan Mah-\ndrei Lupu, Andres Alvarado, Andrew Caples, An-       eswari, Russ Howes, Ruty Rinott, Sai Jayesh Bondu,\ndrew Gu, Andrew Ho, Andrew Poulton, Andrew     Samyak Datta, Sara Chugh, Sara Hunt, Sargun\nRyan, Ankit Ramchandani, Annie Franco, Apara-       Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Verma,\njita Saraf, Arkabandhu Chowdhury, Ashley Gabriel,       Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lind-\nAshwin Bharambe, Assaf Eisenman, Azadeh Yaz-       say, Shaun Lindsay, Sheng Feng, Shenghao Lin,\ndan, Beau James, Ben Maurer, Benjamin Leonhardi,      Shengxin Cindy Zha, Shiva Shankar, Shuqiang\nBernie Huang, Beth Loyd, Beto De Paola, Bhargavi      Zhang, Shuqiang Zhang, Sinong Wang, Sneha Agar-\nParanjape, Bing Liu, Bo Wu, Boyu Ni, Braden Han-      wal, Soji Sajuyigbe, Soumith Chintala, Stephanie\ncock, Bram Wasti, Brandon Spence, Brani Stojkovic,     Max, Stephen Chen, Steve Kehoe, Steve Satterfield,\nBrian Gamido, Britt Montalvo, Carl Parker, Carly      Sudarshan Govindaprasad, Sumit Gupta, Sungmin\nBurton, Catalina Mejia, Changhan Wang, Changkyu      Cho, Sunny Virk, Suraj Subramanian, Sy Choudhury,\nKim, Chao Zhou, Chester Hu, Ching-Hsiang Chu,     Sydney Goldman, Tal Remez, Tamar Glaser, Tamara\nChris Cai, Chris Tindal, Christoph Feichtenhofer, Da-      Best, Thilo Kohler, Thomas Robinson, Tianhe Li,\nmon Civin, Dana Beaty, Daniel Kreymer, Daniel Li,      Tianjun Zhang, Tim Matthews, Timothy Chou, Tzook\nDanny Wyatt, David Adkins, David Xu, Davide Tes-      Shaked, Varun Vontimitta, Victoria Ajayi, Victoria\ntuggine, Delia David, Devi Parikh, Diana Liskovich,      Montanez, Vijai Mohan, Vinay Satish Kumar, Vishal\nDidem Foss, Dingkang Wang, Duc Le, Dustin Hol-      Mangla, Vítor Albiero, Vlad Ionescu, Vlad Poenaru,\nland, Edward Dowling, Eissa Jamil, Elaine Mont-     Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li,\ngomery, Eleonora Presani, Emily Hahn, Emily Wood,     Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will\nErik Brinkman, Esteban Arcaute, Evan Dunbar, Evan      Constable, Xiaocheng Tang, Xiaofang Wang, Xiao-\nSmothers, Fei Sun, Felix Kreuk, Feng Tian, Firat        jian Wu, Xiaolan Wang, Xide Xia, Xilun Wu, Xinbo\nOzgenel, Francesco Caggioni, Francisco Guzmán,     Gao, Yanjun Chen, Ye Hu, Ye Jia, Ye Qi, Yenda Li,\nFrank Kanayet, Frank Seide, Gabriela Medina Flo-      Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam,\nrez, Gabriella Schwarz, Gada Badeer, Georgia Swee,      Yu, Wang, Yuchen Hao, Yundi Qian, Yuzi He, Zach\nGil Halpern, Govind Thattai, Grant Herman, Grigory       Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen,\nSizov, Guangyi, Zhang, Guna Lakshminarayanan,     Zhenyu Yang, and Zhiwei Zhao. 2024. The llama 3\nHamid Shojanazeri, Han Zou, Hannah Wang, Han-      herd of models. Preprint, arXiv:2407.21783.\nwen Zha, Haroun Habeeb, Harrison Rudolph, He-\nlen Suk, Henry Aspegren, Hunter Goldman, Ibrahim    Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\nDamlaj, Igor Molybog, Igor Tufanov, Irina-Elena       taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nVeliche, Itai Gat, Jake Weissman, James Geboski,      guage models are zero-shot reasoners. In Advances\nJames Kohli, Japhet Asher, Jean-Baptiste Gaya,       in Neural Information Processing Systems.\nJeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen,\n                                            Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong,\n                                                and Pontus Stenetorp. 2022. Fantastically orderedJian Jin, Jingyi Yang, Joe Cummings, Jon Carvill,\n                                                  prompts and where to find them: Overcoming few-Jon Shepard, Jonathan McPhie, Jonathan Torres,\n                                                        shot prompt order sensitivity. In Proceedings of theJosh Ginsburg, Junjie Wang, Kai Wu, Kam Hou\n                                                     60th Annual Meeting of the Association for Compu-U, Karan Saxena, Karthik Prasad, Kartikay Khan-\n                                                             tational Linguistics (Volume 1: Long Papers), pagesdelwal, Katayoun Zand, Kathy Matosich, Kaushik\n                                                   8086–8098, Dublin, Ireland. Association for Compu-Veeraraghavan, Kelly Michelena, Keqian Li, Kun\n                                                               tational Linguistics.Huang, Kunal Chawla, Kushal Lakhotia, Kyle Huang,\nLailin Chen, Lakshya Garg, Lavender A, Leandro                                             OpenAI. 2023.   Gpt-4 technical  report.   ArXiv,\nSilva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng                                                      abs/2303.08774.\nYu, Liron Moshkovich, Luca Wehrstedt, Madian\nKhabsa, Manav Avalani, Manish Bhatt, Maria Tsim-   Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chen-\npoukelli, Martynas Mankus, Matan Hasson, Matthew      guang Zhu, and Michael Zeng. 2023.  Automatic\nLennie, Matthias Reso, Maxim Groshev, Maxim      prompt optimization with\" gradient descent\" and\nNaumov, Maya Lathi, Meghan Keneally, Michael L.     beam search. arXiv preprint arXiv:2305.03495.\nSeltzer, Michal Valko, Michelle Restrepo, Mihir\nPatel, Mik Vyatskov, Mikayel Samvelyan, Mike    Reid Pryzant, Ziyi Yang, Yichong Xu, Chenguang Zhu,\nClark, Mike Macey, Mike Wang, Miquel Jubert Her-     and Michael Zeng. 2022. Automatic rule induction\nmoso, Mo Metanat, Mohammad Rastegari, Mun-       for efficient semi-supervised learning. In Findings\nish Bansal, Nandhini Santhanam, Natascha Parks,       of the Association for Computational Linguistics:\nNatasha White, Navyata Bawa, Nayan Singhal, Nick    EMNLP 2022, pages 28–44, Abu Dhabi, United Arab\nEgebo, Nicolas Usunier, Nikolay Pavlovich Laptev,      Emirates. Association for Computational Linguistics.\n\nSubhro Roy and Dan Roth. 2015. Solving general arith-\n  metic word problems. In Proceedings of the 2015\n  Conference on Empirical Methods in Natural Lan-\n  guage Processing, pages 1743–1752, Lisbon, Portu-\n   gal. Association for Computational Linguistics.\n\nMirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\n   bastian Gehrmann, Yi Tay, Hyung Won Chung,\n  Aakanksha Chowdhery, Quoc Le, Ed Chi, Denny\n  Zhou, and Jason Wei. 2023. Challenging BIG-bench\n   tasks and whether chain-of-thought can solve them.\n   In Findings of the Association for Computational Lin-\n   guistics: ACL 2023, pages 13003–13051, Toronto,\n  Canada. Association for Computational Linguistics.\n\nXinyu Tang, Xiaolei Wang, Wayne Xin Zhao, Siyuan\n  Lu, Yaliang Li, and Ji-Rong Wen. 2024. Unleashing\n   the potential of large language models as prompt op-\n   timizers: An analogical analysis with gradient-based\n  model optimizers. arXiv preprint arXiv:2402.17564.\n\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\n  Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,\n  and Denny Zhou. 2022. Chain-of-thought prompt-\n   ing elicits reasoning in large language models. In\n  Advances in Neural Information Processing Systems,\n  volume 35, pages 24824–24837. Curran Associates,\n   Inc.\n\nKexin Yang, Dayiheng Liu, Wenqiang Lei, Baosong\n  Yang, Xiangpeng Wei, Zhengyuan Liu, and Jun Xie.\n  2023. Fantastic expressions and where to find them:\n  Chinese simile generation with multiple constraints.\n   In Proceedings of the 61st Annual Meeting of the\n  Association for Computational Linguistics (Volume\n  1: Long Papers), pages 468–486, Toronto, Canada.\n  Association for Computational Linguistics.\n\nQinyuan Ye, Mohamed Ahmed, Reid Pryzant, and\n   Fereshte Khani. 2024. Prompt engineering a prompt\n   engineer. In Findings of the Association for Com-\n   putational Linguistics ACL 2024, pages 355–385,\n  Bangkok, Thailand and virtual meeting. Association\n   for Computational Linguistics.\n\nTony Zhao, Eric Wallace, Shi Feng, Dan Klein, and\n  Sameer Singh. 2021. Calibrate before use: Improv-\n   ing few-shot performance of language models. In\n   International Conference on Machine Learning.\n\nWangchunshu Zhou, Yuchen Eleanor Jiang, Ethan\n  Wilcox, Ryan Cotterell, and Mrinmaya Sachan.\n  2023a. Controlled text generation with natural lan-\n  guage instructions. In Proceedings of the 40th Inter-\n   national Conference on Machine Learning, volume\n  202 of Proceedings of Machine Learning Research,\n  pages 42602–42613. PMLR.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\n  Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\n  Ba. 2023b. Large language models are human-level\n  prompt engineers.  In The Eleventh International\n  Conference on Learning Representations.",
"headers": [
"arXiv:2504.20355v1  [cs.CL]  29 Apr 2025",
"Local Prompt Optimization"
],
"tables": [
"|Initial Prompt|Let’s think step by step.|\n|---|---|\n|Global Optimization|Global Optimization|\n|Optimum<br>Ensure all given initial values and specific contexts<br>(e.g., rounding rules, phrase interpretation) are con-<br>sidered, and explain the arithmetic operations logi-<br>cally and clearly, step-by-step.|Optimum<br>Ensure all given initial values and specific contexts<br>(e.g., rounding rules, phrase interpretation) are con-<br>sidered, and explain the arithmetic operations logi-<br>cally and clearly, step-by-step.|\n|Local Optimization|Local Optimization|\n|Identifying edit<br>Let’s <edit> think </edit> <edit> step by step<br></edit>.|Identifying edit<br>Let’s <edit> think </edit> <edit> step by step<br></edit>.|\n|Optimum|Let’s carefully read and clearly understand the prob-<br>lem. Next, let’s think through each step and verify<br>each calculation carefully.|",
"|Col1|Col2|\n|---|---|\n|APE<br>APO<br>PE2<br>0<br>1<br>2<br>3<br>4<br>5<br>Optimal Prompt Timestep<br>~~Global Opt.~~<br>Local Opt.|APE<br>APO<br>PE2<br>0<br>1<br>2<br>3<br>4<br>5<br>Optimal Prompt Timestep<br>~~Global Opt.~~<br>Local Opt.|",
"|Col1|64<br>Global Opt.<br>Local Opt.<br>62<br>+2.1%<br>60 Accuracy<br>58 +3.2% (Average)<br>56<br>+1.7%<br>54<br>52<br>APE APO PE2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|\n|---|---|---|---|---|---|---|---|---|---|---|\n||APE<br>APO<br>PE2<br>52<br>54<br>56<br>58<br>60<br>62<br>64<br>(Average) Accuracy<br>+1.7%<br>~~+3.2%~~<br>+2.1%<br>Global Opt.<br>Local Opt.|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~||\n||APE<br>APO<br>PE2<br>52<br>54<br>56<br>58<br>60<br>62<br>64<br>(Average) Accuracy<br>+1.7%<br>~~+3.2%~~<br>+2.1%<br>Global Opt.<br>Local Opt.|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|||||\n||APE<br>APO<br>PE2<br>52<br>54<br>56<br>58<br>60<br>62<br>64<br>(Average) Accuracy<br>+1.7%<br>~~+3.2%~~<br>+2.1%<br>Global Opt.<br>Local Opt.|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|A|PE||A|PO||PE2|PE2|\n||APE<br>APO<br>PE2<br>52<br>54<br>56<br>58<br>60<br>62<br>64<br>(Average) Accuracy<br>+1.7%<br>~~+3.2%~~<br>+2.1%<br>Global Opt.<br>Local Opt.|2<br>4<br>6<br>8<br>0<br>+1.7%<br>~~+3.2%~~|rage<br>y outp<br>s.<br>       , sho<br>)<br>       O)<br>**    g**<br> te<br>       ut<br>     h<br>   at<br>      e<br>       e<br>      a-<br>     te<br>      n<br>n|Accur<br> erfor<br>        wcas<br>BIG<br>atio<br>4 w<br>best<br>cur<br>obs<br>gen<br>a lo<br>tion<br>fro<br>cha<br>beli<br>cal<br>tow<br>**Loc**<br>**ove**<br>efit<br>the<br>the<br>ent<br>indi<br>spe<br>with<br>|ac<br> ms<br>        ing<br>-b<br>ns<br> he<br> p<br>ve<br>er<br>ce<br> t o<br> o<br>m<br>lle<br>ev<br> op<br>ar<br>**al**<br>**r**<br> of<br> pr<br> pr<br> to<br>vi<br>cif<br>o<br>|y on<br>  glob<br>         LPO<br>enc<br> wer<br> n th<br> erfo<br>s of<br>ve m<br> than<br>  f LL<br> ften<br> scrat<br>ngin<br>e red<br> timi<br>ds th<br>** Pro**<br>** pro**<br>  LP<br> odu<br> omp<br> ols a<br>dual<br>y wh<br>ut aff<br>|BBH.<br>  al opt<br>          ben<br>h Ha<br> e ke<br>  e init<br> rmin<br>  opti<br> ajori<br>  glo<br>   M c<br>  lead<br> ch f<br>g an<br> ucin<br> zatio<br> e mi<br>** mpt**<br>** mpt e**<br>  O is<br> ction<br> t has<br>  re d<br> tool<br> ich t<br> ectin<br>|Lo<br>   . a<br>          efit<br> rd<br>  pt<br>   ial<br> g p<br>  ma<br> ty<br>  bal<br>    om<br>  s t<br>  or<br> d<br> g t<br> n k<br>  ni<br>**  O**<br>**  di**<br>    to<br>  p<br>   s<br>   ef<br> s a<br>  oo<br> g<br>|cal Opt.<br>    cross va<br>          s in bot<br>  bench<br>   to 3 an<br>   ization<br>  rompt.<br>  l prom<br>  of task<br>   optimi<br>    pute a<br>   o rewri<br>   the LL<br>  comple<br>  he opti<br>  eeps th<br>  ma.<br>**  ptimi**<br>**  ting.**<br>     contro<br>  rompt<br>   pecific<br>   ined fol<br>  nd thei<br>  l’s instr<br>  the oth<br>|con-<br>     rious<br>            h perf<br>  mark<br>     d we<br>    pro<br>   Fig<br>   pt ti<br>   s re<br>   zati<br>     nd ti<br>    ting<br>    M,<br>  x. O<br>   miza<br>   e gra<br>**  zatio**<br>Per<br>     l the<br>   writt<br>    sect<br>    low<br>   r use<br>   uctio<br>   er to<br>|\n|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|Method<br>LPO<br>GSM8k (_↑_)<br>MultiArith (_↑_)<br># steps (_↓_|\n|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|APE<br>-<br>77.7<br>93.2<br>**2.5**<br>✓<br>**78.0**<br>**96.2**<br>4|\n|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|APO<br>-<br>77.7<br>96.0<br>4<br>✓<br>**79.7**<br>**97.5**<br>**2**|\n|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|PE2<br>-<br>78.7<br>97.0<br>2.5<br>✓<br>**80.6**<br>**97.5**<br>**2**|\n|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|Table 2: Results of Local Prompt Optimization (LP<br>on Math Reasoning benchmark.<br>**4**<br>**Results and Analysis**<br>**Local Prompt Optimization improves existin**<br>**automatic prompting techniques.**<br>We evalua<br>APE, APO and PE2 algorithms with and witho<br>Local Optimization on GSM8K and MultiArit<br>datasets as depicted in Tab. 2. We observe th<br>Local Prompt Optimization is able to improv<br>prompts for Math Reasoning tasks by an averag<br>of 1_._5% while decreasing the number of optimiz<br>tion steps required. Additionally, we demonstra<br>the wide applicability of Local optimization o<br>BIG-bench Hard benchmark (27 subtasks).<br>I|",
"|95 Global Opt.<br>Local Opt.<br>+6.0%<br>Accuracy<br>90<br>(Average)<br>85<br>80<br>Production Prompt|Col2|Col3|Col4|\n|---|---|---|---|\n|Production Prompt<br>80<br>85<br>90<br>95<br>(Average) Accuracy<br>+6.0%<br>~~Global Opt.~~<br>Local Opt.|+60%<br>~~Global Opt.~~<br>Local Opt.|+60%<br>~~Global Opt.~~<br>Local Opt.|+60%<br>~~Global Opt.~~<br>Local Opt.|\n|Production Prompt<br>80<br>85<br>90<br>95<br>(Average) Accuracy<br>+6.0%<br>~~Global Opt.~~<br>Local Opt.|.|.|.|\n|Production Prompt<br>80<br>85<br>90<br>95<br>(Average) Accuracy<br>+6.0%<br>~~Global Opt.~~<br>Local Opt.||||\n|Production Prompt<br>80<br>85<br>90<br>95<br>(Average) Accuracy<br>+6.0%<br>~~Global Opt.~~<br>Local Opt.|Production|Prompt|Prompt|\n|(c) P<br>perfo<br>ployi<br>             rman<br>   The<br>       assig<br>    pt is<br> 3a d<br>    este<br>    hin<br>    app<br>      e. G<br>     e c<br>     akin<br>    the<br>   on s<br>    ient<br>**   can**<br>ps,<br>       cop<br>   n by<br>    ns w<br>     by<br>     Usi<br>    nee<br>    s. F<br>      perf<br>      he o<br>     gain<br>    pro|roduction<br>rmance<br>ng local o<br>             ce and ef<br>    number<br>       n a tim<br>      found t<br> epicts th<br>    p. Nota<br>    g earlier<br>    roaches<br>       lobal o<br>      omplete<br>     g the tas<br>     other h<br>    pace thr<br>     updates<br>**    allow**<br> the bigg<br>       e of edit<br>     domain<br>     here th<br>      instruct<br>     ng LPO,<br>    ds to be<br>     urther, it<br>      ormanc<br>       ptimizat<br>     ed a sig<br>    mpt as s|Prom<br> after em<br>  pt.<br>               ficienc<br>     of ite<br>         estep o<br>       o be th<br>  e violi<br>     bly, w<br>      conve<br>    , savin<br>        ptimiz<br>       promp<br>       k mor<br>      and, w<br>     ough l<br>      aligne<br>**     contro**<br>  est be<br>         ing. I<br>      exper<br>      e diffe<br>      ions o<br>       we ca<br>       update<br>       ensure<br>      e of th<br>       ion pr<br>       nifican<br>      hown i|pt<br>  -<br>               y.<br>      r-<br>          f<br>         e<br>   n<br>      e<br>      r-<br>     g<br>        a-<br>       t<br>        e<br>       e<br>      o<br>      d<br>**     l**<br>   n-<br>          n<br>      t,<br>       r-<br>       n<br>        n<br>       d<br>       s<br>        e<br>        o<br>       t<br>       n|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2504.20355v1.pdf"
}