{
"text": "SEE: Strategic Exploration and Exploitation for Cohesive In-Context\n                            Prompt Optimization\n\n\n               Wendi Cui1*, Zhuohang Li3, Hao Sun 4, Damien Lopez1, Kamalika Das1,2,\n                         Bradley Malin3,5, Sricharan Kumar1,2, Jiaxin Zhang1,2∗\n                   1Intuit   2Intuit AI Research   3Vanderbilt University    4 University of Cambridge\n                                        5Vanderbilt University Medical Center\n\n\n\n                          Abstract                                                   Task description                       Better instruction only\n                                                                                                                                                                   Is the following text hate          Does the provided text contain hate\n                                                                                                                speech? Output Format            speech? Return a Boolean value of\n                 Designing optimal prompts for Large Language                    True or False                      True or False\n                Models (LLMs) is a complicated and resource-                                                                                                                                                                 Better Instruction and Examples\n                   intensive task, often requiring substantial hu-                   Cohesive In-Context            Your task is to evaluate whether the\n                                                                                               Prompt Optimization           provided input includes any2025         man expertise and effort. Existing approaches\n                                                                                                                                                                    offensive language...\n                   typically separate the optimization of prompt                                                       For instance, the phrase “You are a                                                                                             Explore      Exploit\n                    instructions and in-context learning examples,                                                            fool” is offensive due to itsJul                                                                                                                                            derogatory tone, so you should\n                  leading to in-cohesive prompts that is defined                SEE                    return ’True’.\n                and represented by suboptimal task perfor-                                               The phrase “This is a damn tasty12                                                                                                                                                           pizza” includes profanity but is not\n                mance. To overcome these challenges, we pro-                 Exploit     Explore            offensive, so you should return\n                 pose a novel Cohesive In-Context Prompt Op-                                                                      ’False’.\n                   timization framework that refines both prompt        Figure 1: An illustrative example of the cohesive\n                    instructions and examples. However, formulat-        in-context prompt optimization.\n                  ing such an optimization in the discrete and\n                                                               quickly adapting LLMs for downstream tasks due                 high-dimensional space of natural language[cs.CL]                                                                       to its compatibility with black-box APIs (e.g., GPT-                 poses significant challenges in both conver-\n                 gence and computational efficiency. To address      4 (OpenAI, 2023) and PaLM (Chowdhery et al.,\n                   these issues, we introduce, SEE, a scalable and       2022)), and its cost-effectiveness compared to the\n                     efficient prompt optimization framework that       conventional fine-tuning paradigm. Although good\n                 adopts metaheuristic optimization principles      prompt design can substantially improve LLM’s\n                and strategically balances exploration and ex-                                                           performance (Zhu et al., 2023), manually optimiz-\n                     ploitation to enhance optimization performance\n                                                                 ing prompts is a long process that often requires sig-\n                and achieve efficient convergence. SEE features\n                                                                        nificant human effort and expert knowledge. Thus                 a quad-phased design that alternates between\n                  global traversal (exploration) and local opti-       automatic prompt optimization is critical to leverag-\n                  mization (exploitation) and adaptively chooses       ing the power of LLMs and reducing human effort.\n           LLM operators during the optimization process.                                                          However, automatic prompt optimization is a\n           We have conducted a comprehensive evalua-\n                                                                      non-trivial task that involves discrete variables\n                   tion across 35 benchmark tasks, and SEE sig-\n                                                         and complex high-dimensional spaces (Zhou et al.,arXiv:2402.11347v2             nificantly outperforms state-of-the-art baseline\n                                                               2023). To avoid optimizing discrete long prompts,                methods by a large margin, achieving an aver-\n                 age performance gain of 13.94 while reducing        existing research treats the optimization of instruc-\n                  computational costs by 58.67%.                     tion and examples as separate tasks: one line of\n                                                                research (Pryzant et al., 2023; Chen et al., 2023;\n                                                     Yang et al., 2023a; Guo et al., 2023) takes the zero-          1  Introduction\n                                                                shot prompting approach (Kojima et al., 2022) to\n            Large Language Models (LLMs) have exhibited    focus on optimizing a short instruction that com-\n             extraordinary performance across various domains    prises one or few sentences; while the other line\n            and tasks (Bubeck et al., 2023; Yang et al., 2023b).   of work (Liu et al., 2021; Lu et al., 2021, 2022;\n           Prompt engineering seeks to craft effective prompts   Zhang et al., 2022b; An et al., 2023) emphasizes\n              that unleash the complete capabilities of LLMs.   more the importance of few-shot examples (Brown\n                  It is becoming an increasingly popular option for    et al., 2020) and seeks to selecting the best set of\n                                                         examples from a pre-defined dataset given a fixed                  *For correspondence regardng this paper please reach out\n                 to yduwcui@gmail.com, or jxzhangai@gmail.com.            instruction. Although such treatment effectively\n\n\n                                                    1\n\nreduces the optimization complexity, it overlooks   formance while accelerating convergence speed.\nthe cohesiveness of the full prompt and the inter-   Additionally, we integrate two innovative designs\nplay between instruction and examples, resulting    to enhance the performance and efficiency of SEE.\nin sub-optimal performance (Hsieh et al., 2023).      Firstly, we introduce a task-aware similarity met-\n  In this work, we formulate the problem to be a    ric using performance-based vectors and hamming\ncohesive optimization of instruction and examples    distance, proving more effective than traditional\nwhere we simultaneously optimizes the prompt    lexical similarity metrics. Secondly, we implement\ninstruction and examples as a whole.  Coher-   adaptive phase stop criteria that ensure maximum\nence is defined as the degree to which the prompt   performance improvement while optimizing the\ncomponents (instruction and examples) work effec-    overall efficiency.\ntively together to achieve strong task results. As    We conduct an extensive evaluation on a to-\nillustrated in Figure 1, our goal is to not impose     tal number of 35 benchmark tasks and empiri-\nany restrictions or assumptions on the prompt style    cally show that SEE demonstrates substantial im-\n(zero-shot or few-shot), thereby unlocking the full   provements compared to 9 state-of-the-art (SOTA)\npotential of prompt traversal in contrast to previ-   methods,  including APE (Zhou  et  al., 2023),\nous instruction-only optimization methods (Zhou  APO  (Pryzant et al., 2023), OPRO (Yang et al.,\net al., 2023; Pryzant et al., 2023; Chen et al., 2023;   2023a), PromptBreeder (Fernando et al., 2023),\nGuo et al., 2023; Fernando et al., 2023). Such a   EvoPrompt (Guo et al., 2023), MoP (Wang et al.,\nformulation will derive highly adaptive and flexible    2024), EASE (Wu et al., 2024), ZOPO (Hu et al.,\nprompts, ranging from a simple zero-shot prompt    2024), and AELP (Hsieh et al., 2023), with the sig-\nto an elaborative few shot prompt with detailed    nificant computational cost reduction. For harder\nCOT examples, depending on the task at hand.       tasks like BBH, SEE introduces an average of 13.94\n  However, such a problem formulation results in    task accuracy improvement while reducing 58.67%\na complex combinatorial optimization problem that    of computational costs compared to SOTA methods.\nnaturally brings two challenges: (1) performance-   In summary, our key contributions are:\nwise, how to design an optimization framework\n                                                              • We propose SEE, a novel framework integratingthat navigates the high-dimensional joint space of\n                                                       metaheuristic optimization principles to simulta-instructions and examples, steering clear of local\n                                                   neously optimize instructions and examples as aminima to ensure continuous performance enhance-\n                                                            unity, allowing it to generate both zero-shot andment? (2) cost-wise, what strategies can be em-\n                                                    few-shot prompts. To the best of our knowledgeployed to improve the efficiency of the algorithm,\n                                             SEE is the first framework with such capability.enabling fast convergence with a reasonable level\nof computational complexity?                            • We introduce an innovative quad-phase design\n  To address such challenges, we propose a novel      that strategically balances exploration and ex-\nStrategic Exploration and Exploitation (SEE) frame-      ploitation. Together with an adaptive operator\nwork that aims at accelerating cohesive prompt op-      selection mechanism that uses the most suitable\ntimization in high-dimensional spaces while min-      operator at the right time, such innovation signif-\nimizing inference costs. Targeting at continuous      icantly enhances the efficiency compared to tra-\nperformance enhancement, SEE adopts the princi-      ditional metaheuristic optimization frameworks.\nples of metaheuristic optimization framework\n                                                              • We conduct extensive evaluations, demonstrat-\nwhich is an iterative refinement framework widely\n                                                    ing that SEE achieves substantial improvements\nused for complex high dimensional optimizations\n                                                   over state-of-the-art (SOTA) methods while sig-\n(Talbi, 2009). To reduce the cost, SEE introduces a\n                                                            nificantly reducing computational costs.\nquad-phased design that strategically alternates\nbetween exploration and exploitation, efficiently\n                                       2  Preliminariesnavigating high-dimensional space.\n  To apply SEE to prompt optimization task, we   Problem Formulation  Considering the task T\nidentify five LLM operators to generate new can-   specified by a dataset D = (Q, A) of input/out-\ndidates in each iteration.  By analyzing opera-   put pairs, the LLM L produces the corresponding\ntors’ unique strengths and features, SEE is able    output A via prompting with the concatenation of\nto adaptively choose the best operators during   prompt P and a given input Q, i.e., [P; Q]. The\nthe optimization process, achieving optimal per-   objective of prompt optimization is to design the\n\n\n                                         2\n\nbest natural language prompt P∗that maximizes              Phase 0: Initialization        Phase 1: Feedback Mutation\nthe performance of L on T .\n   Typically, an ideal prompt P consists of instruc-\ntion, denoted by I and examples denoted by E as\nin-context learning (ICL) demonstrations. Our goal\nof joint prompt optimization is to search for the op-\ntimal prompt P∗(I,E) given L that maximizes the                               Explore                          Exploit\nperformance towards a performance metric func-           Phase 3: Semantic Mutation    Phase 2: Fusion Mutation\ntion F (e.g., accuracy). This can be formally de-\nfined as the following optimization problem:\n\nP∗(I,E) = arg max E(Q,A) F(P(I,E); Q, A) | L  ,\n          P(I,E)∈X\n                                                 (1)\n  where X denotes the sample space for a natural                                   Exploit                        Explore\n                                                                                          Global Optima       Local Optima     In-Context Prompt\nlanguage prompt, a discrete and intractable space\nof arbitrarily large dimension, which makes the           Figure 2: Illustration of SEE framework.\noptimization problem in Eq. (1) extremely difficult.\n                                                  techniques are widely applied in fields such as en-\nMetaheuristic Optimization Framework  The    gineering design, scheduling, and machine learning\nmetaheuristic optimization framework provides a    (Talbi, 2009; Blum and Roli, 2003).\ngeneralized approach for solving complex opti-\nmization problems, particularly those involving   3  Proposed Method: Strategic\nhigh-dimensional or non-convex solution spaces      Exploration and Exploitation (SEE)\nwhere traditional methods may struggle (Talbi,\n                                                    3.1  Intuition2009). The framework typically follows an iter-\native process comprising the following key compo-   The intuition behind our proposed framework, SEE,\nnents:                                                      lies in addressing key limitations of traditional\n                                                   metaheuristic algorithms. Existing methods often\n• Initialization: An initial set of candidate so-                                                apply generation and variation in a repetitive and\n  lutions is generated, often randomly or using                                               uniform manner—such as genetic algorithms rely-\n  heuristic methods to ensure a diverse starting                                                    ing on mutation and crossover repeatedly—without\n  candidate pool.                                                 adapting to the specific needs of the optimization\n• Generation and Variation: New candidate so-   process. This introduces unnecessary randomness,\n  lutions are derived through Operators such as    increasing computational costs and slowing con-\n  mutation, crossover, probabilistic sampling, or    vergence. In contrast, our framework strategically\n  local search, facilitating effective exploration of    divides the optimization process into four distinct\n  the solution space.                               phases, each dedicated to either exploration or ex-\n                                                           ploitation, thereby accelerating the overall process.• Selection and Pruning: Candidates are evalu-\n                                             To maximize efficiency in each phase, we ensure  ated using an objective function, and suboptimal\n                                                           that only the most effective LLM operators tailored  solutions are discarded to refine the search to-\n                                                      to the requirements of each phase, are utilized to  ward optimal or near-optimal results.\n                                                    generate new candidates. By strategically applying\n  This iterative process continues until a termina-   the right operator at the right time, SEE achieves\ntion criterion, such as convergence to a solution or    both faster convergence and improved performance,\nreaching a computational limit, is met. Examples    delivering a cohesive combination of instructions\nof metaheuristic methods include Genetic Algo-   and examples for a variety of tasks.\nrithms (GA), which simulate the process of natural\n                                                    3.2  Generation Operatorsevolutio; Particle Swarm Optimization (PSO), in-\nspired by the social behavior of birds or fish to   SEE uses LLM operators to perform generation and\niteratively refine solutions; and Differential Evo-    variation.  Full prompts of the operators can be\nlution (DE), which optimizes by iteratively com-   found in the Appendix section D. For operators\nbining and mutating candidate solutions. These    designed for exploration, we call them global oper-\n\n\n                                         3\n\nOperator   Add  Remove   Parents   Prob   Speed  Cost\nators. For ones best at exploitation, we define them                                                             Lamarckian  ✓         -            -          -          -      •\nas local operators. SEE utilizes five operators that      Feedback   ✓    ✓           -      • •   • • ••   ••\nare used in prior research. More detailed operator     EDA          -          -     ✓    • • ••    ••     •\n                                                                  Crossover       -          -     ✓    • • ••    ••     •\ninformation can be found in Appendix section B.                                                               Semantic       -    ✓           -     • • •   • • •    •\nThe three global operators are:\n• Lamarckian Operator is a reverse-engineering      Table 1: Qualitative analysis of mutation operators\n  operator OL that accepts input-output pairs of\n                                                needs to optimize the current candidate to its  the task and attempts to “reverse-engineer” the\n                                                          local minimum solution.  task instruction which will generate the output\n  based on the input.                                      • Two or more parents? This indicates whether\n                                               an operator needs two or more input candi-\n• Estimation of Distribution Operator (EDA) is\n                                                        dates(parents) to generate a new candidate. Op-\n  a function operator OE that takes in a group of\n                                                         erators needing more than one parent have the\n  candidates and outputs a new candidate by study-\n                                                          potential to combine traits from diverse parents,\n  ing the input group. If the input group is ranked\n                                                 enhancing global exploration capability.\n  from the best performer to the worst performer,\n  we call it EDA + Index (EDA+I).                     • API cost per operation. It is the number of API\n                                                            calls needed to perform a specific operator via\n• Crossover Operator (CR) is a function operator\n                                LLM agents.\n OC that takes two candidates as parents and gen-\n                                   We conducted a series of experiments (ran each  erates a new candidate mixing the traits of both\n                                                   operator 100 times based on 4 different initializa-  parents. If the parents are chosen by prioritizing\n                                                        tion settings) to assess the performance of each op-  differences between them, we call it Crossover +\n                                                        erator regarding the five features, aiming at obtain-  Distinct (CR + D).\n                                                   ing a comprehensive understanding of the inherent\n  The two local operators are:                                                       strengths and weaknesses of each operator. This al-\n• Feedback Operator is a function operator OF    lows us to select effective operators to find optimal\n  that utilizes two LLM agents. OF first passes    solutions in an accelerated manner. As shown in\n  mistakes an existing candidate makes to an “Ex-   Table 1, we observe that the Lamarckian operator is\n  aminer” agent, whose task is to examine these   a crucial operator that introduces diverse samples,\n  mistakes and provide remediation strategies. It   making it an ideal choice for exploration and global\n  then uses an “Improver” agent that takes the re-    initialization. The feedback operator leads to faster\n  mediation strategies and applies them to the ex-   convergence (four •), making it good for rapid ex-\n   isting candidate to generate a new candidate.       ploitation, but it requires two API/inference calls\n                                              (two •), higher than the other operators (one •).\n• Semantic Operator is a function operator OS\n                                 EDA and Crossover operators share similar charac-\n  that takes in an existing candidate, and modi-\n                                                             teristics that combine traits from multiple parents\n   fies the candidate lexically while preserving its\n                                            and lead to a higher probability of improvement\n  semantic meaning.\n                                                     (four •), indicating their excellence in exploring\n  To better harness these operators, we compare                                                    the global space. For a more in-depth discussion\nthem along the following five dimensions that are                                            on operators, please refer to Appendix C.1 and C.2.\ncritical to our exploration-exploitation strategy in\nterms of performance and efficiency:                3.3  SEE Framework\n\n• Add or remove examples.  This examines   The SEE framework approaches the complex opti-\n  whether an operator can add or remove few-shot    mization problem strategically through four distinct\n  examples, to traverse the entire space of a cohe-   phases. Beyond the operators mentioned above, it\n  sive prompt optimization problem.                 requests up to three data sets. Dtrain is used for the\n                                                                       first phase of initialization, specifically used by the\n• Probability of improvement. This evaluates the\n                                             Lamarckian Operator. Ddev acts as a development\n  probability (successful rate) of an operator that\n                                                     data set to compute the performance score for each\n  brings performance improvement after iterations.\n                                                  candidate during the optimization process.  Dtest\n• Convergence speed. This metric aims to evalu-    is used for the final performance evaluation of the\n  ate how fast (in terms of iterations) an operator   optimized prompt.\n\n\n                                         4\n\nAlgorithm 1 SEE Framework\n 1: requirements: size of pool n, a dev set Ddev, score function F on the base LLM L, phase improvement t and performance\n    gain threshold t∗and minimum run time tolerance for phases Ki, designed operators OL, OF , OE, OC and OS\n      initialization: generate diverse initial prompts P0 = {p01, ..., p0n} by Ol or Os, evaluate initial scores S0 ←{s0i =\n 2:                                                                                                                                                   ›\n    F(p0i , Ddev)}                                                                           //Phase 0\n     while t < t∗or k ≤K1 do\n 3:4:   Local Feedback Operation:  generate new prompts by Feedback Operator, Pt ←Of(P0), evaluate St ←\n    F(P0, Ddev), update P1 ←{Pt, P0}, and score set S1 ←{St, S0}                              //Phase 1\n\n     while t < t∗or k ≤K2 do\n 5:6:   Global Fusion Operation: select prompts from the current pool {pr1, ..., prk} ∈P1, generate a new prompt via EDA\n      or Crossover Operators, evaluate st ←F(pt, Ddev), and update P2 ←{P1, pt} and S2 ←{S1, st}     //Phase 2\n\n     while t < t∗or k ≤K3 do\n 7:8:   Local Semantic Operation:  generate new prompts by Semantic Operator P∗t ←Os(P2), evaluate S∗t ←\n    F(P2, Ddev), and update P3 ←{P∗t , P2}, and S3 ←{S∗t , S2}                                  //Phase 3\n 9: return p∗←arg maxp∈P3 F(p, Ddev)\n\n3.3.1  Phase 0: Global Initialization             guidance and an LLM Improver to apply these to\n                                                   generate new candidates.Following the principle of metaheuristic optimiza-\ntion, phase 0 aims to create diverse candidates as    3.3.3  Phase 2: Global Fusion Operation\nthe initial candidate pool to explore the vast joint   Phase 1 provides a more refined set of candidates,\nspace of instruction and example. We provide two   while some of them might be stuck in local op-\ntypes of initialization based on the availability of    tima. To address this issue, we prioritize explo-\ndata: initializing from input/output pair of the task,    ration rather than exploitation in Phase 2. By per-\ndenoted SEE-io-pair, and initializing from human-   forming fusion between different candidates lever-\ncomposed example prompts, denoted SEE-example.   aging EDA (EDA-I) Operators OE and CR (CR-D)\n                                                  Operators OC which request multiple parents, SEE• SEE-io-pair: Given a set of input/output pairs\n                                                              facilitates the increased fusion of traits among can-  S = {(Q1, A1), ..., (Qm, Am)} from Dtrain, rep-\n                                                    didates on a larger global scale, thus enabling es-  resenting the input and output for the task T , SEE\n                                                cape from these local optima. Rather than employ-  apply Lamarckian Operator OL to reverse engi-\n                                                   ing cosine similarity as distance metrics, we adopt  neer potential prompts from provided demon-\n                                        hamming distance (see more discussions in Sec-   strating pairs.\n                                                        tion 3.4) for calculating similarity on performance-\n• SEE-example:  SEE takes expert constructed   based vectors so that more diversity is promoted\n  prompts and apply Semantic Operator OS to en-   during optimization.\n  hance the diversity of the initial candidate pool.\n                                                      3.3.4  Phase 3: Local Semantic Operation\n  This allows humans to jump-start the optimiza-\n                                      Upon completing Phase 2’s exploration, Phase 3\n  tion process by incorporating prior knowledge.\n                                             employs local exploitation to hasten the “last mile”\n                                                   of convergence. As the concluding phase of SEE,3.3.2  Phase 1: Local Feedback Operation\n                                                     the performance score of the candidate pool is rel-\nPhase 1 to Phase 3 adheres to the metaheuristic opti-\n                                                       atively optimized. The Semantic Operator OS ismization principles where each phase first conducts\n                                                      selected to expedite a more cost-effective exploita-\ngeneration and variation through designated opera-\n                                                            tion. Finally, we identify the best candidate as our\ntors, then performs selection and pruning greedily\n                                                      ultimate optimal prompt and assess its performance\nbased on the candidates’ performance score on the\n                                          on the testing dataset Dtest. The workflow of SEEdevelopment set Ddev.\n                                             framework is shown in Algorithm 1.\n  While an initial phase (Phase 0) may result in a\n                                                    3.4  SEE Novel Design Schemesdiverse candidate pool, each candidate could still\nbe distant from the best version of itself, its lo-  We also propose two novel design schemes to im-\ncal minimum. To address this, SEE exploits each   prove performance and efficiency.\ncandidate by employing the Feedback Operator    1. Performance vector with Hamming distance.\nOF to expedite its convergence towards their local   Fusion operators like EDA and Crossover function\nminimums. This involves the introduction of an    optimally when parents exhibit distinct attributes\nLLM Examiner to generate bespoke improvement   (Fernando et al., 2023).  In terms of evaluating\n\n\n                                         5\n\nCausal      Dis          Dyck       Formal                  Logical   Color        Salient\n Method                                                                      Hyperbaton\n                            Judgement   -ambiguation   Languages   Fallacies                 Five      Reasoning   Translation\n\n OPRO (Yang et al., 2023a)      71.94        71.53          36.73        49.51      75.92        50.00     65.55       43.88\n EvoPrompt (Guo et al., 2023)   67.24        53.70          47.96        50.81      74.79        61.40     60.90       47.58\n AELP (Hsieh et al., 2023)      77.77        64.79          10.67        58.25      53.74        73.49     68.14       41.43\n\n SEE-io-pair                   72.13        72.37          8.06         58.87      86.02        48.19     60.52       49.19\n SEE-example                  89.09        68.47          46.77        58.65      87.50        86.29     80.64       47.59\n\n           Table 2: Testing performance of the optimal prompt on 8 representative tasks from BBH.\n                   Salient Translation                0.7          Causal Judgement                0.9            Hyperbaton     0.65\n     0.60\n                                                         0.6                                                                                                                                         value 0.8  value 0.55                                                         value\n\n                                                         0.5                                                                                                                                         Score 0.7  Score 0.50                                                         Score     0.45                    High        Avg       Low                    High        Avg       Low       0.6           High        Avg       Low\n     0.40                                                0.4\n          LamaFeedCR+DCREDA+IEDACREDACR+DEDA+ICRCRCRSema        LamaFeedCRCR+DEDAEDA+ICR+DCR+DEDA+ICREDA+IEDA+IEDA+IEDA+ISema        LamaFeedCREDAEDA+IEDA+IEDA+ICR+DEDA+ICR+DEDASemaSemaSemaSema\n                    Iteration (operator)                            Iteration (operator)                            Iteration (operator)\n\nFigure 3: Iteration history of score values with different operators during optimization. The score is defined as the\naccuracy for the given task on the development set Ddev.\n\nsimilarity scores, we adhere to the principle that      global operators, e.g., Fusion Operators, might\nsimilarity should be gauged based on the perfor-     not bring immediate improvement but are capa-\nmance of the prompts rather than their linguistic      ble of accessing more diverse parents with traits\nor semantic similarities. Inspired by this intuition,     worth exploring. Therefore, we assign greater\nwe propose to construct candidate vectors based      tolerance to global operators, allowing them to\non their performance on the development set Ddev,     run for a predefined duration even if immediate\nnamed “performance vectors”. To exemplify, in     improvement is not observed. More details about\na development dataset comprising five elements,      the stop criteria can be found in Appendix C.2.\na candidate answering the  first three queries\ncorrectly and the  final two incorrectly would   4  Experiments\nfeature a vector representation of [1, 1, 1, 0, 0].\n                                We evaluate SEE on 35 tasks across 9 baselines.  Rather than calculating the cosine similarity of\n                                                Unless specified, all SEE results are from GPT-3.5-embedding space, we propose to compute candi-\n                                                      turbo. For additional information regarding thedate similarity scores by Hamming distance, which\n                                                experiment setup, please refer to Appendix E.calculates the distance between two vectors of\nequal length by examining the number of positions\n                                            35 Tasks and Datasets  We curate 35 benchmark\nat which the corresponding symbols are different.\n                                                       tasks from three domains for thorough experiments:\nThis way ensures that one candidate is more likely\n                                           8 Big Bench Hard (BBH) (Suzgun et al., 2022); 3\nto be paired with a candidate that does not repeat\n                                   NLP detection tasks, including Ethos (Mollas et al.,\nthe same mistakes.\n                                                   2021), Liar (Wang, 2017), and Sarcasm (Farha and\n2. Adaptive Phase Stop Criteria. To ensure that\n                                           Magdy, 2020); 24 instruction induction tasks (Hon-\neach optimization phase is fully conducted before\n                                                  ovich et al., 2022). The task and dataset details are\ntransitioning to the next, the decision to proceed to\n                                                        in Appendix E.1.\nthe following phase is influenced by two criteria.\n• Performance Gain. If no performance gain man-   9 Baselines  We evaluate SEE against a variety of\n   ifests after applying the operators in a particular   LLM-based approaches that have achieved state-of-\n  phase, it’s indicative that the candidates have    the-art performance in prompt optimization:\n  been thoroughly optimized by the operator. Con-                                                              • APE (Zhou et al., 2023), ZOPO (Hu et al., 2024)\n  sequently, we transition to the next phase.                                              and APO (Pryzant et al., 2023): APE utilizes a\n• Operator-specific Tolerance. Not all operators     Monte Carlo Search strategy that emphasizes ex-\n  are created equal. For local operators with high      ploration, while APO emphasizes exploitation,\n  convergence speed like the Feedback Operator,     which harnesses incorrect instances as feedback\n   it makes sense to transition to the next phase      gradient. ZOPO utilizes zeroth-order optimiza-\n  without performance improvements. However,      tion methods to find local optimal.\n\n\n                                         6\n\n• OPRO (Yang et al., 2023a): OPRO leverages     Model        Dis-         Formal     Hyperbaton   Salient\n                                                                                  ambiguation   Fallacies                   Translation\n LLM as optimizers to generate better instruction\n                                                                GPT-3.5       69.99(2.95)     58.49(0.33)   84.35(1.83)    48.39(0.66)  via meta-prompt, solution-score pairs, and task                                                           GPT-4         79.34(3.33)     75.91(0.53)   90.58(1.39)    70.45(0.99)\n  descriptions.                                    PaLM 2        71.49(0.37)     58.33(1.53)   79.45(0.98)    49.07(3.25)\n                                                                  Claude 2       72.95(2.26)     49.46(1.52)   83.32(1.01)    61.82(0.38)\n• PromptBreeder (Fernando et al., 2023), Evo-\n                                                                       Mistral-7B     65.89(0.76)     53.23(1.74)   78.76(1.36)    43.84(1.00)\n  Prompt (Guo et al., 2023) and AELP (Hsieh     Llama2-7B    42.74(4.61)     56.72(1.37)   53.23(2.37)    21.23(1.01)\n   et al., 2023): these methods connect LLMs with     Llama3-8B    62.63(3.85)     71.50(4.85)   57.52(4.28)    37.09(2.86)\n                                                             Llama3-70B   74.73(2.01)     70.93(2.25)   82.26(0.66)    62.90(1.97)\n  evolution algorithms for prompt optimization.\n• MoP (Wang et al., 2024), EASE (Wu et al.,    Table 3: SEE performance with different LLM models\n  2024): these methods can optimize instructions                     Dis-         Formal                   Salient\n                                                           Method                              Hyperbaton\n  and examples simultaneously.                                          ambiguation   Fallacies                 Translation\n                                               OPRO         71.53         49.51     75.92        43.88\n4.1  Main Results                                     OPRO-fs       66.93         52.41     62.90        37.39\n                                                             EvoPrompt     53.7          50.81     74.79        47.58\nBBH Tasks  Following the practice of AELP     EvoPrompt-fs  57.43         43.54     79.83        31.45\n(Hsieh et al., 2023), we conduct 8 BBH tasks to      SEE-io-pair     72.37         58.87     86.02        48.19\nevaluate the performance of SEE holistically. We     SEE-example   68.47         58.65     87.51        47.59\nconsider two initialization schemes SEE-io-pair and                                                       Table 4: Effect of few-shot (fs) examples on BBH tasks.\nSEE-example and report the final results in Table 2.\nSEE demonstrates substantial improvements com-  100% tasks over Evoprompt, OPRO, ZOPO, and\npared to state-of-the-art methods, introducing big   66.7% tasks over EASE. Table 21 in Appendix F.3\naverage performance increase over AELP (+15.31),   provides complete experimental results.\nEvoPromopt (+13.29), and OPRO (+13.21).\n   Fig. 3 depicts the iterative history of prompt    4.2  Analysis\noptimization, emphasizing the performance score    Applicability of SEE framework  To evaluate the\nvariations for the best, worst candidate, and aver-   general applicability of the SEE framework, we\nage candidate performance across iterations. Feed-   perform end-to-end optimizations on a diverse set\nback Operator yields a performance boost within    of models, covering both open-source and closed-\na single iteration and rarely introduces continual    source LLMs. Each model undergoes three end-to-\nimprovements. Fusion Operators such as EDA and   end runs, with the average performance and stan-\nCrossover aid in escaping local minima and offer-   dard deviation reported. As shown in Table 3, GPT-\ning additional performance leaps (refer to Hyper-   4 consistently achieves the highest performance\nbaton).  This observation aligns with our initial    across all tasks, followed by Llama3-70B. Claude\noperator analysis. The success of SEE lies in the   2 demonstrates comparable performance to GPT-\norganic organization of these operators, harnessing    3.5.  For open-source LLM models, Mistral-7B\ntheir advantages to maximize performance.         and Llama3-8B are comparable to each other, both\n                                                 outperforming Llama2-7B by a large margin.\nDetection Tasks  To present a more expansive\ncomparison, we adopted the configuration outlined    Necessity of Cohesive Prompt Optimization  To\nin APO (Pryzant et al., 2023) and conducted a com-    better understand whether cohesive prompt opti-\nparative analysis against it across three tasks. SEE   mization is necessary, we randomly add two few-\nexhibits marginally superior performance to APO    shot examples to OPRO and EvoPrompt. Our re-\nin relatively simple tasks such as Ethos (+1) and    sults in Table 4 indicate that OPRO exhibits a per-\nSarcasm (+4). However, for more complex tasks   formance gain on only 1 / 4 tasks while EvoPrompt\nsuch as Liar, SEE demonstrates a significant im-   shows improvement in 2 / 4 tasks. This suggests\nprovement (+18). Full experiment results are in    the necessity of cohesive prompt optimization as\nTable 20 in Appendix.                            performance degrades if optimized instructions do\n                                                   not align cohesively with naive few-shot selection.\nInstruction Induction Tasks  To compare SEE\nwith broader sets of baselines, we evaluate SEE on   Phase Optimization vs Random Optimization\nAPE’s 24 instruction induction tasks. The results   To evaluate the phased design of SEE, we com-\nshow that SEE outperforms in 87.5% tasks over    pare it against a random optimization strategy on\nAPE and MoP, 91.7% tasks over PromptBreeder,   4 BBH tasks shown in Table 5. Notably, SEE con-\n\n\n                                         7\n\nCausal Judgement           Disambiguation            Hyperbaton                   Salient Translation\n Method\n              Average score  High score  Average score  High score  Average score  High score  Average score  High score\n\n Random Evo   67.70(0.75)      70.28(0.56)   58.22(2.47)       61.3(3.17)    83.00(0.15)       87.8(0.00)    52.00(2.35)      56.80(1.60)\n SEE             69.88(2.17)       72.00(3.09)   60.32(2.73)       62.9(2.56)     83.52(0.71)       87.8(0.00)     53.06(0.80)      56.80(0.80)\n\n             Table 5: Comparison of our phase optimization with traditional random optimization.\n\n\n                    Causal Judgement           Disambiguation            Hyperbaton                   Salient Translation\n Method\n                   Average score  High score  Average score  High score  Average score  High score  Average score  High score\n\n Cosine distance      64.70(2.31)      67.86(2.47)   58.96(1.47)      63.30(0.00)   74.70(1.60)       85.7(0.00)    49.56(1.07)      58.80(0.00)\n Hamming distance   65.74(2.87)       69.60(2.97)   64.11(1.28)       66.94(2.88)   79.30(4.48)       86.78(2.15)   50.33(2.32)       58.80(0.00)\n\n                 Table 6: Performance comparison of hamming distance and cosine similarity.\n\nsistently outperforms random optimization in the    search efficiency and enhancing task performance.\naverage score across all tasks and achieves better                  80                                                                                                                                                                        Without Phase 1\nhighest score in two out of four tasks. This supe-                 75                                72.37                      WithoutWithout PhasePhase 23\nrior performance highlights the effectiveness of the                  70               66.94                               SEE\n                                                                                                                                                       Score 65       63.71           64.52well-structured phases with designated operators\nemployed in SEE .                                                                      60                                                                         58.87\n                                                                                                    55                                                        54.03   52.41                                                                                                                                                                                                                                                                                                                                           Performance                                                   50.80\nEffect of Different Phases  We conducted addi-                 50\ntional studies to highlight the value of different                  45\n                                                                                                    40\nphases by removing them from the optimization                         Disambiguation QA            Formal Fallacies\npipeline, as shown in Figure 4. We only experiment\n                                                        Figure 4: Performance comparison with phases removed\nwith Phase 1 - Phase 3 and did not remove Phase\n0 as it generates the initial population. Without                                                  Effect of Operators on Prompt Length  Our\nPhase 0 there would be no candidate to optimize.                                          method is designed to explore the full prompt\nWe observe no significant differences when differ-                                                    space, encompassing both zero-shot and few-shot\nent phases are removed. However, removing Phase                                                      configurations. Understanding how prompt length\n1 with the Feedback Operator will cause the great-                                             varies—and how different operators influence this\nest performance degradation. We hypothesize that                                                  variation—is critical for interpreting the optimiza-\nthe Feedback Operator allows candidates to arrive                                                         tion dynamics. Fig. 5 illustrates the average prompt\nat their local optimal efficiently. Thus, removing                                                 token length over the course of iterations. Interest-\nit will cause the next phase to start with less than                                                         ingly, the length may increase, decrease, or oscil-\nlocally optimized candidates, impacting the overall                                                                 late, which is consistent with the inherently flexible\nperformance most. Having all phases yield the best                                                   nature of the optimization process. This behavior\nresults. This further proves the effectiveness and                                                    supports our design rationale, demonstrating the op-\ncohesion of the different phases of SEE.                                                          erators’ capacity to both add and remove examples\n                                                     as needed. Such variability is not only expected but\nEffect  of Hamming  Distance We  investi-\n                                                       also essential for navigating the diverse and uncon-\ngate the effectiveness of Hamming distance on\n                                                       strained structure of the prompt space effectively.\nperformance-based vectors in comparison to the\ntraditional cosine distance applied to embedding    Effect of Initialization Strategy  The SEE can ac-\nvectors for similarity measurement. This analysis   commodate two types of inputs: input/output pair\nis conducted across four optimization iterations.   and prompt example, each bringing its own bene-\nTable 6 summarizes the results from four BBH     fits. When using the input/output pair approach,\ntasks. The findings show that performance vec-   the initialization is solely based on LLM’s gener-\ntors using Hamming distance consistently outper-    ations, resulting in greater diversity. On the other\nform embedding-based approaches using cosine    hand, initialization in prompt example draws upon\nsimilarity, achieving higher average and maximum   human-provided example prompts, consequently\nscores—particularly in tasks such as Disambigua-   lacking the diversity that input/output pair offers.\ntion (+5.2) and Hyperbaton (+4.6). These results   However, prompt example empowers users to intro-\nvalidate the effectiveness of performance-based rep-   duce prior knowledge without relying on LLM’s\nresentations with Hamming distance in improving    interpretation, which leads to better performance\n\n\n                                         8\n\nhead of the optimization process.   600\n                                        As illustrated in Fig. 6, SEE demonstrates thelength 400                    Antonym  3000                   Hyperbaton\n                                   2000                        highest cost-efficiency, achieving reductions intoken 200                             1000\nAvg                                              computational cost by several orders of magni-\n     0                                0\n          CRCR  CRCRCR                 CR       tude compared to other optimization strategies, in-\n       LamaFeedEDACR+D   CR+DEDA+I      Sema     LamaFeedFeedCR+DEDA+ICR+DCR+DEDAEDAEDA EDACR+DSema   cluding those based on metaheuristic approaches.\n   400                             1000                      For instance, PromptBreeder—an evolutionary al-length\n                                    750                      gorithm representing a traditional metaheuristic\ntoken 200                              500                                            method—requires approximately 2.5 orders ofAvg                   Trans EN-ES                          Orthography\n     0                              250                                              magnitude more API calls than SEE .\n       LamaFeedEDACR+DCRCRCR+DEDA+ICRCRCRSema     LamaFeedFeedFeedEDA+ICRCR+DCRCR+DCR+DEDA+ICR+DSema     Given that SEE , APO, and EvoPrompt exhibit\n                  Iteration (operator)                        Iteration (operator)\n                                                      the lowest number of API calls, we further compare\nFigure 5: Average prompt length through optimization.    these methods based on token consumption on the\n                                BBH task formal fallacies. Even under this stricter\nin more complex tasks such as Dyck Languages,    metric, SEE remains the most efficient, reinforc-\nand Logical Five as shown in Table 2.               ing the advantage of its quad-phased design and\n                                                    adaptive operator selection. This innovation signif-\nPrompt Quality  SEE generates few-shot prompts\n                                                       icantly enhances the computational efficiency of\nfor 20 / 24 Instruction Induction tasks and 4 / 8\n                                                     metaheuristic-inspired optimization frameworks.\nBBH tasks. For hard tasks, SEE even integrates with\n                                              Methods such as ZOPO, MoP, and EASE involve\ndifferent techniques, such as COT for task Logical\n                                                      additional computational components (e.g., model\nDeduction Five, or adding “Let’s think step by step”\n                                                       training or clustering), and are therefore excluded\nfor the task Reasoning Colored Objects. Beyond\n                                            from this analysis to maintain a fair comparison.\nprompt techniques, SEE also generates prompts that\nare easier for human understanding and more rele-                        API Calls        Token Consumption                                                                                                                                     1e6\n                                                                                       106                                                                 1.2vant to the tasks. These validates SEE’s applicabil-            scale)\nity in diverse cases and interpretability for human                                                                                1.0                                                                                              (log\nverifications. More details on prompt quality can be                                                                                0.8                                                                                                                      Calls 105found in Appendix F.4 where we compare prompts                                                                                                                                                                   0.6Consumption                                                                       API\ngenerated by different baselines.  All generated    of                                                                    0.4                                                                                                                                                                                                                       Tokenprompts are in Section H.                                                104                                                                 0.2                                                                                                                                              Number\nHyperparameters  SEE has some hyperparame-                                                                               0.0\n                                                                SEE  APO       APE  AELP  OPROters such as the threshold for phase transition, and                                                                                                               EvoPrompt                        PromptBreederpool size. To test the universal applicability of these\nsettings, we have utilized a threshold of 1% and a\n                                                      Figure 6: Comparison of computational cost measured\npool size of 15 for initialization, and 5 for the rest\n                                               by both total API calls and overall token consumption.\nof the phases in all 35 tasks. SEE achieves superior\nresults without specific parameter calibration. The\nexperiments conducted on 7 other models shown   5  Conclusion\nin Table 3 with the same configuration also provide\n                                We introduce a cohesive in-context prompt opti-competitive results. Given the superior results in\n                                                mization framework that leverages metaheuristicthe universal setting, we believe SEE requires little\n                                                  optimization principles to optimize both promptto no parameter tuning for practical application.\n                                                       instructions and examples.  Through a strategi-\nComputational Cost  We evaluate computational    cally designed exploration–exploitation schedule\ncost using two metrics: (1) the total number of API   and adaptive operator application, SEE achieves\ncalls to the LLM, and (2) the total token consump-  SOTA performance across a diverse set of bench-\ntion during the end-to-end optimization process.   mark tasks, while significantly reducing computa-\nThese metrics include both operator application    tional cost. Notably, SEE is the first framework to\nand candidate evaluation steps. We intentionally   dynamically generate both few-shot and zero-shot\nselect these metrics because they directly correlate   prompts, adapting flexibly to the specific require-\nwith the overall runtime and computational over-   ments of each task.\n\n\n                                         9\n\n6  Limitations                                 Lichang Chen, Jiuhai Chen, Tom Goldstein, Heng\n                                                  Huang, and Tianyi Zhou. 2023.  Instructzero: Ef-\nAlthough SEE is the most cost-effective method        ficient instruction optimization for black-box large\namong baselines, it still needs around 12 iterations      language models.\nand 4, 000 API calls, which might be insufficient                                               Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nfor supporting large-scale online applications. Fu-     Maarten Bosma, Gaurav Mishra, Adam Roberts,\nture work could explore better initialization strate-      Paul Barham, Hyung Won Chung, Charles Sutton,\ngies or data compression techniques to further im-      Sebastian Gehrmann, et al. 2022.  Palm: Scaling\n                                                      language modeling with pathways. arXiv preprint\nprove efficiency and reduce latency. Another im-\n                                                        arXiv:2204.02311.\nportant opportunity lies in extending the framework\nbeyond single-objective optimization. Developing    Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan\nmulti-objective optimization capabilities—such as     Wang, Han Guo, Tianmin Shu, Meng Song, Eric P\n                                                      Xing, and Zhiting Hu. 2022. Rlprompt: Optimizingsimultaneously improving accuracy, interpretabil-\n                                                              discrete text prompts with reinforcement learning.\nity, efficiency, or safety—could significantly en-      arXiv preprint arXiv:2205.12548.\nhance the framework’s flexibility and real-world\nutility, and is not what SEE currently focuses on.     Shizhe Diao, Zhichao Huang, Ruijia Xu, Xuechun Li,\n                                                Yong Lin, Xiao Zhou, and Tong Zhang. 2022. Black-\n                                                   box prompt learning for pre-trained language models.\nAcknowledgments                                                        arXiv preprint arXiv:2201.08531.\n\nThis work includes contributions from Vanderbilt                                                   Ibrahim Abu Farha and Walid Magdy. 2020. From\nUniversity researchers, supported by funding from       arabic sentiment analysis to sarcasm detection: The\nIntuit.                                                 arsarcasm dataset. n Proceedings of the 4th Work-\n                                                    shop on Open-Source Arabic Corpora and Process-\n                                                           ing Tools, with a Shared Task on Offensive Language\n                                                              Detection,, pages 32–39.\nReferences\n                                                      Chrisantha  Fernando,  Dylan  Banarse,  Henryk\nSrivastava Aarohi and BIG bench authors. 2023. Be-\n                                                      Michalewski, Simon Osindero, and Tim Rock-\n  yond the imitation game: Quantifying and extrapolat-\n                                                                taschel.  2023.     Promptbreeder:self-referential\n   ing the capabilities of language models. Transactions\n                                                        self-improvement via prompt evolution.\n  on Machine Learning Research.\n\n                                                Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao\nShengnan An, Bo Zhou, Zeqi Lin, Qiang Fu, Bei Chen,                                                     Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yu-\n  Nanning Zheng, Weizhu Chen, and Jian-Guang Lou.                                                                     jiu Yang. 2023. “connecting large language models\n  2023. Skill-based few-shot selection for in-context                                                         with evolutionary algorithms yields powerful prompt\n   learning. arXiv preprint arXiv:2305.14210.                                                             optimizers\".\n\nChristian Blum and Andrea Roli. 2003. Metaheuristics   Mark Hauschild and Martin Pelikan. 2011. An in-\n   in combinatorial optimization: Overview and concep-      troduction and survey of estimation of distribution\n   tual comparison. ACM Computing Surveys (CSUR),      algorithms. Swarm and evolutionary computation,\n   35(3):268–308.                                        1(3):111–128.\n\nTom Brown, Benjamin Mann, Nick Ryder, Melanie   Or Honovich, Uri Shaham, Samuel R Bowman, and\n   Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind     Omer Levy. 2022. Instruction induction: From few\n   Neelakantan, Pranav Shyam, Girish Sastry, Amanda      examples to natural language task descriptions.\n   Askell,  Sandhini Agarwal,  Ariel  Herbert-Voss,\n  Gretchen Krueger, Tom Henighan, Rewon Child,    Bairu Hou, Joe O’connor, Jacob Andreas, Shiyu Chang,\n  Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens      and Yang Zhang. 2023. Promptboosting: Black-box\n   Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-       text classification with ten forward passes. In Inter-\n   teusz Litwin, Scott Gray, Benjamin Chess, Jack       national Conference on Machine Learning, pages\n   Clark, Christopher Berner, Sam McCandlish, Alec      13309–13324. PMLR.\n   Radford, Ilya Sutskever, and Dario Amodei. 2020.\n  “language models are few-shot learners\".              Cho-Jui Hsieh, Si Si, Felix X. Yu, and Inderjit S. Dhillon.\n                                                       2023. “automatic engineering of long prompts\".\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\n   dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,   Wenyang Hu, Yao Shu, Zongmin Yu, Zhaoxuan\n   Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-     Wu, Xiangqiang Lin, Zhongxiang Dai, See-Kiong\n   berg, et al. 2023. Sparks of artificial general intelli-     Ng, and Bryan Kian Hsiang Low. 2024.  Local-\n   gence: Early experiments with gpt-4. arXiv preprint       ized zeroth-order prompt optimization.  Preprint,\n   arXiv:2303.12712.                                    arXiv:2403.02993.\n\n\n                                         10\n\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-   Tianxiang Sun, Zhengfu He, Hong Qian, Yunhua Zhou,\n   taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-      Xuan-Jing Huang, and Xipeng Qiu. 2022a. Bbtv2:\n  guage models are zero-shot reasoners. Advances in      towards a gradient-free future with large language\n  neural information processing systems, 35:22199–      models. In Proceedings of the 2022 Conference on\n  22213.                                               Empirical Methods in Natural Language Processing,\n                                                      pages 3916–3930.\nXiang Lisa Li and Percy Liang. 2021. Prefix-tuning:\n  Optimizing continuous prompts for generation. arXiv    Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing\n   preprint arXiv:2101.00190.                          Huang, and Xipeng Qiu. 2022b. Black-box tuning for\n                                                          language-model-as-a-service. In International Con-\n                                                          ference on Machine Learning, pages 20841–20855.F. Nelson Liu, Kevin Lin, John Hewitt, Ashwin Paran-\n   jape, Michele Bevilacqua, Fabio Petroni, and Percy     PMLR.\n  Liang. 2023.  Lost in the middle: How language                                                Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\n  models use long contexts.                                                            bastian Gehrmann, Yi Tay, Hyung Won Chung,\n                                                   Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,                                                   Zhou, et al. 2022. Challenging big-bench tasks and\n  Lawrence Carin, and Weizhu Chen. 2021. What                                                     whether chain-of-thought can solve them.  arXiv\n  makes good in-context examples for gpt-3? arXiv                                                             preprint arXiv:2210.09261.\n   preprint arXiv:2101.06804.\n                                                     El-Ghazali Talbi. 2009. Metaheuristics: From Design\nPan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu,       to Implementation. John Wiley & Sons, Hoboken,\n  Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark,      NJ.\n  and Ashwin Kalyan. 2022. Dynamic prompt learning\n   via policy gradient for semi-structured mathematical   Ruochen Wang, Sohyun An, Minhao Cheng, Tianyi\n   reasoning. arXiv preprint arXiv:2209.14610.            Zhou, Sung Ju Hwang, and Cho-Jui Hsieh. 2024.\n                                            One prompt is not enough: Automated construc-\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,       tion of a mixture-of-expert prompts.   Preprint,\n  and Pontus Stenetorp. 2021. Fantastically ordered      arXiv:2407.00256.\n  prompts and where to find them:  Overcoming\n                                                  William Yang Wang. 2017. “liar, liar pants on fire”: A  few-shot prompt order sensitivity.  arXiv preprint\n                                             new benchmark dataset for fake news detection.  arXiv:2104.08786.\n                                               Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai,\nIoannis Mollas, Zoe Chrysopoulou, Stamatis Karlos,                                                      Haotian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P\n  and Grigorios Tsoumakas. 2021. Ethos: An online                                                      Xing,  and  Zhiting Hu.  2023.    Promptagent:\n   hate speech detection dataset.                                                              Strategic planning with language models enables\n                                                              expert-level prompt optimization.  arXiv preprint\nOpenAI. 2023.   Gpt-4 technical  report.   ArXiv,                                                        arXiv:2310.16427.\n  abs/2303.08774.\n                                              Zhaoxuan Wu,  Xiaoqiang  Lin,  Zhongxiang  Dai,\nSilviu  Pitis,  Michael R  Zhang,  Andrew Wang,     Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet,\n  and Jimmy Ba. 2023.   Boosted prompt ensem-      and Bryan Kian Hsiang Low. 2024. Prompt optimiza-\n   bles for large language models.  arXiv preprint       tion with ease? efficient ordering-aware automated\n  arXiv:2304.05970.                                         selection of exemplars. Preprint, arXiv:2405.16122.\n\nArchiki Prasad, Peter Hase, Xiang Zhou, and Mohit    Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jojic.\n   Bansal. 2022. Grips: Gradient-free, edit-based in-      2023. Reprompting: Automated chain-of-thought\n   struction search for prompting large language models.     prompt inference through gibbs sampling.  arXiv\n  arXiv preprint arXiv:2203.07281.                         preprint arXiv:2305.09993.\n\n                                               Chengrun Yang, Xuezhi Wang, Yifeng Lu, HanxiaoReid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Zhu\n                                                           Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen.  Chenguang, and Michael Zeng. 2023. Automatic\n                                                      2023a. “challenging big-bench tasks and whether  prompt optimization with “gradient descent” and\n                                                           chain-of-thought can solve them\".\n  beam search.\n                                                      Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian\nTaylor Shin, Yasaman Razeghi, Robert L Logan IV,     Han, Qizhang Feng, Haoming Jiang, Bing Yin, and\n   Eric Wallace, and Sameer Singh. 2020. Autoprompt:     Xia Hu. 2023b.  Harnessing the power of llms in\n   Eliciting knowledge from language models with       practice: A survey on chatgpt and beyond. arXiv\n   automatically generated prompts.  arXiv preprint       preprint arXiv:2304.13712.\n  arXiv:2010.15980.\n                                               Ningyu Zhang, Luoqiu Li, Xiang Chen, Shumin Deng,\nHao Sun, Alihan Hüyük, and Mihaela van der Schaar.     Zhen Bi, Chuanqi Tan, Fei Huang, and Huajun\n  2023. Query-dependent prompt evaluation and opti-      Chen. 2021. Differentiable prompt makes pre-trained\n   mization with offline inverse rl. arXiv e-prints, pages      language models better few-shot learners.  arXiv\n  arXiv–2309.                                              preprint arXiv:2108.13161.\n\n\n                                         11\n\nTianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schu-\n  urmans, and Joseph E Gonzalez. 2022a.  Tem-\n   pera: Test-time prompting via reinforcement learning.\n  arXiv preprint arXiv:2211.11890.\n\nYiming Zhang, Shi Feng, and Chenhao Tan. 2022b. Ac-\n   tive example selection for in-context learning. arXiv\n   preprint arXiv:2211.04486.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\n  Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\n  Ba. 2023. Large language models are human-level\n  prompt engineers.\n\nKaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen\n  Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei\n  Ye, Neil Zhenqiang Gong, Yue Zhang, et al. 2023.\n  Promptbench: Towards evaluating the robustness of\n   large language models on adversarial prompts. arXiv\n   preprint arXiv:2306.04528.\n\n\n\n\n\n                                         12\n\nOrganization The Appendix is organized as follows:\n\n    • Appendix A. Related Work\n     Related work in automatic prompt optimization.\n\n    • Appendix B. Operator Definition\n   We formally define the operators used in our framework.\n\n    • Appendix C. Operator Analysis\n   We analyze various properties and behaviors of the operators.\n\n    • Appendix D. Operator Prompts\n   We discuss the prompt templates used for these operators.\n\n    • Appendix E. Details of Experiments\n   We provide comprehensive details of our experimental setups and protocols.\n\n    • Appendix F. Additional Experiment Results\n   We present extended results and further analysis beyond the main text.\n\n    • Appendix G. Few-shot Add/ Removal Examples\n   We illustrate representative showcasing operators’ ability to add/ removal examples.\n\n    • Appendix H. Generated Prompts\n   We show all the final prompts automatically generated by our system.\n\nA  Related Work\n\nIn-context prompting is an efficient approach for communicating LLMs but the performance is strongly\naffected by the design of the prompt in specifized tasks. Prompt optimization to find the optimal prompt\nhas thus obtained broader attention. One research direction is the continuous prompt approaches that tune\nembeddings of input tokens to generate better prompts (Li and Liang, 2021; Zhang et al., 2021; Sun et al.,\n2022b,a; Chen et al., 2023). However, the optimized “soft” prompts from this paradigm often fall short of\ninterpretability and are inaccessible for blackbox APIs. Discrete prompt approaches (Diao et al., 2022;\nPrasad et al., 2022), operating discrete tokens directly, offer an interactive interface to humans with better\ninterpretability and show promising performance. Various methods have been proposed via gradient-based\nsearch (Shin et al., 2020), reinforcement learning (Zhang et al., 2022a; Deng et al., 2022; Sun et al., 2023)\nand ensemble methods (Hou et al., 2023; Pitis et al., 2023) while these methods encounter concerns in\nterms of scalability, reliability and efficiency (Wang et al., 2023).\n  More recent advancements rely on iterative sampling, scoring, and selection of exceptionally promising\nprompts, generating diverse possibilities for prompt optimization. Fernando et al. (2023); Guo et al.\n(2023); Hsieh et al. (2023) proposed leveraging LLMs to implement optimization strategies in prompt\nsearches. Yang et al. (2023a) demonstrates the capability of LLM as optimizers in prompt design. Pryzant\net al. (2023); Zhou et al. (2023) utilizes natural language feedback to refine prompt instructions. However,\nthese prompt optimization/refinement strategies largely focus on prompt instructions, typically short\nsentences or paragraphs. While previous search and sampling algorithms have been investigated, such as\nMonte Carlo search (Zhou et al., 2023), Gibbs sampling (Xu et al., 2023), or Beam search (Pryzant et al.,\n2023), we introduce a novel dual exploration-exploitation strategy that leverages the in-depth traits of\neach operator, implementing the metaheuristic optimization framework with adaptive operator selection\nto enhance the interactive dynamics during optimization.\n\n\n\n\n\n                                         13\n\nB  Operator Definition\n\nOperators are used to generate new candidates. Seven types of operators, broadly categorized into five\nclasses are used by SEE. The idea is to provide a diverse set of operators so that a broad cognitive space of\nlinguistics is covered. Table 7 lists the operators that different kinds of methods use.\n\nB.1  Lamarckian Operator\n\nThe Lamarckian operator follows the principles proposed in APE and Prompt Breeder (Zhou et al.,\n2023; Fernando et al., 2023). Given a set of input-output pairs for the task, an LLM agent is used to\nreverse-engineer the prompt from the provided demonstrating pairs. This type of operator allows a diverse\nset of prompt candidates to be generated with no prior knowledge of the task. Any prompt candidate will\nhave to be induced from the demonstrating pairs. The prompt used by the LLM agent is in Table 12.\nDefinition   1.  (Lamarckian  Operator)  Given  a   set   of  input/output  pairs  (Q, A)  =\n[(Q1, A1), ..., (Qm, Am)] and a base LLM L,  the Lamarckian operator  is to reverse engineer\nthe instruction OL so that OL(Qi) = Ai, i = 1, ..., m.\n\nB.2  Feedback Operator\n\nInspired by the concept of Gradient Descent in machine learning model training, we introduce an LLM\nagent that works as an examiner which examines the cases where the current task prompt fails and provides\nimprovement guidance. Such guidance will be treated as gradient and be used by another LLM Agent\nas an improver to generate a new candidate. Though similar to what is proposed in APO (Pryzant et al.,\n2023), instead of only using gradient descent repeatedly, which has a higher probability of arriving at a\nlocal minimum, we take advantage of its fast converge rate to local minimum and combine it with other\noperators to target global minimum. When applying the Feedback operator, it will be applied to every\ncandidate in the current pool. The prompt can be found in Table 13 - 14.\nDefinition 2. (Feedback Operator) The Feedback operator generates a new prompt p′ based on the\nexisting prompt p ∈P, and where p made mistakes for a task. The feedback operator OF first looks at the\ncases where the current p failed to generate a list of advice G, and then asks LLM L to apply such advice\nG to existing prompt p for generating the new prompt p′.\n\nB.3  ESTIMATION OF DISTRIBUTION Operator\n\nThe next class of operators takes a set of parents as input to generate a modified candidate.\n  Estimation of Distribution Operator (EDA): Following the principles proposed by (Hauschild and\nPelikan, 2011) and work in (Fernando et al., 2023), we use a LLM agent that is fed with a subset of the\ncurrent pool to generate new candidate. To ensure the diversity and quality of the subset, we first rank the\ncandidates in the current pool by their performance in descending order. Then starting from the first item\nin the ordered candidates, we only add the candidate to the subset if it does not have a similarity score\nover a threshold with any other candidate that is already in the subset. This way candidates with higher\nperformance are more prone to be added to the subset and the diversity of the subset is achieved. More\ndetails on how similarity is calculated can be found in section 3.4. The subset will be randomized before\nfeeding into the LLM agent so the candidate’s performance does not dictate its order. The prompt can be\nfound in Table 15.\n EDA and Index Operator: This is a variant of the EDA operator above. Based on the observations\nthat LLM is more prone to use examples that appear late in the in-context learning (Liu et al., 2023;\nFernando et al., 2023), after generating the subset following procedures of EDA, the subset is ordered by\ntheir performance in ascending order. To further balance exploitation and exploration and avoid being\ntoo biased over the candidate with the highest performance (Fernando et al., 2023), we instructed LLM\nthat the candidates are ranked by their performance in descending order so that the low performance\ncandidates are taken into consideration. The prompt can be found in Table 16.\n\nDefinition 3. (Estimation of Distribution Operator - EDA) EDA generates a new candidate based on\na list of parents.  It is a function operator OE that performs OE(P,L) = p′. Given a list of prompts\nP = [p1, ..., pm] and an LLM L, EDA provides a new prompt p′. Items in P satisfy the restriction that\n\n\n                                         14\n\nOperator      OPRO  EvoPrompt  AELP  PromptBreeder  APE  APO  SEE\n    Lamarckian Operator   ✓     ✓            -      ✓      ✓       -   ✓\n     Feedback Operator        -             -             -               -              -   ✓   ✓\n      Crossover Operator        -     ✓            -      ✓              -        -   ✓\n     EDA Operator     ✓            -             -      ✓              -        -   ✓\n      Semantic Operator        -     ✓     ✓      ✓      ✓   ✓   ✓\n\n\n                             Table 7: Comparison of operators across methods.\n\nd(pi, pj) < t, where d is a function that calculates similarity, and t is a predefined threshold. If the items\nin P are ordered based on certain criteria, we call it EDA + Index (EDA+I).\n\nB.4  Crossover Operator\n\nThis class of operators takes two parents as input to generate a crossover candidate. The prompt can be\nfound in Table 17.\n  Crossover Operator(CR): Following the concept of crossover in the optimization algorithm, we\nintroduce an LLM agent to function as a crossover operator that takes two parents and generates a\ncrossover candidate. It takes the best two candidates in the current pool, namely the top two candidates\nwith the highest performance, and performs linguistic crossover.\n  Crossover with Diversity Operator(CR+D): This is a variance of the Crossover Operator. To provoke\nexploration, we follow a similar process in EDA where diversity in parents is considered. Thus it takes\nthe best candidate and the most distinct individual to it as two parents for crossover operation. The\ndistinctness between two candidates is measured by a similarity score. More details on how the similarity\nscore is calculated can be found in section 3.4.\n\nDefinition 4. (Crossover Operator - CR) Crossover generates a new candidate based on two parents. It\nis a function operator OC that performs OC(p1, p2, L) = p′ where p1, p2 are two prompts selected from\na prompt pool P where P = [p1..., pm], p′ is the generated prompt that hold features from both p1 and p2.\nIf p2 = arg minp∈P d(p1, pi) is applied for choosing p2, we call it Crossover + Distinct (CR + D).\n\nB.5  Semantic Operator\n\nThis class of operators takes a candidate and uses an LLM agent to compose a new candidate that shares\nits semantic meaning. When applying the Semantic operator, it will be applied to every candidate in the\ncurrent pool. The prompt can be found in Table 18.\n\nDefinition 5. (Semantic Operator) The Semantic operator is a function operator OS that performs\nOS(p, L) = p′ where p′ is the generated prompt that shares the same semantic meaning as p.\n\nC  Operator Analysis\n\nC.1  Few-Shot Additional / Removal Analysis\n\nThe ability to add and remove few-shot examples is crucial in dictating whether it is possible to traverse\nthe full in-context prompt space. Thus we conduct the few-shot addition/ removal analysis to gauge each\noperator’s capabilities. Below are examples of how operators add or remove few-shot examples.\n\n\n\n\n\n                                         15\n\nI gave a friend an instruction and some examples The friend read the instruction and\n              wrote an output for every one of the inputs.\n             Here are the input-output pairs:\n\nOperator In-\n             ## Example ##\nput\n             ## Input ## : 92 24\n             ## Output ##: [’68’]\n\n            The instruction was:\n\n               Subtract the second number from the first number and write the result. If the result is\n                negative, write the absolute value of the result.\n\n             Here are the input-output pairs:\n\n                Input: 10 5\n              Output: [’5’]\n\n                Input: 50 75\n              Output: [’25’]\n\n                Input: 100 100\n              Output: [’0’]\nOperator\nOutput        Input: 7 20\n              Output: [’13’]\n\n                Input: 0 5\n              Output: [’5’]\n\n                Input: -10 5\n              Output: [’15’]\n\n                Input: 92 24\n              Output: [’68’]\n\n                Input: 50 -75\n              Output: [’125’]\n\n\n                         Table 8: Lamarckian Operator Add Few-shot Example\n\n\n\n\n\n                                       16\n\nOriginal      For each word, find its antonym and write it as the output.\n Prompt\n\n                   1. Clarify the definition of \"antonym\" to ensure that the prompt is asking for the op-\n                  posite meaning of the word, rather than just a different word that is related in some way.\n\n                   2. Provide more  specific  instructions  for determining the antonym, such as\n                  indicating whether the opposite meaning should be an adjective or a noun.\n Generated\n Feedback\n                   3. Add a list of common antonyms for each word to help users who may not\n               be familiar with all possible opposites.\n\n                   4. Provide a context or sentence for each word to help users determine the\n                 appropriate antonym.\n\n               For each word, find its antonym, which is a word that has the opposite meaning, and\n                  write it as the output. The antonym should be a word that is commonly used to express\n                 the opposite meaning of the given word, and it should be of the same part of speech\n                    (e.g. noun, verb, adjective, adverb).\n\n              To help you identify the antonym, we have provided a list of common antonyms for\n                each word. Additionally, we have included a context or sentence for each word to help\n Generated   you determine the appropriate antonym.\n Prompt\n               Example:\n              Word: Hot\n              Antonym: Cold\n                 Context: The soup is too hot to eat.\n\n                 Please note that some words may have multiple antonyms depending on the context,\n                so use your best judgment to determine the most appropriate one.\n\n\nTable 9: Feedback Operator Add Few-shot Example: In this operation, few-shot examples are added based on the\nfeedback. Individual feedback and their corresponding changes are color-coded.\n\n\n\n\n\n                                         17\n\nFor each word, remove the prefix or suffix that indicates a negative or opposite\n               meaning, and write the resulting word as the output.\n  Original\n Prompt       For example, for the input \"destabilize,\" remove the prefix \"de-\" which indi-\n                  cates a negative meaning, and the resulting word is \"stabilize\n\n\n                  1.Clarify the prompt to specify that it only applies to words with a negative or opposite\n                  prefix or suffix. This will prevent confusion and mistakes when dealing with words\n                   that do not have such affixes.\n\n                   2. Provide examples of common negative or opposite prefixes and  suffixes,\n               such as \"un-\" or \"-less,\" to help users identify them more easily.\n Generated\n Feedback      3. Include a check to ensure that the resulting word is a valid English word,\n                   to avoid outputs like \"ane\" or \"direct\" that are not actual words. This could be done by\n                 cross-referencing the output with a dictionary or word list.\n\n                   4. Consider adding an option to retain the original word if no negative or op-\n                  posite prefix or suffix is present. This would eliminate confusion when dealing with\n               words like \"linear\" that do not have such affixes.\n\n               For each word that contains a negative or opposite prefix or suffix, remove the affix\n               and write the resulting word as the output. Common negative or opposite prefixes and\n                  suffixes include \"un-,\" \"dis-,\" \"in-,\" \"-less,\" and \"-ful.\" Please note that this prompt\n                only applies to words with these specific affixes.\n\n             To ensure that the resulting word is a valid English word, we will cross-refer-\n Generated\n               ence the output with a dictionary or word list. If the resulting word is not a valid\n Prompt\n                English word, it will be excluded from the output.\n\n                     If the original word does not contain a negative or opposite prefix or suffix,\n              you may choose to retain the original word or exclude it from the output. Please\n                 specify your preference in the input.\n\n\n\nTable 10: Feedback Operator Remove Few-shot Example: In this operation, few-shot examples are removed based\non the feedback. Individual feedback and their corresponding changes are color-coded.\n\n\n\n\n\n                                         18\n\nOrder adjectives correctly in English sentences.\n\n          Q: Which sentence has the correct adjective order:\n            Options:\n           (A) rubber terrible ship (B) terrible rubber ship\n          A: Let’s think step by step. When there is more than one adjective before a noun, the\n            adjectives need to respect the following order before a noun: \"[1. opinion] [2. size]\n              [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun\". Option (A):\n           \"rubber terrible ship\". (1) rubber\" falls into the material category. (2) \"terrible\" falls\n             into the opinion category. Option (A) has the following adjective order: [7. material]\n              [1. opinion] (or, in numeric terms, 7 1). Because 7 < 1 is not correct, (A) does not have\n            the correct ordering. Option (B): \"terrible rubber ship\". Option (B) has the following\n            adjective order: [1. opinion] [7. material] (or, in numeric terms, 1 7). Because 1 < 7 is\n             correct, (B) has the correct ordering. So the answer is (B).\n\n          Q: Which sentence has the correct adjective order:\n            Options:\n           (A) repulsive small Brazilian exercise ship (B) Brazilian repulsive exercise small ship\n          A: Let’s think step by step. When there is more than one adjective before a noun, the\n            adjectives need to respect the following order before a noun: \"[1. opinion] [2. size]\n              [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun\". Option (A):\n            \"repulsive small Brazilian exercise ship\". (1) \"repulsive\" falls into the opinion category.\nOperator\n             (2) \"small\" falls into the size category.  (3) \"Brazilian\" falls into the origin category.\nInput\n             (4) \"exercise\" falls into the purpose category. Option (A) has the following adjective\n            order: [1. opinion] [2. size] [6. origin] [8. purpose] (or, in numeric terms, 1 2 6 8).\n          Because 1 < 2 < 6 < 8 is correct, (A) has the correct ordering. Option (B): \"Brazilian\n            repulsive exercise small ship\". Option (B) has the following adjective order: [6. origin]\n              [1. opinion] [8. purpose] [2. size] (or, in numeric terms, 6 1 8 2). Because 6 < 1 < 8 < 2\n               is not correct, (B) does not have the correct ordering. So the answer is (A).\n\n          Q: Which sentence has the correct adjective order:\n            Options:\n           (A) blue gold wonderful square shoe (B) wonderful square blue gold shoe\n          A: Let’s think step by step. When there is more than one adjective before a noun, the\n            adjectives need to respect the following order before a noun: \"[1. opinion] [2. size] [3.\n            age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun\". Option (A): \"blue\n           gold wonderful square shoe\". (1) \"blue\" falls into the color category. (2) \"gold\" falls\n             into the material category. (3) \"wonderful\" falls into the opinion category. (4) \"square\"\n              falls into the shape category. The adjective order that Option (A) has is [5. color] [7.\n            material] [1. opinion] [4. shape] (or, in numeric terms, 5 7 1 4). Because 5 < 7 < 1 < 4\n               is not correct, (A) does not have the correct ordering. Option (B): \"wonderful square\n            blue gold shoe\". Option (B) has the following adjective order: [1. opinion] [4. shape] [5.\n             color] [7. material] (or, in numeric terms, 1 4 5 7 ). Because 1 < 4 < 5 < 7 is correct, (B)\n           has the correct ordering. So the answer is (B).\n\n\nOperator  Rearrange the adjectives in the given sentence in the correct order.\nOutput\n\n\n                        Table 11: Semantic Operator Remove Few-shot Example\n\n\n\n                                       19\n\nC.2  Operator Feature Analysis\n\nTo study the features of each operator we conduct a preliminary experiment where we study four operators:\nEDA Operator, Crossover, Feedback Operator, and Semantic Operator.\n\nInitialization:  As the initialized points have a tremendous impact on optimization problems. We\nrandomly use four different seeds to create four initial pools for four different tasks: Causal Judgement,\nSalient Translation Error Detection, Disambiguation QA, and Hyperbaton. The idea is to provide various\ninitialization points so that the performance of operators can be averaged to rule out the influence of\ninitialization.\n\nOperator Applications:  For each initialization, we apply the following procedure for all four operators.\n\n   • For one round, starting with the initial pool, we consecutively apply the operator 5 times. This is to\n     study the value of applying the operator consecutively.\n\n      – For EDA and CrossOver, as they require multiple parents, we keep a pool size of 5 for each\n           iteration after applying the operator. Performance gain is defined as whether the average\n         performance of the pool is improved.\n      – For Feedback Operator and Semantic Operator, as they only need one parent, we apply them\n          to a random candidate from the initial pool and use the new candidate as the base for the next\n          round. Performance gain is defined as whether the new candidate has a higher performance than\n             its parent.\n\n   • To reduce the impact of randomness, we run this process 5 rounds for each operator.\n\nThus for each operator, it will be run a total of 4 tasks * 5 rounds * 5 application = 100 times.\n                                   80\n\n                                   70\n\n                                   60\n\n                                   50\n\n                                   40                                                             Count\n                                   30\n\n                                   20\n\n                                   10\n\n                                    0\n                                     EDA     Crossover  Feedback   Semantic\n\n                                  Figure 7: Operator Improvement Count\n\nAnalysis:  There are two aspects we are particularly interested in. The first is what the likelihood of\nperformance gain when applying an operator is (Probability of Improvement), and the second is how\nfast each operator can continuously bring improvement (Convergence Speed).\n\n   • Probability Of Improvement: Figure 7 shows the number of times performance is improved by\n    each operator. Crossover and EDA Operator introduces improvements in more steps with Semantic\n     Operator ranking third. Feedback Operator introduces the least number of improvements. This result\n     helps populate the Prob column in table 1.\n\n   • Convergence Speed: Figure 8 shows that for each operator, as they are applied in 5 consecutive\n     steps, the number of times improvement is introduced for each step. Figure 9 shows the average\n     percentage of performance gain operators brought in each step.\n\n      – For EDA Operator and Crossover, each 5 step has a similar number of contributions for\n         performance gains as shown in figure 8. From figure 9 we can also observe the first step brings\n          the most improvement and the first 4 steps bring a similar improvement ratio.\n\n\n                                         20\n\n– For Feedback Operator and Semantic Operator, the first step has a significantly higher chance\n          of introducing improvement as shown in figure 8. This is especially true for Feedback Operator\n        where step 1 accounts for over 34% of the total improvement counts. As for the improvement\n            ratio, the first step for both Feedback Operator and Semantic Operator introduces significantly\n        more improvements than the rest of the steps shown in figure 9.\n\n    Based on the tests, we learned that the value gained for applying Feedback Operator and Semantic\n     Operator is significantly reduced after the 1st application. We interpret it as Feedback Operator and\n    Semantic Operator can jump to the local minimum pretty fast, namely in 1 step, thus leading to\n     less possibility of improvement for steps 2 - 5. Whereas for EDA Operator and Crossover, as they\n     are merging genetic information between candidates, the likelihood of improvement is relatively\n    randomized. So even if the first round of applying them renders no improvement, there is still a\n    chance of performance gain in the following run. In other words, we should be more patient with\n   EDA Operator and Crossover. Thus the operator tolerance (described in section 3.4-design 2)\n     for EDA and Crossover is set to 4 and for Feedback Operator and Semantic Operator is 1. These\n     learnings help populate the Speed column in table 1.\n\n          20.0\n\n          17.5\n                                                                                                                       Step 1\n          15.0                                                                                                          Step 2\n                                                                                                                       Step 3\n          12.5                                                                                                          Step 4\n                                                                                                                       Step 5\n          10.0           Count\n            7.5\n\n            5.0\n\n            2.5\n\n            0.0\n                 EDA                    Crossover                Feedback                 Semantic\n\nFigure 8: Operator Improvement Pattern: EDA Operator and Crossover have similar improvement counts for each\nstep whereas for Feedback Operator and Semantic Operator, the first step introduced significantly more times of\nimprovement compared to the others.\n                      1.4                            140                                Step 1\n                                                                                         Step 2\n                      1.2                            120                                                                                         Step 3\n                      1.0                            100                                Step 4                                                        Percentage                                                                                                       Percentage                                    Step 5\n                      0.8                             80\n                      0.6                             60\n                      0.4                             40                                                              Improvement                                                                                                                  Improvement                      0.2                             20\n                      0.0                              0\n                    EDA         Crossover      Feedback Mutation   Semantic\n\nFigure 9: Improvement Ratio: On the left, for EDA and Crossover, we observe an almost equal improvement ratio\nfor the first four steps. Improvement Ratio is defined as the relative percentage of improvement in the average\nperformance for the entire pool. On the right, for Feedback and Semantic Operator, we observe the first round\ncontributes significantly more improvement compared to the others. As Feedback and Semantic Operators take\none input candidate, Improvement Ratio is defined as the relative performance improvement percentage for the\ncandidate after applying the operator.\n\n\n\n\n\n                                         21\n\nD  Operator Prompts\n\nOperator Implementation:  The state-of-art frameworks such as APO, EVOPROMPT, and AELP have\nalready implemented operators such as feedback operator, crossover operator, and semantic operator\nwith LLM. However, these implementations inflict restrictions on LLM with prompts. For example, in\nAPO when implementing the feedback operator, the prompt specifically identified the use case to be\nzero-shot. (Pryzant et al., 2023) In EVOPROMPT-DE, when applying crossover operators, the focus is to\nonly change the parts that two parents differentiate from each other. (Guo et al., 2023) In AELP, when\napplying semantic operators, it is restricted to a sentence level, not the whole prompt. (Hsieh et al., 2023).\nIn SEE, we pay special attention not to apply any restrictions in our operator prompt, realizing the full\npotential of LLMs.\n\n            I gave a friend an instruction and some input. The friend read the instruction and\n         wrote an output for every one of the inputs. Here are the input-output pairs:\n\n        ## Example ##\n          {input output pairs}\n\n        The instruction was:\n\n\n                                  Table 12: Lamarckian Operator Prompt\n\n        You are a quick improver. Given an existing prompt and a series of cases where it\n        made mistakes. Look through each case carefully and identify what is causing the\n          mistakes. Based on these observations, output ways to improve the prompts based\n        on the mistakes.\n\n        ## Existing Prompt ##\n           {existing prompt}\n\n        ## Cases where it gets wrong:##\n        {wrong cases}\n\n        ways to improve the existing prompt based on observations of the mistakes in the\n          cases above are:\n\nTable 13: Gradient Descent Generation Prompt: Unlike APO which is also using gradient descent, we are NOT\nadding restrictions such as \"zero-shot classifier prompt.\", nor providing any differentiation between instructions and\nexamples. Instead, we specifically ask LLM to output multiple feedback in one go. Also as are passing in the existing\nprompt as a whole, thus feedback should be on the paragraph/prompt level instead of the sentence/instruction level.\nWe highlight the design that helps us achieve this below.\n\n\n\n\n\n                                         22\n\nYou are a quick improver. Given an existing prompt and feedback on how it should\n         improve. Create an improved version based on the feedback.\n\n        ## Existing Prompt ##\n           {existing prompt}\n\n        ## Feedback##\n         {feedback}\n\n        ## Improved Prompt##\n\nTable 14: Gradient Descent Application Prompt: Following the principle of optimizing prompt as a whole, our\noperator prompts take input and output on the entire prompt level\n\n\n\n\n\n        You are a mutator. Given a series of prompts, your task is to generate another prompt\n         with the same semantic meaning and intentions.\n\n\n\n        ## Existing Prompts ##\n           {existing prompt}\n\n        The newly mutated prompt is:\n\n\n                                         Table 15: EDA Prompt\n\n\n\n\n\n       You are a mutator. Given a series of prompts, your task is to generate another prompt\n         with the same semantic meaning and intentions. The series of prompts are ranked by\n           their quality from best to worst.\n\n        ## Existing Prompts ##\n          {existing prompt}\n\n        The newly mutated prompt is:\n\n\nTable 16: EDA+Index Prompt: The difference between EDA + Index and EDA is that EDA + Index takes advantage\nof the in-context learning technique and informs the order of the passed-in prompts\n\n\n\n\n\n                                         23\n\nYou are a mutator who is familiar with the concept of cross-over in genetic algorithm,\n         namely combining the genetic information of two parents to generate new offspring.\n         Given two parent prompts, you will perform a cross-over to generate an offspring\n         prompt that covers the same semantic meaning as both parents.\n\n        # Example\n          Parent prompt 1: Now you are a categorizer, your mission is to ascertain the\n          sentiment of the provided text, either favorable or unfavorable\n\n          Parent prompt 2: Assign a sentiment label to the given sentence from [’neg-\n            ative’, ’positive’] and return only the label without any other text.\n\n          Offspring prompt:  Your mission  is  to ascertain the sentiment of the pro-\n         vided text and assign a sentiment label from [’negative’, ’positive’].\n\n        ## Given ##\n          Parent prompt 1: {prompt 1}\n          Parent prompt 2: {prompt 2}\n          Offspring prompt:\n\n\n                                      Table 17: Cross Over Prompt\n\n\n\n\n\n        You are a mutator. Given a prompt, your task is to generate another prompt with the\n        same semantic meaning and intentions.\n\n        # Example:\n          current prompt: Your mission is to ascertain the sentiment of the provided text and\n          assign a sentiment label from [’negative’, ’positive’].\n         mutated prompt: Determine the sentiment of the given sentence and assign a label\n         from [’negative’, ’positive’].\n\n\n\n         Given:\n          current prompt: {existing prompt}\n         mutated prompt::\n\nTable 18: Semantic Operator Prompt: To provoke LLM’s creativity, we do not restrict to the semantic level but\nexpand that to intentions, allowing LLM to not stick to a sentence-by-sentence modification.\n\n\n\n\n\n                                         24\n\nE  Details of Experiments\n\nImplementation Details. We utilized GPT-3.5-turbo to develop LLM agents capable of performing\nvarious operators in all tasks. The GPT-3.5-turbo access was through internal hosting of Azure, where\nadditional security guardrails prevented some API calls from completing for security reasons. As such,\naccuracy was computed only on successful responses. We conduct comparisons between GPT 3.5 and\nGPT. 4 in 4 BBh tasks and all the other tasks. We set up training, development, and testing datasets, select\nthe prompt with the highest score on the dev set, and report its score on the testing set. For BBH and APO\ntasks, we conducted three end-to-end runs, with the average performance and standard deviation reported\nin Table 19 and Table 20. For additional parameter settings please refer to Section E.3.\n\nE.1  Benchmark tasks\n\n• 24 Instruction Induction Tasks: These 24 instruction tasks (Honovich et al., 2022) span many facets\n  of language understanding, from simple phrase structure to similarity and causality identification. Both\n  training and testing data are provided for these tasks and we create our training and development data\n   set from the available training data and use the provided testing data set as is. Depending on the task,\n  we use up to 50 training data and up to 50 development data. We use input/output pair format for these\n   tasks.\n\n\n• Ethos: Ethos (Mollas et al., 2021) is an online English hate speech detection data set with 997 online\n  comments and hate speech labels. We select 50 for training, 50 for development, and 150 for testing.\n We use prompt example format for this data set following the practice of APO (Pryzant et al., 2023).\n\n\n• Liar: Liar (Wang, 2017) is an English fake news detection data set with 4000 statements, context, and\n   lie labels. We select 50 for training, 50 for development, and 150 for testing. We use prompt example\n  format for this data set following the practice of APO (Pryzant et al., 2023).\n\n\n• Sarcasm: Sarcasm (Farha and Magdy, 2020) is an Arabic sarcasm detection data set with 10,000 online\n  comments and sarcasm labels. We select 50 for training, 50 for development, and 150 for testing. We\n  use prompt example format for this data set following the practice of APO (Pryzant et al., 2023).\n\n\n• BBH: BBH (Aarohi and bench authors, 2023) is a collaborative benchmark that aims to quantitatively\n  measure the capabilities and limitations of language models. We followed the same practice in the\n AELP paper with the same tasks and randomly selected 125 for training/ development, and up to 125\n  for testing. (Hsieh et al., 2023)\n\n\nE.2  Baselines\n\n9 Baselines.  We evaluate SEE against a variety of LLM-based approaches that have achieved state-of-\nthe-art performance in prompt optimization:\n\n• APE (Zhou et al., 2023), ZOPO (Hu et al., 2024) and APO (Pryzant et al., 2023): APE utilizes a\n  Monte Carlo Search strategy that emphasizes exploration, while APO emphasizes exploitation, which\n  harnesses incorrect instances as feedback gradient. ZOPO utilizes zeroth-order optimization methods to\n  find local optimal.\n\n• OPRO (Yang et al., 2023a): OPRO leverages LLM as optimizers to generate better instruction via\n  meta-prompt, solution-score pairs, and task descriptions.\n\n• PromptBreeder (Fernando et al., 2023), EvoPrompt (Guo et al., 2023) and AELP (Hsieh et al., 2023):\n  these methods connect LLMs with evolution algorithms for prompt optimization.\n\n• MoP (Wang et al., 2024), EASE (Wu et al., 2024): these methods can optimize instructions and\n  examples simultaneously.\n\n\n                                         25\n\nE.3  SEE Setting\n\n• Pool Size: In the experiments, for phase 0: Global initialization we set the pool size to be 15. For the\n   rest phases, we set the pool to be 5.\n\n• Operator Tolerance: Based on operator analysis in section C.2, the tolerance for Feedback Operator\n  and Semantic Operator is set to 1. The tolerance for EDA Operator and Crossover is set to 4. Thus the\n  minimum number of times operators will be applied in phase 2: global optimization operation is 8.\n\n• Model Configuration: For operators, we set the temperature to 0.5 to tap into LLM’s creativity. For\n  performance evaluations, we set the temperature to 0.\n\n• Performance Gain in Stop Criteria: To improve efficiency, when evaluating performance gain to\n  decide whether we should move to the next phase, we are only looking at the best candidate in the\n  current pool.\n\n• Candidate Selection: To improve efficiency, after getting new candidates, we combine them with the\n  current pool and use a greedy algorithm to select the top performer to be the new pool.\n\n\n\n\n\n                                         26\n\nF  Additional Experiment Results\n\nF.1 BBH Task Average & Standard Deviation\n\nWe run each method three times and report and average and standard deviation in Table 19.\n\n               Causal       Dis          Dyck         Formal                      Logical       Color          Salient\n Method                                                             Hyperbaton\n              Judgement    -ambiguation   Languages      Fallacies                    Five         Reasoning     Translation\n\n\n SEE-pair        69.97(2.45)    69.90(3.53)     7.06(1.23)      58.49(0.41)   84.36(2.24)   45.49(2.73)    58.13(2.36)    48.38(0.81)\n SEE-example   84.85(5.45)   68.01(0.4)      35.48(12.18)   53.06(4.95)    81.58(9.89)    73.56(8.99)   77.15(4.13)   47.01(0.88)\n\n                           Table 19: BBH Tasks Average and Standard Deviation\n\n\nF.2  3 Detect Task for APO\n\nBelow are the results of SEE on 3 detection task compared with APO.\n\n                Method                   Ethos      Liar       Sarcasm\n\n            APO (Pryzant et al., 2023)   0.95       0.51       0.85\n                SEE (GPT-3.5)                0.96(0.96)   0.61(3.85)   0.87(1.25)\n                SEE (GPT-4)               0.96       0.69       0.89\n\n\n                         Table 20: Testing performance on 3 detect tasks from APO.\n\n\nF.3  24 Instruction Induction Tasks\n\nTable 21 shows the comparison between APE, PromptBreeder, MoP, EvoPrompt, OPRO, EASE, ZOPO\nand SEE evaluated by the best prompt on 24 instruction induction tasks. For EASE we use the results with\ninstruction for a fair comparison. For ZOPO, we use the better performance between the two versions.\n  SEE outperforms 23 / 24 tasks over APE zero shot, 21 / 24 tasks over APE few shot, 22 / 24 tasks over\nPrompt Breeder, 21 / 24 tasks over MoP, 14 / 14 tasks over EvoPrompt, 14 / 14 tasks over OPRO, 10 / 15\ntasks over EASE and 14 / 14 tasks over ZOPO.\n  SEE generated few-shot prompts for 20 / 24 tasks and zero-shot examples for 4 / 24 tasks. For the full\nset of generated prompts please refer to Table 29.\n\n\n              APE  APE  PB         Evo        EA-  ZO-\n                                           OP-                 SEE-\n Task                  (zero-  (few-  (few-  MoP  Pro-       SE   PO            SEE-4\n                                  RO                    3.5\n                       shot)   shot)   shot)        mpt            (w/in)  (best)\n\n Antonyms           0.83   0.86   0.87   0.88   0.84   0.79   0.85   0.85   0.89     0.91\n\n Cause Effect         0.84   1     1      0.93   0.84   0.83   _      0.95   0.96    1\n\n Common Concept    0.27   0.32   0      0.38   0.11   0.09   _      0.24   0.23     0.28\n\n Diff               1     1     1     1      0.27   1     1     1     1      1\n\n First Word Letter    1     1     1     1     _     _     _     _     1      1\n\n Informal Formal     0.65   0.70   0.07   0.63   0.52   0.48   _      0.62    0.6      0.67\n\n Large Animal        0.97   0.97   0.97   0.96   _     _     1     _      0.96     0.94\n\n Letters List          0.99   1      0.99   0.99   1      0.99   _     1     1      1\n\n Taxonomy Animal   0.66   0.79   1      0.72   0.83   0.30   1      0.90   0.96    1\n\n Negation            0.83    0.9     0.9    0.87   0.86   0.73   1      0.86   0.94     0.88\n\n Num Verb          1     1     1     1     _     _     _     _     1      1\n\n  Continuation of Table 21\n\n\n                                         27\n\nContinuation of Table 21\n\n Active Passive      1     1     1     1     _     _     _     _     1      1\n\n Singular Plural      1     1     1     1     _     _     _     _     1      1\n\n Rhymes           1      0.61   1      0.94   0.60   0.23   1     1     1      1\n\n Second Word Letter   0.87   0.69   0.95   0.75   0.25   0.87   1      0.97   1      1\n\n Sentence Similarity   0.36   0.43   0.56   0.68   0.02   0.03   0.58   0.37   0.38     0.55\n\n Sentiment           0.94   0.93   0.93   0.97   _     _     1     _      0.94     0.94\n\n Orthography Starts   0.68   0.69   0.71   0.72   0.15   0.34   0.82   0.71   0.72     0.94\n\n Sum              1     1     1     1     1     1     1     1     1      1\n\n Synonym            0.22   0.14   0.43   0.26   0.40   0.40   0.32   0.45   0.46     0.38\n\n Trans En De         0.72   0.86   0.87   0.72   _     _      0.90   _      0.83     0.96\n\n Trans En Es         0.86   0.91   0.91   0.86   _     _     1     _      0.92     0.94\n\n Trans En Fr          0.78    0.9    0.91   0.79   _     _      0.85   _      0.88     0.93\n\n Word in Context     0.62   0.63   0.65   0.67   _     _     _     _      0.66     0.7\n\n\n                              Table 21: 24 Instruction Induction Task in APE\n\n\nF.4  Generated Prompt Comparison\n\nWe notice that the prompts generated by SEE are easier to understand by humans. Below is a\ncomparison between prompts generated for task Rhymes. The task description is: \"Write a word that\nrhymes with the input word.\".,\n  The prompt generated by APE and ZOPO does not fit the task. The prompt generated by Prompt\nBreeder is not easy to understand how it relates to rhyme. The prompt generated by SEE is easy to\nunderstand with few shot examples added.\n\n\n Framework   Generated Prompt\n\n                 write a function that takes in a string and outputs the string with the first letter\n APE\n                   capitalized.\n\n  Continuation of Table 22\n\n\n\n\n\n                                         28\n\nContinuation of Table 22\n\n             Prompt 0: If the last letter of the input is ’e’, remove it.\n             Prompt 1: remove the last two letters of the input and add the letters \\xc2 \\x93mote\n               \\xc2 \\x94.\n              Contexts\n              Context 0:\n             Q. pea\n             A. If the last letter of the input is ’e’, remove it.\n             A. If the last letter of the input is ’s’, remove it.\n             A. If the last letter of the input is ’y’, remove it.\n             A. If the last letter of the input is\n             remove the last two letters of the input and add the letters \\xc2 \\x93mote \\xc2 \\x94.\n               Therefore, the correct answer is (a) pea.\n              Context 1:\nPrompt      Q. night\nBreeder      A. If the last letter of the input is ’e’, remove it.\n             A. If the last letter of the input is ’t’, remove it.\n             A. If the last letter of the input is ’h’, remove it.\n             A. If the last letter of the input is\n             remove the last two letters of the input and add the letters \\xc2 \\x93mote \\xc2 \\x94.\n               Therefore, the correct answer is (The answer is night.\n              Context 2:\n             Q. add\n             A. If the last letter of the input is ’e’, remove it.\n             A. If the last letter of the input is ’d’, remove it.\n             A. If the last letter of the input is ’a’, remove it.\n             A. If the last letter of the input is\n             remove the last two letters of the input and add the letters \\xc2 \\x93mote \\xc2 \\x94.\n               Therefore, the correct answer is (The answer is added.\n\n            The prompts were to create a program that takes in a word as input and outputs a\nZOPO         related word based on a specific set of rules. The rules are as follows: If the input\n            word starts with “tri\", the output should be “slip\".\n\nContinuation of Table 22\n\n\n\n\n\n                                       29\n\nContinuation of Table 22\n\n               Create a list of words that rhyme with the given word. To ensure that your rhymes are\n                accurate, make sure that the words have the same vowel sound and ending consonant\n              sound. For example, \"cat\" rhymes with \"bat\" and \"hat,\" but not with \"dog\" or \"mat.\"\n\n            To get started, here are some examples of words that rhyme with the given\n              word:\n\n                   - Love: dove, glove, above, shove, of\n                   - Time: rhyme, chime, climb, mime, prime\n\n            To find more rhyming words, you can use a rhyming dictionary, online re-\n               sources, or brainstorm with friends. Be creative and try to use a variety of different\nSEE          rhyming words instead of repeating the same one multiple times.\n\n            To avoid common pitfalls, make sure to double-check your spelling and pro-\n               nunciation of the words. Also, avoid using words that only partially rhyme or have a\n                 different stress pattern.\n\n               After you’ve created your list, ask for feedback on the quality of your rhymes. This\n              can help you to improve and refine your skills.\n\n              For an added challenge, consider generating rhyming words that  fit a particu-\n                  lar theme or context. This can help you to focus your creativity and generate more\n                interesting and relevant rhymes.\n\n\n\n\n                      Table 22: Generated Prompt Comparison for task \"Rhymes\"\n\n\n\n\n\n                                       30\n\nG  Few-shot Add/ Removal Examples\n\nBelow are cases listing examples where few-shot examples are added or removed with SEE.\n\nG.1  Zero-shot to Few-shot\n\n Task         Ethos\n\n  Input           Is the following text hate speech? \\n ## Output Format ## True or False\n Prompt\n\n              Your task is to evaluate whether the provided input includes any offensive language.\n                This could be language that is sexist, racist, discriminatory, or advocates violence or\n               harm. Offensive language can also be identified by an aggressive or belittling tone.\n               However, remember that the mere presence of profanity does not necessarily make a\n                statement offensive. The context and intention behind the statement should also be\n                taken into account. If none of these conditions are fulfilled, return ’False’.\n Output\n Prompt       For instance, the phrase \"You are a fool\" is offensive due to its derogatory tone, so\n              you should return ’True’. On the other hand, the phrase \"This is a damn tasty pizza\"\n                 includes profanity but is not offensive, so you should return ’False’. Similarly, a phrase\n                   like \"All people of X race are lazy\" is offensive because of its racist undertones, so\n              you should return ’True’. In contrast, a phrase like \"I dislike the color yellow\" is not\n                  offensive, so you should return ’False’.\n\n\n\n                     Table 23: Add Few-shot Example: added examples are highlighted.\n\n\nG.2  Zero-shot to Zero-shot\n\n Task         Ethos\n\n  Input           Is the following text hate speech? \\n ## Output Format ## True or False\n Prompt\n\n                 Classify the given text as hate speech or not and generate a binary output of 1 for Yes\n Output\n               and 0 for No.\n Prompt\n\n\n\n                                     Table 24: Zero-shot to Zero-shot\n\n\nG.3  Few-shot to Zero-shot\n\n\n Task         Hyperbaton\n\n  Continuation of Table 25\n\n\n\n\n\n                                         31\n\nContinuation of Table 25\n\n              Order adjectives correctly in English sentences.\n\n\n\n             Q: Which sentence has the correct adjective order:\n               Options:\n              (A) rubber terrible ship\n              (B) terrible rubber ship\n             A: Let’s think step by step.\n          When there is more than one adjective before a noun, the adjectives need to respect\n                the following order before a noun: \"[1. opinion] [2. size] [3. age] [4. shape] [5. color]\n                  [6. origin] [7. material] [8. purpose] noun\".\n             Option (A): \"rubber terrible ship\". (1) rubber\" falls into the material category. (2)\n                 \"terrible\" falls into the opinion category. Option (A) has the following adjective order:\n                  [7. material] [1. opinion] (or, in numeric terms, 7 1). Because 7 < 1 is not correct, (A)\n              does not have the correct ordering.\n             Option (B): \"terrible rubber ship\". Option (B) has the following adjective order: [1.\n               opinion] [7. material] (or, in numeric terms, 1 7). Because 1 < 7 is correct, (B) has the\n                correct ordering. So the answer is (B).\nInput\nPrompt      Q: Which sentence has the correct adjective order:\n               Options:\n              (A) repulsive small Brazilian exercise ship\n              (B) Brazilian repulsive exercise small ship\n             A: Let’s think step by step.\n          When there is more than one adjective before a noun, the adjectives need to respect\n                the following order before a noun: \"[1. opinion] [2. size] [3. age] [4. shape] [5. color]\n                  [6. origin] [7. material] [8. purpose] noun\".\n             Option (A): \"repulsive small Brazilian exercise ship\". (1) \"repulsive\" falls into the\n              opinion category. (2) \"small\" falls into the size category. (3) \"Brazilian\" falls into\n               the origin category. (4) \"exercise\" falls into the purpose category. Option (A) has\n               the following adjective order: [1. opinion] [2. size] [6. origin] [8. purpose] (or, in\n              numeric terms, 1 2 6 8). Because 1 < 2 < 6 < 8 is correct, (A) has the correct ordering.\n             Option (B): \"Brazilian repulsive exercise small ship\". Option (B) has the following\n                adjective order: [6. origin] [1. opinion] [8. purpose] [2. size] (or, in numeric terms, 6\n             1 8 2). Because 6 < 1 < 8 < 2 is not correct, (B) does not have the correct ordering. So\n                the answer is (A).\n                         ...\n\n\n                Identify the sentence with the correct order of adjectives: opinion, size, age, shape,\nOutput\n                 color, origin, material, purpose.\nPrompt\n\n\n                                   Table 25: Few-shot to Zero-shot\n\n\n\n\n\n                                       32\n\nTask         Hyperbaton\n\n              Order adjectives correctly in English sentences.\n\n\n\n             Q: Which sentence has the correct adjective order:\n               Options:\n              (A) rubber terrible ship\n              (B) terrible rubber ship\n             A: Let’s think step by step.\n          When there is more than one adjective before a noun, the adjectives need to respect\n                the following order before a noun: \"[1. opinion] [2. size] [3. age] [4. shape] [5. color]\n                  [6. origin] [7. material] [8. purpose] noun\".\n             Option (A): \"rubber terrible ship\". (1) rubber\" falls into the material category. (2)\n                 \"terrible\" falls into the opinion category. Option (A) has the following adjective order:\n                  [7. material] [1. opinion] (or, in numeric terms, 7 1). Because 7 < 1 is not correct, (A)\n              does not have the correct ordering.\n             Option (B): \"terrible rubber ship\". Option (B) has the following adjective order: [1.\n               opinion] [7. material] (or, in numeric terms, 1 7). Because 1 < 7 is correct, (B) has the\n                correct ordering. So the answer is (B).\nInput\nPrompt      Q: Which sentence has the correct adjective order:\n               Options:\n              (A) repulsive small Brazilian exercise ship\n              (B) Brazilian repulsive exercise small ship\n             A: Let’s think step by step.\n          When there is more than one adjective before a noun, the adjectives need to respect\n                the following order before a noun: \"[1. opinion] [2. size] [3. age] [4. shape] [5. color]\n                  [6. origin] [7. material] [8. purpose] noun\".\n             Option (A): \"repulsive small Brazilian exercise ship\". (1) \"repulsive\" falls into the\n              opinion category. (2) \"small\" falls into the size category. (3) \"Brazilian\" falls into\n               the origin category. (4) \"exercise\" falls into the purpose category. Option (A) has\n               the following adjective order: [1. opinion] [2. size] [6. origin] [8. purpose] (or, in\n              numeric terms, 1 2 6 8). Because 1 < 2 < 6 < 8 is correct, (A) has the correct ordering.\n             Option (B): \"Brazilian repulsive exercise small ship\". Option (B) has the following\n                adjective order: [6. origin] [1. opinion] [8. purpose] [2. size] (or, in numeric terms, 6\n             1 8 2). Because 6 < 1 < 8 < 2 is not correct, (B) does not have the correct ordering. So\n                the answer is (A).\n                         ...\n\n\nContinuation of Table 26\n\n\n\n\n\n                                       33\n\nContinuation of Table 26\n\n                 Adjective Order Practice:\n\n                 In English grammar, the order of adjectives  is important to convey accurate\n              and effective descriptions.  Here are two examples of sentences with adjectives.\n               Determine which sentence has the correct adjective order.\n\n              Example 1:\n                  a) The big, red, round ball bounced down the street.\n                 b) The round, red, big ball bounced down the street.\n\n              Example 2:\n Output        a) The delicious, homemade, chocolate cake was devoured by the guests.\n Prompt       b) The chocolate, homemade, delicious cake was devoured by the guests.\n\n              Choose the letter of the sentence with the correct adjective order as your an-\n                 swer.\n\n                Note:  Adjective order generally follows  the  pattern of opinion,  size,  age,\n                 shape, color, origin, material, and purpose. If the adjectives do not fit into this pattern,\n                 the order is determined by the speaker’s preference.\n\n                     If you choose the incorrect sentence, we will explain why  it is wrong to help\n              you learn from your mistakes. Good luck!\n\n\n\n                                     Table 26: Few-shot to Few-shot\n\n\nG.4  Synthetic Few-shot Examples.\n\nWe observe that in certain cases SEE would generate novel synthetic few-shot examples instead of selecting\nfrom existing ones. To verify their veracity, we conduct a manual evaluation of the accuracy of the few-\nshot examples generated by SEE on a total of 24 instruction deduction tasks. We find that 90 out of the\n92 examples evaluated (97.8%) are accurate. Among them, 24 out of the 92 (24.09%) are aligned with\nsamples present in the training set. There are two cases where the synthetic example is inaccurate: the\nsentiment of \"A non-mystery mystery\" is identified as \"neutral\" where the ground truth is \"negative\",\nand \"Little more than a well-mounted history lesson\" is identified as \"neutral\" where the ground truth\nis \"negative\". In both cases, we empirically validate that such a level of inaccuracy does not influence\nprompt performance (score remained 94% regardless of the labels).\n\n\n\n\n\n                                         34\n\nH  Generated Prompts\n\nIn this section, we list the prompts generated by SEE with the best performance for each task. All prompts\nare generated by gpt-3.5. We observe a mix of few-shot prompts and zero-shot prompts for different tasks.\nThis indicates both LLM’s ability to perform in-context prompt optimization and SEE’s ability to traverse\nthe whole problem space to find optimal solutions.\n  We also notice that the few-shot examples in the final prompts are largely generated by LLM instead of\ncopied from example instruction or training sets. Thus it serves as further proof of LLM’s capability of\nin-context prompt optimization and SEE’s credibility in this problem space.\n\n\n                   Provide reactions to intentional actions in diverse scenarios, while also con-\n                     sidering causation and its complexities. To assist with determining causation,\n                   provide specific guidelines and examples for each scenario. To avoid any\n                   confusion or misinterpretation, precise language and definitions will be used\n    Causal\n                   throughout the prompt. Additionally, feedback from experts and individuals\n    Judgment\n                   with relevant experience in the field of causation will be incorporated to ensure\n                   accuracy and relevance. To challenge users’ critical thinking skills, include\n                    diverse and complex scenarios that require creative problem-solving and a\n                   deeper understanding of causation in various areas of life.\n\n                    Correctly close all brackets, including nested brackets, in the provided sequence\n                      in the proper order from innermost to outermost. Mistakes such as forgetting to\n                    close a bracket or closing brackets in the wrong order can result in an error. If\n                  an error is made, a clear and concise message will indicate which bracket is not\n                   properly closed and suggest how to correct it. A visual representation of the\n                     correct sequence of closed brackets is provided below:\n                         [  ( [  ( )  ] )  ]\n\n                 Examples of valid and invalid inputs:\n\n    Dyke  Lan-  Valid input: [  ( )  ]\n    guages        Valid input: [  ( [ ] )  ]\n                     Invalid input: [  ( [ )  ]\n                 Warning message: The bracket at position 8 is not properly closed. Please close\n                     the bracket to ensure proper syntax.\n                  Suggested correction: [  ( [ ] )  ]\n\n                     Invalid input: [  ( [  ] ) ]\n                 Warning message: The bracket at position 8 is not properly closed. Please close\n                     the bracket to ensure proper syntax.\n                  Suggested correction: [  ( [ ] )  ]\n\n\n                 Read the given argument carefully and determine whether it is deductively valid\n    Formal Fal-\n                    or invalid based on the explicitly stated premises. Provide a justification for\n     lacies\n                  your answer.\n\n                  For each sentence with a gender-neutral pronoun, determine the antecedent or\n     Dis-\n                       state if it is ambiguous. Use (A) for the first option, (B) for the second option,\n    ambiguation\n                    or (C) for ambiguous. Additionally, provide an explanation of the antecedent\n   QA\n                      (the person or thing the pronoun refers to) for each sentence.\n\n     Continuation of Table 27\n\n\n\n\n                                         35\n\nContinuation of Table 27\n\n               Test your knowledge of adjective order in English sentences with interactive\n               exercises and quizzes. Learn the rule of opinion-size-age-shape-color-origin-\n               material-purpose noun and apply it to different types of nouns such as animals,\nHyperbaton   objects, and people. Practice constructing your own sentences and receive\n              feedback on incorrect answers to improve your skills. By the end of this exercise,\n                you’ll be able to confidently order adjectives and communicate accurately in\n               English.\n\nContinuation of Table 27\n\n\n\n\n\n                                     36\n\nContinuation of Table 27\n\n           On a plate, there are three fruits: a red apple, a yellow banana, and a green pear.\n            The banana is positioned to the immediate left of the apple, meaning there are\n             no other fruits between them. The pear is the rightmost fruit, meaning it comes\n                  last in the order.\n\n            Which of the following statements is true?\n\n              (A) The red apple is the leftmost fruit.\n              (B) The yellow banana is the leftmost fruit.\n              (C) The green pear is the leftmost fruit.\n\n               Explanation:\n            To solve this prompt, pay attention to the precise language used to describe the\n                relationships between the fruits and their positions in the order. The banana is\n                 to the immediate left of the apple, meaning it is directly adjacent to it and there\n               are no other fruits between them. The pear is the rightmost fruit, meaning it\n            comes last in the order.\n               Therefore, the correct answer is (B) The yellow banana is the leftmost fruit.\n\n            To further practice this concept, here are some additional examples:\n                 1. On a plate, there are three different colored balls: a blue ball, a red ball, and\n              a green ball. The red ball is directly to the left of the blue ball, meaning there\n                are no other balls between them. The green ball is the rightmost. Which of the\n               following statements is true?\nLogical De-\n              (A) The blue ball is the leftmost ball.\nduction Five\n              (B) The red ball is the leftmost ball.\n              (C) The green ball is the leftmost ball.\n\n                 2.  In a row of three houses, there is a blue house, a yellow house, and\n               a green house. The blue house is in the middle, and the yellow house is directly\n                to the left of the green house, meaning there are no other houses between them.\n            Which of the following statements is true? (A) The blue house is the leftmost\n               house.\n              (B) The yellow house is the leftmost house.\n              (C) The green house is the leftmost house.\n\n              Feedback:\n                   If you selected the wrong answer, here’s why:\n              (A) The red apple is not the leftmost fruit. The yellow banana is directly to its\n                    left.\n              (C) The green pear is not the leftmost fruit. The banana and the apple come\n               before it in the order.\n\n            To avoid confusion, use precise language to describe the relationships\n             between objects and their positions in the order. Avoid using vague terms like\n              \"newer\" or \"older\" without specifying their exact relationship to other objects\n                in the order. Provide more context or details to help clarify any ambiguities in\n                the prompt. Make sure the order of the objects is clearly defined and consistent\n              throughout the prompt.\n\nContinuation of Table 27\n\n\n                                     37\n\nContinuation of Table 27\n\n                Identify the color of objects arranged in a row on a surface.\n            Q: On the desk, there is a black stapler, a green highlighter, a yellow ruler, a\n               blue pen, and a purple marker. What color is the pen?\n               Options:\n              (A) red\n              (B) orange\n              (C) yellow\n              (D) green\n               (E) blue\n               (F) brown\n              (G) magenta\n              (H) fuchsia\n                   (I) mauve\nReasoning     (J) teal\nColored      (K) turquoise\nObjects       (L) burgundy\n            (M) silver\n              (N) gold\n              (O) black\n               (P) grey\n              (Q) purple\n              (R) pink\n             A: Let’s think step by step.\n             According to this question, the objects are arranged in a row, from left to right,\n               as follows: (1) a black stapler, (2) a green highlighter, (3) a yellow ruler, (4) a\n               blue pen, and (5) a purple marker.\n            The pen is the fourth item on the list, namely (4). The color of the pen is blue.\n            So the answer is (E).\n\n\nContinuation of Table 27\n\n\n\n\n\n                                     38\n\nContinuation of Table 27\n\n            Read the following translations from German to English and identify the type\n               of error present in each one. The error can be one of the following types:\n           Named Entities, Numerical Values, Modifiers or Adjectives, Negation or\n             Antonyms, Facts, or Dropped Content. Write the corresponding letter for each\n                error type in the options provided.\n\n              For example:\n               Source: Der Hund ist braun.\nSalient        Translation: The cat is brown.\nTransla-     The translation contains an error pertaining to:\ntion  Error   Options:\nDetection     (A) Modifiers or Adjectives\n              (B) Numerical Values\n              (C) Negation or Antonyms\n              (D) Named Entities\n               (E) Dropped Content\n                (F) Facts\n\n               Output: (D)\n\n\n\n                                   Table 27: BBH Prompts\n\n\n\n\n\n                                     39\n\nEthos        Does the provided text contain hate speech? Return a boolean value of True or False.\n\n             Analyze the context and other information provided to determine the truthfulness of\n                the statement. To do so, consider the following guidelines:\n\n                1.   Identify key sources of information, such as reputable news  outlets or\n             government reports, and consider the credibility of the sources. Look for corroborat-\n               ing evidence and consider any potential biases or conflicts of interest.\n\n                 2.  Conduct additional research or seek out expert opinions when necessary\n                to determine the truthfulness of a statement. Use resources or links to relevant\n              information provided, and consider consulting with subject matter experts or\n               fact-checking organizations.\n\nLiar            3.  Note that the determination of truthfulness may not always be possible\n              based on the information provided, and that additional research or analysis may be\n                required. Use your best judgment and be transparent about any uncertainties or\n                limitations in your analysis.\n\n                4.  Consider specific examples or scenarios to help you apply the prompt in\n                different contexts. For instance, you might analyze a political statement, a scientific\n               claim, or a news article. Be aware of common pitfalls or errors, such as relying on\n                unreliable sources or failing to consider alternative explanations.\n\n             Output Format:  Assign 0 for true and 1 for false.  Note that this determina-\n                tion is based on the information provided and may not be definitive.\n\n\n             Determine if the input contains any language that could be considered derogatory or\n                discriminatory towards a particular group based on their race, ethnicity, gender, sexual\n                orientation, religion, or any other protected characteristic. If such language is found,\nSarcasm\n               output True. If not, output False. The prompt should be trained on a diverse dataset to\n             improve its accuracy and reduce errors.\n\n\n\n                                       Table 28: APO Prompts\n\n\n\n\n\n                                       40\n\n\"Provide a list of adjectival antonyms for each of these words, keeping in mind the\n               given context:\"\n\n             ## Input ##: hot (in the context of weather)\n             ## Output ##: [’cold’, ’cool’, ’chilly’]\n\n             ## Input ##: happy (in the context of emotions)\n             ## Output ##: [’sad’, ’unhappy’, ’depressed’, ’miserable’]\n\nAntonyms    ## Input ##: big (in the context of size)\n             ## Output ##: [’small’, ’tiny’, ’little’, ’miniature’]\n\n             ## Input ##: fast (in the context of speed)\n             ## Output ##: [’slow’, ’sluggish’, ’leisurely’, ’gradual’]\n\n             ## Input ##: old (in the context of age)\n             ## Output ##: [’young’, ’new’, ’fresh’, ’modern’]\n\n\n\n             Determine the sentence that is the cause in each pair. Remember to thoroughly\n             comprehend the meaning of each sentence before selecting the cause. Additionally,\nCause         verify your output to ensure that you only include the sentence that is the cause. To\nEffect         aid in identifying cause and effect relationships, consider using keywords or phrases\n                 that indicate causality, analyzing the context of each sentence, and practicing with\n              feedback and interactive activities.\n\n              For each input, come up with a category or characteristic that they have in common\nCommon     and write it as the output. Use your knowledge and experience to make educated\nConcept      guesses and be creative in your thinking. Also, try to keep the output concise and\n                  clear.\n\n               Subtract the second number from the first number and give me the result. Make sure\nDiff\n                to double check your calculations and write the answer as a string in a list format.\n\nContinued next page for Table 29\n\n\n\n\n\n                                       41\n\nContinuation of Table 29\n\n              Write a program that takes in a word and returns a list containing the first letter of the\n            word as a string. The program will be used to label items in a game.\n\n           Make sure to handle cases where the input word  is empty or only contains\n               whitespace. You can use the string method ‘strip()‘ to remove any leading or trailing\n               whitespace. If the input is empty or contains only whitespace, return an empty list.\n\n            To ensure that your program works correctly, test  it with the following exam-\n                 ples:\n\n            Example 1:\n                Input: \"apple\"\nFirst Word   Output: [\"a\"]\nLetter\n            Example 2:\n                Input: \" banana\"\n              Output: [\"b\"]\n\n            Example 3:\n                Input: \"\"\n              Output: []\n\n            Example 4:\n                Input: \" \"\n              Output: []\n\n\n            Reword the following sentences using more formal language, but also provide\n                 alternative rewordings that are more appropriate for different contexts:\n\n                 1. \"Regrettably, I am unable to attend the meeting tomorrow.\" (formal)\n                Alternative: \"Unfortunately, I won’t be able to make it to the meeting tomorrow.\"\n                (casual)\n\n                 2. \"I must depart now, farewell!\" (overly formal)\n                Alternative: \"I have to go now, see you later!\" (casual)\nInformal\nFormal         3. \"I apologize, but I am unable to assist you with that matter.\" (formal)\n                Alternative: \"I’m sorry, but I can’t help you with that.\" (casual)\n\n                 4. \"Thank you for the invitation, however, I am unable to attend.\" (formal)\n                Alternative: \"Thanks for inviting me, but I can’t make it.\" (casual)\n\n                 5. \"In my opinion, this is the optimal choice.\" (formal)\n                Alternative: \"I think this is the best option.\" (casual)\n\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       42\n\nContinuation of Table 29\n\n            Choose one animal as the output based on its size. For example, if the input pair is\n                \"elephant, mouse\", choose \"elephant\" as the output. If the input pair is \"giraffe, lion\",\n              choose \"giraffe\" as the output. Use the following criteria to choose the output:\n\n                  - If one animal is significantly larger than the other, choose the larger animal\n               as the output.\n                  - If the animals are similar in size, choose the animal with the name that comes first\n                alphabetically as the output.\nLarge  Ani-\nmal\n             Here are some examples of correct outputs:\n\n                   - \"whale, dolphin\" -> choose \"whale\" as the output\n                   - \"panda, koala\" -> choose \"panda\" as the output\n                   - \"tiger, zebra\" -> choose \"tiger\" as the output\n\n             Choose the output carefully to avoid confusion and errors.\n\n\n               Please write a program that takes in a word as input and outputs a list of its letters\n               separated by spaces. The output should be a list with one element containing the\n               separated letters in the same order as the input word.\n\n            To ensure the program works correctly, please follow these guidelines:\n\n                1.   Input validation:  Check that the input  is a non-empty string containing\n              only alphabetic characters. If the input is invalid, print an error message and exit the\n              program.\n\n                 2.  Separating the letters:  Use the ‘split()‘ method to separate the letters of\n                the input word.\n\n                 3.   Expected output format:  The output should be a  list with one element\nLetters List   containing the separated letters in the same order as the input word.\n\n             Here are some examples of valid and invalid input:\n\n               Valid input: \"hello\"\n              Expected output: [\"h\", \"e\", \"l\", \"l\", \"o\"]\n\n                Invalid input: \"hello world\"\n              Expected output: \"Error: Input must be a non-empty string containing only alphabetic\n                characters.\"\n\n                Invalid input: \"123\"\n              Expected output: \"Error: Input must be a non-empty string containing only alphabetic\n                characters.\"\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       43\n\nContinuation of Table 29\n\n                \"List all the animals from the given inputs.\"\n\n             ## Input ##: apple, banana, orange, kiwi, grape\n             ## Output ##: []\n\n             ## Input ##: dog, cat, fish, bird, hamster\n             ## Output ##: [’dog’, ’cat’, ’fish’, ’bird’, ’hamster’]\n\nTaxonomy\n             ## Input ##: elephant, giraffe, lion, tiger, zebra\nAnimal\n             ## Output ##: [’elephant’, ’giraffe’, ’lion’, ’tiger’, ’zebra’]\n\n             ## Input ##: pencil, eraser, notebook, ruler, pen\n             ## Output ##: []\n\n             ## Input ##: turtle, snake, lizard, frog, salamander\n             ## Output ##: [’turtle’, ’snake’, ’lizard’, ’frog’, ’salamander’]\n\n\n              For each input, negate the specified part of the statement and write it as an output.\n\n                1.  Negate the part about using the gold color: \"We will use gold as the pri-\n            mary color for our new logo.\" Output: \"We will not use gold as the primary color for\n              our new logo.\"\n\nNegation       2.  Negate the part about Gary Kubiak participating as a player:  \"Gary Ku-\n              biak will play as a quarterback in the upcoming game.\" Output: \"Gary Kubiak will\n               not play as a quarterback in the upcoming game.\"\n\n              Note: When negating statements with proper nouns or names, simply negate\n                the verb or action associated with the noun or name.\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       44\n\nContinuation of Table 29\n\n              Convert a given number into its English word representation, including commas for\n              thousands and negative sign if applicable.\n\n             ## Input 1 ## : 1234\n             ## Output 1 ##: [’one thousand two hundred and thirty-four’]\n\n             ## Input 2 ## : 987654321\n            ## Output 2 ##: [’nine hundred and eighty-seven million six hundred and fifty-four\n              thousand three hundred and twenty-one’]\n\nNum Verbal\n             ## Input 3 ## : 0\n             ## Output 3 ##: [’zero’]\n\n             ## Input 4 ## : -42\n             ## Output 4 ##: [’negative forty-two’]\n\n             ## Input 5 ##: 999999999\n             ## Output 5 ##: [’nine hundred and ninety-nine million nine hundred and ninety-nine\n              thousand nine hundred and ninety-nine’]\n\n\n               Passive Voice Practice:\n               In passive voice, the subject of the sentence receives the action instead of performing\n                        it. Rewrite each sentence in passive voice.\n\n             Example: The dog chased the cat.\n               Passive voice: The cat was chased by the dog\n\n                 1. The teacher graded the exams.\n                 2. The company launched a new product.\n                 3. The chef cooked a delicious meal.\n                 4. The team won the championship.\nActive  Pas-   5. The doctor prescribed medication for the patient.\nsive\n                Instructions:\n                   - Rewrite each sentence in passive voice.\n                   - Make sure the subject of the sentence receives the action instead of performing it.\n                   - Use the examples provided to guide you.\n                   - Check your work for accuracy and clarity.\n\n              Feedback:\n                   - If you have any questions or need clarification, please ask.\n                   - Practice makes perfect! Keep practicing to improve your writing skills.\n                   - If you make any mistakes, don’t worry! Learn from them and try again\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       45\n\nContinuation of Table 29\n\n           Add an \"s\" or the correct plural form to the end of the input word, depending on the\n               following rules:\n\n                1.  If the word ends in \"y\" with a consonant before it, change the \"y\" to \"ies\"\n                instead of just adding an \"s\".\n                 2. If the word ends in \"f\" or \"fe\", change the \"f\" or \"fe\" to \"ves\" instead of just adding\n             an \"s\".\n                 3. If the word is already plural, return the input word as is instead of adding an \"s\".\n                4. If the word has an irregular plural form, return the correct plural form instead of\n                  just adding an \"s\".\n\n             Examples:\n\n                   - Input: cat\n              Output: cats\n\n                   - Input: book\n              Output: books\n\nSingular       - Input: car\nPlural        Output: cars\n\n                   - Input: tree\n              Output: trees\n\n                   - Input: computer\n              Output: computers\n\n                   - Input: story\n              Output: stories\n\n                   - Input: half\n              Output: halves\n\n                   - Input: aircraft\n              Output: aircraft\n\n                   - Input: century\n              Output: centuries\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       46\n\nContinuation of Table 29\n\n               Create a list of words that rhyme with the given word. To ensure that your rhymes are\n                accurate, make sure that the words have the same vowel sound and ending consonant\n               sound. For example, \"cat\" rhymes with \"bat\" and \"hat,\" but not with \"dog\" or \"mat.\"\n\n            To get started, here are some examples of words that rhyme with the given\n              word:\n\n                   - Love: dove, glove, above, shove, of\n                   - Time: rhyme, chime, climb, mime, prime\n\n            To find more rhyming words, you can use a rhyming dictionary, online re-\n               sources, or brainstorm with friends. Be creative and try to use a variety of different\nRhymes      rhyming words instead of repeating the same one multiple times.\n\n            To avoid common pitfalls, make sure to double-check your spelling and pro-\n               nunciation of the words. Also, avoid using words that only partially rhyme or have a\n                 different stress pattern.\n\n               After you’ve created your list, ask for feedback on the quality of your rhymes. This\n              can help you to improve and refine your skills.\n\n              For an added challenge, consider generating rhyming words that  fit a particu-\n                  lar theme or context. This can help you to focus your creativity and generate more\n                 interesting and relevant rhymes.\n\n\n              For each input word with at least two letters, identify and output the second letter.\n               Please ensure that the input is a valid word in the specified language or dialect to\n               prevent errors. The prompt is case-insensitive, so it will work for both uppercase and\n              lowercase letters.\n\n              Examples:\nSecond         - Input: \"hello\" Output: \"e\"\nWord Letter   - Input: \"apple\" Output: \"p\"\n                   - Input: \"book\" Output: \"o\"\n\n               Please note that the language or dialect of the input should be specified to\n               avoid confusion with words that have different spellings or pronunciations in different\n                regions.\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       47\n\nContinuation of Table 29\n\n              Rate the similarity of two given sentences on a scale of 1 to 5, where 1 indicates a\n                significant difference in meaning and 5 indicates almost identical meaning. Please\n               consider the following factors when rating:\n\n                   - The overall message and purpose of the sentences\n                   - The structure and syntax of the sentences\n                   - The use of key words and phrases\n\n              Provide a  brief explanation for your  rating,  taking into account any minor\n               differences in wording or details that may affect the similarity rating. Additionally,\n               please provide context for the sentences being compared, such as the intended\nSentence\n              audience or purpose.\nSimilarity\n\n              For reference, here are some examples of sentences that  fall into each cate-\n               gory:\n\n             Highly similar:  \"The cat sat on the mat\" and \"The mat was sat on by the\n                cat\"\n              Moderately similar: \"I enjoy playing soccer\" and \"Soccer is a fun sport to play\"\n             Not similar at all: \"The sky is blue\" and \"I am going to the beach tomorrow\"\n\n            Thank you for your evaluation and explanation.\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       48\n\nContinuation of Table 29\n\n               Please analyze the following statements and determine their overall sentiment as\n                 either [’negative’, ’neutral’, ’positive’]. Keep in mind the context and any figurative\n              language used.\n\n                 1. The sun is shining and the birds are singing.\n              Output: [’positive’]\n\n                 2. I failed my exam and now I have to retake the class.\n              Output: [’negative’]\n\n                 3. My best friend surprised me with a thoughtful gift.\n              Output: [’positive’]\n\n                 4. The traffic on the highway was backed up for miles.\n              Output: [’negative’]\n\nSentiment\n                 5. I received a promotion at work and a raise in salary.\n              Output: [’positive’]\n\n                 6. A non-mystery mystery.\n              Output: [’neutral’]\n\n                 7. Little more than a well-mounted history lesson.\n              Output: [’neutral’]\n\n                 8. Too daft by half ... but supremely good natured.\n              Output: [’positive’]\n\n              Note:  This prompt uses more sophisticated language analysis techniques to\n                 better understand the sentiment of the input. However, providing more context for the\n               input is still important for accurate sentiment analysis.\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       49\n\nContinuation of Table 29\n\n               SIdentify the first word or phrase that starts with the letter given in the input. The\n                identified word or phrase should not contain any punctuation or special characters,\n             and should be case-insensitive. If there are no words or phrases starting with the given\n                    letter, return an empty list.\n\n             Here are the input-output pairs:\n\n                Input: She sang a beautiful song to the audience. [b]\n              Output: [’beautiful’]\n\n                Input: The cat chased the mouse. [c]\n              Output: [’cat’]\n\n                Input: It is important to always be kind to others. [i]\n              Output: [’important’]\n\n                Input: The dog barked loudly, frightening the neighbors. [l]\n              Output: [’loudly’]\n\nOrthography\n                Input: The book is on the shelf. [s]\nStarts With\n              Output: [’shelf’]\n\n                Input: The baby cried all night. [n]\n              Output: []\n\n                Input: The teacher gave a long lecture on the history of art. [l]\n              Output: [’lecture’]\n\n                Input: The car drove down the street, passing by many shops. [s]\n              Output: [’street’]\n\n                Input: To the boy’s delight, he received a new toy for his birthday. [t]\n              Output: [’toy’]\n\n              Note:   If there are multiple words or phrases starting with the given  letter,\n               the prompt will return the first one encountered.  If the input contains multiple\n               sentences or clauses, the prompt will identify the first word or phrase that starts with\n                the given letter in the entire input text. The output will be in lowercase\n\n\n              \"Write a program that takes two numbers as input and returns their sum as a string in a\n                      list. Make sure to test your program with different inputs to ensure it works correctly.\n            Remember to convert the input numbers to integers before adding them together, and\nSum          then convert the sum back to a string before putting it in a list. Also, make sure to use\n                the correct syntax for creating a list with one element (i.e. use square brackets around\n                the string). Good luck!\"\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       50\n\nContinuation of Table 29\n\n               Please provide a list of synonyms for the given words that convey a similar meaning\n             and are commonly used in everyday language. Be sure to double-check your spelling\n             and grammar before submitting.\n\n              For example,  if the word is \"happy,\" acceptable synonyms could be \"joyful,\"\n                \"pleased,\" or \"content.\"\n\nSynonym\n               Please use gender-neutral language and avoid using words with different con-\n               notations or meanings. If you notice any incorrect synonyms, please flag them and\n               provide feedback for improvement.\n\n            Words to avoid using as synonyms include those with different connotations\n               or meanings, such as \"ecstatic\" for \"happy\" or \"depressed\" for \"sad.\"\n\n\n               Translate the following English words into German.\n\n             ## Input ## : happy\n             ## Output ##: [’glücklich’]\n             ## Input ## : love\n             ## Output ##: [’Liebe’]\n             ## Input ## : cat\n             ## Output ##: [’Katze’]\n             ## Input ## : dog\n             ## Output ##: [’Hund’]\n             ## Input ## : house\nTrans En De\n             ## Output ##: [’Haus’]\n             ## Input ## : tree\n             ## Output ##: [’Baum’]\n             ## Input ## : water\n             ## Output ##: [’Wasser’]\n             ## Input ## : sun ## Output ##: [’Sonne’]\n             ## Input ## : moon\n             ## Output ##: [’Mond’]\n             ## Input ## : star\n             ## Output ##: [’Stern’]\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       51\n\nContinuation of Table 29\n\n              Convert these English terms into their corresponding Spanish translations.\n\n             ## Input ## : happy\n             ## Output ##: [’feliz’]\n             ## Input ## : beach\n             ## Output ##: [’playa’]\nTrans En Es  ## Input ## : computer\n             ## Output ##: [’computadora’]\n             ## Input ## : book\n             ## Output ##: [’libro’]\n             ## Input ## : music\n             ## Output ##: [’música’]\n\n\n               Translate the following English words into French.\n\n             ## Input ## : happy\n             ## Output ##: [’heureux’]\n             ## Input ## : love\n             ## Output ##: [’amour’]\n             ## Input ## : family\n             ## Output ##: [’famille’]\n             ## Input ## : friend\n             ## Output ##: [’ami’]\n             ## Input ## : music\nTrans En Fr  ## Output ##: [’musique’]\n             ## Input ## : beach\n             ## Output ##: [’plage’]\n             ## Input ## : book\n             ## Output ##: [’livre’]\n             ## Input ## : movie\n             ## Output ##: [’film’]\n             ## Input ## : food\n             ## Output ##: [’nourriture’]\n             ## Input ## : travel\n             ## Output ##: [’voyage’]\n\n\nContinued next page for Table 29\n\n\n\n\n\n                                       52\n\nContinuation of Table 29\n\n            Compare the usage of a given word in two different sentences and determine if they\n             have the same or different meanings based on the context of the sentences. Write\n             \"same\" or \"not the same\" as the output.\n\n            To avoid ambiguity and ensure  clarity,  please provide  sufficient context for\n               the sentences. If the word has multiple meanings depending on the context, please\n                indicate all correct answers.\nWord    In\nContext\n              For example, consider the word \"bank.\" In the sentence \"I need to deposit\n          my paycheck at the bank,\" and \"I sat on the bank of the river and watched the sunset,\"\n                the word \"bank\" has different meanings. Therefore, the correct answer would be \"not\n                the same.\"\n\n               Please note that the comparison should be based on the context of the sentences, not\n                  just the isolated word\n\n\n                                       Table 29: APE Prompts\n\n\n\n\n\n                                       53",
"headers": [
"arXiv:2402.11347v2  [cs.CL]  12 Jul 2025",
"SEE: Strategic Exploration and Exploitation for Cohesive In-Context",
"Prompt Optimization"
],
"tables": [
"|of instruc-<br>d by E as<br>Our goal<br>or the op-<br>mizes the Exp|lore Exploit|\n|---|---|\n|||",
"|mally de-<br>em:<br>A) | L\u0003,<br>(1)<br>a natural Exp|loit Explore|\n|---|---|\n|<br>Global Optima|Local Optima<br>In-Context Prompt|",
"|Operator|Add Remove Parents|Prob Speed Cost|\n|---|---|---|\n|Lamarckian<br>Feedback<br>EDA<br>Crossover<br>Semantic|✓<br>-<br>-<br>✓<br>✓<br>-<br>-<br>-<br>✓<br>-<br>-<br>✓<br>-<br>✓<br>-|-<br>-<br>_•_<br>_• •_<br>_• • ••_<br>_••_<br>_• • ••_<br>_••_<br>_•_<br>_• • ••_<br>_••_<br>_•_<br>_• • •_<br>_• • •_<br>_•_|",
"|Method|Causal Dis Dyck Formal Logical Color Salient<br>Hyperbaton<br>Judgement -ambiguation Languages Fallacies Five Reasoning Translation|\n|---|---|",
"|OPRO (Yang et al., 2023a<br>EvoPrompt (Guo et al., 20<br>AELP (Hsieh et al., 2023)|) 71.94 71.53 36.73 49.51 75.92 50.00 65.55 43.88<br>23) 67.24 53.70 47.96 50.81 74.79 61.40 60.90 47.58<br>77.77 64.79 10.67 58.25 53.74 73.49 68.14 41.43|\n|---|---|",
"|SEE-io-pair<br>SEE-example|72.13 72.37 8.06 58.87 86.02 48.19 60.52 49.19<br>89.09 68.47 46.77 58.65 87.50 86.29 80.64 47.59|\n|---|---|",
"|0.65 Salient Translation|Col2|Col3|Col4|Salient T|Translation|n|Col8|Col9|0.7 Causal Judge|Col11|Col12|Col13|Causal Judge|ement 0.9 Hyperbaton|Col16|Col17|Col18|Hype|erbaton|Col21|Col22|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Lama<br>Feed<br>CR+D<br>CR<br>EDA+I<br>EDA<br>CR<br>EDA<br>CR+D<br>EDA+I<br>CR<br>CR<br>CR<br>Se<br>Iteration (operator)<br>0.40<br>0.45<br>0.50<br>0.55<br>0.60<br>0.65<br>Score value<br>High<br>Avg<br>Low|||||||||ma<br><br>Lama<br>Feed<br>CR<br>CR+D<br>EDA<br>EDA+I<br>CR+D<br>CR+D<br>EDA+I<br>Iteration (op<br>0.4<br>0.5<br>0.6<br><br>Score value<br>High<br>|||||CR<br>EDA+I<br>EDA+I<br>EDA+I<br>EDA+I<br>Sema<br> erator)<br>Avg<br>Low<br>Lama<br>Feed<br>CR<br>EDA<br>EDA+I<br>EDA+I<br>EDA+I<br>CR+D<br>EDA+I<br>CR+D<br>EDA<br>Sema<br>Sema<br>Sema<br>Se<br>Iteration (operator)<br>0.6<br>0.7<br>0.8<br>.<br>Score value<br>~~High~~<br>~~Avg~~<br>~~Low~~||||||||\n|Lama<br>Feed<br>CR+D<br>CR<br>EDA+I<br>EDA<br>CR<br>EDA<br>CR+D<br>EDA+I<br>CR<br>CR<br>CR<br>Se<br>Iteration (operator)<br>0.40<br>0.45<br>0.50<br>0.55<br>0.60<br>0.65<br>Score value<br>High<br>Avg<br>Low||||||||||||||||||||||\n|Lama<br>Feed<br>CR+D<br>CR<br>EDA+I<br>EDA<br>CR<br>EDA<br>CR+D<br>EDA+I<br>CR<br>CR<br>CR<br>Se<br>Iteration (operator)<br>0.40<br>0.45<br>0.50<br>0.55<br>0.60<br>0.65<br>Score value<br>High<br>Avg<br>Low||||Hih|Av|||Low|Low||||High<br>|High<br>||||~~High~~|~~Avg~~||~~Low~~|",
"|66.93|52.41|62.90|37.39|\n|---|---|---|---|",
"|EvoPrompt-fs|57.43|43.54|79.83|31.45|\n|---|---|---|---|---|",
"|Method|Causal Judgement<br>Average score High score|Disambiguation<br>Average score High score|Hyperbaton<br>Average score High score|\n|---|---|---|---|\n|Random Evo<br>SEE|67_._70(0_._75)<br>70_._28(0_._56)<br>**69.88**(2_._17)<br>**72.00**(3_._09)|58_._22(2_._47)<br>61_._3(3_._17)<br>**60.32**(2_._73)<br>**62.9**(2_._56)|83_._00(0_._15)<br>87_._8(0_._00)<br>**83.52**(0_._71)<br>**87.8**(0_._00)|",
"|Method|Causal Judgement<br>Average score High score|Disambiguation<br>Average score High score|Hyperbaton<br>Average score High score|\n|---|---|---|---|\n|Cosine distance<br>Hamming distance|64_._70(2_._31)<br>67_._86(2_._47)<br>**65.74**(2_._87)<br>**69.60**(2_._97)|58_._96(1_._47)<br>63_._30(0_._00)<br>**64.11**(1_._28)<br>**66.94**(2_._88)|74_._70(1_._60)<br>85_._7(0_._00)<br>**79.30**(4_._48)<br>**86.78**(2_._15)|",
"|80<br>Without Phase 1<br>75 Without Phase 2<br>72.37 Without Phase 3<br>70 SEE<br>66.94 Score<br>65 63.71 64.52<br>Performance<br>60 58.87<br>55 54.03<br>52.41<br>50.80<br>50<br>45<br>40|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|<br> <br>40<br>45<br>50<br>55<br>60<br>65<br>70<br>75<br>80<br>Performance Score<br>~~63.71~~<br>50.80<br>66.94<br>~~54.03~~<br>64.52<br>52.41<br>72.37<br>~~58.87~~<br>Without Phase 1<br>~~Without Phase 2~~<br>Without Phase 3<br>SEE|||72.37|72.37|72.37|72.37|With<br>~~With~~<br>With<br>SEE|out Phase 1<br>~~out Phase 2~~<br>out Phase 3|\n|<br> <br>40<br>45<br>50<br>55<br>60<br>65<br>70<br>75<br>80<br>Performance Score<br>~~63.71~~<br>50.80<br>66.94<br>~~54.03~~<br>64.52<br>52.41<br>72.37<br>~~58.87~~<br>Without Phase 1<br>~~Without Phase 2~~<br>Without Phase 3<br>SEE|~~63.71~~<br>66.9|~~63.71~~<br>66.9|4<br>64.52|||||~~58.87~~|\n|<br> <br>40<br>45<br>50<br>55<br>60<br>65<br>70<br>75<br>80<br>Performance Score<br>~~63.71~~<br>50.80<br>66.94<br>~~54.03~~<br>64.52<br>52.41<br>72.37<br>~~58.87~~<br>Without Phase 1<br>~~Without Phase 2~~<br>Without Phase 3<br>SEE|||||50.80<br>~~5~~|50.80<br>~~5~~|~~4.03~~<br>52.4|1|\n|<br> <br>40<br>45<br>50<br>55<br>60<br>65<br>70<br>75<br>80<br>Performance Score<br>~~63.71~~<br>50.80<br>66.94<br>~~54.03~~<br>64.52<br>52.41<br>72.37<br>~~58.87~~<br>Without Phase 1<br>~~Without Phase 2~~<br>Without Phase 3<br>SEE|||||||||\n|<br> <br>40<br>45<br>50<br>55<br>60<br>65<br>70<br>75<br>80<br>Performance Score<br>~~63.71~~<br>50.80<br>66.94<br>~~54.03~~<br>64.52<br>52.41<br>72.37<br>~~58.87~~<br>Without Phase 1<br>~~Without Phase 2~~<br>Without Phase 3<br>SEE|||||||||\n|4: P<br>**t of**<br>od is<br>, enc<br>urat<br>|4: P<br>**t of**<br>od is<br>, enc<br>urat<br>|Disamb<br>  erform<br>**  Oper**<br>  desi<br> ompa<br>ions.<br>|iguation<br>  ance<br>**  ator**<br>  gned<br> ssing<br> Unde<br>|QA<br>   com<br>**  s on**<br>   to<br>  bot<br> rsta<br>|paris<br>**    P**<br>    exp<br>  h z<br> ndi<br>|For<br>   on w<br>**    rom**<br>    lore<br>   ero-s<br> ng ho<br>|mal Falla<br>    ith ph<br>**    pt Le**<br>     the<br>   hot a<br>  w pr<br>|cies<br>     ases re<br>**     ngth**<br>      full p<br>    nd few<br>   ompt l<br>|",
"|API Calls Token Consumptio|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|on|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|mptBreeder<br>0.0<br>0.2<br>0.4<br>0.6<br>0.8<br>1.0<br>1.2<br>Token Consumption<br>1e6<br> n|\n|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|||||||||||||\n|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|||||||||||||\n|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|||||||||||||\n|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio|||||||||||||\n|SEE<br>APO<br>EvoPrompt<br>APE<br>AELP<br>OPRO<br>Pro<br>104<br>105<br>106<br>Number of API Calls (log scale)<br>API Calls<br>Token Consumptio||E|E|A|PO<br>EvoP|PO<br>EvoP|rompt|A|PE<br>A|ELP|OPRO<br>Pro|OPRO<br>Pro|",
"|Operator|OPRO EvoPrompt AELP PromptBreeder APE APO SEE|\n|---|---|",
"|Lamarckian Operator<br>Feedback Operator<br>Crossover Operator<br>EDA Operator<br>Semantic Operator|✓ ✓ - ✓ ✓ - ✓<br>- - - - - ✓ ✓<br>- ✓ - ✓ - - ✓<br>✓ - - ✓ - - ✓<br>- ✓ ✓ ✓ ✓ ✓ ✓|\n|---|---|",
"|Operator In-<br>put|I gave a friend an instruction and some examples The friend read the instruction and<br>wrote an output for every one of the inputs.<br>Here are the input-output pairs:<br>## Example ##<br>## Input ## : 92 24<br>## Output ##: [’68’]<br>The instruction was:|\n|---|---|",
"|Operator<br>Output|Subtract the second number from the first number and write the result. If the result is<br>negative, write the absolute value of the result.<br>Here are the input-output pairs:<br>Input: 10 5<br>Output: [’5’]<br>Input: 50 75<br>Output: [’25’]<br>Input: 100 100<br>Output: [’0’]<br>Input: 7 20<br>Output: [’13’]<br>Input: 0 5<br>Output: [’5’]<br>Input: -10 5<br>Output: [’15’]<br>Input: 92 24<br>Output: [’68’]<br>Input: 50 -75<br>Output: [’125’]|\n|---|---|",
"|Original<br>Prompt|For each word, find its antonym and write it as the output.|\n|---|---|",
"|Generated<br>Feedback|1. Clarify the definition of \"antonym\" to ensure that the prompt is asking for the op-<br>posite meaning of the word, rather than just a different word that is related in some way.<br>2. Provide more specific instructions for determining the antonym, such as<br>indicating whether the opposite meaning should be an adjective or a noun.<br>3. Add a list of common antonyms for each word to help users who may not<br>be familiar with all possible opposites.<br>4. Provide a context or sentence for each word to help users determine the<br>appropriate antonym.|\n|---|---|",
"|1. Clarify the d|efinition of \"antonym\" to en|Col3|sure that th|e promp|t is askin|g for|the|op-|\n|---|---|---|---|---|---|---|---|---|\n|posite meaning|of the word, rather t|han just a|different wo|rd that i|s related|in some|in some|way.|",
"|2. Provide mo|re specific instru|ctions f|or determin|ing the|antony|m, s|uch|Col9|as|\n|---|---|---|---|---|---|---|---|---|---|\n|indicating whet|her the opposite meaning sh|her the opposite meaning sh|ould be an a|djective|or a no|un.|un.|un.|un.|",
"|3. Add a list o|f common antonyms for|Col3|each word|to help|users w|ho m|ay|not|\n|---|---|---|---|---|---|---|---|---|\n|be familiar with|all possible oppos|ites.|||||||",
"|4. Provide a c|ontext or sentenc|e for ea|ch word t|o help|users de|termine|the|\n|---|---|---|---|---|---|---|---|\n|appropriate anto|appropriate anto|appropriate anto|appropriate anto|appropriate anto|appropriate anto|appropriate anto|appropriate anto|",
"|Generated<br>Prompt|For each word, find its antonym, which is a word that has the opposite meaning, and<br>write it as the output. The antonym should be a word that is commonly used to express<br>the opposite meaning of the given word, and it should be of the same part of speech<br>(e.g. noun, verb, adjective, adverb).<br>To help you identify the antonym, we have provided a list of common antonyms for<br>each word. Additionally, we have included a context or sentence for each word to help<br>you determine the appropriate antonym.<br>Example:<br>Word: Hot<br>Antonym: Cold<br>Context: The soup is too hot to eat.<br>Please note that some words may have multiple antonyms depending on the context,<br>so use your best judgment to determine the most appropriate one.|\n|---|---|",
"|appropriate antonym.|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|For each word, find its antonym, w|For each word, find its antonym, w|hich is a|word that h|as the o|pposite|meani|ng,|and|\n|write it as the ou|tput. The antonym|should b|e a word tha|t is com|monly us|ed to|exp|ress|\n|the opposite me|aning of the given|word, an|d it should|be of the|same p|art of|speech|speech|\n|(e.g. noun, verb|, adjective, adverb)|.|.|.|.|.|.|.|",
"|To help you ide|ntify the antonym,|we have|provided a|list of co|mmon a|ntonyms|Col8|for|\n|---|---|---|---|---|---|---|---|---|\n|each word. Addi|tionally, we have i|ncluded a|context or s|entence|for each|word|to|help|\n|you determine t|he appropriate antonym.|he appropriate antonym.|||||||",
"|Example:<br>Word: Hot|Col2|\n|---|---|\n|Antonym: Cold|Antonym: Cold|\n|Context: The s|oup is too hot to ea|",
"|Please note that|some words may|have mul|tiple antony|ms depe|nding o|n the|con|text,|\n|---|---|---|---|---|---|---|---|---|\n|so use your best|judgment to deter|mine the|most appro|priate on|priate on|priate on|priate on|priate on|",
"|Original<br>Prompt|For each word, remove the prefix or suffix that indicates a negative or opposite<br>meaning, and write the resulting word as the output.<br>For example, for the input \"destabilize,\" remove the prefix \"de-\" which indi-<br>cates a negative meaning, and the resulting word is \"stabilize|\n|---|---|",
"|Generated<br>Feedback|1.Clarify the prompt to specify that it only applies to words with a negative or opposite<br>prefix or suffix. This will prevent confusion and mistakes when dealing with words<br>that do not have such affixes.<br>2. Provide examples of common negative or opposite prefixes and suffixes,<br>such as \"un-\" or \"-less,\" to help users identify them more easily.<br>3. Include a check to ensure that the resulting word is a valid English word,<br>to avoid outputs like \"ane\" or \"direct\" that are not actual words. This could be done by<br>cross-referencing the output with a dictionary or word list.<br>4. Consider adding an option to retain the original word if no negative or op-<br>posite prefix or suffix is present. This would eliminate confusion when dealing with<br>words like \"linear\" that do not have such affixes.|\n|---|---|",
"|1.Clarify the prompt to spe|cify that it only applies to word|Col3|s with a|negative|or op|posite|\n|---|---|---|---|---|---|---|\n|prefix or suffix. This will p|revent confusion and mis|tak|es when|dealing|with|words|\n|that do not have such affix|es.|es.|es.|es.|es.|es.|",
"|2. Provide examples of|common negative or oppo|site pre|fixes a|nd su|ffixes,|\n|---|---|---|---|---|---|\n|such as \"un-\" or \"-less,\" to|help users identify them more|easily.||||",
"|3. Include a check to en|sure that the resulting wor|d is a v|alid En|glish|word,|\n|---|---|---|---|---|---|\n|to avoid outputs like \"ane\"|or \"direct\" that are not actual w|ords. T|his coul|d be d|one by|\n|cross-referencing the outpu|t with a dictionary or word li|st.|st.|st.|st.|",
"|4. Consider adding an o|ption to retain the original|word if|no neg|ative|or op-|\n|---|---|---|---|---|---|\n|posite prefix or suffix is pr|esent. This would eliminate c|onfusion|when|dealin|g with|\n|words like \"linear\" that do|words like \"linear\" that do|words like \"linear\" that do|words like \"linear\" that do|words like \"linear\" that do|words like \"linear\" that do|",
"|Generated<br>Prompt|For each word that contains a negative or opposite prefix or suffxi, remove the affxi<br>and write the resulting word as the output. Common negative or opposite prefixes and<br>suffixes include \"un-,\" \"dis-,\" \"in-,\" \"-less,\" and \"-ful.\" Please note that this prompt<br>only applies to words with these specific affixes.<br>To ensure that the resulting word is a valid English word, we will cross-refer-<br>ence the output with a dictionary or word list. If the resulting word is not a valid<br>English word, it will be excluded from the output.<br>If the original word does not contain a negative or opposite prefix or suffix,<br>you may choose to retain the original word or exclude it from the output. Please<br>specify your preference in the input.|\n|---|---|",
"|and write the resulting wor|d as the output. Common nega|tive or o|pposite|prefix|es and|\n|---|---|---|---|---|---|\n|suffixes include \"un-,\" \"di|s-,\" \"in-,\" \"-less,\" and \"-ful.\"|Please n|ote that|this p|rompt|\n|only applies to words with|these specific affixes.|these specific affixes.|these specific affixes.|these specific affixes.|these specific affixes.|",
"|To ensure that the resulti|ng word is a valid English|word,|we will|cross|-refer-|\n|---|---|---|---|---|---|\n|ence the output with a dic|tionary or word list. If the r|esulting|word is|not a|valid|\n|English word, it will be ex|cluded from the output.|cluded from the output.|cluded from the output.|cluded from the output.|cluded from the output.|",
"|If the original word doe|s not contain a negative|or|opposi|te pref|ix or|suffix,|\n|---|---|---|---|---|---|---|\n|you may choose to retain|the original word or exclude|the original word or exclude|it from|the ou|tput.|Please|\n|specify your preference in|the input.|the input.|the input.|the input.|the input.|the input.|",
"|Operator<br>Input|Order adjectives correctly in English sentences.<br>Q: Which sentence has the correct adjective order:<br>Options:<br>(A) rubber terrible ship (B) terrible rubber ship<br>A: Let’s think step by step. When there is more than one adjective before a noun, the<br>adjectives need to respect the following order before a noun: \"[1. opinion] [2. size]<br>[3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun\". Option (A):<br>\"rubber terrible ship\". (1) rubber\" falls into the material category. (2) \"terrible\" falls<br>into the opinion category. Option (A) has the following adjective order: [7. material]<br>[1. opinion] (or, in numeric terms, 7 1). Because 7 < 1 is not correct, (A) does not have<br>the correct ordering. Option (B): \"terrible rubber ship\". Option (B) has the following<br>adjective order: [1. opinion] [7. material] (or, in numeric terms, 1 7). Because 1 < 7 is<br>correct, (B) has the correct ordering. So the answer is (B).<br>Q: Which sentence has the correct adjective order:<br>Options:<br>(A) repulsive small Brazilian exercise ship (B) Brazilian repulsive exercise small ship<br>A: Let’s think step by step. When there is more than one adjective before a noun, the<br>adjectives need to respect the following order before a noun: \"[1. opinion] [2. size]<br>[3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun\". Option (A):<br>\"repulsive small Brazilian exercise ship\". (1) \"repulsive\" falls into the opinion category.<br>(2) \"small\" falls into the size category. (3) \"Brazilian\" falls into the origin category.<br>(4) \"exercise\" falls into the purpose category. Option (A) has the following adjective<br>order: [1. opinion] [2. size] [6. origin] [8. purpose] (or, in numeric terms, 1 2 6 8).<br>Because 1 < 2 < 6 < 8 is correct, (A) has the correct ordering. Option (B): \"Brazilian<br>repulsive exercise small ship\". Option (B) has the following adjective order: [6. origin]<br>[1. opinion] [8. purpose] [2. size] (or, in numeric terms, 6 1 8 2). Because 6 < 1 < 8 < 2<br>is not correct, (B) does not have the correct ordering. So the answer is (A).<br>Q: Which sentence has the correct adjective order:<br>Options:<br>(A) blue gold wonderful square shoe (B) wonderful square blue gold shoe<br>A: Let’s think step by step. When there is more than one adjective before a noun, the<br>adjectives need to respect the following order before a noun: \"[1. opinion] [2. size] [3.<br>age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun\". Option (A): \"blue<br>gold wonderful square shoe\". (1) \"blue\" falls into the color category. (2) \"gold\" falls<br>into the material category. (3) \"wonderful\" falls into the opinion category. (4) \"square\"<br>falls into the shape category. The adjective order that Option (A) has is [5. color] [7.<br>material] [1. opinion] [4. shape] (or, in numeric terms, 5 7 1 4). Because 5 < 7 < 1 < 4<br>is not correct, (A) does not have the correct ordering. Option (B): \"wonderful square<br>blue gold shoe\". Option (B) has the following adjective order: [1. opinion] [4. shape] [5.<br>color] [7. material] (or, in numeric terms, 1 4 5 7 ). Because 1 < 4 < 5 < 7 is correct, (B)<br>has the correct ordering. So the answer is (B).|\n|---|---|",
"|Operator<br>Output|Rearrange the adjectives in the given sentence in the correct order.|\n|---|---|",
"|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|Col18|Col19|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|||||||||||||||||||Step 1<br>Step 2<br>Step 3<br>Step 4<br>|\n||||||||||||||||||||\n||||||||||||||||||||\n||||||||||||||||||||\n||||||||||||||||||||\n||||||||||||||||||||\n||||||||||||||||||||\n||||||||||||||||||||",
"|Ex|ist|ing|Prompt|\n|---|---|---|---|",
"|ways|to|im|prove|\n|---|---|---|---|",
"|adding|res|tric|tions|\n|---|---|---|---|",
"|nor|pro|vid|ing|any|dif|fer|en|ti|a|tion|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|pass|ing|in|the|ex|ist|ing|\n|---|---|---|---|---|---|---|",
"|prompt|as|a|whole|\n|---|---|---|---|",
"|Ex|ist|ing|Prompt|\n|---|---|---|---|",
"|##|Im|proved|Prompt|##|\n|---|---|---|---|---|",
"|The|se|ries|of|prompts|are|ranked|by|\n|---|---|---|---|---|---|---|---|",
"|their|qual|ity|from|best|to|worst.|\n|---|---|---|---|---|---|---|",
"|same|se|man|tic|mean|ing|and|in|ten|tions.|\n|---|---|---|---|---|---|---|---|---|---|",
"|se|man|tic|\n|---|---|---|",
"|int|en|tions|\n|---|---|---|",
"|stick|to|a|sen|tence-|by-|sen|tence|mod|if|ica|tion.|\n|---|---|---|---|---|---|---|---|---|---|---|---|",
"|Method|Causal Dis Dyck Formal Logical Color Salient<br>Hyperbaton<br>Judgement -ambiguation Languages Fallacies Five Reasoning Translation|\n|---|---|",
"|SEE-pair<br>SEE-example|69.97 69.90 7.06 58.49 84.36 45.49 58.13 48.38<br>(2.45) (3.53) (1.23) (0.41) (2.24) (2.73) (2.36) (0.81)<br>84.85 68.01 35.48 53.06 81.58 73.56 77.15 47.01<br>(5.45) (0.4) (12.18) (4.95) (9.89) (8.99) (4.13) (0.88)|\n|---|---|",
"|Method|Ethos Liar Sarcasm|\n|---|---|",
"|APO (Pryzant et al., 2023)<br>SEE (GPT-3.5)<br>SEE (GPT-4)|0.95 0.51 0.85<br>0.96 0.61 0.87<br>(0.96) (3.85) (1.25)<br>0.96 0.69 0.89|\n|---|---|",
"|Task|APE<br>(zero-<br>shot)|APE<br>(few-<br>shot)|PB<br>(few-<br>shot)|MoP|Evo<br>Pro-<br>mpt|OP-<br>RO|EA-<br>SE<br>(w/in)|ZO-<br>PO<br>(best)|SEE-<br>3.5|SEE-4|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Antonyms|0.83|0.86|0.87|0.88|0.84|0.79|0.85|0.85|0.89|0.91|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Cause Effect|0.84|1|1|0.93|0.84|0.83|_|0.95|0.96|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Common Concept|0.27|0.32|0|0.38|0.11|0.09|_|0.24|0.23|0.28|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Diff|1|1|1|1|0.27|1|1|1|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|First Word Letter|1|1|1|1|_|_|_|_|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Informal Formal|0.65|0.70|0.07|0.63|0.52|0.48|_|0.62|0.6|0.67|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Large Animal|0.97|0.97|0.97|0.96|_|_|1|_|0.96|0.94|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Letters List|0.99|1|0.99|0.99|1|0.99|_|1|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Taxonomy Animal|0.66|0.79|1|0.72|0.83|0.30|1|0.90|0.96|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Negation|0.83|0.9|0.9|0.87|0.86|0.73|1|0.86|0.94|0.88|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Num Verb|1|1|1|1|_|_|_|_|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Active Passive|1|1|1|1|_|_|_|_|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Singular Plural|1|1|1|1|_|_|_|_|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Rhymes|1|0.61|1|0.94|0.60|0.23|1|1|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Second Word Letter|0.87|0.69|0.95|0.75|0.25|0.87|1|0.97|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Sentence Similarity|0.36|0.43|0.56|0.68|0.02|0.03|0.58|0.37|0.38|0.55|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Sentiment|0.94|0.93|0.93|0.97|_|_|1|_|0.94|0.94|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Orthography Starts|0.68|0.69|0.71|0.72|0.15|0.34|0.82|0.71|0.72|0.94|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Sum|1|1|1|1|1|1|1|1|1|1|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Synonym|0.22|0.14|0.43|0.26|0.40|0.40|0.32|0.45|0.46|0.38|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Trans En De|0.72|0.86|0.87|0.72|_|_|0.90|_|0.83|0.96|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Trans En Es|0.86|0.91|0.91|0.86|_|_|1|_|0.92|0.94|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Trans En Fr|0.78|0.9|0.91|0.79|_|_|0.85|_|0.88|0.93|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Word in Context|0.62|0.63|0.65|0.67|_|_|_|_|0.66|0.7|\n|---|---|---|---|---|---|---|---|---|---|---|",
"|Framework|Generated Prompt|\n|---|---|",
"|APE|write a function that takes in a string and outputs the string with the first letter<br>capitalized.|\n|---|---|",
"|Prompt<br>Breeder|Prompt 0: If the last letter of the input is ’e’, remove it.<br>Prompt 1: remove the last two letters of the input and add the letters \\xc2 \\x93mote<br>\\xc2 \\x94.<br>Contexts<br>Context 0:<br>Q. pea<br>A. If the last letter of the input is ’e’, remove it.<br>A. If the last letter of the input is ’s’, remove it.<br>A. If the last letter of the input is ’y’, remove it.<br>A. If the last letter of the input is<br>remove the last two letters of the input and add the letters \\xc2 \\x93mote \\xc2 \\x94.<br>Therefore, the correct answer is (a) pea.<br>Context 1:<br>Q. night<br>A. If the last letter of the input is ’e’, remove it.<br>A. If the last letter of the input is ’t’, remove it.<br>A. If the last letter of the input is ’h’, remove it.<br>A. If the last letter of the input is<br>remove the last two letters of the input and add the letters \\xc2 \\x93mote \\xc2 \\x94.<br>Therefore, the correct answer is (The answer is night.<br>Context 2:<br>Q. add<br>A. If the last letter of the input is ’e’, remove it.<br>A. If the last letter of the input is ’d’, remove it.<br>A. If the last letter of the input is ’a’, remove it.<br>A. If the last letter of the input is<br>remove the last two letters of the input and add the letters \\xc2 \\x93mote \\xc2 \\x94.<br>Therefore, the correct answer is (The answer is added.|\n|---|---|",
"|ZOPO|The prompts were to create a program that takes in a word as input and outputs a<br>related word based on a specific set of rules. The rules are as follows: If the input<br>word starts with “tri\", the output should be “slip\".|\n|---|---|",
"|SEE|Create a list of words that rhyme with the given word. To ensure that your rhymes are<br>accurate, make sure that the words have the same vowel sound and ending consonant<br>sound. For example, \"cat\" rhymes with \"bat\" and \"hat,\" but not with \"dog\" or \"mat.\"<br>To get started, here are some examples of words that rhyme with the given<br>word:<br>- Love: dove, glove, above, shove, of<br>- Time: rhyme, chime, climb, mime, prime<br>To find more rhyming words, you can use a rhyming dictionary, online re-<br>sources, or brainstorm with friends. Be creative and try to use a variety of different<br>rhyming words instead of repeating the same one multiple times.<br>To avoid common pitfalls, make sure to double-check your spelling and pro-<br>nunciation of the words. Also, avoid using words that only partially rhyme or have a<br>different stress pattern.<br>After you’ve created your list, ask for feedback on the quality of your rhymes. This<br>can help you to improve and refine your skills.<br>For an added challenge, consider generating rhyming words that fit a particu-<br>lar theme or context. This can help you to focus your creativity and generate more<br>interesting and relevant rhymes.|\n|---|---|",
"|Task|Ethos|\n|---|---|",
"|Input<br>Prompt|Is the following text hate speech? \\n ## Output Format ## True or False|\n|---|---|",
"|Output<br>Prompt|Your task is to evaluate whether the provided input includes any offensive language.<br>This could be language that is sexist, racist, discriminatory, or advocates violence or<br>harm. Offensive language can also be identified by an aggressive or belittling tone.<br>However, remember that the mere presence of profanity does not necessarily make a<br>statement offensive. The context and intention behind the statement should also be<br>taken into account. If none of these conditions are fulfilled, return ’False’.<br>For instance, the phrase \"You are a fool\" is offensive due to its derogatory tone, so<br>you should return ’True’. On the other hand, the phrase \"This is a damn tasty pizza\"<br>includes profanity but is not offensive, so you should return ’False’. Similarly, a phrase<br>like \"All people of X race are lazy\" is offensive because of its racist undertones, so<br>you should return ’True’. In contrast, a phrase like \"I dislike the color yellow\" is not<br>offensive, so you should return ’False’.|\n|---|---|",
"|For|Col2|in|Col4|stance|Col6|, the|Col8|phrase \"Y|Col10|ou ar|e a fo|ol\" is|of|fens|Col16|ive|du|e to i|ts derog|Col21|atory|Col23|tone,|Col25|so|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|you|you|should r|should r|should r|should r|eturn|eturn|’True’. O|’True’. O|n the|other|hand,|the|the|phrase \"|phrase \"|phrase \"|This|is a|dam|n tasty|n tasty|n tasty|pizza\"|pizza\"|\n|in|cludes|cludes|cludes|cludes|prof|an|ity|but|is not|offen|sive, s|o you|should|should|should|re|turn|’False’.|’False’.|Simi|larly,|larly,|a|phrase|phrase|\n|like|like|\"All|\"All|\"All|peo|ple o|ple o|f X|race|are lazy\" is|are lazy\" is|offen|sive|sive|be|cause|cause|of its|racist u|racist u|ndert|ndert|ones,|ones,|so|\n|you|you|should r|should r|should r|should r|eturn|eturn|’True’. In|’True’. In|cont|rast, a|phrase|phrase|like|like|\"I|disl|ike th|e color|e color|yel|low\"|low\"|is|not|\n|of|fen|fen|sive|sive|, so|you|you|should ret|should ret|urn ’False’|urn ’False’|.|.|.|.|.|.|.|.|.|.|.|.|.|.|",
"|Task|Ethos|\n|---|---|",
"|Input<br>Prompt|Is the following text hate speech? \\n ## Output Format ## True or False|\n|---|---|",
"|Output<br>Prompt|Classify the given text as hate speech or not and generate a binary output of 1 for Yes<br>and 0 for No.|\n|---|---|",
"|Task|Hyperbaton|\n|---|---|",
"|Input<br>Prompt|Order adjectives correctly in English sentences.<br>Q: Which sentence has the correct adjective order:<br>Options:<br>(A) rubber terrible ship<br>(B) terrible rubber ship<br>A: Let’s think step by step.<br>When there is more than one adjective before a noun, the adjectives need to respect<br>the following order before a noun: \"[1. opinion] [2. size] [3. age] [4. shape] [5. color]<br>[6. origin] [7. material] [8. purpose] noun\".<br>Option (A): \"rubber terrible ship\". (1) rubber\" falls into the material category. (2)<br>\"terrible\" falls into the opinion category. Option (A) has the following adjective order:<br>[7. material] [1. opinion] (or, in numeric terms, 7 1). Because 7 < 1 is not correct, (A)<br>does not have the correct ordering.<br>Option (B): \"terrible rubber ship\". Option (B) has the following adjective order: [1.<br>opinion] [7. material] (or, in numeric terms, 1 7). Because 1 < 7 is correct, (B) has the<br>correct ordering. So the answer is (B).<br>Q: Which sentence has the correct adjective order:<br>Options:<br>(A) repulsive small Brazilian exercise ship<br>(B) Brazilian repulsive exercise small ship<br>A: Let’s think step by step.<br>When there is more than one adjective before a noun, the adjectives need to respect<br>the following order before a noun: \"[1. opinion] [2. size] [3. age] [4. shape] [5. color]<br>[6. origin] [7. material] [8. purpose] noun\".<br>Option (A): \"repulsive small Brazilian exercise ship\". (1) \"repulsive\" falls into the<br>opinion category. (2) \"small\" falls into the size category. (3) \"Brazilian\" falls into<br>the origin category. (4) \"exercise\" falls into the purpose category. Option (A) has<br>the following adjective order: [1. opinion] [2. size] [6. origin] [8. purpose] (or, in<br>numeric terms, 1 2 6 8). Because 1 < 2 < 6 < 8 is correct, (A) has the correct ordering.<br>Option (B): \"Brazilian repulsive exercise small ship\". Option (B) has the following<br>adjective order: [6. origin] [1. opinion] [8. purpose] [2. size] (or, in numeric terms, 6<br>1 8 2). Because 6 < 1 < 8 < 2 is not correct, (B) does not have the correct ordering. So<br>the answer is (A).<br>...|\n|---|---|",
"|Output<br>Prompt|Identify the sentence with the correct order of adjectives: opinion, size, age, shape,<br>color, origin, material, purpose.|\n|---|---|",
"|Task|Hyperbaton|\n|---|---|",
"|Input<br>Prompt|Order adjectives correctly in English sentences.<br>Q: Which sentence has the correct adjective order:<br>Options:<br>(A) rubber terrible ship<br>(B) terrible rubber ship<br>A: Let’s think step by step.<br>When there is more than one adjective before a noun, the adjectives need to respect<br>the following order before a noun: \"[1. opinion] [2. size] [3. age] [4. shape] [5. color]<br>[6. origin] [7. material] [8. purpose] noun\".<br>Option (A): \"rubber terrible ship\". (1) rubber\" falls into the material category. (2)<br>\"terrible\" falls into the opinion category. Option (A) has the following adjective order:<br>[7. material] [1. opinion] (or, in numeric terms, 7 1). Because 7 < 1 is not correct, (A)<br>does not have the correct ordering.<br>Option (B): \"terrible rubber ship\". Option (B) has the following adjective order: [1.<br>opinion] [7. material] (or, in numeric terms, 1 7). Because 1 < 7 is correct, (B) has the<br>correct ordering. So the answer is (B).<br>Q: Which sentence has the correct adjective order:<br>Options:<br>(A) repulsive small Brazilian exercise ship<br>(B) Brazilian repulsive exercise small ship<br>A: Let’s think step by step.<br>When there is more than one adjective before a noun, the adjectives need to respect<br>the following order before a noun: \"[1. opinion] [2. size] [3. age] [4. shape] [5. color]<br>[6. origin] [7. material] [8. purpose] noun\".<br>Option (A): \"repulsive small Brazilian exercise ship\". (1) \"repulsive\" falls into the<br>opinion category. (2) \"small\" falls into the size category. (3) \"Brazilian\" falls into<br>the origin category. (4) \"exercise\" falls into the purpose category. Option (A) has<br>the following adjective order: [1. opinion] [2. size] [6. origin] [8. purpose] (or, in<br>numeric terms, 1 2 6 8). Because 1 < 2 < 6 < 8 is correct, (A) has the correct ordering.<br>Option (B): \"Brazilian repulsive exercise small ship\". Option (B) has the following<br>adjective order: [6. origin] [1. opinion] [8. purpose] [2. size] (or, in numeric terms, 6<br>1 8 2). Because 6 < 1 < 8 < 2 is not correct, (B) does not have the correct ordering. So<br>the answer is (A).<br>...|\n|---|---|",
"|Output<br>Prompt|Adjective Order Practice:<br>In English grammar, the order of adjectives is important to convey accurate<br>and effective descriptions. Here are two examples of sentences with adjectives.<br>Determine which sentence has the correct adjective order.<br>Example 1:<br>a) The big, red, round ball bounced down the street.<br>b) The round, red, big ball bounced down the street.<br>Example 2:<br>a) The delicious, homemade, chocolate cake was devoured by the guests.<br>b) The chocolate, homemade, delicious cake was devoured by the guests.<br>Choose the letter of the sentence with the correct adjective order as your an-<br>swer.<br>Note: Adjective order generally follows the pattern of opinion, size, age,<br>shape, color, origin, material, and purpose. If the adjectives do not fit into this pattern,<br>the order is determined by the speaker’s preference.<br>If you choose the incorrect sentence, we will explain why it is wrong to help<br>you learn from your mistakes. Good luck!|\n|---|---|",
"|Causal<br>Judgment|Provide reactions to intentional actions in diverse scenarios, while also con-<br>sidering causation and its complexities. To assist with determining causation,<br>provide specific guidelines and examples for each scenario. To avoid any<br>confusion or misinterpretation, precise language and definitions will be used<br>throughout the prompt. Additionally, feedback from experts and individuals<br>with relevant experience in the field of causation will be incorporated to ensure<br>accuracy and relevance. To challenge users’ critical thinking skills, include<br>diverse and complex scenarios that require creative problem-solving and a<br>deeper understanding of causation in various areas of life.|\n|---|---|",
"|Dyke Lan-<br>guages|Correctly close all brackets, including nested brackets, in the provided sequence<br>in the proper order from innermost to outermost. Mistakes such as forgetting to<br>close a bracket or closing brackets in the wrong order can result in an error. If<br>an error is made, a clear and concise message will indicate which bracket is not<br>properly closed and suggest how to correct it. A visual representation of the<br>correct sequence of closed brackets is provided below:<br>[ ( [ ( ) ] ) ]<br>Examples of valid and invalid inputs:<br>Valid input: [ ( ) ]<br>Valid input: [ ( [ ] ) ]<br>Invalid input: [ ( [ ) ]<br>Warning message: The bracket at position 8 is not properly closed. Please close<br>the bracket to ensure proper syntax.<br>Suggested correction: [ ( [ ] ) ]<br>Invalid input: [ ( [ ] ) ]<br>Warning message: The bracket at position 8 is not properly closed. Please close<br>the bracket to ensure proper syntax.<br>Suggested correction: [ ( [ ] ) ]|\n|---|---|",
"|Formal Fal-<br>lacies|Read the given argument carefully and determine whether it is deductively valid<br>or invalid based on the explicitly stated premises. Provide a justification for<br>your answer.|\n|---|---|",
"|Dis-<br>ambiguation<br>QA|For each sentence with a gender-neutral pronoun, determine the antecedent or<br>state if it is ambiguous. Use (A) for the first option, (B) for the second option,<br>or (C) for ambiguous. Additionally, provide an explanation of the antecedent<br>(the person or thing the pronoun refers to) for each sentence.|\n|---|---|",
"|Hyperbaton|Test your knowledge of adjective order in English sentences with interactive<br>exercises and quizzes. Learn the rule of opinion-size-age-shape-color-origin-<br>material-purpose noun and apply it to different types of nouns such as animals,<br>objects, and people. Practice constructing your own sentences and receive<br>feedback on incorrect answers to improve your skills. By the end of this exercise,<br>you’ll be able to confidently order adjectives and communicate accurately in<br>English.|\n|---|---|",
"|Logical De-<br>duction Five|On a plate, there are three fruits: a red apple, a yellow banana, and a green pear.<br>The banana is positioned to the immediate left of the apple, meaning there are<br>no other fruits between them. The pear is the rightmost fruit, meaning it comes<br>last in the order.<br>Which of the following statements is true?<br>(A) The red apple is the leftmost fruit.<br>(B) The yellow banana is the leftmost fruit.<br>(C) The green pear is the leftmost fruit.<br>Explanation:<br>To solve this prompt, pay attention to the precise language used to describe the<br>relationships between the fruits and their positions in the order. The banana is<br>to the immediate left of the apple, meaning it is directly adjacent to it and there<br>are no other fruits between them. The pear is the rightmost fruit, meaning it<br>comes last in the order.<br>Therefore, the correct answer is (B) The yellow banana is the leftmost fruit.<br>To further practice this concept, here are some additional examples:<br>1. On a plate, there are three different colored balls: a blue ball, a red ball, and<br>a green ball. The red ball is directly to the left of the blue ball, meaning there<br>are no other balls between them. The green ball is the rightmost. Which of the<br>following statements is true?<br>(A) The blue ball is the leftmost ball.<br>(B) The red ball is the leftmost ball.<br>(C) The green ball is the leftmost ball.<br>2. In a row of three houses, there is a blue house, a yellow house, and<br>a green house. The blue house is in the middle, and the yellow house is directly<br>to the left of the green house, meaning there are no other houses between them.<br>Which of the following statements is true? (A) The blue house is the leftmost<br>house.<br>(B) The yellow house is the leftmost house.<br>(C) The green house is the leftmost house.<br>Feedback:<br>If you selected the wrong answer, here’s why:<br>(A) The red apple is not the leftmost fruit. The yellow banana is directly to its<br>left.<br>(C) The green pear is not the leftmost fruit. The banana and the apple come<br>before it in the order.<br>To avoid confusion, use precise language to describe the relationships<br>between objects and their positions in the order. Avoid using vague terms like<br>\"newer\" or \"older\" without specifying their exact relationship to other objects<br>in the order. Provide more context or details to help clarify any ambiguities in<br>the prompt. Make sure the order of the objects is clearly defined and consistent<br>throughout the prompt.|\n|---|---|",
"|Reasoning<br>Colored<br>Objects|Identify the color of objects arranged in a row on a surface.<br>Q: On the desk, there is a black stapler, a green highlighter, a yellow ruler, a<br>blue pen, and a purple marker. What color is the pen?<br>Options:<br>(A) red<br>(B) orange<br>(C) yellow<br>(D) green<br>(E) blue<br>(F) brown<br>(G) magenta<br>(H) fuchsia<br>(I) mauve<br>(J) teal<br>(K) turquoise<br>(L) burgundy<br>(M) silver<br>(N) gold<br>(O) black<br>(P) grey<br>(Q) purple<br>(R) pink<br>A: Let’s think step by step.<br>According to this question, the objects are arranged in a row, from left to right,<br>as follows: (1) a black stapler, (2) a green highlighter, (3) a yellow ruler, (4) a<br>blue pen, and (5) a purple marker.<br>The pen is the fourth item on the list, namely (4). The color of the pen is blue.<br>So the answer is (E).|\n|---|---|",
"|Salient<br>Transla-<br>tion Error<br>Detection|Read the following translations from German to English and identify the type<br>of error present in each one. The error can be one of the following types:<br>Named Entities, Numerical Values, Modifiers or Adjectives, Negation or<br>Antonyms, Facts, or Dropped Content. Write the corresponding letter for each<br>error type in the options provided.<br>For example:<br>Source: Der Hund ist braun.<br>Translation: The cat is brown.<br>The translation contains an error pertaining to:<br>Options:<br>(A) Modifiers or Adjectives<br>(B) Numerical Values<br>(C) Negation or Antonyms<br>(D) Named Entities<br>(E) Dropped Content<br>(F) Facts<br>Output: (D)|\n|---|---|",
"|Ethos|Does the provided text contain hate speech? Return a boolean value of True or False.|\n|---|---|",
"|Liar|Analyze the context and other information provided to determine the truthfulness of<br>the statement. To do so, consider the following guidelines:<br>1. Identify key sources of information, such as reputable news outlets or<br>government reports, and consider the credibility of the sources. Look for corroborat-<br>ing evidence and consider any potential biases or conflicts of interest.<br>2. Conduct additional research or seek out expert opinions when necessary<br>to determine the truthfulness of a statement. Use resources or links to relevant<br>information provided, and consider consulting with subject matter experts or<br>fact-checking organizations.<br>3. Note that the determination of truthfulness may not always be possible<br>based on the information provided, and that additional research or analysis may be<br>required. Use your best judgment and be transparent about any uncertainties or<br>limitations in your analysis.<br>4. Consider specific examples or scenarios to help you apply the prompt in<br>different contexts. For instance, you might analyze a political statement, a scientific<br>claim, or a news article. Be aware of common pitfalls or errors, such as relying on<br>unreliable sources or failing to consider alternative explanations.<br>Output Format: Assign 0 for true and 1 for false. Note that this determina-<br>tion is based on the information provided and may not be definitive.|\n|---|---|",
"|Sarcasm|Determine if the input contains any language that could be considered derogatory or<br>discriminatory towards a particular group based on their race, ethnicity, gender, sexual<br>orientation, religion, or any other protected characteristic. If such language is found,<br>output True. If not, output False. The prompt should be trained on a diverse dataset to<br>improve its accuracy and reduce errors.|\n|---|---|",
"|Antonyms|\"Provide a list of adjectival antonyms for each of these words, keeping in mind the<br>given context:\"<br>## Input ##: hot (in the context of weather)<br>## Output ##: [’cold’, ’cool’, ’chilly’]<br>## Input ##: happy (in the context of emotions)<br>## Output ##: [’sad’, ’unhappy’, ’depressed’, ’miserable’]<br>## Input ##: big (in the context of size)<br>## Output ##: [’small’, ’tiny’, ’little’, ’miniature’]<br>## Input ##: fast (in the context of speed)<br>## Output ##: [’slow’, ’sluggish’, ’leisurely’, ’gradual’]<br>## Input ##: old (in the context of age)<br>## Output ##: [’young’, ’new’, ’fresh’, ’modern’]|\n|---|---|",
"|Cause<br>Effect|Determine the sentence that is the cause in each pair. Remember to thoroughly<br>comprehend the meaning of each sentence before selecting the cause. Additionally,<br>verify your output to ensure that you only include the sentence that is the cause. To<br>aid in identifying cause and effect relationships, consider using keywords or phrases<br>that indicate causality, analyzing the context of each sentence, and practicing with<br>feedback and interactive activities.|\n|---|---|",
"|Common<br>Concept|For each input, come up with a category or characteristic that they have in common<br>and write it as the output. Use your knowledge and experience to make educated<br>guesses and be creative in your thinking. Also, try to keep the output concise and<br>clear.|\n|---|---|",
"|Diff|Subtract the second number from the first number and give me the result. Make sure<br>to double check your calculations and write the answer as a string in a list format.|\n|---|---|",
"|First Word<br>Letter|Write a program that takes in a word and returns a list containing the first letter of the<br>word as a string. The program will be used to label items in a game.<br>Make sure to handle cases where the input word is empty or only contains<br>whitespace. You can use the string method ‘strip()‘ to remove any leading or trailing<br>whitespace. If the input is empty or contains only whitespace, return an empty list.<br>To ensure that your program works correctly, test it with the following exam-<br>ples:<br>Example 1:<br>Input: \"apple\"<br>Output: [\"a\"]<br>Example 2:<br>Input: \" banana\"<br>Output: [\"b\"]<br>Example 3:<br>Input: \"\"<br>Output: []<br>Example 4:<br>Input: \" \"<br>Output: []|\n|---|---|",
"|Informal<br>Formal|Reword the following sentences using more formal language, but also provide<br>alternative rewordings that are more appropriate for different contexts:<br>1. \"Regrettably, I am unable to attend the meeting tomorrow.\" (formal)<br>Alternative: \"Unfortunately, I won’t be able to make it to the meeting tomorrow.\"<br>(casual)<br>2. \"I must depart now, farewell!\" (overly formal)<br>Alternative: \"I have to go now, see you later!\" (casual)<br>3. \"I apologize, but I am unable to assist you with that matter.\" (formal)<br>Alternative: \"I’m sorry, but I can’t help you with that.\" (casual)<br>4. \"Thank you for the invitation, however, I am unable to attend.\" (formal)<br>Alternative: \"Thanks for inviting me, but I can’t make it.\" (casual)<br>5. \"In my opinion, this is the optimal choice.\" (formal)<br>Alternative: \"I think this is the best option.\" (casual)|\n|---|---|",
"|Large Ani-<br>mal|Choose one animal as the output based on its size. For example, if the input pair is<br>\"elephant, mouse\", choose \"elephant\" as the output. If the input pair is \"giraffe, lion\",<br>choose \"giraffe\" as the output. Use the following criteria to choose the output:<br>- If one animal is significantly larger than the other, choose the larger animal<br>as the output.<br>- If the animals are similar in size, choose the animal with the name that comes first<br>alphabetically as the output.<br>Here are some examples of correct outputs:<br>- \"whale, dolphin\" -> choose \"whale\" as the output<br>- \"panda, koala\" -> choose \"panda\" as the output<br>- \"tiger, zebra\" -> choose \"tiger\" as the output<br>Choose the output carefully to avoid confusion and errors.|\n|---|---|",
"|Letters List|Please write a program that takes in a word as input and outputs a list of its letters<br>separated by spaces. The output should be a list with one element containing the<br>separated letters in the same order as the input word.<br>To ensure the program works correctly, please follow these guidelines:<br>1. Input validation: Check that the input is a non-empty string containing<br>only alphabetic characters. If the input is invalid, print an error message and exit the<br>program.<br>2. Separating the letters: Use the ‘split()‘ method to separate the letters of<br>the input word.<br>3. Expected output format: The output should be a list with one element<br>containing the separated letters in the same order as the input word.<br>Here are some examples of valid and invalid input:<br>Valid input: \"hello\"<br>Expected output: [\"h\", \"e\", \"l\", \"l\", \"o\"]<br>Invalid input: \"hello world\"<br>Expected output: \"Error: Input must be a non-empty string containing only alphabetic<br>characters.\"<br>Invalid input: \"123\"<br>Expected output: \"Error: Input must be a non-empty string containing only alphabetic<br>characters.\"|\n|---|---|",
"|Taxonomy<br>Animal|\"List all the animals from the given inputs.\"<br>## Input ##: apple, banana, orange, kiwi, grape<br>## Output ##: []<br>## Input ##: dog, cat, fish, bird, hamster<br>## Output ##: [’dog’, ’cat’, ’fish’, ’bird’, ’hamster’]<br>## Input ##: elephant, giraffe, lion, tiger, zebra<br>## Output ##: [’elephant’, ’giraffe’, ’lion’, ’tiger’, ’zebra’]<br>## Input ##: pencil, eraser, notebook, ruler, pen<br>## Output ##: []<br>## Input ##: turtle, snake, lizard, frog, salamander<br>## Output ##: [’turtle’, ’snake’, ’lizard’, ’frog’, ’salamander’]|\n|---|---|",
"|Negation|For each input, negate the specified part of the statement and write it as an output.<br>1. Negate the part about using the gold color: \"We will use gold as the pri-<br>mary color for our new logo.\" Output: \"We will not use gold as the primary color for<br>our new logo.\"<br>2. Negate the part about Gary Kubiak participating as a player: \"Gary Ku-<br>biak will play as a quarterback in the upcoming game.\" Output: \"Gary Kubiak will<br>not play as a quarterback in the upcoming game.\"<br>Note: When negating statements with proper nouns or names, simply negate<br>the verb or action associated with the noun or name.|\n|---|---|",
"|Num Verbal|Convert a given number into its English word representation, including commas for<br>thousands and negative sign if applicable.<br>## Input 1 ## : 1234<br>## Output 1 ##: [’one thousand two hundred and thirty-four’]<br>## Input 2 ## : 987654321<br>## Output 2 ##: [’nine hundred and eighty-seven million six hundred and fifty-four<br>thousand three hundred and twenty-one’]<br>## Input 3 ## : 0<br>## Output 3 ##: [’zero’]<br>## Input 4 ## : -42<br>## Output 4 ##: [’negative forty-two’]<br>## Input 5 ##: 999999999<br>## Output 5 ##: [’nine hundred and ninety-nine million nine hundred and ninety-nine<br>thousand nine hundred and ninety-nine’]|\n|---|---|",
"|Active Pas-<br>sive|Passive Voice Practice:<br>In passive voice, the subject of the sentence receives the action instead of performing<br>it. Rewrite each sentence in passive voice.<br>Example: The dog chased the cat.<br>Passive voice: The cat was chased by the dog<br>1. The teacher graded the exams.<br>2. The company launched a new product.<br>3. The chef cooked a delicious meal.<br>4. The team won the championship.<br>5. The doctor prescribed medication for the patient.<br>Instructions:<br>- Rewrite each sentence in passive voice.<br>- Make sure the subject of the sentence receives the action instead of performing it.<br>- Use the examples provided to guide you.<br>- Check your work for accuracy and clarity.<br>Feedback:<br>- If you have any questions or need clarification, please ask.<br>- Practice makes perfect! Keep practicing to improve your writing skills.<br>- If you make any mistakes, don’t worry! Learn from them and try again|\n|---|---|",
"|Singular<br>Plural|Add an \"s\" or the correct plural form to the end of the input word, depending on the<br>following rules:<br>1. If the word ends in \"y\" with a consonant before it, change the \"y\" to \"ies\"<br>instead of just adding an \"s\".<br>2. If the word ends in \"f\" or \"fe\", change the \"f\" or \"fe\" to \"ves\" instead of just adding<br>an \"s\".<br>3. If the word is already plural, return the input word as is instead of adding an \"s\".<br>4. If the word has an irregular plural form, return the correct plural form instead of<br>just adding an \"s\".<br>Examples:<br>- Input: cat<br>Output: cats<br>- Input: book<br>Output: books<br>- Input: car<br>Output: cars<br>- Input: tree<br>Output: trees<br>- Input: computer<br>Output: computers<br>- Input: story<br>Output: stories<br>- Input: half<br>Output: halves<br>- Input: aircraft<br>Output: aircraft<br>- Input: century<br>Output: centuries|\n|---|---|",
"|Rhymes|Create a list of words that rhyme with the given word. To ensure that your rhymes are<br>accurate, make sure that the words have the same vowel sound and ending consonant<br>sound. For example, \"cat\" rhymes with \"bat\" and \"hat,\" but not with \"dog\" or \"mat.\"<br>To get started, here are some examples of words that rhyme with the given<br>word:<br>- Love: dove, glove, above, shove, of<br>- Time: rhyme, chime, climb, mime, prime<br>To find more rhyming words, you can use a rhyming dictionary, online re-<br>sources, or brainstorm with friends. Be creative and try to use a variety of different<br>rhyming words instead of repeating the same one multiple times.<br>To avoid common pitfalls, make sure to double-check your spelling and pro-<br>nunciation of the words. Also, avoid using words that only partially rhyme or have a<br>different stress pattern.<br>After you’ve created your list, ask for feedback on the quality of your rhymes. This<br>can help you to improve and refine your skills.<br>For an added challenge, consider generating rhyming words that fit a particu-<br>lar theme or context. This can help you to focus your creativity and generate more<br>interesting and relevant rhymes.|\n|---|---|",
"|Second<br>Word Letter|For each input word with at least two letters, identify and output the second letter.<br>Please ensure that the input is a valid word in the specified language or dialect to<br>prevent errors. The prompt is case-insensitive, so it will work for both uppercase and<br>lowercase letters.<br>Examples:<br>- Input: \"hello\" Output: \"e\"<br>- Input: \"apple\" Output: \"p\"<br>- Input: \"book\" Output: \"o\"<br>Please note that the language or dialect of the input should be specified to<br>avoid confusion with words that have different spellings or pronunciations in different<br>regions.|\n|---|---|",
"|Sentence<br>Similarity|Rate the similarity of two given sentences on a scale of 1 to 5, where 1 indicates a<br>significant difference in meaning and 5 indicates almost identical meaning. Please<br>consider the following factors when rating:<br>- The overall message and purpose of the sentences<br>- The structure and syntax of the sentences<br>- The use of key words and phrases<br>Provide a brief explanation for your rating, taking into account any minor<br>differences in wording or details that may affect the similarity rating. Additionally,<br>please provide context for the sentences being compared, such as the intended<br>audience or purpose.<br>For reference, here are some examples of sentences that fall into each cate-<br>gory:<br>Highly similar: \"The cat sat on the mat\" and \"The mat was sat on by the<br>cat\"<br>Moderately similar: \"I enjoy playing soccer\" and \"Soccer is a fun sport to play\"<br>Not similar at all: \"The sky is blue\" and \"I am going to the beach tomorrow\"<br>Thank you for your evaluation and explanation.|\n|---|---|",
"|Sentiment|Please analyze the following statements and determine their overall sentiment as<br>either [’negative’, ’neutral’, ’positive’]. Keep in mind the context and any figurative<br>language used.<br>1. The sun is shining and the birds are singing.<br>Output: [’positive’]<br>2. I failed my exam and now I have to retake the class.<br>Output: [’negative’]<br>3. My best friend surprised me with a thoughtful gift.<br>Output: [’positive’]<br>4. The traffic on the highway was backed up for miles.<br>Output: [’negative’]<br>5. I received a promotion at work and a raise in salary.<br>Output: [’positive’]<br>6. A non-mystery mystery.<br>Output: [’neutral’]<br>7. Little more than a well-mounted history lesson.<br>Output: [’neutral’]<br>8. Too daft by half ... but supremely good natured.<br>Output: [’positive’]<br>Note: This prompt uses more sophisticated language analysis techniques to<br>better understand the sentiment of the input. However, providing more context for the<br>input is still important for accurate sentiment analysis.|\n|---|---|",
"|Orthography<br>Starts With|SIdentify the first word or phrase that starts with the letter given in the input. The<br>identified word or phrase should not contain any punctuation or special characters,<br>and should be case-insensitive. If there are no words or phrases starting with the given<br>letter, return an empty list.<br>Here are the input-output pairs:<br>Input: She sang a beautiful song to the audience. [b]<br>Output: [’beautiful’]<br>Input: The cat chased the mouse. [c]<br>Output: [’cat’]<br>Input: It is important to always be kind to others. [i]<br>Output: [’important’]<br>Input: The dog barked loudly, frightening the neighbors. [l]<br>Output: [’loudly’]<br>Input: The book is on the shelf. [s]<br>Output: [’shelf’]<br>Input: The baby cried all night. [n]<br>Output: []<br>Input: The teacher gave a long lecture on the history of art. [l]<br>Output: [’lecture’]<br>Input: The car drove down the street, passing by many shops. [s]<br>Output: [’street’]<br>Input: To the boy’s delight, he received a new toy for his birthday. [t]<br>Output: [’toy’]<br>Note: If there are multiple words or phrases starting with the given letter,<br>the prompt will return the first one encountered. If the input contains multiple<br>sentences or clauses, the prompt will identify the first word or phrase that starts with<br>the given letter in the entire input text. The output will be in lowercase|\n|---|---|",
"|Sum|\"Write a program that takes two numbers as input and returns their sum as a string in a<br>list. Make sure to test your program with different inputs to ensure it works correctly.<br>Remember to convert the input numbers to integers before adding them together, and<br>then convert the sum back to a string before putting it in a list. Also, make sure to use<br>the correct syntax for creating a list with one element (i.e. use square brackets around<br>the string). Good luck!\"|\n|---|---|",
"|Synonym|Please provide a list of synonyms for the given words that convey a similar meaning<br>and are commonly used in everyday language. Be sure to double-check your spelling<br>and grammar before submitting.<br>For example, if the word is \"happy,\" acceptable synonyms could be \"joyful,\"<br>\"pleased,\" or \"content.\"<br>Please use gender-neutral language and avoid using words with different con-<br>notations or meanings. If you notice any incorrect synonyms, please flag them and<br>provide feedback for improvement.<br>Words to avoid using as synonyms include those with different connotations<br>or meanings, such as \"ecstatic\" for \"happy\" or \"depressed\" for \"sad.\"|\n|---|---|",
"|Trans En De|Translate the following English words into German.<br>## Input ## : happy<br>## Output ##: [’glücklich’]<br>## Input ## : love<br>## Output ##: [’Liebe’]<br>## Input ## : cat<br>## Output ##: [’Katze’]<br>## Input ## : dog<br>## Output ##: [’Hund’]<br>## Input ## : house<br>## Output ##: [’Haus’]<br>## Input ## : tree<br>## Output ##: [’Baum’]<br>## Input ## : water<br>## Output ##: [’Wasser’]<br>## Input ## : sun ## Output ##: [’Sonne’]<br>## Input ## : moon<br>## Output ##: [’Mond’]<br>## Input ## : star<br>## Output ##: [’Stern’]|\n|---|---|",
"|Trans En Es|Convert these English terms into their corresponding Spanish translations.<br>## Input ## : happy<br>## Output ##: [’feliz’]<br>## Input ## : beach<br>## Output ##: [’playa’]<br>## Input ## : computer<br>## Output ##: [’computadora’]<br>## Input ## : book<br>## Output ##: [’libro’]<br>## Input ## : music<br>## Output ##: [’música’]|\n|---|---|",
"|Trans En Fr|Translate the following English words into French.<br>## Input ## : happy<br>## Output ##: [’heureux’]<br>## Input ## : love<br>## Output ##: [’amour’]<br>## Input ## : family<br>## Output ##: [’famille’]<br>## Input ## : friend<br>## Output ##: [’ami’]<br>## Input ## : music<br>## Output ##: [’musique’]<br>## Input ## : beach<br>## Output ##: [’plage’]<br>## Input ## : book<br>## Output ##: [’livre’]<br>## Input ## : movie<br>## Output ##: [’film’]<br>## Input ## : food<br>## Output ##: [’nourriture’]<br>## Input ## : travel<br>## Output ##: [’voyage’]|\n|---|---|",
"|Word In<br>Context|Compare the usage of a given word in two different sentences and determine if they<br>have the same or different meanings based on the context of the sentences. Write<br>\"same\" or \"not the same\" as the output.<br>To avoid ambiguity and ensure clarity, please provide sufficient context for<br>the sentences. If the word has multiple meanings depending on the context, please<br>indicate all correct answers.<br>For example, consider the word \"bank.\" In the sentence \"I need to deposit<br>my paycheck at the bank,\" and \"I sat on the bank of the river and watched the sunset,\"<br>the word \"bank\" has different meanings. Therefore, the correct answer would be \"not<br>the same.\"<br>Please note that the comparison should be based on the context of the sentences, not<br>just the isolated word|\n|---|---|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/test/2402.11347v2.pdf"
}