{
"text": "A Systematic Survey of Automatic Prompt Optimization Techniques\n\n       Kiran Ramnath, Kang Zhou, Sheng Guan, Soumya Smruti Mishra, Xuan Qi, Zhengyuan Shen,\n             Shuai Wang, Sangmin Woo, Sullam Jeoung, Yawei Wang, Haozhu Wang, Han Ding,\n        Yuzhe Lu, Zhichao Xu, Yun Zhou, Balasubramaniam Srinivasan, Qiaojing Yan, Yueyan Chen,\n                           Haibo Ding, Panpan Xu, and Lin Lee Cheong\n                                   Amazon Web Services\n          {raxkiran,zhoukang,shguan,soumish,xuaqi,donshen, wshui,sangminw,sullamij,\n          yawenwan, haozhuw, handing, yuzhelu, xzhichao, yunzzhou, srbalasu, qiaojiny,\n          yyanc, hbding, xupanpan, lcheong}@amazon.com\n\n                          Abstract                       not require parameter access on LLMs performing\n                                                                    the task, (2) they systematically search through the\n                 Since the advent of large language models      prompt solution space, and (3) they retain human\n               (LLMs), prompt engineering has been a cru-        interpretability of prompt improvements.  In this\n                      cial step for eliciting desired responses for vari-       survey paper, we aim to highlight the advances in\n                 ous Natural Language Processing (NLP) tasks.                                                                 the field. Our core contribution is a 5-part APO\n                However, prompt engineering remains an im-2025                                                taxonomy combined with a comprehensive fine-\n                pediment for end users due to rapid advances\n                                                              grained categorization of various design choices                    in models, tasks, and associated best practices.\n               To mitigate this, Automatic Prompt Optimiza-        therein (see Fig. 1, Tables 2, 3, 4 in Appendix). WeApr\n                    tion (APO) techniques have recently emerged      hope our framework will be informational for new\n2             that use various automated techniques to help      and seasoned researchers alike, enabling further\n                improve the performance of LLMs on various       research on open questions.\n                    tasks. In this paper, we present a comprehen-\n                   sive survey summarizing the current progress      2  Automatic Prompt Optimization\n                and remaining challenges in this field. We pro-         Formulation\n                  vide a formal definition of APO, a 5-part uni-[cs.CL]                                     We formalize the process of automatic prompt op-                  fying framework, and then proceed to rigor-\n                                                                 timization (APO) as follows. Given a task model                 ously categorize all relevant works based on\n                     their salient features therein. We hope to spur       Mtask, initial prompt ρ ∈V , the goal of an APO-\n                    further research guided by our framework.          system MAPO is to obtain the best performing\n                                                            prompt-template ρopt under a metric f ∈F and\n          1  Introduction                                     eval-set Dval\n            Since McCann et al. (2018) cast multi-task NLP     ρopt := arg max Ex∼Dval[f(Mtask(ρ ⊕x))] (1)\n                                                                        ρ∈V\n             as Question Answering, using prompts as inputs\n                                                             This objective function is not tractable for discrete            has become the standard way to elicit desired re-\n                                                       prompt optimization as token-sequence search            sponses from Large Language Models (LLMs).\n                                                               spaces are combinatorial. Instead, APO techniques            Furthermore, LLMs’ few-shot learning (Brown\n                                                              follow the general anatomy as described in Algo-               et al., 2020), instruction-following (Ouyang et al.,\n                                                              rithm 1 to obtain approximate solutions.             2022), and zero-shot reasoning capabilities (Ko-arXiv:2502.16923v2\n            jima et al., 2023) have led to a widespread prolif-   3   Initialize Seed Prompts\n              eration of prompting tricks for various tasks and\n                                                                 3.1  Manual Instructions\n           model variants. However, LLMs still exhibit unpre-\n              dictable sensitivity to various factors (explanation    Several approaches use a seed of manually cre-\n             of the task (Li et al., 2023b),ordering (Liu et al.,   ated instructions that offer interpretable and strong\n             2024a), stylistic formatting (Sclar et al.), etc.) caus-   baselines as the basis for further improvement,inter\n             ing a performance gap between two prompts that     alia., ProteGi (Pryzant et al., 2023), GPS (Xu et al.,\n             are semantically similar, thereby adding impedi-   2022), SPRIG (Zhang et al., 2024b). While ob-\n            ments for adoption by end users. Against this back-    taining quality examples can be costly, APE (Zhou\n             drop, Black-Box Automatic Prompt Optimization    et al., 2022) 1 showed that a few hundred samples\n          (APO) techniques have emerged that improve task    are sufficient for further optimization.\n            performance via automated prompt improvements.                                                                                1Note: APE stands for Automatic Prompt Engineer method\n           The possess various attractive features - (1) they do     introduced by (Zhou et al., 2022), not to be confused with APO\n\nManual Instructions §3.1\n\n                Seed Prompts §3\n\n                                                                                Instruction-induction via LLMs §3.2\n\n                                                                                         Task accuracy §4.1.1\n\n                                                                              Reward model score §4.1.2\n                                            Numeric score §4.1\n                                                                                            Entropy-based §4.1.3\n\n                                                                                         Negative log-likelihood §4.1.4\n\n                  Inference evaluation\n                 and feedback §4                                                   Improving single candidate §4.2.1\n                               LLM Feedback §4.2\n                                                                                 Improving multiple candidates §4.2.2\n\n §2                                                         Human Feedback §4.3\n\n                                                                            Monte Carlo Sampling §5.1.1   anatomy\n                                                                                           Genetic Algorithm §5.1.2                                                       Heuristic-based\n                                                                edits §5.1                                                                         Word / phrase edits §5.1.3      optimization                                                                                      Vocabulary pruning §5.1.4\n   Prompt                                                                                      Reinforcement Learning §5.2.1\n\n                                                    Editing with auxiliary\n                                                          LLM Finetuning §5.2.2\n                                                          trained NN §5.2\n\n                                                                                      Generative Adversarial Networks §5.2.3\n                 Candidate prompt\n                     generation §5\n                                                                      Metaprompt design §5.3\n\n\n                                                                                            Single prompt expansion §5.4.1\n\n                                                Coverage-based §5.4                      Mixture of experts §5.4.2\n\n                                                                                  Ensemble methods §5.4.3\n\n\n                                                                      Program Synthesis §5.5\n\n                                                             TopK Greedy Search §6.1\n\n\n                                                              Upper confidence bound and variants §6.2\n                       Filter and retain\n              promising candidates §6\n                                                                         Region-based joint search §6.3\n\n\n                                                                                Meta-heuristic ensemble §6.4\n\n                                                                                Fixed steps §7.1\n\n                     Iteration depth §7\n\n                                                                                      Variable steps §7.2\n\n                           Figure 1: Taxonomy of Automatic Prompt Optimization\n\n\nAlgorithm 1 Prompt optimization framework        3.2  Instruction Induction via LLMs\n  1: P0 := {ρ1, ρ2, . . . , ρk}   ▷§3. Seed prompts   Honovich et al. (2023) were the first to propose\n  2: Dval := {(x1, y1)}ni=1       ▷Validation set   inducing LLMs to infer human-readable prompts\n  3: f1, . . . , fm ∈F   ▷§4. Inference evaluation   based on a few demonstrations E (see Appendix\n  4: for t = 1, 2, . . . , N do  ▷§7. Iteration depth   14.1 for prompt). APE (Zhou et al., 2022) and\n   ▷§5. Generate prompt candidates         DAPO (Yang et al., 2024c) use the induced seed\n  5:    Gt := MAP O(P, Dval, F)                    instructions for further optimization, while MOP\n   ▷§6. Filter and retain candidates             (Wang et al., 2025) and GPO (Li et al., 2023c) use\n  6:    Pt := Select(Gt, Dval, F)            APE to induce cluster-specific prompts. Apart from\n   ▷§7. Optionally check for early convergence    demonstrations, SCULPT (Kumar et al., 2024) in-\n  7:       if fconvergence ≤ϵ then                  duced instructions from task-READMEs, while\n  8:         exit                               UniPrompt (Juneja et al., 2024) used LLMs to fill-\n  9: return arg maxρ∈PN Ex∼Dval [f(Mtask(ρ ⊕x))]\n                                                     which broadly refers to the entire area of Automatic Prompt\n                                                            Optimization\n\nFigure 2: Representative APO system\n\n\nin structured templates.                               4.1.3  Entropy-based Scores\n\n4  Inference Evaluation and Feedback       Entropy-based scores evaluate the entire output\n                                                       distribution induced by candidates, as opposed toThe evaluation  step helps  identify promising\n                                                a single inference instance.  They are gradient-prompt candidates in each iteration. Some methods\n                                                       free but require access to the entire output prob-also use LLM feedback on prompt-response pairs\n                                                          ability distribution, something not usually possi-to help generate more prompt candidates.\n                                                    ble with black-box LLMs. CLAPS (Zhou et al.,\n4.1  Numeric Score Feedback                                             2023) leverages the negative incremental cross-\n4.1.1  Accuracy                                 entropy of π(xi⊕v∈V ) v/s π(xi) to identify promis-\n                                                  ing words v ∈V to add to the prompt. The topK\nUsing task-specific accuracy metrics is the most\n                                             words are then used as candidate tokens from which\nstraightforward and widespread way of eliciting\n                                                      to construct candidate prompts. GRIPS (Prasad\nfeedback, i.a., (Zhou et al., 2022, 2023; Zhang\n                                                           et al., 2023) simply added an entropy term to\net al., 2024b; Khattab et al., 2022).  Classifica-\n                                                      the task-weighted accuracy −P πρ(y) ln(πρ(y))+\ntion and MCQ-based QA tasks use exact accuracy,     1                      P 1(y = ˆy) to prioritize output diversity in po-\nwhile code-related tasks measure execution accu-     |T|\n                                                            tential prompt candidates.\nracy. Text generation tasks (summarization, transla-\ntion, creative writing) employ flexible metrics like    4.1.4  Negative Log-likelihood of Output\nBLEU-N, Rouge-N, Rouge-N-F1, or embedding-                                      Some approaches like APE, GPS (Xu et al., 2022),\nbased measures such as BERTScore (Zhang* et al.,                                   PACE (Dong et al., 2024b) consider the negative\n2020) (Honovich et al., 2023; Dong et al., 2024b).                                                      log-likelihood (NLL) of token sequences under the\n4.1.2  Reward-model Scores                        target LLM, i.e., −log(πρ(y)). This however re-\n                                                     quires the log-probabilities to be accessible during\nGiven the limitations of rigid accuracy metrics,\n                                                    the decoding of each token, limiting its applica-\nsome approaches proposed using learned reward\n                                                                 bility. The NLL for ground truth one-hot token-\nmodels to provide more nuanced evaluations of\n                                               sequence is equivalent to the cross-entropy.\nprompts-response pairs (Deng et al., 2022; Sun\net al., 2024a; Kong et al., 2024). OIRL (Sun et al.,   4.2 LLM Feedback\n2024a) trained an XGBoost-based reward model                             A popular paradigm to augment or fully replace\nthat takes query-prompt embedding pairs as input                                               numeric scores is to use textual feedback generated\nand predicts whether the prompt will elicit correct                                            by LLMEvaluator (Wang et al., 2024a; Long et al.,\nanswers from the language model and use it to se-                                              2024; Sinha et al., 2024).  It is versatile because\nlect appropriate prompts for specific queries using                                                                            it can evaluate both the response as well as the\na best-of-N strategy. DRPO (Amini et al., 2024)                                             prompt input. It can directly aid the prompt rewrit-\nfollows an LLM-based reward modeling approach                                                   ing process while being flexible to individual tasks\nusing both predefined and dynamic reward criteria.                                                   as it only needs natural language instructions for\nIt first optimizes in-context learning examples E,                                                   general-purpose LLMs as opposed to task-specific\nand using that it optimizes the specific task prompt.                                                  handcrafting of metrics. A potential downside is\n                                                    the inference cost incurred due to an additional\n                              LLM call. All the LLM feedback approaches pro-\n\nPaper             Seed instructions          Iteration depth  Inference evaluation   Candidate generation   Search+filter strategy\n  ProTeGi  (Pryzant  Manually created          Fixed        LLM feedback +     LLM rewriter       UCB for trees\n  et al., 2023)                                                  Task accuracy\n APE (Zhou et  al.,  Instruction induction       Fixed           Task accuracy        N/A            UCB\n  2022)\n CRISPO (He et al.,  Manually created          Fixed        LLM feedback +     LLM rewriter        TopK selection\n  2025)                                                       Task accuracy\n MOP (Wang et al.,  Instruction induction       Fixed           Task accuracy          Mixture of experts      Region-based\n  2025)                                                                                                                             joint search\n DSPY    (Khattab  Manually created +         Variable      LLM feedback +       Program Synthesis     TopK selection\n  et al., 2024)          Instruction induction                       Task accuracy\n OPRO (Yang et al.,  Manually created           Variable      LLM feedback +       Metaprompt design    TopK selection\n  2024a)                                                      Task accuracy\n GATE (Joko et al.,  Manually created           Variable       Human feedback     LLM rewriter        N/A\n  2024)\n\n    Table 1: Comparison of some APO techniques under our framework (Tables 2,3,4 show full comparison)\n\n\nvide multiple feedback data and broadly fall into    to generate several prompt candidates for evalu-\ntwo categories - improving a single prompt candi-   ation in the next iteration. PromptAgent (Wang\ndate versus improving multiple prompt candidates    et al., 2024a) similarly used an error collection ap-\n(discussed below, examples in Appendix 14.3).      proach to emulate expert-written prompts that con-\n                                                          sisted of clear sections like “Task description”, “Do-\n4.2.1  Improving Single Candidate\n                                           main Knowledge”, “Solution Guidance”, “Excep-\nSCULPT (Kumar et al., 2024) introduces a system-    tion Handling”, “Output Formatting”. PREFER\natic method for tuning long, unstructured prompts   (Zhang et al., 2024a) utilizes a feedback-reflect-\nby employing a hierarchical tree structure and    refine cycle to aggregate feedback into multiple\ntwo-step feedback loops - preliminary assessment   prompts in an ensemble to improve the model’s\nand error assessment - to evaluate and correct    ability to generalize across various tasks.   Sur-\nprompts before and after execution.  The feed-    vival of the Safest (SOS) (Sinha et al., 2024) added\nback updates the hierarchical prompt tree which is    safety-score into a multi-objective prompt opti-\nthen back-synthesized into a new prompt candidate.   mization framework that used an interleaved strat-\nPACE (Dong et al., 2024b) applies an actor-critic   egy to balance performance and security in LLMs\nediting framework to the prompt refinement pro-   simultaneously. To avoid accidentally damaging\ncess itself, allowing for more dynamic and adaptive    well-functioning prompts, StraGo (Wu et al., 2024)\nadjustments. Overcoming the limitations of opti-   summarized strategic guidance based on both cor-\nmizing a single metric, CRISPO (He et al., 2025)    rect and incorrect predictions as feedback.\nadopts a multi-aspect critique-suggestion meta-\n                                                    4.3  Human-feedback\nprompt to highlight flaws in the generated response\nacross multiple dimensions such as style, preci-  A few works also incorporate human feedback, ei-\nsion, and content alignment. Thereafter it leverages    ther during compile-time or inference-time in the\ndetailed, aspect-specific feedback and iteratively   prompt construction / optimization process. Joko\nupdates the prompts. Autohint (Sun et al., 2023)    et al. (2024) proposed “Generative Active Task\nsummarizes feedback for multiple incorrect infer-    Elicitation” to better capture human preferences.\nences via hints to instill improvements into a single     It prompts a language model to interactively ask\nprompt candidate.                                   questions and infer human preferences conditioned\n                                            on the history of free-form interaction. Cheng et al.\n4.2.2  Improving Multiple Candidates\n                                                (2024) trained a smaller LLM to optimize input\nProTeGi (Pryzant et al., 2023) and TextGrad (Yuk-   prompts based on user preference feedback, achiev-\nsekgonul et al., 2024) leverage textual “gradients”   ing up to 22% increase in win rates for ChatGPT\nto guide the discrete prompt optimization proce-   and 10% for GPT-4. PROMST (Chen et al., 2024)\ndure, very similar to the gradient-descent style of    tackles the challenges of multi-step tasks by in-\ncontinuous prompt optimization approaches. Dif-   corporating human-designed feedback rules and a\nferent from continuous gradient-descent, ProTeGi    learned heuristic model. APOHF (Lin et al., 2024)\nsampled multiple “gradients” i.e.  directions of    focuses on optimizing prompts using only human\nimprovement, and each such “gradient” is used    preference feedback rather than numeric scores,\n\nemploying a dueling bandits-inspired strategy to   needing repeated task-specific optimizations.\nefficiently select prompt pairs for preference feed-\n                                      LLM-based mutation: LMEA (Liu et al., 2023),\nback, proving effective for tasks like text-to-image\n                                   SOS (Sinha et al., 2024), and StraGo (Wu et al.,\ngeneration and response optimization.\n                                             2024) uses mutation prompts with LLMs to over-\n5  Candidate Prompt Generation          come the traditional complexity of designing tai-\n                                                    lored operators for cross-over / mutation. Prompt-In this step, one or more candidate prompts are gen-\n                                               Breeder (Fernando et al., 2023) advocates self-erated that are most likely to result in an improve-\n                                                         referential improvement of  all prompts in thement in a metric of interest f ∈F. The approaches\n                                            prompt optimization system - Direct Mutation ofreviewed below range from simple rule-based ed-\n                                                      task prompts, Hypermutation of mutation promptsits (sec. 5.1) to sophisticated agentic systems that\n                                                  themselves, Lamarckian Mutation where promptscombine with LLM-based evaluations (sec. 4.2)\n                                                    are reverse-engineered from successful examplesand various filtering strategies (sec. 6).\n                                                      (similar to Instruction Induction Honovich et al.\n5.1  Heuristic-based Edits                                                   (2023), and finally Crossover and Shuffling to im-\nSeveral works proposed heuristic-based mecha-   prove diversity of the prompt pool. EvoPrompt\nnisms to make edits to intermediate prompt can-   (Guo et  al., 2024) use Differential Evolution -\ndidates to generate newer candidates. They range   where differences between existing prompts is in-\nfrom edits at the word / phrase / sentence-level    corporated to form new prompt candidates to over-\n(either simple rule-based or LLM-generated), or   come the problem of local optima. AELP (Hsieh\nmetric-driven incremental search.  While these    et al., 2024) also uses mutation operators to per-\nstrategies may not result in the most optimal so-   form sentence-level edits in an iterative fashion.\nlution, they help in making the discrete prompt   They include sentence-level histories of reward\noptimization problem computationally tractable.     {(st−1, st, rt)} in the mutation prompt in order\n                                                      to avoid local optima and accidentally returning\n5.1.1  Monte Carlo Sampling\n                                                      to sub-optimal versions. GPS (Xu et al., 2022)\nProTeGi (Pryzant et al., 2023) uses Monte carlo   used Back-translation, Sentence Continuation, and\nsampling to explore combinatorial discrete solution   Cloze transformations to perform prompt mutation.\nspaces in an incremental fashion - it samples multi-   PromptWizard (Agarwal et al., 2024) proposed a\nple textual gradients to use to generate prospective    pipeline combining several steps including itera-\ncandidates, and spawns paraphrases as monte-carlo    tive improvement, few shot example synthesis and\nsuccessors for evaluation. PromptAgent (Wang    selection, utilizing LLM’s reasoning capability to\net al., 2024a) uses a tree-variant called Monte Carlo   improve and validate the prompt, and finally an\nTree Search (MCTS) which consists of 4 steps —   expert persona to ensure consistency of the style of\nSelection, Expansion, Simulation, and Backpropa-   generated prompts.\ngation (also explained in Sec. 6).\n                                                      5.1.3  Word / Phrase Level Edits\n5.1.2  Genetic Algorithm\n                                                  Several word-edit approaches first identify \"influ-\nA significant line of work applies the well-studied    ential\" tokens in the prompts. COPLE (Zhan et al.,\ngenetic algorithms to make discrete edits to texts.   2024) argued that LLMs exhibit lexical sensitivity,\nThe common recipe for several genetic algorithms   showing that merely replacing a few words with\nis 1/ Mutate and 2/ Cross-over components from    their synonyms can yield significant improvements.\npromising candidates. Token mutations: SPRIG    First, “influential” tokens are identified where ex-\n(Zhang et al., 2024b) and CLAPS perform token-   pected loss on dev-set EDval[L(y, ˆy)] drops the\nlevel mutations. SPRIG uses a starting corpus of   most after removing that token versus the original\n300 components grouped into categories like COT,   prompt, and then influential tokens are replaced\nroles, styles, emotions, scenarios, and good prop-   using predictions from a Masked-Language Mod-\nerties. It performs add/rephrase/swap/delete, high-    els. This token-replacement approach is also at-\nlighting complementary strengths of optimizing    tractive as a standalone post-processing step for\nsystem prompts alongside task-prompts (via meth-   long prompts that are already optimized using other\nods like ProTeGi) to enhance accuracy across mul-   LLM-based approaches. GRIPS (Prasad et al.,\ntiple diverse domains, languages, and tasks without   2023) argues that phrase level edition is an effec-\n\ntive and interpretable method to optimize prompts,   perform prompt optimizations to preserve privacy\nleveraging 4 basic edit operations -add, delete, para-   and adapt to target models better leveraging both\nphrase, and swap                                   data diversification and strategic fine-tuning such\n                                                    as SFT, preference optimization, and iterative pref-\n5.1.4  Vocabulary Pruning\n                                                  erence learning.\nSome works prune the vocabulary space V  to\n                                                      5.2.3  Generative Adversarial Networks\nVpruned for decoding the next token for the op-\ntimized prompt ρ∗. CLAPS (Zhou et al., 2023)   Long et al. (2024) framed the prompt optimization\nargued that general search spaces are highly re-   process in the GAN setting. The LLM generator\ndundant and use K-means clustering to find word-   takes question and the generation prompt to pro-\nclusters and retain top-2000 words closest to cluster   duce output. The (input, output) pairs are evaluated\ncentroids. BDPL (Diao et al., 2022) used pairwise   by an LLM powered discriminator, whose goal is\nmutual information (PMI) to retain top co-occuring    to identify generated pairs from ground truth pairs.\nngrams for decoding. PIN (Choi et al., 2024) in-   Both generator and the discriminator are jointly op-\nstead added regularization in the form of Tsallis-   timized using adversarial loss, by utilizing a prompt\nentropy (ideal for heavy-tailed distributions like    modifier LLM to rewrite their prompts.\nnatural language) for the RL training of a prompt                                                    5.3  Metaprompt Design\ngeneration network, to reduce the probability mass\n                                      PE2 (Ye et al., 2024) argued that previous worksfor unlikely tokens and improve interpetability.\n                                                  under-explored meta-prompt search space. OPRO\n5.2  Editing via Auxiliary Trained NN                                              (Yang et al., 2024a) proposes a meta-prompt design\nSome approaches leverage a trained auxiliary neu-   (see Appendix 14.2) which includes the optimiza-\nral network to edit the  initial prompt for ob-    tion problem description in natural language and\ntaining desired improvements. We include ap-   previously generated solutions (multiple solutions\nproaches where the finetuned network is different    per stage for diversity) and scores alongisde the\nand smaller than the task network.                   meta-instruction for prompt refinement. DAPO\n                                             (Yang et al., 2024c) utilizes a well-designed meta-\n5.2.1  Reinforcement-learning\n                                                      instruction to guide the LLM in generating high-\nMulti-objective Optimization techniques (Jafari    quality and structured initial prompts (contain task-\net al., 2024) demonstrate superiority over simple    specific info, e.g. task type and description, output\nreward averaging, particularly through volume-   format and constraints, reasoning process, profes-\nbased methods that effectively balance competing    sional tips) by observing given input-output ex-\nobjectives. Dynamic prompt modification strate-   emplars. Then, DAPO iteratively optimizes the\ngies, introduced through prompt rewriting (Kong   prompts at the sentence level, leveraging previous\net al., 2024), directional stimulus prompting (Li    tuning experience to expand prompt candidates.\net al., 2023d) and test-time editing (Zhang et al.,\n                                                    5.4  Coverage-based\n2022) solve the important goal of moving beyond\nstatic prompt generation. Prompt-OIRL (Sun et al.,  Some approaches seek to \"cover\" the entire prob-\n2024a) also tackled test-time optimization objec-   lem space - either within a single prompt, or using\ntive by learning an offline reward model and    multiple prompts working individually or in an en-\nsubsequently using a best-of-N strategy to recom-   semble during inference.\nmend the optimal prompt in a query-dependent                                                      5.4.1  Single Prompt-expansion\nfashion. BDPL (Diao et al., 2022) optimized dis-\n                             AMPO (Yang et al., 2024d) uses LLM feedbackcrete prompts using variance-reduced policy gradi-\n                                                      to enumerate all the failure cases based on theent algorithm to estimate gradients, allowing user\n                                                       evaluation-set Dval and then enlists each of them indevices to fine-tune tasks with limited API calls.\n                                                      the meta-instruction in an if-then-else format using\n5.2.2  Finetuning LLMs                                           3 modules - 1/ Pattern Recognition, 2/ Branch Ad-\nBPO (Cheng et al., 2024) trains a smaller 7B model    justment, and 3/ Branch Pruning to decide whether\nto align itself to task-performance on individual    to enhance existing branches, or to grow new\nLLMs using reward-free alignment. FIPO (Lu    branches. Similarly, UNIPROMPT focused on ex-\net al., 2025) trains a local model (7B - 13B) to    plicitly ensuring that various semantic facets of a\n\ntask get represented in the final prompt. It designs a   (Opsahl-Ong et al., 2024) automates the optimiza-\nhuman-like (manual) prompt engineering approach    tion of multi-stage language model programs by\n(UniPrompt) with two stages: a) task facets ini-   improving instructions and demonstrations for each\ntialization using background knowledge, and b)   module. SAMMO (Schnabel and Neville, 2024)\nrefinement using examples.                       proposed symbolic prompt programming, repre-\n                                                     senting prompts as directed-acyclic-graphs (DAG).\n5.4.2  Mixture of Experts\n                              A set of user-defined node mutation rules guide the\nWang et  al. (2025) introduced the Mixture-of-   mutation-search to find the optimal DAG, which is\nExpert-Prompts where each expert is a task-prompt    then converted back to a prompt.\nto be used for specialized inference. MOP first\n                                       6   Filter and Retain Promising Prompts\nclusters all demonstrations using K-means cluster-\ning. Then, the Region-based Joint Search (RBJS)    In this step, promising prompt candidates are fil-\n(sec.6.3) algorithm generates the appropriate in-   tered for further optimization.\nstruction for each exemplar-cluster via instruction                                                    6.1  TopK Greedy Search\ninduction (sec.3.2) based on a mix of in-cluster\n                                         The simplest mechanism to  iteratively searchand out-of-cluster demonstrations to cover “blind-\n                                                through prompt candidate sets is a greedy topKspots”. During inference, a single expert prompt is\n                                                  search where in each iteration of the optimiza-invoked whose cluster centroid µc is closest to the\n                                                             tion, the top-K best-performing candidates on mini-\ninstance-embedding arg minC ||ϕ(xi) −µc||2.\n                                                   batch of data instances Dval are retained for further\n5.4.3  Ensemble Methods                            iterations (e.g. - ProTeGi, AELP. This differs from\n                                               beam-search which judges partial solutions’ basedPromptBoosting (Hou  et  al., 2023), Boosted-\n                                          on the reward for the entire trajectory of promptPrompting (Pitis et al., 2023), PREFER (Zhang\n                                                         edits r({ρ11, ρ12, . . . , ρ1t }).et al., 2024a), etc. are ensemble methods that in-\nvoke multiple prompts during inference and com-   6.2  Upper Confidence Bound and Variants\nbine them to generate the final output ˆy = y0 +\n                                               Relying on a single static evaluation dataset can\nΣmβiyi. GPO (Li et al., 2023c) also uses labeled\n                                                     lead to biases in the selection procedure and finally\nsource data to generate an ensemble of prompts,\n                                                suboptimal solutions. ProTeGi, SPRIG, inter alia,\nwhich are applied to unlabeled target data to gener-\n                                                         cast the candidate prompt selection problem as that\nate output through majority voting.\n                                                   of bandit search - identifying the most suitable\n5.5  Program Synthesis                     arm (prompt candidate) operating on a fixed com-\n                                                    putation budget. They use the Upper ConfidenceProgram-synthesis based approaches transform\n                                           Bounds (UCB, Algorithm 2) which balances explo-LLM pipelines into structured, modular compo-\n                                                         ration with exploitation. In each iteration of promptnents that can be systematically optimized and\n                                                    optimization, they sample a different evaluationcomposed. These optimization techniques itera-\n                                                     dataset Dsample ∈Dval, and maintain a movingtively refine instructions and demonstrations for\n                                                     estimate of the optimality of each arm (i.e. prompt).each module to improve the entire pipeline’s per-\n                                                   In each iteration, the playout filters top-B promptformance, DSP (Khattab et al., 2022) introduces\n                                                  candidates with the greatest score for further ex-a three-stage framework for retrieval-augmented\n                                                       ploration. PromptAgent uses a variation of UCBinference: Demonstrate (generates task-specific\n                                                       called UCB for Trees (UCT) which are used in thedemonstrations), Search (retrieves relevant infor-\n                                                        setting of contextual bandits (i.e. the action-spacemation), and Predict (combines retrieved info with\n                                              and the reward function is state-dependent). AELPdemonstrations). DSPY (Khattab et al., 2024)\n                                                 (Hsieh et al., 2024) used a modification called Lin-transforms LLM pipelines into text transformation\n                                                      ear UCB (Li et al., 2010) which uses a closed formgraphs - introducing parameterized models, learn-\n                                                         linear estimate based on the reward trajectories ofing through demonstrations, and a compiler that op-\n                                                    previously sampled edits as well as prompt embed-timizes pipelines. DLN (Sordoni et al., 2023) simi-\n                                                 ding ϕ(s) to select the next best-arm.larly considers chained LLM calls as stacked deep\nlanguage networks performing variational infer-\nence, where the learnable parameters for each layer\nare task-decomposed prompt templates. MIPRO\n\n6.3  Region-based Joint Search                      settings. Barring a few tasks covered by Joko et al.\n                                                  (2024); Sun et al. (2024a); Zhang et al. (2022);MOP (Wang et al., 2025) proposes a Mixture-\n                                            Choi et al. (2024), inference-time optimization ofof-Expert-Prompts performing prompt optimiza-\n                                                   multiple unknown tasks is underexplored. Moretion for each expert individual. Once C exemplar-\n                                                   robust evaluations are needed for task-agnosticclusters are identified, the RBJS search first sam-\n                                APO systems combining seen and unseen tasks.ples examples Dexemplars ∈DC ∪D \\ DC, and\nthen uses APE to induct and optimize each expert    9.2  Unclear Mechanisms\ninstruction.                                       Melamed et al. (2024) showed that prompts have\n6.4  Metaheuristic Ensemble                      so-called ’evil twins’ that are uninterpretable yet\n                                                   recover some of the performance of gold-standardPLUM (Pan et al., 2024) library offered a meta-\n                                                prompts. Lu et al. (2024) showed that rare gib-heuristic ensemble of different search algorithms\n                                                    berish strings can serve as competitive delimiterslike Hill climbing, Simulated Annealing, Genetic\n                                                 τ in prompts. Yang et al. (2024b) showed thatAlgorithms, Tabu Search, and Harmony Search.\n                                                          self-reflection by LLMs can suffer from incorrect\n7  Iteration Depth                                                       error identification, prior biases, semantic invalid-\n7.1  Fixed Steps                                               ity, leading to failure in yielding improved prompts.\n                                         More studies are needed to better uncover the mech-\nMost approaches choose to carry out the prompt\n                                               anisms of prompt optimization.\noptimization for a fixed number of steps N.\n                                                    9.3 APO for System Prompts / Agents\n7.2  Variable number of steps\n                                             Although SPRIG explored optimizing system\nGRIPS (Prasad et al., 2023) concludes search when\n                                              prompts in chat-style settings, scalability remains\nsuccessive iterations with negative gains breach\n                                                a challenge - optimizing system prompts required\na patience parameter, whereas PromptAgent con-\n                                                 a predefined corpus and close to 60 hours whereas\ncluded APO when rt ≤ϵmin ∨rt ≥ϵmax.                                                      Protegi only needed ˜10 minutes per task. Similarly,\n8  Theoretical Perspectives                   optimizing prompts for several components in an\n                                                   agentic system in a concurrent fashion poses an\n8.1  Upper Bound of Improvement from APO\n                                                      exciting direction for future research.\nAlignPro (Trivedi et al., 2025) establishes an upper\n                                                    9.4  Multimodal APO\nbound on the gains realizable from discrete prompt\noptimization under a given prompt optimizer and    Recently,  textual prompt optimization has ex-\nalso a suboptimality-gap w.r.t. RLHF-optimal pol-   panded to multimodal domains: text-to-image (Liu\nicy π∗, while a lower bound is left unexplored.        et al., 2024b; Mañas et al., 2024; Liu et al., 2024d),\n                                                       text-to-video (Ji et al., 2024), text-to-audio (Huang\n8.2  Other Related Perspectives\n                                                             et al., 2023), and text-image alignment models like\nBhargava et al. (2024) proposed a control theo-   CLIP (Du et al., 2024; Mirza et al., 2024). Be-\nretic framework to establish bounds on the set of   yond textual prompts, Huang et al. (2023) explore\nreachable LLM-outputs for self-attention in terms    optimizing multimodal inputs, such as images, to\nof the singular values of its weight matrices. Liu     elicit better responses from large multimodal mod-\net al. (2024c) showed the existence of a strong     els. However, the interplay between modalities in\ntransformer that can approximate any sequence-to-   prompt optimization remains underexplored. Fu-\nsequence Lipschitz function. They also showed the    ture research could develop APO frameworks to\nexistence of “difficult” datasets that depth-limited    jointly optimize multimodal prompts (eg - remove\ntransformers could not commit to memory.         background noise from audio, add visual markers\n9  Challenges and Future Directions           to videos, etc.) to fully leverage their synergies.\n                                       10  Conclusion9.1  Task-agnostic APO\n                                                   In this paper, we provide a comprehensive fine-All the surveyed APO methods assume that the task\n                                                 grained review of existing APO techniques andtype T is known beforehand; additionally offline\n                                                          identified key areas for future growth. It is our aimAPO methods also require an evaluation set Dval,\n                                                        to spur future research spawning from our survey.something not explicitly available in production\n\n11  Limitations                                  Iwaszuk, Smriti Jha, Dan Klein, Jayant Krishnamurthy,\n                                             Theo Lanman, Percy Liang, C. H. Lin, Ilya Lintsbakh,\nWhile we attempted to cover all qualifying papers,                                          Andy McGovern, Aleksandr Nisnevich, Adam Pauls,\nit is possible that we may have unintentionally    Dmitrij Petters, Brent Read, Dan Roth, Subhro Roy,\nmissed out on some relevant papers. We also men-    Jesse Rusak, Beth Ann Short, Div Slomin, B Snyder,\n                                                  Stephon Striplin, Yu Su, Zachary Tellman, Sam Thom-tion some of the papers that were excluded in this\n                                                         son, A. A. Vorobev, Izabela Witoszko, Jason Wolfe,\nsurvey with specific reasons in section 12.2. Also,                                                  A. G. Wray, Yuchen Zhang, and Alexander Zotov. 2020.\nwe realize that fitting varied research works into a    Task-oriented dialogue as dataflow synthesis. Transac-\nsingle unifying framework might risk broad catego-    tions of the Association for Computational Linguistics,\nrizations for some papers, or skipping some char-   8:556–571.\nacteristics for others (e.g. Tempera (Zhang et al.,    Trapit Bansal, Rishikesh Jha, and Andrew McCallum.\n2022) consists of both RL-based and word/phrase-   2019. Learning to few-shot learn across diverse natural\nlevel editing techniques, applied to both instruc-   language classification tasks. In International Confer-\n                                                    ence on Computational Linguistics.\ntions and exemplars). In such cases, we categorize\na paper based on its most salient features. Another   Aman Bhargava, Cameron Witkowski, Shi-Zhuo Looi,\nchallenge is that when presenting a survey paper   and Matt Thomson. 2024. What’s the magic word? a\n                                                          control theory of llm prompting.under 8 pages, we had to make tradeoffs and only\nretain content in the main body that was deemed    Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng\nmost necessary. This resulted in having to relegate   Gao, and Yejin Choi. 2019.  Piqa: Reasoning about\n                                                        physical commonsense in natural language. In AAAIa core contribution (Tables 2,3,4) which contained\n                                                    Conference on Artificial Intelligence.\na rigorous comparison of all the surveyed papers\ninto the appendix. We have attempted our best   Samuel R Bowman, Gabor Angeli, Christopher Potts,\n                                                and Christopher D Manning. 2015. A large annotatedto strike the right balance between specificity and\n                                                    corpus for learning natural language inference. arXiv\nbrevity to present a novel framework. We also pro-                                                          preprint arXiv:1508.05326.\nvide copious references to interested researchers\nfor further reading.                         Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie\n                                                     Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\n                                                     Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nReferences                                             Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen\n                                                        Krueger, Tom Henighan, Rewon Child, Aditya Ramesh,\nEshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav                                                      Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christo-\nMagazine, Tanuja Ganu, and Akshay Nambi. 2024.                                                    pher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,\nPromptwizard: Task-aware prompt optimization frame-    Scott Gray, Benjamin Chess, Jack Clark, Christopher\nwork.                                                          Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\n                                                and Dario Amodei. 2020. Language models are few-\nFernando Alva-Manchego, Louis Martin, Antoine Bor-                                                         shot learners.\ndes, Carolina Scarton, Benoît Sagot, and Lucia Specia.\n2020.  Asset: A dataset for tuning and evaluation of   Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nsentence simplification models with multiple rewriting    Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ramadan,\ntransformations.  In Proceedings of the 58th Annual    and Milica Gasic. 2018. Multiwoz-a large-scale multi-\nMeeting of the Association for Computational Linguis-   domain wizard-of-oz dataset for task-oriented dialogue\ntics, pages 4668–4679.                                 modelling. In Proceedings of the 2018 Conference on\n                                                    Empirical Methods in Natural Language Processing,\nAfra Amini, Tim Vieira, and Ryan Cotterell. 2024. Di-                                                    pages 5016–5026.\nrect preference optimization with an offset. In Findings\nof the Association for Computational Linguistics: ACL    Daniel Matthew Cer, Mona T. Diab, Eneko Agirre, Iñigo\n2024, pages 9954–9972, Bangkok, Thailand. Associa-   Lopez-Gazpio, and Lucia Specia. 2017. Semeval-2017\ntion for Computational Linguistics.                       task 1: Semantic textual similarity multilingual and\n                                                           crosslingual focused evaluation. In International Work-\nR. Anantha, Svitlana Vakulenko, Zhucheng Tu, S. Long-                                                  shop on Semantic Evaluation.\npre, Stephen G. Pulman, and Srinivas Chappidi. 2020.\nOpen-domain question answering goes conversational   Mauro Cettolo, Marcello Federico, Luisa Bentivogli,\nvia question rewriting. In North American Chapter of    Niehues  Jan,  Stüker  Sebastian, Sudoh  Katsuitho,\nthe Association for Computational Linguistics.          Yoshino Koichiro, and Federmann Christian. 2017.\n                                                 Overview of the iwslt 2017 evaluation campaign. In In-\nJacob  Andreas,  Johannes  Bufe,  David  Burkett,    ternational Workshop on Spoken Language Translation.\nCharles C. Chen, Joshua Clausman, Jean Crawford,\nKate Crim, Jordan DeLoach, Leah Dorner, Jason Eis-   Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang,\nner, Hao Fang, Alan Guo, David Leo Wright Hall,   Nicholas Roy, and Chuchu Fan. 2024. PRompt opti-\nKristin Delia Hayes, Kellie Hill, Diana Ho, Wendy    mization in multi-step tasks (PROMST): Integrating\n\nhuman feedback and heuristic-based sampling. In Pro-   Ido Dagan, Oren Glickman, and Bernardo Magnini.\nceedings of the 2024 Conference on Empirical Meth-   2005. The pascal recognising textual entailment chal-\nods in Natural Language Processing, pages 3859–3920,    lenge. In Machine Learning Challenges Workshop.\nMiami, Florida, USA. Association for Computational\nLinguistics.                                          Marie-Catherine de Marneffe, Mandy Simons, and Ju-\n                                                            dith Tonhauser. 2019. The commitmentbank: Investi-\nJiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongn-    gating projection in naturally occurring discourse.\ning Wang, Yuxiao Dong, Jie Tang, and Minlie Huang.\n2024. Black-box prompt optimization: Aligning large    Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan\nlanguage models without model training. In Proceed-   Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing,\nings of the 62nd Annual Meeting of the Association for   and Zhiting Hu. 2022. Rlprompt: Optimizing discrete\nComputational Linguistics (Volume 1: Long Papers),    text prompts with reinforcement learning.\npages 3201–3219, Bangkok, Thailand. Association for\n                                                   Franck Dernoncourt and Ji Young Lee. 2017. PubmedComputational Linguistics.\n                                                200k rct: a dataset for sequential sentence classification\n                                                             in medical abstracts. In International Joint ConferenceWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\n                                               on Natural Language Processing.Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E Gonzalez, et al.\n                                                   Robert C. Detrano, András Jánosi, Walter Steinbrunn,2023. Vicuna: An open-source chatbot impressing gpt-\n                                                      Matthias Emil Pfisterer, Johann-Jakob Schmid, Sarbjit4 with 90%* chatgpt quality. See https://vicuna. lmsys.\n                                                   Sandhu, Kern Guppy, Stella Lee, and Victor Froelicher.org (accessed 14 April 2023), 2(3):6.\n                                                   1989.  International application of a new probability\n                                                      algorithm for the diagnosis of coronary artery disease.Minje Choi, Jiaxin Pei, Sagar Kumar, Chang Shu, and\n                                               The American journal of cardiology, 64 5:304–10.David Jurgens. 2023. Do llms understand social knowl-\nedge? evaluating the sociability of large language mod-\n                                                   Shizhe Diao, Zhichao Huang, Ruijia Xu, Xuechun Li,\nels with socket benchmark. In Proceedings of the 2023\n                                            Yong Lin, Xiao Zhou, and Tong Zhang. 2022. Black-Conference on Empirical Methods in Natural Language\n                                              box prompt learning for pre-trained language models.\nProcessing, pages 11370–11403.\n                                                     arXiv preprint arXiv:2201.08531.\n\nYunseon Choi, Sangmin Bae, Seonghyun Ban, Min-                                                     Rezarta Islamaj Do˘gan, Robert Leaman, and Zhiyong\nchan Jeong, Chuheng Zhang, Lei Song, Li Zhao, Jiang                                                   Lu. 2014. Ncbi disease corpus: a resource for disease\nBian, and Kee-Eung Kim. 2024. Hard prompts made                                           name recognition and concept normalization. Journal\ninterpretable: Sparse entropy regularization for prompt                                                             of biomedical informatics, 47:1–10.\ntuning with rl.\n                                                   William B. Dolan and Chris Brockett. 2005. Automat-\nChristopher Cieri, Mark Liberman, Sunghye Cho,                                                               ically constructing a corpus of sentential paraphrases.\nStephanie  Strassel, James Fiumara, and Jonathan                                                          In International Joint Conference on Natural Language\nWright. 2022. Reflections on 30 years of language re-                                                        Processing.\nsource development and sharing. In Proceedings of the\nThirteenth Language Resources and Evaluation Con-   Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan\nference, pages 543–550, Marseille, France. European   Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu,\nLanguage Resources Association.                    Baobao Chang, Xu Sun, Lei Li, and Zhifang Sui. 2024a.\n                                 A survey on in-context learning. In Proceedings of the\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,   2024 Conference on Empirical Methods in Natural Lan-\nAshish Sabharwal, Carissa Schoenick, and Oyvind   guage Processing, pages 1107–1128, Miami, Florida,\nTafjord. 2018.  Think you have solved question an-   USA. Association for Computational Linguistics.\nswering? try arc, the ai2 reasoning challenge. ArXiv,\nabs/1803.05457.                                   Yihong Dong, Kangcheng Luo, Xue Jiang, Zhi Jin, and\n                                        Ge Li. 2024b. PACE: Improving prompt with actor-\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,     critic editing for large language model. In Findings of\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plap-    the Association for Computational Linguistics: ACL\npert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al.   2024, pages 7304–7323, Bangkok, Thailand. Associa-\n2021. Training verifiers to solve math word problems.    tion for Computational Linguistics.\narXiv preprint arXiv:2110.14168.\n                                                  Yingjun Du, Wenfang Sun, and Cees GM Snoek.\nMike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie,    2024. Ipo: Interpretable prompt optimization for vision-\nJun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei    language models. arXiv preprint arXiv:2410.15397.\nZaharia, and Reynold Xin. 2023. Free dolly: Introduc-\ning the world’s first truly open instruction-tuned llm.   Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel\nCompany Blog of Databricks.                           Stanovsky, Sameer Singh, and Matt Gardner. 2019.\n                                                  Drop: A reading comprehension benchmark requiring\nLeyang Cui, Yu Wu, Shujie Liu, Yue Zhang, and Ming    discrete reasoning over paragraphs. In North American\nZhou. 2020. Mutual: A dataset for multi-turn dialogue    Chapter of the Association for Computational Linguis-\nreasoning. ArXiv, abs/2004.04494.                              tics.\n\nStefan Daniel Dumitrescu, Petru Rebeja, Beáta L˝orincz,   Han He, Qianchu Liu, Lei Xu, Chaitanya Shivade,\nMihaela G˘aman, Mihai Daniel Ilie, Andrei Pruteanu,   Yi Zhang, Sundararajan Srinivasan, and Katrin Kirch-\nAdriana Stan, Luciana Morogan, Traian Rebedea, and    hoff. 2025. Crispo: Multi-aspect critique-suggestion-\nSebastian Ruder. 2021. Liro: Benchmark and leader-   guided automatic prompt optimization for text genera-\nboard for romanian language tasks.   In NeurIPS     tion.\nDatasets and Benchmarks.\n                                          Dan Hendrycks, Collin Burns, Steven Basart, Andy\nIbrahim Abu Farha and Walid Magdy. 2020a. From    Zou, Mantas Mazeika, Dawn Xiaodong Song, and Ja-\narabic sentiment analysis to sarcasm detection: The   cob Steinhardt. 2020.  Measuring massive multitask\narsarcasm dataset. In OSACT.                          language understanding. ArXiv, abs/2009.03300.\n\nIbrahim Abu Farha and Walid Magdy. 2020b. From                                          Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul\narabic sentiment analysis to sarcasm detection: The                                                        Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob\narsarcasm dataset. In OSACT.                                                           Steinhardt. Measuring mathematical problem solving\n                                                    with the math dataset.  In Thirty-fifth Conference onChrisantha  Fernando,  Dylan  Banarse,  Henryk\n                                                  Neural Information Processing Systems Datasets and\nMichalewski,  Simon  Osindero,  and Tim  Rock-\n                                                Benchmarks Track (Round 2).täschel.  2023.    Promptbreeder:   Self-referential\nself-improvement  via prompt  evolution.    ArXiv,\n                                            Or Honovich, Uri Shaham, Samuel R. Bowman, and\nabs/2309.16797.\n                                         Omer Levy. 2022.  Instruction induction: From few\nRory A. Fisher. 1936. The use of multiple measure-   examples to natural language task descriptions. ArXiv,\nments in taxonomic problems. Annals of Human Genet-   abs/2205.10782.\nics, 7:179–188.\n                                            Or Honovich, Uri Shaham, Samuel R. Bowman, and\nNoa Garcia, Chentao Ye, Zihua Liu, Qingtao Hu, Mayu   Omer Levy. 2023.  Instruction induction: From few\nOtani, Chenhui Chu, Yuta Nakashima, and Teruko Mita-   examples to natural language task descriptions. In Pro-\nmura. 2020. A dataset and baselines for visual question    ceedings of the 61st Annual Meeting of the Association\nanswering on art. In European Conference on Computer    for Computational Linguistics (Volume 1: Long Papers),\nVision, pages 92–108.                                pages 1935–1952, Toronto, Canada. Association for\n                                                    Computational Linguistics.\nMiguel Garc’ia-Orteg’on, Gregor N. C. Simm, Austin\nTripp, José Miguel Hernández-Lobato, Andreas Ben-   Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren\nder, and Sergio Bacallado. 2021.  Dockstring: Easy    Etzioni, and Nate Kushman. 2014. Learning to solve\nmolecular docking yields better benchmarks for ligand    arithmetic word problems with verb categorization. In\ndesign. Journal of Chemical Information and Modeling,   Conference on Empirical Methods in Natural Language\n62:3486 – 3502.                                        Processing.\n\nClaire Gardent, Anastasia Shimorina, Shashi Narayan,    Bairu Hou, Joe O’Connor, Jacob Andreas, Shiyu Chang,\nand Laura Perez-Beltrachini. 2017. Creating training    and Yang Zhang. 2023. Promptboosting: black-box text\ncorpora for nlg micro-planners. In Annual Meeting of     classification with ten forward passes. In Proceedings of\nthe Association for Computational Linguistics.            the 40th International Conference on Machine Learning,\n                                               ICML’23. JMLR.org.\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,\nDan Roth, and Jonathan Berant. 2021. Did aristotle use\n                                                   Cho-Jui Hsieh, Si Si, Felix Yu, and Inderjit Dhillon.\na laptop? a question answering benchmark with implicit                                                     2024. Automatic engineering of long prompts. In Find-\nreasoning strategies. Transactions of the Association                                                        ings of the Association for Computational Linguistics:\nfor Computational Linguistics, 9:346–361.                                       ACL 2024, page 10672—10685, Bangkok, Thailand.\n                                                       Association for Computational Linguistics.Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and\nAleksander Wawer. 2019. Samsum corpus: A human-\n                                               Minqing Hu and Bing Liu. 2004.  Mining and sum-annotated dialogue dataset for abstractive summariza-\n                                                    marizing customer reviews. Proceedings of the tenthtion. In Proceedings of the 2nd Workshop on New Fron-\n                                  ACM SIGKDD international conference on Knowledgetiers in Summarization, pages 70–79.\n                                                        discovery and data mining.\nChulaka Gunasekara, Jonathan K. Kummerfeld, Lazaros\nPolymenakos, and Walter S. Lasecki. 2019. Dstc7 task    Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and\n1: Noetic end-to-end response selection. Proceedings    Yejin Choi. 2019. Cosmos qa: Machine reading com-\nof the First Workshop on NLP for Conversational AI.     prehension with contextual commonsense reasoning.\n                                                        In Proceedings of the 2019 Conference on Empirical\nQingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao   Methods in Natural Language Processing and the 9th\nSong, Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu Yang.    International Joint Conference on Natural Language\n2024. Connecting large language models with evolu-   Processing (EMNLP-IJCNLP), pages 2391–2401.\ntionary algorithms yields powerful prompt optimizers.\nIn The Twelfth International Conference on Learning    Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren,\nRepresentations.                                    Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang\n\nYin, and Zhou Zhao. 2023. Make-an-audio: Text-to-   Omar Khattab, Arnav Singhvi, Paridhi Maheshwari,\naudio generation with prompt-enhanced diffusion mod-   Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan,\nels. In International Conference on Machine Learning,    Saiful Haq, Ashutosh Sharma, Thomas T. Joshi, Hanna\npages 13916–13932. PMLR.                      Moazam, Heather Miller, Matei Zaharia, and Christo-\n                                                      pher Potts. 2024. Dspy: Compiling declarative language\nYasaman Jafari, Dheeraj Mekala, Rose Yu, and Taylor   model calls into self-improving pipelines.\nBerg-Kirkpatrick. 2024. Morl-prompt: An empirical\nanalysis of multi-objective reinforcement learning for    Johannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\ndiscrete prompt optimization.                        manuel Vincent, Payam Adineh, D. Corney, Benno\n                                                              Stein, and Martin Potthast. 2019. Semeval-2019 task 4:\nYatai  Ji, Jiacheng Zhang,  Jie Wu, Shilong Zhang,    Hyperpartisan news detection. In International Work-\nShoufa Chen, Chongjian GE, Peize Sun, Weifeng Chen,   shop on Semantic Evaluation.\nWenqi Shao, Xuefeng Xiao, et al. 2024. Prompt-a-video:\nPrompt your video diffusion model via preference-    Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\naligned llm. arXiv preprint arXiv:2412.15156.            taka Matsuo, and Yusuke Iwasawa. 2023. Large lan-\n                                                  guage models are zero-shot reasoners.\nYichen Jiang, Shikha Bordia, Zheng Zhong, Charles\nDognin, Maneesh Kumar Singh, and Mohit Bansal.                                                Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish\n2020. Hover: A dataset for many-hop fact extraction                                                     Sabharwal, Oren Etzioni, and Siena Dumas Ang. 2015.\nand claim verification. In Findings.                                                        Parsing algebraic word problems into equations. Trans-\n                                                        actions of the Association for Computational Linguis-\nCan Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang,                                                                        tics, 3:585–597.\nWujiang Xu, Ligong Han, Jiahui Zhao, Kai Zhong,\nSanguthevar Rajasekaran, and Dimitris N. Metaxas.                                               Weize Kong, Spurthi Amba Hombaiah, Mingyang\n2024. Apeer: Automatic prompt engineering enhances                                                  Zhang, Qiaozhu Mei, and Michael Bendersky. 2024.\nlarge language model reranking.                                                            Prewrite: Prompt rewriting with reinforcement learning.\n\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,\n                                                Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu\nHanyi Fang, and Peter Szolovits. 2020. What disease\n                                                  Khandelwal, Bishal Santra, Parag Agrawal, and Man-\ndoes this patient have? a large-scale open domain ques-\n                                                            ish Gupta. 2024.  Sculpt: Systematic tuning of long\ntion answering dataset from medical exams.  ArXiv,\n                                                      prompts.\nabs/2009.13081.\n\n                                      Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William\n                                                                     field, Michael Collins, Ankur Parikh, Chris Alberti,Cohen, and Xinghua Lu. 2019. Pubmedqa: A dataset\n                                                       Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-for biomedical research question answering.  In Pro-\n                                                      ton Lee, et al. 2019. Natural questions: a benchmarkceedings of the 2019 Conference on Empirical Methods\n                                                            for question answering research. Transactions of thein Natural Language Processing and the 9th Interna-\n                                                        Association for Computational Linguistics, 7:453–466.tional Joint Conference on Natural Language Process-\ning (EMNLP-IJCNLP), pages 2567–2577.\n                                             Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and\n                                                Eduard Hovy. 2017. Race: Large-scale reading com-Hideaki Joko, Shubham Chatterjee, Andrew Ramsay,\n                                                     prehension dataset from examinations. arXiv preprintArjen P De Vries, Jeff Dalton, and Faegheh Hasibi.\n                                                     arXiv:1704.04683.2024. Doing personal laps: Llm-augmented dialogue\nconstruction for personalized multi-session conversa-\n                                                 Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.tional search. In Proceedings of the 47th International\n                                                    2019. Latent retrieval for weakly supervised open do-ACM SIGIR Conference on Research and Development\n                                               main question answering. ArXiv, abs/1906.00300.in Information Retrieval, pages 796–806.\n\nGurusha Juneja, Nagarajan Natarajan, Hua Li, Jian Jiao,    Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.\nand Amit Sharma. 2024. Task facet learning: A struc-   The power of scale for parameter-efficient prompt tun-\ntured approach to prompt optimization. arXiv preprint    ing. In Proceedings of the 2021 Conference on Empir-\narXiv:2406.10504.                                          ical Methods in Natural Language Processing, pages\n                                                   3045–3059, Online and Punta Cana, Dominican Repub-\nDavid Jurgens, Srijan Kumar, Raine Hoover, Daniel A.     lic. Association for Computational Linguistics.\nMcFarland, and Dan Jurafsky. 2018. Measuring the\nevolution of a scientific field through citation frames.   Hector J. Levesque, Ernest Davis, and L. Morgenstern.\nTransactions of the Association for Computational Lin-   2011. The winograd schema challenge. In AAAI Spring\nguistics, 6:391–406.                               Symposium: Logical Formalizations of Commonsense\n                                                     Reasoning.\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li,\nDavid Hall, Percy Liang, Christopher Potts, and Matei    Bei Li, Rui Wang, Junliang Guo, Kaitao Song, Xu Tan,\nZaharia. 2022.   Demonstrate-search-predict: Com-   Hany Hassan, Arul Menezes, Tong Xiao, Jiang Bian,\nposing retrieval and language models for knowledge-   and JingBo Zhu. 2023a. Deliberate then generate: En-\nintensive nlp. arXiv preprint arXiv:2212.14024.         hanced prompting framework for text generation.\n\nCheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu,   Xiaogeng Liu, Zhiyuan Yu, Yizhe Zhang, Ning Zhang,\nWenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang,   and Chaowei Xiao. 2024c. Automatic and universal\nand Xing Xie. 2023b. Large language models under-   prompt injection attacks against large language models.\nstand and can be enhanced by emotional stimuli. arXiv\npreprint arXiv:2307.11760.                             Yilun Liu, Minggui He, Feiyu Yao, Yuhe Ji, Shimin Tao,\n                                                    Jingzhou Du, Duan Li, Jian Gao, Li Zhang, Hao Yang,\nLihong Li, Wei Chu, John Langford, and Robert E.    et al. 2024d. What do you want? user-centric prompt\nSchapire. 2010. A contextual-bandit approach to per-    generation for text-to-image synthesis via multi-turn\nsonalized news article recommendation. In Proceedings    guidance. arXiv preprint arXiv:2408.12910.\nof the 19th International Conference on World Wide\nWeb, WWW ’10, page 661–670, New York, NY, USA.   Xuan Do Long, Yiran Zhao, Hannah Brown, Yuxi Xie,\nAssociation for Computing Machinery.                James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi,\n                                                  Michael Shieh, and Junxian He. 2024. Prompt opti-\nMoxin Li, Wenjie Wang, Fuli Feng, Yixin Cao, Jizhi    mization via adversarial in-context learning.  In Pro-\nZhang, and Tat-Seng Chua. 2023c. Robust prompt opti-    ceedings of the 62nd Annual Meeting of the Association\nmization for large language models against distribution    for Computational Linguistics (Volume 1: Long Papers),\nshifts. In Proceedings of the 2023 Conference on Em-   pages 7308–7327, Bangkok, Thailand. Association for\npirical Methods in Natural Language Processing, pages    Computational Linguistics.\n1539–1554, Singapore. Association for Computational\n                                            Ryan Lowe, Nissan Pow, Iulian Serban, and JoelleLinguistics.\n                                                       Pineau. 2015. The ubuntu dialogue corpus: A large\nZekun Li, Baolin Peng, Pengcheng He, Michel Galley,    dataset for research in unstructured multi-turn dialogue\nJianfeng Gao, and Xifeng Yan. 2023d. Guiding large    systems. In SIGDIAL Conference.\nlanguage models via directional stimulus prompting.\n                                                     Junru Lu, Siyu An, Min Zhang, Yulan He, Di Yin, andarXiv preprint arXiv:2302.11520.\n                                               Xing Sun. 2025. FIPO: Free-form instruction-oriented\nStephanie Lin, Jacob Hilton, and Owain Evans. 2022.   prompt optimization with preference dataset and mod-\nTruthfulqa: Measuring how models mimic human false-    ular fine-tuning schema.  In Proceedings of the 31st\nhoods. In Proceedings of the 60th Annual Meeting of    International Conference on Computational Linguistics,\nthe Association for Computational Linguistics (Volume    page 11029—11047, Abu Dhabi, UAE. Association for\n1: Long Papers), pages 3214–3252.                     Computational Linguistics.\n\nTsung-Yi Lin, Michael Maire, Serge Belongie, James   Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,\nHays, Pietro Perona, Deva Ramanan, Piotr Dollár, and   and Pontus Stenetorp. 2021.   Fantastically ordered\nC Lawrence Zitnick. 2014. Microsoft coco: Common    prompts and where to find them: Overcoming few-shot\nobjects in context. In Computer Vision–ECCV 2014:   prompt order sensitivity. In Annual Meeting of the As-\n13th European Conference, Zurich, Switzerland, Septem-    sociation for Computational Linguistics.\nber 6-12, 2014, Proceedings, Part V 13, pages 740–755.\n                                            Yao Lu, Jiayi Wang, Raphael Tang, Sebastian Riedel,Springer.\n                                                  and Pontus Stenetorp. 2024. Strings from the library of\nXiaoqiang Lin, Zhongxiang Dai, Arun Verma, See-    babel: Random sampling as a strong baseline for prompt\nKiong Ng, Patrick Jaillet, and Bryan Kian Hsiang Low.    optimisation. In Proceedings of the 2024 Conference of\n2024. Prompt optimization with human feedback.         the North American Chapter of the Association for Com-\n                                                          putational Linguistics: Human Language Technologies\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-   (Volume 1: Long Papers), page 2221—2231, Mexico\nsom. 2017. Program induction by rationale generation:    City, Mexico. Association for Computational Linguis-\nLearning to solve and explain algebraic word problems.     tics.\nIn Annual Meeting of the Association for Computational\nLinguistics.                                       Yi Luan, Luheng He, Mari Ostendorf, and Hannaneh\n                                                               Hajishirzi. 2018. Multi-task identification of entities, re-\nNelson F Liu, Kevin Lin, John Hewitt, Ashwin Paran-    lations, and coreference for scientific knowledge graph\njape, Michele Bevilacqua, Fabio Petroni, and Percy    construction. ArXiv, abs/1808.09602.\nLiang. 2024a. Lost in the middle: How language mod-\nels use long contexts. Transactions of the Association   Andrew Maas, Raymond E Daly, Peter T Pham, Dan\nfor Computational Linguistics, 12:157–173.            Huang, Andrew Y Ng, and Christopher Potts. 2011.\n                                                   Learning word vectors for sentiment analysis. In Pro-\nShengcai Liu, Caishun Chen, Xinghua Qu, Ke Tang,    ceedings of the 49th annual meeting of the association\nand Yew Soon Ong. 2023. Large language models as    for computational linguistics: Human language tech-\nevolutionary optimizers. 2024 IEEE Congress on Evo-    nologies, pages 142–150.\nlutionary Computation (CEC), pages 1–8.\n                                                  Oscar Mañas,  Pietro  Astolfi,  Melissa  Hall, Can-\nShihong Liu, Samuel Yu, Zhiqiu Lin, Deepak Pathak,   dace Ross, Jack Urbanek, Adina Williams, Aish-\nand Deva Ramanan. 2024b. Language models as black-   warya Agrawal, Adriana Romero-Soriano, and Michal\nbox optimizers for vision-language models. In Proceed-   Drozdzal. 2024. Improving text-to-image consistency\nings of the IEEE/CVF Conference on Computer Vision    via automatic prompt optimization.  arXiv preprint\nand Pattern Recognition, pages 12687–12697.           arXiv:2403.17804.\n\nBryan McCann, Nitish Shirish Keskar, Caiming Xiong,   Maddie Simens, Amanda Askell, Peter Welinder, Paul\nand Richard Socher. 2018. The natural language de-    Christiano, Jan Leike, and Ryan Lowe. 2022. Train-\ncathlon:  Multitask learning as question answering.    ing language models to follow instructions with human\narXiv preprint arXiv:1806.08730.                        feedback.\n\nRimon Melamed, Lucas H. McCabe, Tanay Wakhare,   Ankit Pal, Logesh Kumar Umapathi, and Malaikannan\nYejin Kim, H. Howie Huang, and Enric Boix-Adsera.   Sankarasubbu. 2022. Medmcqa: A large-scale multi-\n2024. Prompts have evil twins.                           subject multi-choice dataset for medical domain ques-\n                                                              tion answering. In Conference on health, inference, and\nM Jehanzeb Mirza, Mengjie Zhao, Zhuoyuan Mao,                                                           learning, pages 248–260. PMLR.\nSivan Doveh, Wei Lin, Paul Gavrikov, Michael Dorken-\nwald, Shiqi Yang, Saurav Jha, Hiromi Wakaki, et al.                                                Rui Pan, Shuo Xing, Shizhe Diao, Wenhe Sun, Xiang\n2024. Glov: Guided large language models as implicit                                                          Liu, KaShun Shum, Jipeng Zhang, Renjie Pi, and Tong\noptimizers for vision language models. arXiv preprint                                                   Zhang. 2024. Plum: Prompt learning using metaheuris-\narXiv:2410.06154.                                                                       tics. In Findings of the Association for Computational\n                                                           Linguistics: ACL 2024, page 2177—2197, Bangkok,Swaroop Mishra, Daniel Khashabi, Chitta Baral, and\n                                                        Thailand. Association for Computational Linguistics.Hannaneh Hajishirzi. 2021. Cross-task generalization\nvia natural language crowdsourcing instructions.  In\n                                         Bo Pang and Lillian Lee. 2004. A sentimental education:Annual Meeting of the Association for Computational\n                                                    Sentiment analysis using subjectivity summarizationLinguistics.\n                                                    based on minimum cuts. ArXiv, cs.CL/0409058.\nIoannis Mollas, Zoe Chrysopoulou, Stamatis Karlos,\nand Grigorios Tsoumakas. 2020.   Ethos:  an on-   Bo Pang and Lillian Lee. 2005. Seeing stars: Exploit-\nline hate speech detection dataset.  arXiv preprint    ing class relationships for sentiment categorization with\narXiv:2006.08328.                                        respect to rating scales. In Annual Meeting of the Asso-\n                                                            ciation for Computational Linguistics.\nRamesh Nallapati, Bowen Zhou, Cícero Nogueira\ndos Santos, Çaglar Gülçehre, and Bing Xiang. 2016.    Arkil Patel, S. Bhattamishra, and Navin Goyal. 2021.\nAbstractive  text summarization using sequence-to-   Are nlp models really able to solve simple math word\nsequence rnns and beyond.  In Conference on Com-   problems? In North American Chapter of the Associa-\nputational Natural Language Learning.                    tion for Computational Linguistics.\n\nShashi Narayan, Shay B. Cohen, and Mirella Lapata.   Mohammad Taher Pilehvar and Jose Camacho-Collados.\n2018.  Don’t give me the details, just the summary!    2019. Wic: the word-in-context dataset for evaluating\ntopic-aware convolutional neural networks for extreme    context-sensitive meaning representations. In Proceed-\nsummarization. ArXiv, abs/1808.08745.                  ings of the 2019 Conference of the North American\n                                                  Chapter of the Association for Computational Linguis-\nEhsan Nezhadarya, Yang Liu, and Bingbing Liu. 2019.    tics: Human Language Technologies, Volume 1 (Long\nBoxnet: A deep learning method for 2d bounding box   and Short Papers), pages 1267–1273.\nestimation from bird’s-eye view point cloud. In 2019\nIEEE Intelligent Vehicles Symposium (IV), pages 1557–                                                          Silviu Pitis, Michael R Zhang, Andrew Wang, and\n1564. IEEE.                                  Jimmy Ba. 2023. Boosted prompt ensembles for large\n                                                     language models. arXiv preprint arXiv:2304.05970.\nYixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,\nJason Weston, and Douwe Kiela. 2019. Adversarial nli:                                                Edoardo Maria Ponti, Goran Glavaš, Olga Majewska,\nA new benchmark for natural language understanding.                                                Qianchu Liu, Ivan Vuli´c, and Anna Korhonen. 2020.\nArXiv, abs/1910.14599.\n                                                  Xcopa: A multilingual dataset for causal commonsense\n                                                         reasoning. arXiv preprint arXiv:2005.00333.Jekaterina Novikova, Ondrej Dusek, and Verena Rieser.\n2017. The e2e dataset: New challenges for end-to-end\n                                                     Archiki Prasad, Peter Hase, Xiang Zhou, and Mohitgeneration. ArXiv, abs/1706.09254.\n                                                       Bansal. 2023. Grips: Gradient-free, edit-based instruc-\nKrista Opsahl-Ong, Michael J Ryan, Josh Purtell, David    tion search for prompting large language models.\nBroman, Christopher Potts, Matei Zaharia, and Omar\nKhattab. 2024.  Optimizing instructions and demon-   Reid Pryzant, Dan Iter, Jerry Li, Yin Lee, Chenguang\nstrations for multi-stage language model programs. In    Zhu, and Michael Zeng. 2023. Automatic prompt opti-\nProceedings of the 2024 Conference on Empirical Meth-   mization with “gradient descent” and beam search. In\nods in Natural Language Processing, page 9340—9366,    Proceedings of the 2023 Conference on Empirical Meth-\nMiami, Florida, USA. Association for Computational    ods in Natural Language Processing, page 7957—7968,\nLinguistics.                                            Singapore. Association for Computational Linguistics.\n\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-   Ye Qi, Devendra Singh Sachan, Matthieu Felix, Sarguna\nroll L. Wainwright, Pamela Mishkin, Chong Zhang,   Padmanabhan, and Graham Neubig. 2018. When and\nSandhini Agarwal, Katarina Slama, Alex Ray, John   why are pre-trained word embeddings useful for neural\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,   machine translation? ArXiv, abs/1804.06323.\n\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and   Noah Shinn, Federico Cassano, Ashwin Gopinath,\nPercy Liang. 2016.  Squad: 100,000+ questions for    Karthik Narasimhan, and Shunyu Yao. 2024. Reflexion:\nmachine comprehension of text. In Conference on Em-   Language agents with verbal reinforcement learning.\npirical Methods in Natural Language Processing.        Advances in Neural Information Processing Systems,\n                                                         36.\nDavid Rein, Betty Li Hou, Asa Cooper Stickland, Jack-\nson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian                                               Mohit  Shridhar,  Xingdi  Yuan,  Marc-Alexandre\nMichael, and Samuel R. Bowman. 2023.  Gpqa: A                                                      Côté, Yonatan Bisk, Adam Trischler, and Matthew\ngraduate-level google-proof q&a benchmark.  ArXiv,                                                   Hausknecht. 2020. Alfworld: Aligning text and em-\nabs/2311.12022.                                                   bodied environments for interactive learning.  arXiv\n                                                          preprint arXiv:2010.03768.Melissa Roemmele, Cosmin Adrian Bejan, and An-\ndrew S Gordon. 2011. Choice of plausible alternatives:\nAn evaluation of commonsense causal reasoning. In    Ankita Sinha, Wendi Cui, Kamalika Das, and Jiaxin\n2011 AAAI spring symposium series.                   Zhang. 2024. Survival of the safest: Towards secure\n                                                  prompt optimization through interleaved multi-objective\nSubhro Roy and Dan Roth. 2016. Solving general arith-    evolution. In Proceedings of the 2024 Conference on\nmetic word problems. ArXiv, abs/1608.01413.           Empirical Methods in Natural Language Processing:\n                                                        Industry Track, pages 1016–1027, Miami, Florida, US.\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan                                                       Association for Computational Linguistics.\nLe Bras, and Yejin Choi. 2019. Social iqa: Common-\nsense reasoning about social interactions. In Proceed-                                                   Richard Socher, Alex Perelygin, Jean Wu, Jason\nings of the 2019 Conference on Empirical Methods                                                Chuang, Christopher D Manning, Andrew Y Ng, and\nin Natural Language Processing and the 9th Interna-                                                       Christopher Potts. 2013. Recursive deep models for se-\ntional Joint Conference on Natural Language Process-                                                    mantic compositionality over a sentiment treebank. In\ning (EMNLP-IJCNLP), pages 4463–4473.                                                     Proceedings of the 2013 conference on empirical meth-\n                                                   ods in natural language processing, pages 1631–1642.Tobias Schnabel and Jennifer Neville. 2024. Symbolic\nprompt program search: A structure-aware approach to\nefficient compile-time prompt optimization.           Gizem Sogancioglu, Hakime Öztürk, and Arzucan\n                                                    Özgür. 2017. Biosses: a semantic sentence similarity\nChristoph Schuhmann, Romain Beaumont, Richard    estimation system for the biomedical domain. Bioinfor-\nVencu, Cade Gordon, Ross Wightman, Mehdi Cherti,    matics, 33:i49 – i58.\nTheo Coombes, Aarush Katta, Clayton Mullis, Mitchell\nWortsman, et al. 2022. Laion-5b: An open large-scale    Alessandro Sordoni, Eric Yuan, Marc-Alexandre Côté,\ndataset for training next generation image-text models.   Matheus Pereira, Adam Trischler, Ziang Xiao, Arian\nAdvances in Neural Information Processing Systems,    Hosseini, Friederike Niedtner, and Nicolas Le Roux.\n35:25278–25294.                                    2023.  Joint prompt optimization of stacked llms us-\n                                                       ing variational inference. In Advances in Neural Infor-\nMelanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane\n                                                  mation Processing Systems, volume 36, pages 58128–\nSuhr. Quantifying language models’ sensitivity to spu-\n                                                    58151. Curran Associates, Inc.\nrious features in prompt design or: How i learned to\nstart worrying about prompt formatting. In The Twelfth\n                                                  Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,International Conference on Learning Representations.\n                                         Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch,\nJingyuan Selena She, Christopher Potts, Sam Bowman,  Adam R Brown, Adam Santoro, Aditya Gupta, Adrià\nand Atticus Geiger. 2023. Scone: Benchmarking nega-    Garriga-Alonso, et al. 2022. Beyond the imitation game:\ntion reasoning in language models with fine-tuning and    Quantifying and extrapolating the capabilities of lan-\nin-context learning. In Annual Meeting of the Associa-   guage models. arXiv preprint arXiv:2206.04615.\ntion for Computational Linguistics.\n                                          Hao Sun, Alihan Hüyük, and Mihaela van der Schaar.\nZeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Fan    2024a. Query-dependent prompt evaluation and opti-\nYang, and Yongfeng Zhang. 2024. Robustness-aware    mization with offline inverse RL. In The Twelfth Inter-\nautomatic prompt optimization.                          national Conference on Learning Representations.\n\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV,\n                                          Hong Sun, Xue Li, Yinchuan Xu, Youkow Homma,Eric Wallace, and Sameer Singh. 2020. AutoPrompt:\n                                              Qi Cao, Min Wu, Jian Jiao, and Denis Charles. 2023.Eliciting Knowledge from Language Models with Au-\n                                                         Autohint: Automatic prompt optimization with hint gen-tomatically Generated Prompts. In Proceedings of the\n                                                               eration. arXiv preprint arXiv:2307.07415.2020 Conference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 4222–4235, Online.\n                                                    Jingwei Sun, Ziyue Xu, Hongxu Yin, Dong Yang,Association for Computational Linguistics.\n                                             Daguang Xu, Yudong Liu, Zhixu Du, Yiran Chen, and\nNoah Shinn, Federico Cassano, Edward Berman, Ash-   Holger R. Roth. 2024b.  Fedbpt:  efficient federated\nwin Gopinath, Karthik Narasimhan, and Shunyu Yao.   black-box prompt tuning for large language models. In\n2023.  Reflexion: Language agents with verbal rein-   Proceedings of the 41st International Conference on\nforcement learning.                                Machine Learning, ICML’24. JMLR.org.\n\nMirac Suzgun, Nathan Scales, Nathanael Schärli, Sebas-   Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\ntian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha    Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh\nChowdhery, Quoc Le, Ed Chi, Denny Zhou, et al.    Hajishirzi. 2023. Self-instruct: Aligning language mod-\n2023. Challenging big-bench tasks and whether chain-    els with self-generated instructions. In Proceedings of\nof-thought can solve them. In Findings of the Associa-    the 61st Annual Meeting of the Association for Com-\ntion for Computational Linguistics: ACL 2023, pages    putational Linguistics (Volume 1: Long Papers), pages\n13003–13051.                                     13484–13508, Toronto, Canada. Association for Com-\n                                                           putational Linguistics.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. Commonsenseqa: A question    Yushi Wang, Jonathan Berant, and Percy Liang. 2015.\nanswering challenge targeting commonsense knowledge.   Building a semantic parser overnight. In Annual Meet-\nArXiv, abs/1811.00937.                                 ing of the Association for Computational Linguistics.\n\nPrashant Trivedi, Souradip Chakraborty, Avinash Reddy,   Zhichao Wang, Bin Bi, Shiva Kumar Pentyala, Kiran\nVaneet Aggarwal, Amrit Singh Bedi, and George K.   Ramnath, Sougata Chaudhuri, Shubham Mehrotra, Zixu,\nAtia. 2025. Align-pro: A principled approach to prompt    Zhu, Xiang-Bo Mao, Sitaram Asur, Na, and Cheng.\noptimization for llm alignment.                        2024b. A comprehensive survey of llm alignment tech-\n                                                         niques: Rlhf, rlaif, ppo, dpo and more.\nNirali Vaghani and Mansi Thummar. 2023.  Flipkart\n                                                 Alex Warstadt, Amanpreet Singh, and Samuel R. Bow-product reviews with sentiment dataset.\n                                               man. 2018. Neural network acceptability judgments.\n                                                       Transactions of the Association for Computational Lin-Ellen M Voorhees and Dawn M Tice. 2000. Building a\n                                                                guistics, 7:625–641.question answering test collection. In Proceedings of\nthe 23rd annual international ACM SIGIR conference\n                                                      Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005.on Research and development in information retrieval,\n                                                    Annotating expressions of opinions and emotions inpages 200–207.\n                                                        language. Language Resources and Evaluation, 39:165–\n                                                      210.Xingchen Wan, Ruoxi Sun, Hootan Nakhost, and Ser-\ncan O. Arik. 2024. Teach better or show smarter? on\n                                                Adina Williams, Nikita Nangia, and Samuel R. Bow-\ninstructions and exemplars in automatic prompt opti-\n                                               man. 2017. A broad-coverage challenge corpus for\nmization.\n                                                      sentence understanding through inference.  In North\n                                                  American Chapter of the Association for Computational\nRuochen Wang, Sohyun An, Minhao Cheng, Tianyi\n                                                             Linguistics.\nZhou, Sung Ju Hwang, and Cho-Jui Hsieh. 2025. One\nprompt is not enough: automated construction of a                                                 Yurong Wu, Yan Gao, Bin Benjamin Zhu, Zineng Zhou,\nmixture-of-expert prompts.   In Proceedings of the                                                   Xiaodi Sun, Sheng Yang, Jian-Guang Lou, Zhiming\n41st International Conference on Machine Learning,                                                    Ding, and Linjun Yang. 2024.  StraGo: Harnessing\nICML’24. JMLR.org.                                                              strategic guidance for prompt optimization.  In Find-\n                                                        ings of the Association for Computational Linguistics:\nRuoyao Wang, Peter Jansen, Marc-Alexandre Côté, and                                   EMNLP 2024, pages 10043–10061, Miami, Florida,\nPrithviraj Ammanabrolu. 2022a. Scienceworld: Is your                                          USA. Association for Computational Linguistics.\nagent smarter than a 5th grader?  In Proceedings of\nthe 2022 Conference on Empirical Methods in Natural                                                        Jasper Xian, Saron Samuel, Faraz Khoubsirat, Ronak\nLanguage Processing, pages 11279–11298.                                                      Pradeep, Md Arafat Sultan, Radu Florian, Salim\n                                                  Roukos, Avirup Sil, Christopher Potts, and Omar Khat-\nWilliam Yang Wang. 2017.  “liar, liar pants on fire”:                                                                   tab. 2024. Prompts as auto-optimized training hyperpa-\nA new benchmark dataset for fake news detection. In                                                         rameters: Training best-in-class ir models from scratch\nAnnual Meeting of the Association for Computational                                                     with 10 gold labels. arXiv preprint arXiv:2406.11706.\nLinguistics.\n                                             Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Wang\nXinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Hao-   Yanggang, Haiyu Li, and Zhilin Yang. 2022. Gps: Ge-\ntian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P. Xing, and    netic prompt search for efficient few-shot learning. In\nZhiting Hu. 2024a. Promptagent: Strategic planning    Proceedings of the 2022 Conference on Empirical Meth-\nwith language models enables expert-level prompt opti-   ods in Natural Language Processing, pages 8162–8171.\nmization. In The Twelfth International Conference on\nLearning Representations, ICLR 2024, Vienna, Austria,   Wei Xu, Alan Ritter, William B. Dolan, Ralph Grish-\nMay 7-11, 2024. OpenReview.net.                     man, and Colin Cherry. 2012. Paraphrasing for style. In\n                                                           International Conference on Computational Linguistics.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\nLiu, Noah A. Smith, Daniel Khashabi, and Hannaneh    Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jo-\nHajishirzi. 2022b.  Self-instruct: Aligning language     jic. 2024. Reprompting: automated chain-of-thought\nmodels with self-generated instructions.  In Annual    prompt inference through gibbs sampling. In Proceed-\nMeeting of the Association for Computational Linguis-    ings of the 41st International Conference on Machine\ntics.                                                  Learning, ICML’24. JMLR.org.\n\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,   Lechen Zhang, Tolga Ergen, Lajanugen Logeswaran,\nQuoc V. Le, Denny Zhou, and Xinyun Chen. 2024a.   Moontae Lee, and David Jurgens. 2024b. Sprig: Im-\nLarge language models as optimizers.                   proving large language model performance by system\n                                                 prompt optimization. ArXiv, abs/2410.14826.\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,\nQuoc V Le, Denny Zhou, and Xinyun Chen. 2024b.    Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schu-\nLarge language models as optimizers. In The Twelfth    urmans, and Joseph E. Gonzalez. 2022. Tempera: Test-\nInternational Conference on Learning Representations.   time prompting via reinforcement learning.\n\n                                                       Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q.\nMuchen Yang, Moxin Li, Yongle Li, Zijun Chen, Chong-\n                                                     Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluat-\nming Gao, Junqi Zhang, Yangyang Li, and Fuli Feng.                                                      ing text generation with bert. In International Confer-\n2024c. Dual-phase accelerated prompt optimization.                                                    ence on Learning Representations.\nIn Findings of the Association for Computational Lin-\nguistics: EMNLP 2024, pages 12163–12173, Miami,   Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. 2015.\nFlorida, USA. Association for Computational Linguis-                                                           Character-level convolutional networks for text classifi-\ntics.                                                              cation. In Neural Information Processing Systems.\n\nSheng Yang, Yurong Wu, Yan Gao, Zineng Zhou,   Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\nBin Benjamin Zhu, Xiaodi Sun, Jian-Guang Lou, Zhim-   Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuo-\ning Ding, Anbang Hu, Yuan Fang, et al. 2024d. Ampo:   han Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E.\nAutomatic multi-branched prompt optimization. arXiv    Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge\npreprint arXiv:2410.08696.                             with mt-bench and chatbot arena. In Proceedings of the\n                                                    37th International Conference on Neural Information\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,   Processing Systems, NIPS ’23, Red Hook, NY, USA.\nWilliam W. Cohen, Ruslan Salakhutdinov, and Christo-   Curran Associates Inc.\npher D. Manning. 2018. Hotpotqa: A dataset for di-\nverse, explainable multi-hop question answering.  In   Han Zhou, Xingchen Wan, Ivan Vuli´c, and Anna Ko-\nConference on Empirical Methods in Natural Language    rhonen. 2023. Survival of the most influential prompts:\nProcessing.                                                 Efficient black-box prompt search via clustering and\n                                                       pruning. In Findings of the Association for Computa-\n                                                             tional Linguistics: EMNLP 2023, pages 13064–13077,Qinyuan Ye, Maxamed Axmed, Reid Pryzant, and\n                                                       Singapore. Association for Computational Linguistics.Fereshte Khani. 2024. Prompt engineering a prompt\nengineer.\n                                              Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\n                                                     Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba.\nMert Yuksekgonul, Federico Bianchi, Joseph Boen,                                                    2022. Large language models are human-level prompt\nSheng Liu, Zhi Huang, Carlos Guestrin, and James Zou.                                                          engineers.\n2024. Textgrad: Automatic \"differentiation\" via text.\n\nJohn M. Zelle and Raymond J. Mooney. 1996. Learning\nto parse database queries using inductive logic program-\nming. In AAAI/IAAI, Vol. 2.\n\nRowan Zellers, Ari Holtzman, Yonatan Bisk, Ali\nFarhadi, and Yejin Choi. 2019. Hellaswag: Can a ma-\nchine really finish your sentence? In Proceedings of the\n57th Annual Meeting of the Association for Computa-\ntional Linguistics, pages 4791–4800.\n\nPengwei Zhan, Zhen Xu, Qian Tan, Jie Song, and\nRu Xie. 2024. Unveiling the lexical sensitivity of llms:\nCombinatorial optimization for prompt enhancement.\nIn Conference on Empirical Methods in Natural Lan-\nguage Processing.\n\nChenrui Zhang,  Lin  Liu, Chuyuan Wang,  Xiao\nSun, Hongyu Wang, Jinpeng Wang, and Mingchen\nCai. 2024a.  Prefer: prompt ensemble learning via\nfeedback-reflect-refine. In Proceedings of the Thirty-\nEighth AAAI Conference on Artificial Intelligence and\nThirty-Sixth Conference on Innovative Applications\nof Artificial Intelligence and Fourteenth Symposium\non Educational Advances in Artificial Intelligence,\nAAAI’24/IAAI’24/EAAI’24. AAAI Press.\n\n12  Appendix\n\n12.1  Notation\n\nWe now define the notation of key terms and expressions used throughout the paper.\n\n  1. T = Task type, I= Task instruction, E = (xi, yi)ei=1 Few shot demonstrations in the prompt, τ=\n    Template delimiters, z = CoT recipe for a task-instance, zi ∈Ii\n\n  2. Mtask target model, MAPO APO system\n\n  3. ρ = concat([s1, s2, . . . , sm]) = concat(I, τ, E) Prompt composed of m sentences, which comprise\n     of Instruction, template delimiters and few-shot demonstrations.\n  4. D = {(xi, yi)}mi=1 collection of m input-output pairs. Dval is the validation set used to validate\n    prompt performance, Dtrain is the training set used to finetune the language model(Reprompting).\n  5. {f1, f2, . . .} ∈F metric function upon which to evaluate task-prompt performance\n\n  6. r : S × A →R= reward model score, where S is the state-space and A is the action-space\n\n  7. |V | = length of vocabulary\n\n  8. ϕ : S ∈V∗→Rd embedding function which takes in a sentence generated as a finite sequence of\n     tokens belonging to a vocabulary V, and generating a floating point array representation of dimension\n    d\n\n  9. ρ∗= argmaxρ∈V∗EDval[fi(ρ)] The best performing prompt based on the metric score on validation\n      set\n\n 10. k = number of candidates for top-K search, B = Beam width for beam search, N = number of\n     iterations for search\n\n 11. C = number of experts in a Mixture of Experts approach (MOP), µC= cluster centroid of cluster C\n    (MOP).\n\n 12. LLMtarget= target model which will be used for inference, LLMrewriter= rewriter model which\n     will be used for rewriter, LLMevaluator= evaluator model which provides the LLM feedback to\n    prompts / responses or both\n\n 13. λ with subscripts to denote different latency types: λt = Total training cost/latency, including all\n     offline costs for data collection, preprocessing, and model fine-tuning, λi = per-example inference\n     latency, λm = MLM inference latency per-example\n\n12.2  Excluded works\n\nFedBPT (Sun et al., 2024b) used federated learning to update soft prompts and not discrete tokens.\nDeliberate-then-generate (Li et al., 2023a) randomly sampled arbitrary noisy inference and prompted\nthe task LLM to deliberate on the wrong inference, while Reflexion (Shinn et al., 2023) agents maintain\nan episodic buffer of past deliberations. Neither method optimizes the input prompt. AutoPrompt (Shin\net al., 2020) required gradient access to the task LLM and therefore doesn’t remain blackbox.\n\n12.3 UCB based selection algorithm\n\nAlgorithm 2 Select(·) with UCB Bandits\nRequire: n prompts ρ1, ..., ρn, dataset Dval, T time steps, metric function m\n  1: Initialize: Nt(ρi) ←0 for all i = 1, . . . , n\n  2: Initialize: Qt(ρi) ←0 for all i = 1, . . . , n\n  3: for t = 1, . . . , T do\n  4:    Sample uniformly Dsample ⊂Dval\n              n Qt(ρ)  q log t o                 + c  5:     ρi ←arg maxρ                                        Nt(ρ)                            Nt(ρi)\n  6:    Observe reward ri,t = m(ρi, Dsample)\n  7:    Nt(ρi) ←Nt(ρi) + |Dsample|\n  8:    Qt(ρi) ←Qt(ρi) + ri,t\n  9: return SelectTopb(QT /NT )\n\n13  Comparison of different approaches + Tasks\n\n13.1  Comparison\n\nBelow we offer a comprehensive comparison of all the surveyed methods against our framework, covering\nthe following aspects\n\n\n  1. Seed instructions\n\n  2. Inference evaluation\n\n  3. Candidate generation\n\n  4. Search+filter strategy\n\n  5. Iteration depth\n\n  6. Optimization time complexity\n\n  7. Prompt generation model\n\n  8. Target models\n\nGPT-4\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                text-curie-003,                                            llama-1-7b,      base                InstructGPT                                                                                                     GPT-4                PaLM-2                                                                                                                and                                                  GPT-3       GPT-2                                      GPT-3                                                                                                                                         GPT-3\n                         2/                                                                                                                                                                                                                                               Codex,                                                          ColBERTv2                                                                                                  GPT-4,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  code-davinci-002                          largemodels                                                                                                                                                                                 text-bison                                                                                                                                                                                                                                                                                                                                                                                                                                                  (text-davinci-003),                                                                                                                                                                                                                                                                                                                                                                                GPT-3.5,                                                              BERT,Target   T0                                            InstructGPT                  InstructGPT,   1/                                   RoBERTa-large      PaLM                  InstructGPT,              GPT-4            RoBERTa,                      text-curie-001,  GPT-3.5,                      Vicuna-7b-v1.3,    vicuna-13b-v1.3,   llama-1-13b  Flan-T5            ChatGPT,        GPT-3        LM:  Retrieval:                          GPT-4                           gpt-3.5-turbo-0301                         text-davinci-002,    text-davinci-003,    (gpt-3.5-turbo),  ChatGPT            GPT-3.5,\ngenera-                                para-        GPT-3                model-                          GPT-                          GPT-3       text-  GPT-3.5,                                                            (text-\n                                            model                           2-L      model                                                                                                                                                                                            GPT-2                                                                   T5,Prompt tion                                    PEGASUS phrase   InstructGPT,                   RoBERTa-large Reward  DistilBERT   RoBERTa-large      PaLM                  InstructGPT, 3,  InsertGPT                      RoBERTa,                      text-curie-001,   curie-003,    code-davinci-002   Llama2-7b-chat                   Flan-T5    T5,       GPT-3   davinci-003), GPT-4  GPT-3.5                                GPT-4                           gpt-3.5-turbo-0301                   gpt-3.5-turbo (0301)          ChatGPT       GPT-4\ntime     ∗λi)    ∗              ∗λi)|        ∗C)| ∗∗|D| ∗                                         ∗λi)         ∗λi)|                                     ∗λi)    + ∗|∗B                                                                                                                                                   (λm                                                                                          ∗λi)                                                                                                                                                                                                                                                                                                                                                                                                                                  ∗|Dval|)                                                                                                                                                                                                                                                                                                                                                                                                                                                             ∗|Dval|)     ∗k                                               ∗|Dval|                                                                                                                                    ∗|Dval|                                                                                                   ∗λi)                                                                                                            ∗λi)                                                                                                                                                                       ∗λi)                                                                                                ∗B                                                                                                                                                                                                                                          ∗λi)                                                ∗|V                                                                                                              ∗|V                                     ∗k                                     ∗|V                                                                                                                                                                                                                                                                                                                                                                                               ∗|Dtrain|)                                                                                                                                                                                    |Dval|                                                                                                                                                                                                                                                        ∗λi)) ∗|V                                    ∗λi)                                          ∗k                                                      ∗k                                                           ∗k                                                                                           ∗k                                                                                                ∗k    ∗                                                                                                                                ∗k                                                                                                                                                                                                                                       ∗|ρ|                                                                                                                                                                                                                                                     ∗|ρ|                                ∗k                                     ∗ρ                         ∗ρ                                                                          ∗k                                  +                                                                                   ∗k                                                                                                              ∗C     ∗N                                                                                                  ∗|D|               ∗NOptimization  complexity O(T            O(k B) O(|ρ|    O(N        O(N    O(N λi) O(N λi)    O(T    O(N    O(N          O(λt        O(N       O(λt)    O(N        O(N    O(N            O(N |Dval| O(N E) O(N        O(N    O(N\n\ndepth                                                                                                                                                                                                                                                                                                                                                                                                                                               framework\n                                                          3                   ourIteration        Fixed                    Fixed       Fixed       Fixed              Fixed       Fixed       Fixed              Fixed            Variable            Variable     NA                      Variable            Variable       Fixed              Fixed            Variable                                        Open-ended    <              Fixed       Fixed                                                                                                on\n                                                                                                                                                                                                                                               basedstrategy            ensemble                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        bandit-search\n                                                                    selection                                    selection                               search             selection                         selection             selection             selection                                                          selection                                    selection                         selection             selection                                                          selection             selection                         selection                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               techniquesSearch+filter                    Metaheuristic                TopK                TopK                     Beam      TopK           TopK      TopK      TopK     NA           TopK                TopK           TopK      TopK                          TopK      TopK           TopK             UCT-based\n                                                                                                                                                APO                         NN                                                                                 based\n                                                              +           all                                                                                                                                                                                                                                                                                                                                                           Crossover                                NN                                                                                NNgeneration                                                                                                of                                                       NN                     LLMs\n                                       +                                             translation,                  continuation                                    trained                                                                                                                                                                                                                                                                                                                                                                                                                              Synthesis             Synthesis                                                                                   method                         Algorithm:                                                                                                                                                                                           algorithm:               candidates                                                                                                                                                                                                                                                                                                                                                                                     Algorithm:                                      level                                                                                                                                                                                                       rewriter                                                                                                                   mutator                                                                                 rewriter                                                                                 rewriter\n                                                                newCandidate           Genetic Back Cloze,  Sentence Phrase       add/remove/swap/paraphrase   LLM-rewriter            RL-based                           RL-trained          Genetic   LLM-mutator No        LLM               RL-trained            Ensemble method             Finetuned                   Genetic  Mutation  RL-trained    LLM                   Program          Program            LLM                         Metaprompt-design                  LLM-rewriter                                 LLM-rewriter  Ensemble LLM\n\n                                                                                                                F1  -                                                                                                                               NLL                                                                                                                                                                                 Comparison                                                                                                                                                                        and                                                                                                                                                                                                                                score+            + score                         +                                                                 +    2:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        accuracy                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               BERTScoreevaluation                                       score+ +                                                                                                                                                                                                                                                                                                                                                (pairwise)                                                                     model                                          +     +                                feedback                                                                                                                                                                                                                                                                                                                                                                      BERTScore                                                                                                                                                                                                                                            Task                                                                                                                                                                                     and                    accuracy                                          accuracy                      accuracy                      accuracy            accuracy            accuracy                      accuracy            accuracy            accuracy                                                              accuracy                      accuracy                      accuracy            accuracy         +                      accuracy            accuracy          TableInference      Task                                                    Entropy-based Task  Accuracy  BERTScore Task Reward      Task      Task      Task           Task   LLM-feedback Task      Task                LLMaaJ                                   Entropy-based Task BLEU,      Task           Task      Task   LLM-feedback              Human                   Task-Accuracy     NLL BLEU      Task      Task   LLM-feedback\ninstruc-                                                                                                                                                                                            cre-\n\n                                                  +Seed tions  Manually  created                      Manually  created   Instruction  induction  Manually  created            Manually  created  Manually  created   Instruction  induction            Manually  created  Manually  created   Instruction-  induction            Manually  created            Manually  created  Manually  created  Manually  created                Instruction  induction  Manually ated   Instruction  Induction  Manually  created   Instruction  induction  Manually  created            Manually  created  Manually  created\n\n                              al.,                al.,           al.,                              al.,                                             al.,    (Li      al.,                     al.,                                                  al.,      al.,\n                                                                                                                                 et                                et                                                                                                                                                                                                                                        2022)                                                                                              2024)                         et                                                                                                                           et                                                                                                                                                                        2024)                                                                                                                                         2022)                                                                                                                                                                                                                                                                           2024)               et                                                                                                et                                                                                                                                                                                                                                                                                                                                                                  2024b)                                                 et                                                                          et                                                                                    et                                                                                                          2022)                                                        2023)                                                                                                                                                                                          al.,                                                                           al.,                                                                                                                                      al.,             2022)                                                                                                              al.,                                                                                                                                                                                                                      al.,                                                                                                                                                                                                                                            al.,                                                                                                                                                                                                                                                                                                                                                2023c)                                                                                     al.,                                                                                             et                                     et                                             al.,                                                                                                                                                                                                                                                                                                                                  (Wang                                                                   et                                                       et                                                                                                                      et                                                                                                           et                                                                                                (Zhang                                                              (Deng          al.,                                          et                                                                                                                                                            2023)                                                                                                   (Sun                                                                                                                                                                                                                                al.,                                                                                          induction                      et                                                                                                                                                                                                                                                                                                                                                                                 (Zhang                                                                                                                                                                                         (Zhou     et                                                    (Prasad                                                                                                                et                                                                                                                                                                                                                                                                             Prompting                                                                                                                            al.,                                                                                                                                                                                                                                                                                                                                                                                                (Khattab                                                                                                                                                                                                                                                                                                                                               (Sordoni                                                                                                                                         (Diao                                                                                                                                                                                                                                                                           (Joko                                                                                                                (Hsieh                                                                                                                                                                                                                                                                                                       (Dong                                                                                                                                                                                                                                                      2023d)                                                              et                                                                                                                                                                        (Li                                                                                                                                                                                                          (Cheng                                                                                                          (Zhou        (Xu                                                                                                                                                                                                                                                                                                                                                                                    (Khattab\n                                                                                                                                                                    al.,                                                                                  et DLN 2023)     DSP      DSPy 2024)           GATE    GPO      PACE                PREFER 2024a)   Promptagent 2024a)Method     GPS                    GRIPS 2023)   Instruction  (Honovich  RLPrompt 2022)          TEMPERA 2022) AELP    APE                      AutoHint 2023) BDPL          Boosted (Pitis    BPO             CLAPS 2023)     Directional-stimulus\n\n\n\nSNo.  1    2 3 4   5 6 7   8 9   10     11     12   13   14     15   16        17   18   19     20   21\n\n(In-\n                                         7B.                                                         Chat-                          Qwen2                                                                                                                                              (chat), 8b               2-L                                                                                                                Instruct,                                                                                                                                                                                                                                                                                                                                                                                                                                          (Instruct), 70b 3\n                                                                                            8B          7b 2                         7B Llama2  ChatGPT                                                              Llama-2-70B-                           vicuna,             ,                    PaLM                XL,                                                                                                                                                                                                                                  Llama3,                                                                                                                                                                                                                                                                               Llama                                         7B,                                                                                                                                                                                                                                                                                                                                                           Llama2-7b                                             GPT2  Mistral                                                                                                                                                                                                                                                                                                                                                                                                                                          GPT-3.5                                        Tulu2-13B,                                                                                                                                                                                                                                                                                    Llama3              GPT-4          Mistral Llama                                                                           Chat,                                                                                                                                    ChatGPT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              (gpt-3.5-turbo-0125)                                                                                                                                                                                                                                                                                                                         Sonnet,                                                                                                                                                                                                                                                                                                                                                            Instant,                                     7B,   7B                                                                                                                   GPT3.5,                                             3 7B,                7b, 70b,2 8b,3models                                                             Large,Target                    RoBERTa-large                         text-davinci-003,                                   GPT-3.5-turbo      GPT2  Mistral   Llama-Alpaca Llama2                                                                        GPT-3.5-Turbo, chat                                              text-davinci-002, GPT                GPT-4-turbo       GPT4,            DALLE-3,                     GPT-3.5-turbo,   GPT-4o-mini,    Llama-2-7B-chat      Mistral-7B-Instruct-v0.1,  ChatGPT Claude Claude  Mistral                     GPT-3.5-Turbo,  Baichuan2,          Mistral Llama Llama  struct),   gpt-3.5-turbo                           Alpaca-7b,                                        Llama2-7B,   Baichuan2-13B\ngenera-                                         GPT2          Mistral    7B,       Chat,                                                               to-                        Llama3                                    Mistral        Llama       Llama                                      Tulu-                                                                                                                                                                                                                                                                                                                         Sonnet,                                         7B,        7B. 7B                                                                                                                               masked            Instant,                   2-L                        Large,                                             3 7B,               7b,      70b,2  (chat), 8b,3      model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          (Instruct),                                                                                                                                       Instruct,                                                                                                                                                                                                                                                                                                                                                                                                                             (Instruct),                                                                                                                                                                        70b   8bPrompt tion T5                         text-davinci-003, PaLM                   GPT-3.5-Turbo      GPT2 XL,  Mistral 7B   Llama-Alpaca Llama2 Llama2  ChatGPT GPT-4                                                                   text-davinci-002,  vicuna,  ChatGPT   GPT-4-turbo                            ChatGPT                   GPT-3.5-turbo          RoBERTa  (filling kens) Claude Claude  Mistral 8B   GPT-3.5-Turbo,  Baichuan2, GPT-4  Mistral 7b Llama 2 Llama 3   gpt-3.5-turbo                                              Tulu-13B, 70B\n\n\n         ∗                              ∗\ntime              ∗λi)\n\n     |                                                                               ∗k                                                                         ∗λi)\n                                                                             ∗λi)              ∗λi)         ∗λi)                                                               ∗λi)        ∗N)               ∗T               ∗|V                 ∗|Dval|    ∗λ)                                                                                                                                                             ∗|I| ∗λi)                                                                                                       ∗T)                ∗|D|∗|ρ|∗λi)                                                                                                                                                                    λm))     ∗k     ∗k               ∗k          ∗N     ∗C   ∗k                  ∗N        ∗k     ∗C                ∗|ρ|∗|Dval|)\n                                             +Optimization  complexity O(λm)    O(ρ        O(N λi) O(N                           O(B            O(N        O(N    O(N    O(N    O(N    O(N |Dval|                    O(N∗k∗(|Dtrain|∗ λi        O(N        O(B                       O(N                                                         O(λt+|Dval|∗λi))\n\ndepth                                                                                                                                                                                                  epochs                                                                                                                                                                                                                                     framework                    Stopping                                      steps                                             Steps          3                                                                                                                                                                                                                             Stopping\n                                                                                                                                                  ourIteration        Early       Fixed              Fixed       Fixed                                             Fixed                    Fixed                      Variable      Used       Fixed       Fixed            Variable              Fixed                    Fixed              Fixed                                      Early                                                                                                  on\n                                                                                                                                                                                                                                                    basedstrategy                                Ensemble                                                                                                                                                                                                                                 search                                                                                                                                   ensemble                                                                                                                  bandit-search\n                                                                                                     selection                                                                                selection                                    selection                         selection            UCB             selection                               greedy                                    selection                search                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        techniquesSearch+filter                 Beam-search                   Metaheuristic                         UCT-based      TopK                                    TopK                    Top-1           TopK                        Linear      TopK                          TOP-K                    Top-1           Beam                                                                                                    Metaheuristic\n                                                                                                                                                  APO             based\n                                                                                                                                                  all                                                                                                                                                                                                                                                                                                                                    preference                                                                                                                                                                                                       usinggeneration\n                                +                                                        Crossover                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Algorithm:                                                  Algorithm: +                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     operators+           LLMs    of                                                                      rewriter                                                                                                                                                                                                         rewriter            rewriter       edits                      rewriter                                                              rewriterCandidate            Ensemble method  Genetic Mutate   (LLM-edits) LLM                  LLM-rewriter                                                                                                           LLM-rewriter                                                LLM-rewriter                                      Coverage-based            Feedback   optimization LLM    LLM       Token MLM    LLM                                                LLM-rewriter        LLM                                                      Genetic  Mutation  Crossover             Finetuned\n\n                                                                                         F-      +                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Comparison\n     +         +           +        +    + +     +                                      score        +           3:             Score                                                                                                                                                                                                                                                         SARIevaluation   F1                                                                                                                                                                                                                                                                                                 feedback                                                                            model                                        Feedback  accuracy            accuracy            accuracy                                                                       accuracy                                Feedback                      accuracy                   accuracy-nDCG            accuracy            accuracy            accuracy                      feedback                                accuracy                                Feedback                                                    Accuracy                                accuracy          Table                                                                                                                                                            scoreInference              Accuracy,    LLM Task      Task   LLM-feedback Task                                    Task   LLM-feedback        LLM           Task F1 Task      Task Human Task   LLM-feedback Task        LLM   ROUGE-1/2/L  measure,  AlignScore Task                Reward LLM                          Task  ROUGUE+           Task\ninstruc-                                                                                cre-                                                                                                                                                         cre-\n\n                      +                                       +Seed tions   Instruction-  induction  Manually  created            Manually  created  Manually  created                                                             Manually ated   Instruction  Induction  Manually  created            Manually  created  Manually  created  Manually  created  Manually  created  Manually  created            Manually  created                      Manually  created            Manually  created                                                   Manually ated   Instruction  Induction  Manually  created\n\n\n\n                                                                                                                           et                                                                          et   et              2025)                        2024c)     et          (Hou                     al.,et    (Lu                                                      2024b)                al.,et           al.,et       2024)       2024)      al.,      al.,                                             al.,                               al.,                                                                                                                                                                                                                                                                                                                                         2025)                                                                                                                                           al.,                               al.,                al.,                                              (Guo                                             (Fernando                                                             al.,                                         al.,                                                                                                                                                    (Shi                                                                      et                                                                                                  et                                                                 et                                          et                                                                                                                                 (Long                                                                                                                                                                                                     (Zhan     et                                                                                                                                                    (Yang                                                                     (Pryzant               separators                                                                                                                                   (He                                                                                                                                                                                                                                                                                                                      (Amini                                                   al.,                                                                                                                                           (Lin                                                                                                                                 (Jin                   2023)       2023)                          2024)                                      (Yang                                                                                                                                     (Yang                                 et(Lu\n               al.,      al.,                     al.,Method                     Promptboosting et   Promptbreeder et          ProTeGi 2023) Random et                       ABO                           Adv-ICL 2024)      AMPO 2024d) APEER       APOHF             BATPrompt 2024) COPLE 2024)         CRISPO                DAPO           DRPO 2024)                                                           EVOPROMPT 2024)           FIPO\n\n\n\nSNo.   22   23     24   25                  26        27     28   29   30   31   32     33        34     35               36        37\n\n70B,                                                         2407,                                                                                                                                                                                   gpt3.5-turbo                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2.5-72B,                   LM)                                                                                                                                                                                                                                                                                                          GPT-4                                                                                                                                                                                                                                                                                                                                                                                                                                                            (classification),                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Llama3-8B,                                                                                                                       or                                                                                                                                                                                                                                                                                                    2407.                                                                                                                                                                  (translation)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     textdavinci-003          Llama-2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Instruct,  Instruct  Instruct,                                                                                                 models                                                                                                                                                                                                                           (others)                               (task                                        transfer),                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Llama3.1-8B                                                                                                                                                                                                                                     Qwen                                                                                                                                                                                                                                                                                                                                                                                            GPT-4o                                                                                                                                                                                           GPT-4                     GPT4 andmodels                                                             (style                        family                                          2-L                                                                                                                                                                                                                                                                                                                                 3.1-8B Nemo 2.5-7B 70B, Large                                                                                                                                                                    modelsTarget                            GPT-3.5-turbo-0613                           Llama-3-8B                   GPT-3.5-Turbo       GPT-2   flan-T5-small    Llama2-7B-chat,    Tigerbot-13B-chat, PaLM                                                               text-davinci-003                                                    RoBERTa-large OPT   GPT-3-babbage      PaLM                               GPT3.5/GPT4/Llama-70B                      GPT-3.5,                     gpt-3.5-turbo,                  Mixtral7x8B,  GPT3.5, GPT-4o                                                        GPT-3.5-turbo,  Mistral-7B       Llama  Mistral Qwen Llama  Mistral   GPT-3.5-turbo                      GPT-3.5,          GPT-3.5\ngenera-                                               (proposer                                            text-    and                                                                                                                                                                                                                                                                                                                                    Llama2-                                                                2-L,\n      model                                                                                       2-SPrompt tion                            GPT-3.5 LM)   GPT-3.5-Turbo                distilGPT-2      GPT4      PaLM bison,   gpt-3.5-turbo GPT-4 GPT-4            OPT                   GPT-3-babbage      PaLM                GPT3.5/GPT4              GPT-4                    gpt-3.5-turbo,    textdavinci-003                GPT-4o                                                       GPT-3.5-turbo,  Llama3-8B,  Mistral-7B       tuner007/pegasus_paraphrase                          GPT-4                                                    Fine-tuned 13B\ntime     ∗∗k            ∗k)|                                         ∗C)     ∗λi)   |)∗|V             ∗              ∗λi)                                ∗λi)         ∗λi)                                                      ∗λi)                                                                                                                                                                                                                                                                                                  ∗k∗λi)                                                                                                                                                                                 ∗|ρ|\n                                                                                                  ∗k         ∗λi)                                     ∗|Dval|)    ∗|V                                                                                                                      ∗T                   ∗λi)                                                           ∗λi)              ∗λi)              |∗λi   ∗k    ∗λi     ∗λi)         ∗λi)       ∗|ρ|)     ∗λi)                                                                                        ∗k        ∗C           ∗B∗T          ∗k                 ∗|Dval|   ∗k     ∗k                 ∗|Dval|   ∗N   ∗C               |Dval| ∗k        ∗k            ∗|V   ∗C   ∗C   ∗C     ∗k   ∗k   ∗k\n               +Optimization  complexity O(N        O(N λi) O(C    O(N                     O(|Dtrain|∗ρ∗λi+ λt O(N            O(N            O(N    O(N    O(N    O(N        O(N    O(N    O(N    O(N |Dval|)        O(N        O(N                O(N        O(N    O(N\n\n                                   per-                                                                                                                       con-\ndepth                                                                                                                                                                                                until                                           steps                                                                                                                                                                                                                                                                                                                                                                                                         framework                                                                                                                                               steps                    or                                                                                                                                                       Stopping                                          Stopping\n                                                                                                                                                       ourIteration        Fixed              Fixed       Fixed  cluster Fixed                                Variable                    Fixed                    Fixed       Fixed       Fixed       Fixed              Fixed       Fixed  vergence Fixed       Fixed                    Fixed              Fixed                          Early                      Variable       Early                                                                                                     on\n                                                                                                                                                                                                                                                            basedstrategy                                                                                                                                                                                                                                                                                                     (UCB)                                                                                                                                                                                                                                                                                                                              sampling                        search                       selection                         selection             selection                                                          selection                                    selection                                    selection                                    selection             selection                         selection                                                                                                                                                                                                                                                                                                                                                                                             selection         bandit                                    selection                                                      Search                               Search                                                                                                                                                                                                                                                                                                                                                                                                                                                                   exploration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         techniquesSearch+filter      TopK           TopK      TopK                          TopK                TopK                TopK                     Metaheuristics      TopK      TopK           TopK             Rejection with TopK    UCB                TopK                              Beam-search                               Bandit                     Beam\n                                                                                                                                                                                                                             (to-                                   APO\n                                                             cluster   NN                                                                                                                              all                                                                                                 design                        design                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               CrossOver                                                                              LLM                                                                                             LLMgeneration                                                                                                     of                                                                               trained                                   each                                                            +                         Algorithm:  Crossover+             Synthesis                                                                                                                                                                                                                                                                                              Algorithm:  crossover+                                                                                                                                                                                                                                                                                                                                                Algorithm:  Crossover+                                                                                                                                                                                                                                                                                                                                                                                             synthesis                                                                                                      Algorithm:  Crossover+                                        Algorithm:                          for                                rewriter                                                                                                                                                                                     rewriter                                                                                                                                                                                                         rewriterCandidate           Genetic Mutate   (LLM-edits)  Program    APE            RL-based    LLM               Metaprompt                                        Metaprompt                                        RL-trained          Genetic Mutate  RL-trained          Genetic Mutate   (LLM-edits) LLM                  LLM-rewriter          Program                  LLM-rewriter                                            LLM-mutator                   Genetic  Mutate kens)                   Genetic Mutate  (tokens) LLM                  LLM-rewriter                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Comparison\n           + + score +    +         + score +   +      +    +         +   + +        4:evaluation                 Score-based                                             score       model                                                                                  model                                          feedback                                                  accuracy            Accuracy            accuracy            accuracy            accuracy                                accuracy                                accuracy            accuracy            accuracy            accuracy                      accuracy            accuracy            accuracy            accuracy                                accuracy                      accuracy                                          accuracy                      accuracy            accuracy                   TableInference           Numeric           Task      Task      Task Reward Task Reward Task   LLM-feedback           Task   LLM-feedback           Task      Task      Task Reward Task   LLM-feedback      Task Human Task      Task      Task   LLM-feedback           Task   LLM-feedback      Task                     Task   LLM-feedback      Task   LLM-feedback Task   LLM-feedback\ninstruc-                                                                                cre-                                                                                                                                                             generated                                task-                                                                      cre-                      +                                                                                                                                             process.                         +Seed tions  Manually  created            Manually  created   Instruction  induction  Manually  created  Manually  created  Manually  created                      Manually ated   Instruction  Induction  Manually  created  Manually  created  Manually  created  Manually  created            Manually  created LLM CoT  Manually  created   Instruction  induction on README  Manually  created            Manually  created                               Manually  created            Manually  created  Manually ated   Instruction  Induction\n\n                                                                                                                           al.,                     al.,      al.,    and      al.,                              al.,\n                                                                               et                                                                                         et                                                                          et                                                              et                                                                              (Jafari                                            2025)                                                                                                  2024a)                                                                                                          et                                                                                                                                               2024)                                                                                                                                                                                                                                                                                                          2024)             2023)                                                                                                                                                                                                                                                                                                                                                                                                                                                                         (Juneja                                                                                                                                                                                                                                                         2024)                                                                                  2024a)                                                                                                                                   2024)                                                                                                                                                                              2024)                                   al.,                                                                 al.,                                                                                                                  al.,                                                                                                                                                                                                                                               al.,          al.,                                                                                                          2024)                                                                                                                                                                                                       al.,                                                                                                                      (Xu                                                       al.,                                                                                                         al.,                                 et                 et                                                         et                                                                    (Opsahl-Ong                                                                                                                       et     et                                                                                                                                           al.,                                                                                                   et                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (Yuksekgonul                           et                                                                                                                                                                                         (Chen                                                                                     al.,                                                                                                                                                          (Kong                                                    et                                                                                                                                                                                                                                                                                                                                                                                         (Schnabel                                                                                                                                                                                                                                                                          (Kumar                                                                      et                                                                                                                                                                                                                                                                                                                              (Zhang                                          et                                                                                                                                                                                                                          2024)          (Liu                                                                                                                                                                                   (Wu                                                                                                                  (Pan                                                                                  (Yang                                                       (Sun                                      2024)                                                              2024)                                                                                                                                                                                                                                                                                                                                   2024)                                                                                                                                                                                                                                                                                                                                                2024)                                            (Wang                                                                                                                                                                                                                                                                                                          (Sinha                                                                (Ye                                                                                                                                   (Choi\n                              al.,                al.,                                                                                                                                                                                                             al.,      al.,Method      LMEA             MIPRO et MOP                MORL-Prompt et OIRL      OPRO            PE2            PIN      PLUM            PRewrite 2024)   PROMPTWIZARD  (Agarwal         PROMST 2024)   Reprompting 2024) SAMMO  Neville, SCULPT 2024)        SOS             SPRIG 2024b)                        StraGo                      TextGrad et  UNIPROMPT et\n\n\n\nSNo.   38     39   40   41   42   43        44        45   46   47   48     49   50   51   52        53     54          55     56   57\n\n13.2  Evaluation tasks and datasets\n\nBelow we describe the different datasets and tasks that each method was evaluated on.\n SNo.                 Paper                  Tasks\n   1           GPS (Xu et al., 2022)           10 unseen tasks from the T0 benchmark, which span:\n                                                           1. Natural Language Inference: ANLI R1, R2, R3, CB, RTE (Nie et al., 2019; Dagan et al.,\n                                                     2005).\n                                                             2. Coreference Resolution: WSC, Winogrande.(Levesque et al., 2011)\n                                                             3. Sentence Completion: COPA(Roemmele et al., 2011) , HellaSwag (Zellers et al., 2019).\n                                                            4. Word Sense Disambiguation: WiC (Pilehvar and Camacho-Collados, 2019).\n   2         GRIPS (Prasad et al., 2023)         8 classification tasks from NaturalInstructions (Mishra et al., 2021)\n   3     Instruction induction (Honovich et al., 2022)   1. Spelling, 2. Syntax, 3. Morpho-syntax, 4. Lexical semantics,\n                                                             5. Phonetics, 6. Knowledge, 7. Semantics, 8. Style\n   4         RLPrompt (Deng et al., 2022)           1. Classification\n                                                             2. Text-style transfer\n   5       TEMPERA (Zhang et al., 2022)         Classification\n   6         AELP (Hsieh et al., 2024)          Big Bench Hard (Suzgun et al., 2023)\n   7          APE (Zhou et al., 2022)              1. 24 Instruction induction tasks (Honovich et al., 2022) 2. 21 BIG Bench Hard tasks (Suzgun\n                                                               et al., 2023)\n   8           AutoHint (Sun et al., 2023)         BIG-Bench Instruction Induction (Epistemic Reasoning, Logical Fallacy Detection, Implica-\n                                                              tures, Hyperbaton, Causal Judgment, Winowhy) (Zhou et al., 2022)\n   9         BDPL (Diao et al., 2022)             1. MNLI (Williams et al., 2017), 2. QQP (Cer et al., 2017), 3. SST-2 (Socher et al., 2013), 4.\n                                 MRPC (Dolan and Brockett, 2005), 5. CoLA (Warstadt et al., 2018), 6. QNLI (Rajpurkar et al.,\n                                                    2016), 7. RTE (Dagan et al., 2005), 8. CitationIntent (Jurgens et al., 2018), 9. SciERC (Luan\n                                                               et al., 2018), 10. RCT (Dernoncourt and Lee, 2017), 11. HyperPartisan (Kiesel et al., 2019)\n  10      Boosted Prompting (Pitis et al., 2023)    GSM8K (Cobbe et al., 2021) and AQuA (Garcia et al., 2020)\n  11        BPO (Cheng et al., 2024)            Generation: Dolly Eval (Conover et al., 2023), Vicuna Eval (Chiang et al., 2023), Self-Instruct\n                                                  Eval (Wang et al., 2022b)\n  12        CLAPS (Zhou et al., 2023)\n  13       Directional-stimulus (Li et al., 2023d)    MultiWOZ (Budzianowski et al., 2018)\n  14        DLN (Sordoni et al., 2023)            1. Mpqa Sentiment analysis (Lu et al., 2021)\n                                                             2. Trec Question type classification (Lu et al., 2021)\n                                                             3. Subj Determine whether a sentence is subjective or objective (Lu et al., 2021)\n                                                              4. Leopard (Bansal et al., 2019)- Disaster Determine whether a sentence is relevant to a disaster.\n                                                             5. Leopard (Bansal et al., 2019)- Airline Airline tweet sentiment analysis.\n                                                             6. BBH (Suzgun et al., 2023)- (Hyper, Nav, Date, Logic datasets)\n  15         DSP (Khattab et al., 2022)             1. open-domain question answering (Open-SQuAD) (Lee et al., 2019)\n                                                             2. multi-hop question answering (HotPotQA) (Yang et al., 2018)\n                                                             3. conversational question answering (QReCC) (Anantha et al., 2020)\n  16         DSPy (Khattab et al., 2024)\n  17         GATE (Joko et al., 2024)        LAPS (Joko et al., 2024) (1. Content Recommendation (user likes to read a given held-out\n                                                                article or not) 2. Moral Reasoning, 3. Email Verification)\n  18         GPO (Li et al., 2023c)               1. Sentiment analysis - Yelp (Zhang et al., 2015), Flipkart (Vaghani and Thummar, 2023),\n                                   IMDB (Maas et al., 2011), Amazon (Zhang et al., 2015)\n                                                           2. NLI - MNLI (Williams et al., 2017), ANLI (Nie et al., 2019) 3.Entailment - RTE (Dagan\n                                                               et al., 2005), 4. CommonsenseQA - SocialIQA (Sap et al., 2019)\n                                                           5. Multi-turn dialog - DSTC7 (Gunasekara et al., 2019), Ubuntu Dialog (Lowe et al., 2015),\n                                           MuTual (Cui et al., 2020)\n                                                             6. NumericalQA - DROP (Dua et al., 2019)\n  19         PACE (Dong et al., 2024b)       BBH (Suzgun et al., 2023), instruction induction tasks (24 tasks) (Honovich et al., 2022) and\n                                                           translation tasks (en-de, en-es, en-fr)\n  20       PREFER (Zhang et al., 2024a)          1. NLI tasks including SNLI (Bowman et al., 2015), MNLI (Williams et al., 2017), QNLI\n                                                    (Rajpurkar et al., 2016), RTE (Dagan et al., 2005)\n                                                              2. Classification: Ethos (Mollas et al., 2020), liar (Wang, 2017), ArSarcasm (Farha and Magdy,\n                                                 2020a)\n  21        Promptagent (Wang et al., 2024a)         1. BigBenchHard (BBH) (Suzgun et al., 2023) - 6 BBH tasks that emphasize a blend of domain\n                                               knowledge\n                                                           2. Biomedical - Disease NER (NCBI) (Do˘gan et al., 2014), MedQA (Jin et al., 2020), Bio\n                                                         similar sentences (Sogancioglu et al., 2017)\n                                                             3. 2 classification - TREC (Voorhees and Tice, 2000) + Subj. (Pang and Lee, 2004) 1 NLI(CB)\n                                                     (de Marneffe et al., 2019)\n  22        Promptboosting (Hou et al., 2023)       Text Classification\n  23      Promptbreeder (Fernando et al., 2023)      1. Arithmetic Reasoning: Benchmarks: GSM8K (Cobbe et al., 2021), MultiArith (Roy and\n                                                    Roth, 2016), AddSub (Hosseini et al., 2014),\n                                   SVAMP (Patel et al., 2021), SingleEq (Koncel-Kedziorski et al., 2015), AQuA-RAT (Ling et al.,\n                                                     2017).\n                                                            2. Commonsense Reasoning: Benchmarks: CommonSenseQA (CSQA) (Talmor et al., 2019),\n                                                StrategyQA (SQA) (Geva et al., 2021).\n                                                             3. Hate Speech Classification: Dataset: ETHOS (Mollas et al., 2020).\n                                                            4. Instruction Induction (Honovich et al., 2022): Tasks: 24 datasets spanning\n                                                     sentence similarity, style transfer, sentiment analysis, and more\n\n                               Table 5: Tasks covered in the different papers\n\nSNo.                Paper                 Tasks\n 24        ProTeGi (Pryzant et al., 2023)         Jailbreak (Pryzant et al., 2023), Liar (Wang, 2017), Sarcasm (Farha and Magdy, 2020b), Ethos\n                                                (Mollas et al., 2020)\n 25     Random separators (Lu et al., 2024)      1. SST-2, SST-5,(Socher et al., 2013) 3. DBPedia (Zhang et al., 2015), 4. MR (Pang and Lee,\n                                                  2005), 5. CR (Hu and Liu, 2004), 6. MPQA (Wiebe et al., 2005), 7. Subj (Pang and Lee, 2004),\n                                                         8. TREC (Voorhees and Tice, 2000), 9. AGNews (Zhang et al., 2015)\n 26       ABO (Yang et al., 2024b)         BigBenchHard tasks (Suzgun et al., 2023): Object Counting, Navigate, Snarks, Question\n                                                   Selection\n 27        Adv-ICL (Long et al., 2024)        Summarization (XSUM (Narayan et al., 2018), CNN/Daily Mail (Nallapati et al., 2016)),\n                                                   Data-to-Text (WebNLG (Gardent et al., 2017), E2E NLG (Novikova et al., 2017)), Translation\n                                         (LIRO (Dumitrescu et al., 2021), TED Talks (Qi et al., 2018)), Classification (YELP-5 (Zhang\n                                                           et al., 2015), WSC (Levesque et al., 2011)), Reasoning (GSM8k (Cobbe et al., 2021), SVAMP\n                                                       (Patel et al., 2021))\n 28      AMPO (Yang et al., 2024d)         Text classification task TREC (Voorhees and Tice, 2000),\n                                                 sentiment classification task SST-5 (Socher et al., 2013),\n                                                     largescale reading comprehension task RACE (Lai et al., 2017),\n                                               medical question-answering tasks MedQA (Jin et al., 2020) and MedMCQA (Pal et al., 2022)\n 29        APEER (Jin et al., 2024)          Passage reranking\n 30        APOHF (Lin et al., 2024)            1. User instruction optimization using tasks from Instructzero, 2. Text-to-image , 3. Response\n                                                  optimization\n 31        BATPrompt (Shi et al., 2024)          1. Language understanding, 2. Text summarization, 3. Text simplification\n 32       COPLE (Zhan et al., 2024)      GLUE - SST2 (Socher et al., 2013), COLA (Warstadt et al., 2018), MNLI (Williams et al.,\n                                                 2017), QNLI (Rajpurkar et al., 2016), RTE (Dagan et al., 2005), MRPC (Dolan and Brockett,\n                                                2005), QQP (Cer et al., 2017) MMLU (Hendrycks et al., 2020) - STEM, Humanities, Social\n                                                 Sciences and Other\n 33         CRISPO (He et al., 2025)          Summarization, QA\n 34       DAPO (Yang et al., 2024c)           1. Sentiment classification, 2. topic classification, 3. News, 4. TREC (Voorhees and Tice,\n                                                2000), 5. subjectivity classification (Pang and Lee, 2004), 6. Logic Five, 7. Hyperbaton, 8.\n                                                Disambiguation, 9. Salient, 10.Translation\n 35       DRPO (Amini et al., 2024)         Alignment benchmark\n 36     EVOPROMPT (Guo et al., 2024)        1. Language Understanding: Sentiment classification (e.g., SST-2, SST-5, CR, MR (Socher\n                                                          et al., 2013; Hu and Liu, 2004; Pang and Lee, 2005)), 2. Topic classification (e.g., AGNews\n                                             (Zhang et al., 2015), TREC (Voorhees and Tice, 2000)), Subjectivity classification (Subj (Pang\n                                           and Lee, 2004)). 3. Language Generation: Summarization (SAMSum (Gliwa et al., 2019)).\n                                                     Simplification (ASSET (Alva-Manchego et al., 2020)). 4. Reasoning (BIG-Bench Hard Tasks)\n                                             (Suzgun et al., 2023): Multi-step reasoning tasks from BBH, such as logical deduction, causal\n                                               judgment, and object tracking.\n 37          FIPO (Lu et al., 2025)              1. Generation: GSM8K (Cobbe et al., 2021), BBH (Suzgun et al., 2023) 2. Multiple Choice:\n                                     PiQA (Bisk et al., 2019), CosmosQA (Huang et al., 2019), MMLU (Hendrycks et al., 2020)\n 38       LMEA (Liu et al., 2023)           Traveling Salesman Problems (TSPs)\n 39     MIPRO (Opsahl-Ong et al., 2024)       1. Question Answering (HotPotQA)(Yang et al., 2018) 2. Classification (Iris (Fisher, 1936),\n                                               Heart Disease (Detrano et al., 1989)) 3. Entailment (ScoNe) (She et al., 2023) 4. Multi-hop\n                                                  Fact Extraction and Claim Verification (HoVer) (Jiang et al., 2020)\n 40       MOP (Wang et al., 2025)         50 tasks comprising of Instruction Induction (Honovich et al., 2022), Super Natural Instructions\n                                               (Mishra et al., 2021), BBH (Suzgun et al., 2023)\n 41      MORL-Prompt (Jafari et al., 2024)       1. Unsupervised Text Style Transfer: Shakespearean data (Xu et al., 2012) 2. Supervised\n                                          Machine Translation: iwslt2017 (Cettolo et al., 2017)\n 42         OIRL (Sun et al., 2024a)           Arithmetic reasoning: GSM8K (Cobbe et al., 2021), MAWPS, SVAMP (Patel et al., 2021)\n 43       OPRO (Yang et al., 2024a)      GSM8K (Cobbe et al., 2021), BBH (23 tasks) (Suzgun et al., 2023), MultiArith (Roy and Roth,\n                                                 2016), AQuA (Garcia et al., 2020)\n 44           PE2 (Ye et al., 2024)              1. MultiArith and GSM8K for math reasoning (Cobbe et al., 2021),\n                                                         2. Instruction Induction (Honovich et al., 2022),\n                                                         3. BIG-bench Hard for challenging LLM tasks (Suzgun et al., 2023)\n                                                        4. Counterfactual Evaluation\n                                                         5. Production Prompt\n 45          PIN (Choi et al., 2024)             1. Classification: SST-2 and etc (Socher et al., 2013)\n                                                         2. Unsupervised Text Style transfer: Yelp (Zhang et al., 2015)\n                                                  3.Textual Inversion From Images: MSCOCO (Lin et al., 2014), LAION (Schuhmann et al.,\n                                             2022)\n 46       PLUM (Pan et al., 2024)            Natural-Instructions datasets v2.6 (Mishra et al., 2021)\n 47         PRewrite (Kong et al., 2024)          1. Classification: AG News (Zhang et al., 2015), SST-2 (Socher et al., 2013)\n                                                         2. Question answering: NQ (Kwiatkowski et al., 2019)\n                                                         3. Arithmetic reasoning: GSM8K (Cobbe et al., 2021)\n 48  PROMPTWIZARD (Agarwal et al., 2024)   1. BIG-Bench Instruction Induction (BBII) (Honovich et al., 2022)\n                                                          2. GSM8k (Cobbe et al., 2021), AQUARAT (Ling et al., 2017), and SVAMP (Patel et al., 2021)\n                                                         3. BIG-Bench Hard (BBH) (Suzgun et al., 2023)\n                                                         4. MMLU (Hendrycks et al., 2020), Ethos (Mollas et al., 2020), PubMedQA (Jin et al., 2019),\n                                MedQA (Jin et al., 2020)\n 49      PROMST (Chen et al., 2024)       11 multistep tasks: 1. Webarena, 2. Alfworld (Shridhar et al., 2020), 3. Scienceworld (Wang\n                                                           et al., 2022a), 4. BoxNet1 (Nezhadarya et al., 2019), 5. BoxNet2,\n                                                         6. BoxLift, 7. Warehouse, 8. Gridworld 1, 9. Gridworld 2, 10. Blocksworld, 11. Logistics\n 50        Reprompting (Xu et al., 2024)     BBH (Suzgun et al., 2023), GSM8K (Cobbe et al., 2021), MATH (Hendrycks et al.)\n\n                              Table 6: Tasks covered in the different papers\n\nSNo.               Paper                Tasks\n 51  SAMMO (Schnabel and Neville, 2024)   1. BigBench zero-shot classification tasks (Srivastava et al., 2022)\n                                                      2. GeoQuery (Zelle and Mooney, 1996), SMCalFlow (Andreas et al., 2020), Overnight (Wang\n                                                       et al., 2015) 3. Super-NaturalInstructions (Mishra et al., 2021)\n 52      SCULPT (Kumar et al., 2024)    BBH (23 tasks) (Suzgun et al., 2023), RAI (Kumar et al., 2024)\n 53        SOS (Sinha et al., 2024)           1. Sentiment Analysis 2. Orthography Analysis, 3. Taxonomy of Animals, 4. Disambiguation\n                                   QA, 5. Logical Five, 6. Color Reasoning\n 54       SPRIG (Zhang et al., 2024b)         1. Reasoning: Tasks requiring multi-step logic or causal reasoning.\n                                                     2. Math: Arithmetic and logical deduction problems.\n                                                     3. Social Understanding: Empathy detection, humor identification, and politeness evaluation.\n                                                     4. Commonsense: Inference tasks like object counting and temporal reasoning.\n                                                     5. Faithfulness: Ensuring generated outputs align with input data.\n                                                     6. Knowledge: Open-domain QA and knowledge recall tasks.\n                                                     7. Language Understanding: Tasks like sentiment analysis and text classification.\n                                                     8. Popular benchmarks include MMLU (Hendrycks et al., 2020), BBH (Suzgun et al., 2023),\n                                         TruthfulQA (Lin et al., 2022), XCOPA (Ponti et al., 2020), SocKET (Choi et al., 2023), and\n                                                    others, covering 47 task types across multiple languages and domains.\n 55          StraGo (Wu et al., 2024)      BBH (Suzgun et al., 2023)(five challenging tasks within Big-Bench Hard) 2. SST-5 (Socher\n                                                        et al., 2013)(fine-grained sentiment classification) 3. TREC (Voorhees and Tice, 2000)(question-\n                                               type classification). 4. MedQA (Jin et al., 2020),MedMCQA (Pal et al., 2022) (medical-domain\n                                  QA) 5. Personalized Intent Query (an internal industrial scenario)\n 56     TextGrad (Yuksekgonul et al., 2024)   LeetCode Hard (Shinn et al., 2024), Google-proof QA (Rein et al., 2023), MMLU (Hendrycks\n                                                       et al., 2020) (Machine Learning, College Physics), BBH (Suzgun et al., 2023) (Object Count-\n                                                   ing, Word Sorting), GSM8k (Cobbe et al., 2021), DOCKSTRING (Garc’ia-Orteg’on et al.,\n                                            2021)(molecule evaluation)\n 57    UNIPROMPT (Juneja et al., 2024)     (1) Ethos (Mollas et al., 2020), (2) ARC (Clark et al., 2018) , (3) MedQA (Jin et al., 2020), (4)\n                             GSM8K (Cobbe et al., 2021) and (5) one real-world task: Search Query Intent (Juneja et al.,\n                                           2024)\n\n                              Table 7: Tasks covered in the different papers\n\n14  Prompt examples\n\n14.1  Instruction Induction\n\nBelow is the original instruction induction prompt used by Honovich et al. (2023)\n\n  {{# system ∼}}\n  You are a helpful assistant\n {{∼/ system }}\n  {{# user ∼}}\n   I gave a friend an instruction and [[n_demo]] inputs. The friend read the instruction and wrote an\n  output for every one of the inputs. Here are the input - output pairs:\n  {{ demos }}\n  What was the instruction ? It has to be less than {{ max_tokens }} tokens .\n {{∼/ user }}\n  {{# assistant ∼}}\n  The instruction was {{gen ’instruction ’ [[ GENERATION_CONFIG ]]}}\n {{∼/ assistant }}\n\n\n14.2  Metaprompt design example\n\nBelow is the metaprompt used in OPRO (Yang et al., 2024a)\n\n   I have some texts along with their corresponding scores. The texts are arranged in ascending order\n  based on their scores, where higher scores indicate better quality. text:\n  Let’s figure it out!\n  score: 61\n   text: Let’s solve the problem.\n  score: 63\n   (. . . more instructions and scores . . . )\n  The following exemplars show how to apply your text:\n  you replace in each input with your text, then read the input and give an output. We say your output\n   is wrong if your output is different from the given output, and we say your output is correct if they\n  are the same.\n  input: Q: Alannah, Beatrix, and Queen are preparing for the new school year and have been given\n  books by their parents. Alannah has 20 more books than Beatrix. Queen has 1/5 times more books\n  than Alannah. If Beatrix has 30 books, how many books do the three have together?\n  A: output: 140\n   (. . . more exemplars . . . )\n  Write your new text that is different from the old ones and has a score as high as possible. Write the\n   text in square brackets\n\n\n14.3 LLM Feedback prompts\n\ntrue the and                                           or-        re-                                   rea- 2:       step. * not\n                       is on                                                                                                                                                                                                                                                                                             length                                                                                                                                                                              step                                                                                      the                                                                                                                                                                                                                                                                                   ’entail-                                                                                                   Do                                                                                            by                                                                                                                                                                                                                                                                                                                         Current                                                                                                                                                                                                                                                  words                                                                                                                                                                         your                                                                                                                                                                                                   direct                                                                                                                       speaker.                                                                                                                                                                                                                                                                             sentences.  subtleties                                             #\n                                a                                                                                                                                                                                                                                              total                                                                                                 50                                                                                                                                                                              with                                                                                                                                                                                        step                                                              based                                                                                                                                                                                                                                                                                                                                                                                                       differentiate   assumptions.                                                                                                                                                                                                               select                                             the                                                                                   the                                                                 is                                                                                                                                                      referenced,                                                                                                      statement                                                                                                                                               The                              of                                                                                                                                                                                                                                      pinpoint                                                                                                                                                                                                                                                                                                                                                           prompt.                                                                                                                                                                                                                                                             review                                                                                                                                                                                                  than                                                                                          and                                                                                              and                                                *                                                 (No)                                                                                                                                                                                                                                      think                                                                                                                                                                                                                                                                 text.                                                                                                                                                                                                                       provided                                  the                                                                                                                                                     the                                                                                                                                                                                                                                                                                                                proceed                                                                                                                                                                                                                                                                                                                         prompt.2024).                                                                                                                                                                                                  less                       if                   prompt                                                                                                                                                                                                                                                                                   premise,                                                                                 the  account                                                                                          biases                                                                                                                                                            facts                                                              false                                                                                                sources                                                                                                                                                                                                                                      Let’s                                                                                                                                                                                                                                                                 other                                                                                                 be                                                                                                                                                                                    events                                                                                                                                  and                                                                                                                                      the                                                                                                                                                                                                                                      context,                                                                                                                                                                                                      with                                                                                                       the                                                                                                                                                                                                                                                                                                                                     hypothesisal.,                         or                                                                                                                                                                                                                                                                                                                                                                                            carefully                                                                                                              intoet                                                                                   the of    the of                                                                                                                                                       Instructions                             Rewritten                                                               Determine (Yes)  context,  potential                                                                            Compare Take in der  between If sult ment’.                   Now soning refine Prompt # should Reply  include(Ye\n                                                                                                  to                                        in-                                                                                       the                                                                                                     im-                                                                                                                                                                                     cor-                                                                                                                                                                                          edit                                                                                                                                                                                                          sub-                                          into                                                                                                         con-                                                                                                                                                            tiled                                                                                                                          com-                                                                                       state-                                                                                                                                                                  large                                                                                                                                                                                                                                 away.PE2                                                                                                                                             might                                                          of                                                                                                                                                                                                                                                                      didn’t                                                                                                                                                                                                                ...]                               a                                                                                             to                                a                                                                                                                                                                                                                                                                                                                                                  correct?                                                                  could                                                                                                                                                                                     task                                                                                                                                                                                                                                                                                                      edited                                                                                                         potential                                          take                                                               of                                                                        their                                                                                    is                                                                 of                                                                                                                                                         waterand                                                                                                                                                                                                                                 threw                                                                                                                                                                                                                                                                              directly                                                                                                  be                                                                                                                                             model                                                                                                                                        the                                                                                                                                                                                                                           model                             of                                                                                                                                                                                                                                                                                                                                                                  perform                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Suggestions:                                                                                                                                                                                                            details                                                             in                               not                                                                                              out                                                                                          he                                                                                                                                                                                                                                             \"Ignoring                                                                  which                                                                                                     to                                                                                                                                   the                                                                                                                                                                                                                                                                                                                                                                                                                                examples                                                                                       the                                                                                    The                                                                                                                                                                  image                                                                                                                                                                                                                                                             Output                                                                                                                                                                                                                                                                                                                                                                                                                                   Necessary                                                                                                                          play                                                                                                                                                                                               Yes.                                          does                                                                                                                                                                         which                                                                                                         speaker’s                                                                                                                                                                                                                                                                                                      should                                          1                                                                                                                                                                                                                                 socks2024a)            output                                                                 an                                                                                                                    veracity                                                                                                                                                                                                                           streams                                                                                                                                                                                                                                                             model                                                                                            agenda,                                                                                                                                                                                                                                                                    [More                                                                                                                                                                                                                                                                                                                                                                                                    hypothesis.                                                                                                                                                                         it,’,                                                                                                                                                         ’kids                                                                                                                                                                                                     detail\"                                                                                                                                       the  describing Yes.                                           the                                                               inal.,                          or                                                                                                                                                        the                                                                                                                                                                                                                                             Feedback:                                                                                                                                  with                                                                                                          the                                                                   on                                                               prompt the                                                                                                                                                                                                                                                                                                                                                                                                                                                     Reasoning:                                                                                    and                                                               up                                                                                                                                                                                                                                                                                                                                              prompt? promptet                                                                                                                                                                                                                                                                                                        Example                                                                                                                                                                                                                                                                                                                                 overlooking                                Evaluation                   The  account biases  fluence ments.                                                  Error text be  premise ing floor rose plies            ## No.  subtract Prompt  rectly? the The guide  traction.\nWang\n                      both)\n\n    /2023;\nal.,                   evaluation  response\net    of /\n\n                                                                                                                                                                                            Both(Pryzant             Subject  (prompt                                              Prompt                                                                                                     Prompt\ngradients                          Response                           N/A                                                                                                                                                                                                                                             Non-entailment                                             N/A\ntext\n                                                       up with\n                                                                                           it.                                                                                                                              that          Predic-                                  think        think ## 28had socks4 Step 2:Step ...]                                         State- (No) other     in Sena-  republi-  Liberty                                   that in                        not                                                                                                                                                                                                                                                                                                                                                       Template                            and                    the                                                                                                                                                                                             learns                                                                                                                                                                                                                                 Let’s                                                             on                                                                                                                     businesses                                                                                     title:                                                                                                                                                                                                                Let’s                                                                                                       business                or                                                                                                                                                                                                                                                                                                                                                                                                                                   examples                                                                                                                                                                                                     water.methods,                                                                                                                                                                                                                                                                                                                                                                           Examples                                       No                                      learns coming floor                                                                                                                                                                                                                                                                                             George away         socks.                                                                                                                                                                           Full                                           Job Party: at                          of                                                                                                                                                tiled                                                                                                                         rose                                             #                                                                  in                                                                                                      speech           a             #                                                   Reasoning: 28                                        (Yes)                                                                                           “‘                 a                                                          Small                                                                 Context                                                                                                                                                                                                                            William                                       out                                                                                                                                                                                                                                                                      [More                                                                                                                                                                                                                                                                                                                           Answer:                                                                                                                                          water                                                                                                                                                                                                                                                threw                                                          of                                               whether                                                                                                                                                                                                                                                          Prompt                                                                                                                                                                                                                    Prediction:                                                                                                                                                                                        William                                                                                                                                                        large                                                                                                                                                                                                                                                                                             Input:                   prompt                                                                                                  64 had                        lie                                                       in                            the                                                                                                         60                              a                                                                                                he                                               1                                                                                                                                                                                                                      step.        a                                                                                                                                                                                                                                      playing                                                                                      out                                                                                                                                                                                                                                   step.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Non-entailment                                                          Yes                                                                                                                  numbers. Texas.                                                                                                If                                                             of                  on                is                                                                 going                                                                                                                                                                                                                                                                                                                                                                 Entailment                                                                                      by                                                                                                               play                                                                                           by                                                                                                  are                                                                                                                                        Context:                                                                                             State:                                                                                                                                                                                                                                                                                                   Current              Question:                           Output: George Label:                             Candidate                       Determine ment based   information.  Statement: (are) record tor. can.   University\" Label:                                                  Premise: kids  streams image   Hypothesis: kids Label: tion:      # step “‘ step  Example socks. ... 1: ...LLM-as-a-Judge\n                                                                                        to                                                                                      lan-                                                                                               and                                                        and                                                                                                                                   pro-                                                                                                                                                                                     last,                                                                                                                   task.                                                                                                                                                      sum-                                                                                                                                                      care-                                                                                                                                                                                  leadsfor                                                                      Wrap                     a                       a                                                                                                                                                                                                                                            differ-                                                                              follow-                                                                                                                                                                                         follow-                                                    current                                                                                                                                                                                                                                                                               aspects                                                                                                                                                                                                                                                                                                      prompt                                                                        At                                                                                                       reasons got-                                                                                                                                                                                                                                                                                                                                                  prompt?                                                                                                                                                                                                                                                                                                                                                       example,                                                                                                                                                                    step,                                                                have                                                                     for                                                       zero-shot                                                                for                                                                                                  on                                                                                                     and                                 the                                                                               the                                                                                                                                                                                                                                                                                          prompt.      a                                                                                                                    the               My                                                                  by                                                                                                                                                 the                                                                                                                                                                                                                      prompt                                                                                                                                                                                                                                                              question                                                                                                                                                                                                                                                                                                                                                                                                             according                                                                                                          wrong.                                                                                                                                                                                                                                                                                                            reasons,                                                                                                                                                                           each                                                                                                                                  <START>                                                                                                                         the                                                                                                                                                                                                                                                example,                                                                                                                    all                                                                                could                                                                                                           the                                                                                                                                                                                                 edit                                                                                                                                   step                                                                                                                                                                                                                                                             answer.                               write                                                                                                                               each                                                                                                                                                                                                                                                                                                                                                                              template                                            gets wrong:                                                                                                         gets wrong:                                                                                                                                 For                                                                                                                                                                                        designed is:                                                                                                                                                      prompts                                                                                                 to                                                                                                                                                           list                                                                                                                                                                                            these                                                                          with                                                                                                                                                 prompt                                                                                                                                                                                                                                                                                                                                                                                        correct?            to                                                                                                           why                                                    prompt.                                                                                                                                                      wrong                                                                                                                 all                                                                                                                                             examplesoptimization            prompt                                                                                              is                suggestions                                                                                                                                                              prompt                                                                                                                    and  improve                             reasoning                          is:         prompt                        prompt                                                                                                                                                                                                     answer             wrong                                                                                                                                                                                                            string}                                                                                                                   model                                                                           on                                                                                                                                                                                                                                                                                                                                                                                                                                                      comprehensive                                                                                                                                                                                                                             {num_feedbacks} the                                     trying                this  examples                                                                                                                reason              writing          current  prompt} this  examples      each  examine                                                                                        these                                                                                                                                                                                                                                                          reasons the                                                                                                                         can                      Instruction             following Output  Necessary yes,Ifprompt            LLMaaJ      I’m  classifier prompt  \"{prompt}\" But ing   {error_string} give why ten each <END>  I’m guage My {cur But ing {error For fully wrong, vide ent to based marize that  #  provide the * * *  editing?\n                                                                 2023)                                                                                                     2024a)\n                                                    al.,Automatic                        et                                                                    al.,\n                                                              et\n8:                                                                                              (Pryzant                                                                                     (Wang                                                                           2024)Table                                                                                                                                                                                            al.,\n                                                                                              et\n                                                                                                                                             (Ye                   Method                                                                                                                            Text-gradients                                                                                                                                                                                                                                             Text-gradients                                                                                                                                             PE2\n\ntruth                                                                                                                    false                                                                                                  when or                                                                  conse- when                             of  simpli-                                              is                        or                                                                                          the  hypothe-  options    tag                                                 sentence useful    the                                        the                                                                         when  guaran-  hypothe-  possibil-                                or                                                                                                                                                                                    beliefs                                       when                      a                                                                                               the         within                                                           not                                                                                                                                                                                                                 between and                  one Some                                                                regardless             involved. occurs                                                              the is                                                                            logical                                                                                                          people.\n                                          of                                                                                                                                                                                                       [input]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ’non-entailment’.                                                                                                                                                                                                                                                     especially                                                                                      terms                                                                                                 premise,                                                          occurs a                                                                              does                                                                                                                                                                                                             involves                                                                                                              there  hypothesis                      is                                                                                                                                        other                                    next.                                                                                                                                       guarantees                specificity                                                                   or answer  </Ans>.                                                    the                                    the                  prompt              whether                                                                                                                                                                                                                                               relation  premises from\n                                of                                                                      the     of Input: the                                  of             truth                      the        of                                                                                                            and                                                                                        when                                                                                                                                                                 hypothesis,                                  are:                                                                                                                                                                                                                                                               choosing      your                                                                                                                                         premise the or that  unknown,  premise                                                                                              premise the level                                                                                                 Entailment                                                                                                                                              Given                                                                                                                                                                                                                               Result                                                                                                                                                                                                                                                                Non-entailment                            Rewritten                  Determine  entails hints -  hypothesis quence the of the  fication - the tee sis, ity or the  thoughts #  Identify  following ses,   ’entailment’ Put <Ans> #\n\n                                        the                                                                                      truth                                                                                                                                       false                                                                                                                 when or                                                                                        conse- when                                     of  simpli-                                                      is                                or                                                    the                                                                                        when  guaran-  hypothe-  possibil-                                       or                                                      when                          a\n                                                                      not                                                                                                                                                                                       regardless             involved. occurs                                             beliefs                                                                         the is                                                                                                      logical                                                                                                          people.\n                                                 of               a                                                                                                                                                                                                                                                                                         especially                                                                                                         terms                                                                                                                               premise,                                                                                             does                                                                                                                                                                                                                                           involves                                                                                                                                there  hypothesis                             is                                                                                                                                                           other                                                                                                                                                                            guarantees                specificity2023).           output                                                        occurs                                                               the                                                the\n                                       of                                                                                 the     of                                          of             truthal.,                             of                                                                                                       when                                                                                                                                                                                                         hypothesis,\net                                                                                                                                                                   premise the or that  unknown,  premise                                                                                                                        premise the level                                                                                                                                      Entailment                                                                                                                                                                                                                                                                                                                    Non-entailment                               Evaluation         -  hypothesis quence the of the  fication - the tee sis, ity or the  thoughts(Sun\nHints               both)/\n                               evaluation  responsemethods,    of /\n                     Subject  (prompt                                                                                                     Prompt\nLLM-as-a-Judge\nfor                         Response                                                                                                                                                                                                                                                              Non-entailment\n                                                                                                                                 sentence        the  hypothe-  options    tag                                                                  the         withinoptimization                                             one                   between and                                                                                                                                 [input]           from    ’non-entailment’.                                               or answer  </Ans>.prompt           prompt                                                                                     whether next            relation  premises                                                                                                               Input: the                                                    the                       and                                                                                                                                                                                choosing      your                                                                                            Given                                              Result                            Candidate                                                                                                             Determine  entails #  Identify  following ses,   ’entailment’ Put <Ans> #Automatic\n9:                                                  De-             [out-      it’s within\nTable                                                                                   [Task               why                                                                                                                                                      Output:      hint output                                                                                         task:                                                or            </hint>.                                                                                                                                              [Input]\n                                                                                and                  prompt                                                                                                                                           expected         reason  expected                                                                                                                                                                following         Input:                                                                its    the this                                                                                                                                                               <hint>                  LLMaaJ                                                                     Given  scription] Given And put] List with tag\n                                                                                                               2023)\n                                                                                         al.,\n                                            et\n                                                                                         (Sun\n                  Method                                                                                           Hints\n\nhas within Fo- and  unneces-                                                                                      that                              in and  between Then  summary con-                                                                                                                                                                                                            important willwho an                                                                                                                          provided HERE             as who                                                                                                                                                                                                                                                        possible.  characters                                                  or  keeping                                                                                                          events                                                                                                                                                                          outcomes.             these                                                                                                                                                                                                                                                   omitting                                                     key            sentence                   prompt                                                                                          dialogue INPUT    and                such dress while where theon                                                     the    1-2    a                                              the    a  〈summary〉tags  captures                                             events,                                                                                                                                                                       points,                                                                                                                                                                                                                                                            context.                                                                                                                                          words only                            Rewritten                                             Read INSERT  identify  characters write within cisely plot borrow  interview, 10 cus  salient sary\n\n                                                   on                                                                                 de-                                                     im-                                                                    1-2                                              and are                                                                                      sum-                                                                                                                                                                             output                                                                                                                                               desired                                                                    and                                                                  here                                                                                                                                focus                                                                the                                                                                         could                                                                                                                                      which                                                                                      the  unnessary                                                             the                                                   to\n                                                                       that        for                                                                                                                                                        high-score                                words2025).                                                                                                                                                                                   specify                                              the             10                                             contain                   output                                                                                                                                                                  instructions,                    range            andal.,                                           or (e.g.,                   not  〈/suggestion〉et                                                                                                                                                                                      suggestions them:                                                                                                                                                                 events   〈/suggestion〉(He                   Evaluation                                                                                                     Comparing  low-score some prove    〈suggestion〉Specify length maries     sentences).〈/suggestions〉    〈suggestion〉Specify key tails    〈suggestion〉Specify should  context\n\n                      both)Critique   /\n                               evaluation  response\n      of /methods,\n                      Subject  (prompt                                                                         both\n\n                                                                       up.                                                                                 not                                                                                                                                    previ-                                                                                                                                             Tegan her                                     on media, and                                                                                                                                                                             advises ignore                                                                   tells that  brother frienda                                                              she                                                                                                                                      42.1                                                   to                                                                                                                                              broken                                                                  had                                                    her                                                                                                                                                                                                              revisit   relationship Paul.LLM-as-a-Judge                                                                                                                                                                                                                       request,for               Response                                               Tegan  Valentia Paul’s sent  request social though Paul ously  Valentia Tegan the  wanting to past with Score:\n\n                                                1-2                                                                                 any were                                                    on                a 〈sum- the Focus people  between        in-                                                                                                                  that  outcome\n                                                                               write within        key                    focusoptimization                                                                                                                                                                           highlights  details.                                                                the           HERE to   characters,                                                                               text,                                                                         that     who  happened                                             overall                                                                                        the                                                                                                            main                                                                                                                            INPUT  details                                                                                                                                                                                                                                                                                                                                                     arrangementsprompt           prompt                                                           given  summary                                                                                         what                                                                                        and                                                                                 the                                                                             key                                                                                                                                                                                important                                                         or                                                the                                                                                                                                                                                               including and                                                                                     resolution.                            Candidate                                   For  sentence  mary〉tags most on are them. INSERT Some clude plans made, orAutomatic                 be                                                                  not                             pre-                                               in       high- sum- the                 to while were    The more                                          in                                                                                                                                                                                                  length sen-                                                                                               inputs10:                                                                                                   1-2          include  details  should                      The                                                                                                                 from                                                                                        were                                                the                                                           used                                                                                                                                                          summaries fewerwith    the                                                   tended  details                                                                      details             mentioned                                                                                                                                                                                     details                                   only           details                                                                                                                                                                     (e.g.Table                                                                                                                                                                                                                                                                                     omitted                                                                                                                                                                                                                                                  reference                                                                                                                                                                                                                                                                  expected                                                                       to                                                                              key                                                                                                                                      sentences:                                                                                                   summaries  concise.                                                                      not                                            words:                                                                               or                                                                                                                                                                                                     missing                                                                                                                                                                                                                               summaries                                                                                                 the                                                                                   Some                                                                                                                                                                                                  which                                                                                 the                           of                                                                                                                                                   succinct                                                 more               of                                                                                                                                                                                                      summaries                                                                      and                                                                                                                                    summaries  describeto  reference                                                                                                                                                                                                                                                                                                         summaries.                                                                                                       Some                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   important/key                   prompt                                                      in                                                                                                                 were                                     and                                                                                                                                                                                                                                        summary                                                                            summaries morewith                                                   the                                                                         more                                                                                                   reference                                                                                                                                                                                                                               reference                                                                                                                                                     most                                                                                                   the                                                                                                                                                                                                                                                                                                                                                                                                                                                    prioritized                                            Number                                                                                                                                                                                                                                                                                                                                                                                                       Emphasizing                                                                                Number                                                                Precision:                                                                                                                                                                                     Recall:                                                    Specifying                                                                                                                                                                                                                                                                                                                                                                                                    Indicating                   LLMaaJ                  Critique: - dicted longer the  shorter -  predicted  sentences while were  sentences. -  predicted  important the -  lighted maries  predicted   Suggestion: - of  tences) - the - be\n                                                                                                                     2025)\n                                                                                              al.,\n                                               et\n                                                                      (He\n                   Method                                                                                                                                                           Critique\n\nto                                                           di-                                           step.                                                                                                                                       rele-                          a\n                                                     is                                                    reason-                                                                                                                                    Ensure indi-                                                                                                                                                                                                          context                 by                                     ’-                                                                                                                                                  provide                                                                                                                                                                count                                                                                 the       a                                                                                                                                                                                                                                                                              potential  input.the                                                                                                                                                                                                    ’Answer: nu-                                                                              response for- where value.  reason-a anditem con-and Item:                                                                                                                      values                                     as                                                                                      the                                                               in                                   step                                                              and                                                                                                                                                                   clearly\n                                                          to                                                                                                                                                                final                                                                each                                                           the                                                                                                   following                                                                                      clear                                       your                                               is                                                                                                                                   VALUE                                                                                                                                                                  Verify                                                                                                                                                                                    handle                                                                                   list                                             answer                                                                         such                 a                                                                                       $VALUE’                                                                                        answer                    of                                 the                                                                                                                   item                                                                                                                                                                            format:                                                                List                                           Think                                                                                                                          numerical                                  in                                                           Sum                                                                                          and                                                              the                                                                                optimization:                              will                      of              a                                                                                                                                                                                                                             summation.                                                                                                                                   where                   prompt                                                           will                                                                          the                                       line                                                                                                                                            answer                                                                                                                                                                                                                                                                                                                                                        ambiguities                                                                                                                   each                           is                                                                                                                                                                  value.                      be                                                                                                                                 format,                                                                                                the  accuracy.\"                      You                                                                                   from                                                 in                                                               or                                                          of                                                                                                                                                      query                                       last            ’Answer:    You                                                                                                                    final                                     prompt             question.                                                                                                                                                 question.  quantity                                                                                          the                                                                                                                                                          concise                            Rewritten      For From: ing The should mat: VALUE To: ing its  sistent  Quantity’. rectly a the cated  $VALUE’  merical vance of  errors   Double-check ensure\n                                                           opti- prob-     The                                       be when        re-                                                                                                                                                       output (math                                                                              k‘**:  correctly  ‘nums[i] re-                                                                                                                                               simply                                                                                               instance  coding   == not         should                                    optimization:                                example)2022).                                for                     when                differently        LLM          matches for                                                                  does                                                                    generated                                                                                                                                     truth                                                                                                         specific                                                                       case                   output                                                                                                                                       balance                                                                                                                                          promptal.,                                                                                                                             ‘nums[i]                                                                           the                                                                       output                                                                                                                                                                                                   result,                          (a  example):                                                                                   logic                                                     theet                                                                     for                                                          The                                                  if                                                                                                                                                                  adjusted                                                                                                                                                                                                                                                                    encountered.                                           for                                                                                                                                                                                                                       evaluator                                                                                                                                                               ground                                        or                                                          k‘.                                           is(Cieri                   Evaluation                                                      Exmaple  mization lem,  Handling  current handle == set ‘k‘ Output The turns and  problem\n                      both)\n\n    /Reflection                               evaluation  response\n      of /\nmethods,                      Subject  (prompt                                                          both\nLLM-as-a-Judge               Response                                               N/A\nfor                                                                          {x}: and\n                                     on   criticisms,                                                                                                                                                                                          criticisms             variable.optimization                                                       the                   prompt                                           the    new\n                                                        are aprompt                            Candidate                                                                        Below   Incorporate  produce\n\n                                 an           {y}:Automatic                                                             with     on {x}.\n11:                                                                                                                                                                                                criticisms  improve\n                                           toTable                                                                                                                                                                                                      conversation        the                   prompt            a            how                                                             are\n                   LLMaaJ                         isHere LLM: {x|y}. Below  Explain\n                                                                                                   2022)\n                                                                               al.,\n                                        et\n                                                                                                                       (Cieri\n                   Method                                                                                                                                                             Reflection\n\nis                                       to                                                                                                                   or                                                                                                      in-                                                                                      be-                                                                                                                                                                                      fol-                                                                                                                                          sin-                                                                                            and                                                                                                                                                                                                                             sen-                                                      ana-                         Sen-                                                                          Lan-                                                             clas-                                                                                                                                                                                                                                                                                     with-                                                                                                                                                                                                     with-                                  a                                                   senti-\n      a                                                                                                                                                                                                                                                                  exam-                                                                                                                                            please                                                                                                        model                                                                                                                           model                                                                                                                                                                                 impor-                                                                                                                                                                                                                                                                                                     update                                                                                                      The                             task                           to                                                                                                                                        the                                                                                                                                                                                     support                                                                                                                                                                                                                                                                            provide                                                                                                                                identify                                                                     of                                                                                                         improve                                                                                                                                                                                                                                                                                                            activities,                                                                                                                                                                                                                                                                                                                                                                                                                              classifica-                   are                                                                                                                                                                                                                             text                                                                                                                                                                                                                                 respectful                                                                                                                                                                                                                                                                                                                                       paragraph                                                                                                   sentiment                                                                                                                                                                                                                                                                                                                                                                                                              emotional                                                                                           in                                or                                                                                        the                                                                                                  understand                                                                                                                                                                                                              shot                                                                             any                                                                                                                                                                                                                                                                                                                                                                                                                                                              information                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  efficient.\"                                                                                                                                                                                                                                                       positive                                                                                                                                                                                                                                                                 unethical                                                                                                                                                                                 important                             Your                                                      used                                                                   and                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 emotional                   You                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           information                    to                                 and                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [’positive’]                                                                                                                                     the                                       is                                                                                                              sentiment                                                                                                                                                                                                                                             Format:                                                                                                                                                                                                                                     should                                                         or                                                                                                                                                                                      short                                                                                                                                                                                                                                                                                                                                                                                                       software                                                                                                                                                                                                                                                                                     input                                                                                                                                                                                                                                                 consist                                                                                                                                                                                        Respectful                                                                                                                                                           few                                                                                                                                                                                               illegal                                                                                                                                                                                                                                                                                                                                                                  sentiment                                                                                                                                                                       language                                                                                                                                                     and                                                                             emotional                           be                                                                                                                                                                                                    language                                    a                                       It                                                                                                                                                                      the                                                                                                                                                                                                                                         Therefore,                                                                                                                                       feedback,                                       text                                                                                                                                                                                                                                                                                                                                                   sentiment                                                       for                                                                         or                                                                                  for                                            tone                                                                                                                                                   new                                                               the                                                 This                          the                                                                                                                                                                                     provide                                                                                                                                          only                                                                                                                                                                                                                             each                                                                                                                                                                                                                                                                                                                                                                                                                         expressed                                                                          the                                                                                                                                                                                                              four                                        can                                                                                                                                                                                                                                                                                                                                                                                                                                   interactions.                   prompt                                                                                                                                                                                                                                     output                                                                                                                                                                                    positive                                                                                                                                                                                                           Output                                                                                                                          issues.                             the                                                                                                                                                                                                                                                                         Emphasize                                                                                                                                                                                                                                                                                                                                                                                                                     additional                                                                                                                                                                                                                                                                                     promoting                                                                                                                                                                                                                                     actions,                                                                                                                                                                                                experiences,                                                                                                                                                                                                                                                                                                                                                                    Answer:                                                                                                                                                                                                                                                                                                                                                                  classify                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 additional                                                                             not                                                                                                                                                                                                                                                                                           texts:                                                                                 Classifier.                                                                                   that                                                                                                                                                                      for                                                                                                                      Model:                                                                                                                                                                                                                                                                                                                                                                                                  provide                                                                                                                                                                                                    \"The                    of                                                              of                                                                                                  that                                                                                                      and                                                                                                                   The                                                                           Description:                                                                                                                        customer                                                                                                                                                                                                                                                                                                                                                                  emotional                                                                                                                          any                                                                                                                                                                                                                                                                                                             requires                                                                             overall                                                                                                                                                                                                              should                                                                                                                                                                             any                                                                                                                                                                                                                                                                                                   sentence                                                                     classify                                                                                                                                                                                                                          guidance                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          suggestions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     user-friendly                             Rewritten        Task timent to ment the  expressed.  sification lyze  product  potential   Instructions guage ensure  promotes   interactions. note should or  harmful  havior. tance  respectful Input put gle that tion. the out or  Examples: Please  sentiment lowing  Input: is  Correct  {Another ples}  Please timent out   suggestions.\n                                                                                                                 with itif on  prompts   in\n                                                                                                  all                                                                                                                                                                                                      optimal                                            performance  objectives2024).                                                                                                                                                                                                                                                              objective   performance                                                                                                                                                                   among                                                           an best          similar otheral.,           output                                                                                                                                                                         locally\net                                                                                 the to the        all                                                                                                                                                                                                                                                                                                                                                                        objectives                                                                                                                                                                                                                                                                                                     objective  exhibit(Sinha                   Evaluation                                                                                                                                                 Select  respect  achieves this that across other\nScore                both)/\nSafety                   evaluation  response\n      of /\n                      Subject  (prompt                                                                                                                                                                                                                       Responsemethods,\n                                                                                                                                                                                                     score:\n                                                                                                                                                                                              score:                         Response                                                                                  KPI  SecurityLLM-as-a-Judge                     a\n                                                                                                gen- the in-    as- pro-            the\n                                                          to                                                                               and  current                                                to                                                          is thefor                                                                                                           Given                                                                                                     with\n                                                is                                                            of  sentimenta ’posi-                      sentence  [’nega-                                                                                                                                                      from                                                                                                                                                                                                                                                                                                                            Determine given                                                                                                task                                                                                                                                                                                                          mission                                                                                                                                                       prompt  meaning                                                                                                                                                                                                assign                                                                                                                                                                                           label                                                                                                                                                                                                                             Example:                                                                                                                                                                                                                                                                                                                                                                                                       [’negative’,                                                                                                                                                                                      mutator.                                                                                                                                                                                                                                                                               sentiment                                     a              data}                            #                   prompt                                                                        of                                                                                                and                       a                                                                                                your                                                                                                                   Youroptimization                                                                                                                                                                                                                                                      prompt: the                                                                                   in                                                                                          the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ’positive’].                                                                    are          another  semantic                text                                                                                                                                  from                        assignprompt                 Candidate                                                        You  prompt, erate same  tentions.  prompt:  certain vided label  tive’].  mutated  sentiment and tive’, Given:#  {passed\n\n                                                                          of                                                                                                                                        in-                                                                                                         se-                                                                                                                        de-                                                                                                                                                          ob-                                                                                                                                                            the                                 and                                                                                   mis-                                                                                                                                 like,                                                                                                            help                                                                                                                                                           Con-                                                      each                                                           what                                                                                                                     mali-                                                                                                                            LLM                                                                                          LLM                                                                                                 LLM                                                                                     LLM                                                                  LLM                                                 made                                                                               From                                                                                                        in                                                                                                       on                                                                                Based                                                                                                                                                                                                                                                                      ensure                                                                                                       output                     a                       a                                                                                                                     it.                         it                                                                                                                                                                                                                       without                                                                                                                                                                                                                                                                                                                                                                                                         existing                                                                                                                                 prompts                                                                                          the                                                                                                                            the                                                                                                                                                                                                      responds                                                                                                 the                                                                                       to                                                                                     the                                                                  the                                                                                                                                                                                                                                                                                 around                                                                                                                                                                                                                   prompt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            respectful.                                                            If                                                                                                            gatekeeper.\n                                   a                                                                                                                                                                  cannot                                                                                                                                                                                                                                                                 based                                                                  promptAutomatic                                                       the                                                                                                                                                                                                  solve                                                                                         is                                                                                                                                                   the                                                                                                                       identify                           I                                                                                              through                                                                                                                                 then                                                                                                                                                                                                                                                                                                                                                                                                                      description                                                                                                                 then                                                             where                                                                          LLM                                                                                                                                                                                                                                                                                                                                                                                                                                 mistakes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  step-by-step                                                                              to                                                                                                                                                                                                                                                                  response\",                                                                                                                                                                   perform                                                                                        when                                                                                                                                                                                        answer                                                                                                                                                      user.                                                                                                                                                                                                                                                                                                  process                                        a                                                                                                                                                                                                                                                                                                                                          format.                                                                                                                                                mistakes.                                                                                                                                                                                 mistakes.12:                                             and                                                                                                                                            make                                                                                 AI,                                                                          the                                                                                                                                                            the                                                                                                                                                                                                                                                                                                                     secure                                                                                                                                                                                                                      are:                                                                                                                                                                                                                                                                                                  data}*                                                                                          the                                                                                                                     how                                                                                                                                                                                                                                                          perspective,                                                      Look                                                                      to                                                                                                                            the                                                                              security                                                                                             user                                                  If                                                                                                                                                                                                     make                                                             cases                                                                                                                                                                                                                                                                            answer                                                                                                                                                                                                                                                                                                                                                                                                                                                                       guardrails                                                      an                                                the                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           instructions                                                                                        existing                                                                                                        of                                                           the                                                                                                                                                                                                                               observations,                                                                                                                                 improve                                                                                                                                                                                                                                  this...\"                                                                                        made                                                                                                 in          a                                                                                                                                                                                                                                                                                                        detailed                                                                                   of                   prompt                         of                                                                                                                                                                                                                                                                                           output                                                                                                                                                                                        cannot                                                                                                                     and                                     a                                                                                                                                                                                                              more                                                                                                                                                                        help.                                                                      the                                                                                                                        help                                                                                                                                                                                     \"canned                                     to                                                                                                                                                                                                                                                                                                       follow.                                                                                                  to                      anTable                                       on                                                                                                            just                                                                                                                                            ways                                                                                                                            task.                                                                                                                                                                                                                                                                           above                                                                                                                                                                                                                                                                                                                                                                   information                                                             it                          a                                                                                                                                                                                                                                                                                                                                                                         providing                             are                                                                  was                                                                                                                                      carefully                                                                                                                                                are:                                                                                                                 with                                                                                      these                                                                                                     not                                                                                                                                              and                                                                                          not                                                                                                                                                                                                                               LLM’s                                                                                                                                                           task                                                                                                                                                                                                                                                                                                                              Specify                                                      am                                                                                                               Add                                                                                                                                                                                                                                                                                                                 Specify                                                                                                                causing                                                                                                                                                                       security                                                       way                                                                          series                   LLMaaJ                 You Given a  mistakes. case is on a based a take helped cious with \"I you did says more did Some cure 1. the sider  scription should 2. the 3. put  *{passed ways prompt  servations cases\n                                                                                                                                                                 2024)\n                                                                                                                                 al.,\n                                                                 et\n                                                                                                                                                                                                  (Sinha\n                                                                                                                                                                 Score\n                   Method                                                                                                                                                                         Safety",
"headers": [
"arXiv:2502.16923v2  [cs.CL]  2 Apr 2025",
"A Systematic Survey of Automatic Prompt Optimization Techniques",
"Kiran Ramnath, Kang Zhou, Sheng Guan, Soumya Smruti Mishra, Xuan Qi, Zhengyuan Shen,",
"Shuai Wang",
",",
"Sangmin Woo",
"Sullam Jeoung",
"Yawei Wang",
"Haozhu Wang",
"Han Ding",
"Yuzhe Lu",
"Zhichao Xu",
"Yun Zhou",
"Balasubramaniam Srinivasan",
"Qiaojing Yan",
"Yueyan Chen",
"Haibo Ding",
"Panpan Xu",
", and",
"Lin Lee Cheong",
"Amazon Web Services",
"{raxkiran,zhoukang,shguan,soumish,xuaqi,donshen, wshui,sangminw,sullamij,",
"yawenwan, haozhuw, handing, yuzhelu, xzhichao, yunzzhou, srbalasu, qiaojiny,",
"yyanc, hbding, xupanpan, lcheong}@amazon.com",
"Abstract",
"2",
"Automatic Prompt Optimization",
"Formulation",
"1",
"Introduction",
"3",
"Initialize Seed Prompts",
"4",
"Inference Evaluation and Feedback",
"5",
"Candidate Prompt Generation",
"6",
"Filter and Retain Promising Prompts",
"7",
"Iteration Depth",
"8",
"Theoretical Perspectives",
"9",
"Challenges and Future Directions",
"10",
"Conclusion",
"11",
"Limitations",
"References",
"12",
"Appendix",
"13",
"Comparison of different approaches + Tasks",
"14",
"Prompt examples",
"prompt solution space, and (3) they retain human",
"interpretability of prompt improvements. In this",
"the field. Our core contribution is a 5-part APO",
"taxonomy combined with a comprehensive fine-",
"grained categorization of various design choices",
"and seasoned researchers alike, enabling further",
"timization (APO) as follows. Given a task model",
", initial prompt",
", the goal of an APO-",
"system",
"is to obtain the best performing",
"prompt-template",
"under a metric",
"and",
"prompt optimization as token-sequence search",
"follow the general anatomy as described in Algo-",
"Several approaches use a seed of manually cre-",
"2022",
"), SPRIG (",
"Zhang et al.",
"2024b",
"). While ob-",
"Since",
"McCann et al.",
"(",
"2018",
") cast multi-task NLP",
"as Question Answering, using prompts as inputs",
"has become the standard way to elicit desired re-",
"sponses from Large Language Models (LLMs).",
"Furthermore, LLMs’ few-shot learning (",
"Brown",
"), and zero-shot reasoning capabilities (",
"Ko-",
"jima et al.",
"2023",
") have led to a widespread prolif-",
"eration of prompting tricks for various tasks and",
"of the task (",
"Li et al.",
"2023b",
"),ordering (",
"Liu et al.",
"ing a performance gap between two prompts that",
"are semantically similar, thereby adding impedi-",
"Honovich et al.",
") were the first to propose",
"inducing LLMs to infer human-readable prompts",
"based on a few demonstrations",
"(see Appendix",
"14.1",
"for prompt). APE (",
"Zhou et al.",
") and",
"DAPO (",
"Yang et al.",
"2024c",
") use the induced seed",
"instructions for further optimization, while MOP",
"duced instructions from task-READMEs, while",
"The evaluation step helps identify promising",
"Entropy-based scores evaluate the entire output",
"a single inference instance. They are gradient-",
"free but require access to the entire output prob-",
"ability distribution, something not usually possi-",
"ble with black-box LLMs. CLAPS (",
") leverages the negative incremental cross-",
"entropy of",
"v/s",
"to identify promis-",
"ing words",
"to add to the prompt. The topK",
"to construct candidate prompts. GRIPS (",
"Prasad",
"et al.",
") simply added an entropy term to",
"Using task-specific accuracy metrics is the most",
"straightforward and widespread way of eliciting",
"feedback, i.a., (",
";",
"Zhang",
"Khattab et al.",
"). Classifica-",
"while code-related tasks measure execution accu-",
"BLEU-N, Rouge-N, Rouge-N-F1, or embedding-",
"PACE (",
"Dong et al.",
") consider the negative",
"target LLM, i.e.,",
". This however re-",
"the decoding of each token, limiting its applica-",
"bility. The NLL for ground truth one-hot token-",
"Given the limitations of rigid accuracy metrics,",
"some approaches proposed using learned reward",
"models to provide more nuanced evaluations of",
"prompts-response pairs (",
"Deng et al.",
"Sun",
"2024a",
") trained an XGBoost-based reward model",
"a best-of-N strategy. DRPO (",
"Amini et al.",
"2024",
")",
"It first optimizes in-context learning examples",
"A popular paradigm to augment or fully replace",
"Sinha et al.",
"). It is versatile because",
"it can evaluate both the response as well as the",
"as it only needs natural language instructions for",
"handcrafting of metrics. A potential downside is",
"the inference cost incurred due to an additional",
"vide multiple feedback data and broadly fall into",
"to generate several prompt candidates for evalu-",
"ation in the next iteration. PromptAgent (",
"Wang",
"tion Handling”, “Output Formatting”.",
"PREFER",
") utilizes a feedback-reflect-",
"refine cycle to aggregate feedback into multiple",
"prompts in an",
"ensemble",
"to improve the model’s",
"ability to generalize across various tasks.",
"Sur-",
"safety-score",
"into a multi-objective prompt opti-",
"simultaneously. To avoid accidentally damaging",
"by employing a",
"hierarchical tree structure",
"and error assessment - to evaluate and correct",
"prompts before and after execution.",
"The feed-",
"editing framework to the prompt refinement pro-",
"adjustments. Overcoming the limitations of opti-",
"mizing a single metric, CRISPO (",
"He et al.",
"2025",
"adopts a",
"multi-aspect critique-suggestion",
"meta-",
"across multiple dimensions such as style, preci-",
"detailed, aspect-specific feedback and iteratively",
"updates the prompts. Autohint (",
"Sun et al.",
"prompt construction / optimization process.",
"Joko",
") proposed “Generative Active Task",
"Elicitation” to better capture human preferences.",
"It prompts a language model to interactively ask",
") trained a smaller LLM to optimize input",
"ing up to 22% increase in win rates for ChatGPT",
"tackles the challenges of multi-step tasks by in-",
"preference feedback rather than numeric scores,",
"to guide the discrete prompt optimization proce-",
"dure, very similar to the gradient-descent style of",
"continuous prompt optimization approaches. Dif-",
"sampled multiple “gradients” i.e. directions of",
"improvement, and each such “gradient” is used",
"employing a dueling bandits-inspired strategy to",
"reviewed below range from simple rule-based ed-",
"combine with LLM-based evaluations (sec.",
"4.2",
"Several works proposed heuristic-based mecha-",
"nisms to make edits to intermediate prompt can-",
"from edits at the word / phrase / sentence-level",
"(either simple rule-based or LLM-generated), or",
"metric-driven incremental search.",
"While these",
"strategies may not result in the most optimal so-",
"lution, they help in making the discrete prompt",
"SOS (",
"), and StraGo (",
"Wu et al.",
") uses mutation prompts with LLMs to over-",
"come the traditional complexity of designing tai-",
"Breeder (",
"Fernando et al.",
") advocates self-",
"referential improvement of all prompts in the",
"prompt optimization system - Direct Mutation of",
"are reverse-engineered from successful examples",
"(similar to Instruction Induction",
"prove diversity of the prompt pool. EvoPrompt",
"Guo et al.",
") use Differential Evolution -",
"come the problem of local optima. AELP (",
"Hsieh",
") also uses mutation operators to per-",
"form sentence-level edits in an iterative fashion.",
"They include sentence-level histories of reward",
"in the mutation prompt in order",
"to avoid local optima and accidentally returning",
"to sub-optimal versions. GPS (",
"Xu et al.",
"PromptWizard (",
"Agarwal et al.",
") proposed a",
"pipeline combining several steps including itera-",
"improve and validate the prompt, and finally an",
"ProTeGi (",
"Pryzant et al.",
") uses Monte carlo",
"successors for evaluation. PromptAgent (",
"Tree Search (MCTS) which consists of 4 steps —",
"genetic algorithms to make discrete edits to texts.",
"is 1/ Mutate and 2/ Cross-over components from",
") and CLAPS perform token-",
"level mutations. SPRIG uses a starting corpus of",
"roles, styles, emotions, scenarios, and good prop-",
"lighting complementary strengths of optimizing",
"showing that merely replacing a few words with",
"pected loss on dev-set",
"drops the",
"prompt, and then influential tokens are replaced",
"els. This token-replacement approach is also at-",
"tractive as a standalone post-processing step for",
"LLM-based approaches.",
"GRIPS (",
"Prasad et al.",
") argues that phrase level edition is an effec-",
"and adapt to target models better leveraging both",
"data diversification and strategic fine-tuning such",
"process in the GAN setting. The LLM generator",
"takes question and the generation prompt to pro-",
"Some works prune the vocabulary space",
"to",
"for decoding the next token for the op-",
"timized prompt",
". CLAPS (",
"argued that general search spaces are highly re-",
"ngrams for decoding. PIN (",
"Choi et al.",
") in-",
"stead added regularization in the form of Tsallis-",
"entropy (ideal for heavy-tailed distributions like",
"natural language) for the RL training of a prompt",
"ral network to edit the initial prompt for ob-",
"taining desired improvements.",
"We include ap-",
"PE2 (",
"Ye et al.",
") argued that previous works",
"tion problem description in natural language and",
"per stage for diversity) and scores alongisde the",
"meta-instruction for prompt refinement. DAPO",
"instruction to guide the LLM in generating high-",
"sional tips) by observing given input-output ex-",
"emplars. Then, DAPO iteratively optimizes the",
"Some approaches seek to \"cover\" the entire prob-",
") demonstrate superiority over simple",
"reward averaging, particularly through volume-",
"objectives. Dynamic prompt modification strate-",
"), directional stimulus prompting (",
"Li",
"2023d",
"test-time editing",
") also tackled test-time optimization objec-",
"tive by learning an",
"offline reward model",
"mend the optimal prompt in a query-dependent",
"fashion. BDPL (",
"Diao et al.",
") optimized dis-",
"AMPO (",
"2024d",
") uses LLM feedback",
"to enumerate all the failure cases based on the",
"to enhance existing branches, or to grow new",
"plicitly ensuring that various semantic facets of a",
"to align itself to task-performance on individual",
"LLMs using reward-free alignment.",
"FIPO (",
"Lu",
") trains a local model (7B - 13B) to",
"(UniPrompt) with two stages: a) task facets ini-",
"tialization using background knowledge, and b)",
"tion of multi-stage language model programs by",
"module. SAMMO (",
"Schnabel and Neville",
"proposed symbolic prompt programming, repre-",
"In this step, promising prompt candidates are fil-",
"Wang et al.",
") introduced the Mixture-of-",
"to be used for specialized inference. MOP first",
"ing. Then, the Region-based Joint Search (RBJS)",
"(sec.",
"6.3",
") algorithm generates the appropriate in-",
"induction (sec.",
"3.2",
") based on a mix of in-cluster",
"The simplest mechanism to iteratively search",
"through prompt candidate sets is a greedy topK",
"search where in each iteration of the optimiza-",
"on the reward for the entire trajectory of prompt",
"PromptBoosting (",
"Hou et al.",
"), Boosted-",
"Prompting (",
"Pitis et al.",
"), PREFER (",
"), etc. are ensemble methods that in-",
"bine them to generate the final output",
". GPO (",
"2023c",
") also uses labeled",
"source data to generate an ensemble of prompts,",
"Relying on a single static evaluation dataset can",
"of bandit search - identifying the most suitable",
"putation budget. They use the Upper Confidence",
"optimization, they sample a different evaluation",
"dataset",
", and maintain a moving",
"candidates with the greatest score for further ex-",
"ploration. PromptAgent uses a variation of UCB",
"Program-synthesis based approaches transform",
"LLM pipelines into structured, modular compo-",
"nents that can be systematically optimized and",
"composed. These optimization techniques itera-",
"tively refine instructions and demonstrations for",
"each module to improve the entire pipeline’s per-",
"formance, DSP (",
") introduces",
"a three-stage framework for retrieval-augmented",
"inference: Demonstrate (generates task-specific",
"demonstrations), Search (retrieves relevant infor-",
"demonstrations).",
"DSPY (",
"language networks performing variational infer-",
"are task-decomposed prompt templates. MIPRO",
");",
"multiple unknown tasks is underexplored. More",
"robust evaluations are needed for task-agnostic",
"MOP (",
") proposes a Mixture-",
"of-Expert-Prompts performing prompt optimiza-",
"clusters are identified, the RBJS search first sam-",
"ples examples",
"PLUM (",
"Pan et al.",
") library offered a meta-",
"heuristic ensemble of different search algorithms",
"Melamed et al.",
") showed that prompts have",
"so-called ’evil twins’ that are uninterpretable yet",
"prompts.",
"Lu et al.",
") showed that rare gib-",
"berish strings can serve as competitive delimiters",
"in prompts.",
") showed that",
"Most approaches choose to carry out the prompt",
"successive iterations with negative gains breach",
"a patience parameter, whereas PromptAgent con-",
"Although SPRIG explored optimizing system",
"optimizing prompts for several components in an",
"agentic system in a concurrent fashion poses an",
"optimization under a given prompt optimizer and",
"Bhargava et al.",
") proposed a control theo-",
"retic framework to establish bounds on the set of",
"of the singular values of its weight matrices.",
"Liu",
") showed the existence of a strong",
"Recently, textual prompt optimization has ex-",
"CLIP (",
"Du et al.",
"Mirza et al.",
"). Be-",
"prompt optimization remains underexplored. Fu-",
"ture research could develop APO frameworks to",
"In this paper, we provide a comprehensive fine-",
"grained review of existing APO techniques and",
"type",
"is known beforehand; additionally offline",
"something not explicitly available in production",
"it is possible that we may have unintentionally",
"rizations for some papers, or skipping some char-",
"acteristics for others (e.g. Tempera (",
"level editing techniques, applied to both instruc-",
"challenge is that when presenting a survey paper",
"retain content in the main body that was deemed",
"a rigorous comparison of all the surveyed papers",
"into the appendix. We have attempted our best",
"vide copious references to interested researchers",
"= Task type,",
"= Task instruction,",
"Few shot demonstrations in the prompt,",
"=",
"collection of m input-output pairs.",
"is the validation set used to validate",
"embedding function which takes in a sentence generated as a finite sequence of",
"= number of candidates for top-K search,",
"= Beam width for beam search,",
"= number of",
"= target model which will be used for inference,",
"= rewriter model which",
"will be used for rewriter,",
"= evaluator model which provides the LLM feedback to",
"with subscripts to denote different latency types:",
"= Total training cost/latency, including all",
"FedBPT",
") used federated learning to update soft prompts and not discrete tokens.",
"I gave a friend an instruction and [[n_demo]] inputs. The friend read the instruction and wrote an",
"ther during compile-time or inference-time in the",
"Several word-edit approaches first identify \"influ-",
"First, “influential” tokens are identified where ex-",
"voke multiple prompts during inference and com-",
"In each iteration, the playout filters top-B prompt",
"optimizing multimodal inputs, such as images, to",
"distribution induced by candidates, as opposed to",
"like Hill climbing, Simulated Annealing, Genetic",
"input: Q: Alannah, Beatrix, and Queen are preparing for the new school year and have been given",
"didates to generate newer candidates. They range",
"where differences between existing prompts is in-",
"by an LLM powered discriminator, whose goal is",
"promising candidates.",
"Token mutations:",
"SPRIG",
"summarizes feedback for multiple incorrect infer-",
"using predictions from a Masked-Language Mod-",
"tion for each expert individual. Once C exemplar-",
"APO methods also require an evaluation set",
"survey paper, we aim to highlight the advances in",
"main Knowledge”, “Solution Guidance”, “Excep-",
"its (sec.",
"5.1",
") to sophisticated agentic systems that",
"format and constraints, reasoning process, profes-",
"self-reflection by LLMs can suffer from incorrect",
"focuses on optimizing prompts using only human",
"14.2",
") which includes the optimiza-",
"subsequently using a best-of-N strategy to recom-",
"ent algorithm to estimate gradients, allowing user",
"), inference-time optimization of",
"LLM-based mutation:",
"LMEA (",
"),",
"selection, utilizing LLM’s reasoning capability to",
"proaches where the finetuned network is different",
"Multi-objective Optimization",
"techniques (",
"Jafari",
"arm (prompt candidate) operating on a fixed com-",
"prompts in chat-style settings, scalability remains",
"els. However, the interplay between modalities in",
"background noise from audio, add visual markers",
"to strike the right balance between specificity and",
"offline costs for data collection, preprocessing, and model fine-tuning,",
"= per-example inference",
"Deliberate-then-generate",
"2023a",
") randomly sampled arbitrary noisy inference and prompted",
"is wrong if your output is different from the given output, and we say your output is correct if they",
"erated that are most likely to result in an improve-",
"), and finally Crossover and Shuffling to im-",
") solve the important goal of moving beyond",
"error identification, prior biases, semantic invalid-",
"under 8 pages, we had to make tradeoffs and only",
"I have some texts along with their corresponding scores. The texts are arranged in ascending order",
"2020",
"), instruction-following (",
"Ouyang et al.",
"also use LLM feedback on prompt-response pairs",
"that takes query-prompt embedding pairs as input",
"LLM call. All the LLM feedback approaches pro-",
"two categories - improving a single prompt candi-",
"lored operators for cross-over / mutation. Prompt-",
"graphs - introducing parameterized models, learn-",
"a challenge - optimizing system prompts required",
"summarized strategic guidance based on both cor-",
"themselves, Lamarckian Mutation where prompts",
"dundant and use K-means clustering to find word-",
"tion some of the papers that were excluded in this",
"drop, Black-Box Automatic Prompt Optimization",
"answers from the language model and use it to se-",
"perform prompt optimizations to preserve privacy",
"then uses APE to induct and optimize each expert",
"books by their parents. Alannah has 20 more books than Beatrix. Queen has 1/5 times more books",
"showed that a few hundred samples",
"and out-of-cluster demonstrations to cover “blind-",
"setting of contextual bandits (i.e. the action-space",
"linear estimate based on the reward trajectories of",
"existence of “difficult” datasets that depth-limited",
"We formalize the process of automatic prompt op-",
"dictable sensitivity to various factors (explanation",
"demonstrations, SCULPT (",
"Kumar et al.",
"two-step feedback loops - preliminary assessment",
"ferent from continuous gradient-descent, ProTeGi",
") utilizes a well-designed meta-",
"based methods that effectively balance competing",
"suboptimal solutions. ProTeGi, SPRIG,",
"inter alia",
"survey with specific reasons in section",
"12.2",
". Also,",
"= number of experts in a Mixture of Experts approach (MOP),",
"= cluster centroid of cluster C",
"corporating human-designed feedback rules and a",
"efficiently select prompt pairs for preference feed-",
"prompts at the sentence level, leveraging previous",
"Opsahl-Ong et al.",
") automates the optimiza-",
"struction for each exemplar-cluster via instruction",
"reachable LLM-outputs for self-attention in terms",
"we realize that fitting varied research works into a",
"mization framework that used an interleaved strat-",
"most after removing that token versus the original",
"egy to balance performance and security in LLMs",
"under-explored meta-prompt search space. OPRO",
"Kong et al.",
"). OIRL (",
"atic method for tuning long, unstructured prompts",
"A few works also incorporate human feedback, ei-",
"A significant line of work applies the well-studied",
"previously generated solutions (multiple solutions",
"branches. Similarly, UNIPROMPT focused on ex-",
"and 10% for GPT-4. PROMST (",
"Chen et al.",
"erties. It performs add/rephrase/swap/delete, high-",
"also a suboptimality-gap w.r.t. RLHF-optimal pol-",
"research on open questions.",
"M",
"ρ",
"∈",
"V",
"f",
"F",
"eval-set",
"D",
":= arg max",
"E",
"[",
"⊕",
"x",
"))]",
"(1)",
"rithm",
"to obtain approximate solutions.",
"3.1",
"Manual Instructions",
"are sufficient for further optimization.",
"Algorithm 1",
"Prompt optimization framework",
"Instruction Induction via LLMs",
"P",
":=",
"{",
", ρ",
", . . . , ρ",
"}",
"▷",
"§",
".",
"Seed prompts",
", y",
"Validation set",
", . . . , f",
"Inference evaluation",
"for",
"t",
"= 1",
", . . . , N",
"do",
"Iteration depth",
"Generate prompt candidates",
"G",
"P, D",
", F",
"Filter and retain candidates",
"Select",
", D",
"Optionally check for early convergence",
"if",
"≤",
"ϵ",
"then",
"exit",
"UniPrompt (",
"Juneja et al.",
") used LLMs to fill-",
"arg max",
"4.1.3",
"Entropy-based Scores",
"in structured templates.",
"to help generate more prompt candidates.",
"4.1",
"Numeric Score Feedback",
"4.1.1",
"Accuracy",
"π",
"v",
"−",
"y",
"ln",
"))+",
"= ˆ",
"tential prompt candidates.",
"4.1.4",
"Negative Log-likelihood of Output",
") (",
").",
"4.1.2",
"Reward-model Scores",
"log(",
"))",
"sequence is equivalent to the cross-entropy.",
"LLM Feedback",
"LLM",
"(discussed below, examples in Appendix",
"14.3",
"4.2.1",
"Improving Single Candidate",
"rect and incorrect predictions as feedback.",
"4.3",
"Human-feedback",
"prompt candidate.",
"4.2.2",
"Improving Multiple Candidates",
"needing repeated task-specific optimizations.",
"generation and response optimization.",
"and various filtering strategies (sec.",
"Heuristic-based Edits",
"optimization problem computationally tractable.",
"5.1.1",
"Monte Carlo Sampling",
"s",
", s",
", r",
"generated prompts.",
"gation (also explained in Sec.",
"5.1.3",
"Word / Phrase Level Edits",
"5.1.2",
"Genetic Algorithm",
"L",
"y,",
"ˆ",
")]",
"phrase, and swap",
"5.1.4",
"Vocabulary Pruning",
"erence learning.",
"5.2.3",
"Generative Adversarial Networks",
"modifier LLM to rewrite their prompts.",
"5.3",
"Metaprompt Design",
"for unlikely tokens and improve interpetability.",
"5.2",
"Editing via Auxiliary Trained NN",
"Some approaches leverage a trained auxiliary neu-",
"and smaller than the task network.",
"5.2.1",
"Reinforcement-learning",
"tuning experience to expand prompt candidates.",
"5.4",
"Coverage-based",
"semble during inference.",
"5.4.1",
"Single Prompt-expansion",
"devices to fine-tune tasks with limited API calls.",
"5.2.2",
"Finetuning LLMs",
"3 modules - 1/ Pattern Recognition, 2/ Branch Ad-",
"refinement using examples.",
"5.4.2",
"Mixture of Experts",
"then converted back to a prompt.",
"tered for further optimization.",
"6.1",
"TopK Greedy Search",
"clusters all demonstrations using K-means cluster-",
"µ",
"instance-embedding",
"arg min",
"||",
"ϕ",
"5.4.3",
"Ensemble Methods",
"edits",
"r",
"6.2",
"Upper Confidence Bound and Variants",
"+",
"Σ",
"β",
"ate output through majority voting.",
"5.5",
"Program Synthesis",
"ding",
"to select the next best-arm.",
"Region-based Joint Search",
"APO systems combining seen and unseen tasks.",
"9.2",
"Unclear Mechanisms",
"∪",
"\\",
"instruction.",
"6.4",
"Metaheuristic Ensemble",
"Algorithms, Tabu Search, and Harmony Search.",
"7.1",
"Fixed Steps",
"τ",
"anisms of prompt optimization.",
"optimization for a fixed number of steps N.",
"9.3",
"APO for System Prompts / Agents",
"7.2",
"Variable number of steps",
"cluded APO when",
"∨",
"≥",
"8.1",
"Upper Bound of Improvement from APO",
"˜",
"exciting direction for future research.",
"9.4",
"Multimodal APO",
"icy",
", while a lower bound is left unexplored.",
"8.2",
"Other Related Perspectives",
"transformers could not commit to memory.",
"to videos, etc.) to fully leverage their synergies.",
"9.1",
"Task-agnostic APO",
"to spur future research spawning from our survey.",
"T",
"for further reading.",
"12.1",
"Notation",
"We now define the notation of key terms and expressions used throughout the paper.",
"1.",
"I",
"= (",
"xi, yi",
"Template delimiters, z = CoT recipe for a task-instance,",
"z",
"2.",
"target model,",
"APO system",
"3.",
"concat",
"([",
", . . . , s",
"]) =",
"I, τ, E",
"of Instruction, template delimiters and few-shot demonstrations.",
"4.",
"prompt performance,",
"is the training set used to finetune the language model(Reprompting).",
"5.",
", f",
", . . .",
"} ∈",
"metric function upon which to evaluate task-prompt performance",
"6.",
":",
"S",
"×",
"A",
"→",
"R",
"= reward model score, where S is the state-space and A is the action-space",
"7.",
"|",
"= length of vocabulary",
"8.",
"d",
"9.",
"argmax",
"set",
"10.",
"k",
"B",
"N",
"iterations for search",
"11.",
"C",
"(MOP).",
"12.",
"prompts / responses or both",
"13.",
"λ",
"latency,",
"= MLM inference latency per-example",
"Excluded works",
") required gradient access to the task LLM and therefore doesn’t remain blackbox.",
"12.3",
"UCB based selection algorithm",
"Algorithm 2",
"·",
"with UCB Bandits",
"Require:",
"n",
"prompts",
", ..., ρ",
", dataset",
"time steps, metric function",
"m",
"Initialize:",
"←",
"0",
"for all",
"i",
", . . . , n",
"Q",
", . . . , T",
"Sample uniformly",
"⊂D",
"o",
"c",
"q",
"Observe reward",
") +",
"|D",
"return",
"SelectTop",
"/N",
"13.1",
"Comparison",
"the following aspects",
"Seed instructions",
"Candidate generation",
"Search+filter strategy",
"Optimization time complexity",
"Prompt generation model",
"Target models",
"13.2",
"Evaluation tasks and datasets",
"Below we describe the different datasets and tasks that each method was evaluated on.",
"Instruction Induction",
"Below is the original instruction induction prompt used by",
"{{# system",
"∼",
"}}",
"You are a helpful assistant",
"{{",
"/",
"system }}",
"{{# user",
"output for every one of the inputs. Here are the input - output pairs:",
"{{ demos }}",
"What was the instruction ? It has to be less than {{ max_tokens }} tokens .",
"user }}",
"{{# assistant",
"The instruction was {{gen ’instruction ’ [[ GENERATION_CONFIG ]]}}",
"assistant }}",
"Metaprompt design example",
"Below is the metaprompt used in OPRO (",
"based on their scores, where higher scores indicate better quality. text:",
"Let’s figure it out!",
"score: 61",
"text: Let’s solve the problem.",
"score: 63",
"(. . . more instructions and scores . . . )",
"The following exemplars show how to apply your text:",
"are the same.",
"than Alannah. If Beatrix has 30 books, how many books do the three have together?",
"A: output: 140",
"(. . . more exemplars . . . )",
"text in square brackets",
"LLM Feedback prompts",
"and predicts whether the prompt will elicit correct",
") applies an",
"actor-critic",
"Selection, Expansion, Simulation, and Backpropa-",
"invoked whose cluster centroid",
"is closest to the",
"recover some of the performance of gold-standard",
"lect appropriate prompts for specific queries using",
"date versus improving multiple prompt candidates",
") similarly used an error collection ap-",
") consists of both RL-based and word/phrase-",
"the task LLM to deliberate on the wrong inference, while",
"Reflexion",
"Shinn et al.",
") agents maintain",
"tion, creative writing) employ flexible metrics like",
"centroids. BDPL (",
") used pairwise",
"jointly optimize multimodal prompts (eg - remove",
"While we attempted to cover all qualifying papers,",
"missed out on some relevant papers. We also men-",
"an episodic buffer of past deliberations. Neither method optimizes the input prompt.",
"AutoPrompt",
"Shin",
"(APO) techniques have emerged that improve task",
"follows an LLM-based reward modeling approach",
") and TextGrad (",
"Yuk-",
"The common recipe for several genetic algorithms",
"system prompts alongside task-prompts (via meth-",
"you replace in each input with your text, then read the input and give an output. We say your output",
"hope our framework will be informational for new",
"performance via automated prompt improvements.",
"tion and MCQ-based QA tasks use exact accuracy,",
"task prompts, Hypermutation of mutation prompts",
") argued that LLMs exhibit lexical sensitivity,",
"a predefined corpus and close to 60 hours whereas",
"This objective function is not tractable for discrete",
") and GPO (",
") use",
"lem space - either within a single prompt, or using",
"larly considers chained LLM calls as stacked deep",
"settings. Barring a few tasks covered by",
"Joko et al.",
"a core contribution (Tables",
") which contained",
"general-purpose LLMs as opposed to task-specific",
"back updates the hierarchical prompt tree which is",
"tive improvement, few shot example synthesis and",
"tive and interpretable method to optimize prompts,",
"beam-search which judges partial solutions’ based",
"elicit better responses from large multimodal mod-",
"Write your new text that is different from the old ones and has a score as high as possible. Write the",
"not require parameter access on LLMs performing",
"quires the log-probabilities to be accessible during",
"learned heuristic model. APOHF (",
"Lin et al.",
"ods like ProTeGi) to enhance accuracy across mul-",
"to identify generated pairs from ground truth pairs.",
"multiple prompts working individually or in an en-",
"tions and exemplars). In such cases, we categorize",
"prompt input. It can directly aid the prompt rewrit-",
"corporated to form new prompt candidates to over-",
"transforms LLM pipelines into text transformation",
"a paper based on its most salient features. Another",
"most necessary. This resulted in having to relegate",
"Some approaches like APE, GPS (",
"using both predefined and dynamic reward criteria.",
"proach to emulate expert-written prompts that con-",
"back, proving effective for tasks like text-to-image",
"ple textual gradients to use to generate prospective",
"ential\" tokens in the prompts. COPLE (",
"Zhan et al.",
"specific info, e.g. task type and description, output",
"gies, introduced through",
"prompt rewriting",
"Kong",
"crete prompts using variance-reduced policy gradi-",
"senting prompts as directed-acyclic-graphs (DAG).",
"Hsieh et al.",
") used a modification called Lin-",
"brevity to present a novel framework. We also pro-",
"used Back-translation, Sentence Continuation, and",
"300 components grouped into categories like COT,",
"as SFT, preference optimization, and iterative pref-",
"Long et al.",
") framed the prompt optimization",
"iterations (e.g. - ProTeGi, AELP. This differs from",
"called UCB for Trees (UCT) which are used in the",
"mation), and Predict (combines retrieved info with",
"spots”. During inference, a single expert prompt is",
"yond textual prompts,",
"Huang et al.",
") explore",
"ated instructions that offer interpretable and strong",
"by",
"mutation-search to find the optimal DAG, which is",
"ing process while being flexible to individual tasks",
"previously sampled edits as well as prompt embed-",
"generation network, to reduce the probability mass",
"timizes pipelines. DLN (",
"Sordoni et al.",
") simi-",
"identified key areas for future growth. It is our aim",
"taining quality examples can be costly, APE (",
"Zhou",
"justment, and 3/ Branch Pruning to decide whether",
"which are applied to unlabeled target data to gener-",
"the task, (2) they systematically search through the",
"and the reward function is state-dependent). AELP",
"text-to-video (",
"Ji et al.",
"), text-to-audio (",
"Huang",
"Prompt composed of m sentences, which comprise",
"static prompt generation. Prompt-OIRL (",
"panded to multimodal domains: text-to-image (",
"spaces are combinatorial. Instead, APO techniques",
"to prioritize output diversity in po-",
"log-likelihood (NLL) of token sequences under the",
"Cloze transformations to perform prompt mutation.",
"), and text-image alignment models like",
"therein (see Fig.",
", Tables",
"in Appendix). We",
"baselines as the basis for further improvement,",
"inter",
"alia.",
", ProteGi (",
"), GPS (",
"model variants. However, LLMs still exhibit unpre-",
"), stylistic formatting (",
"Sclar et al.",
"), etc.) caus-",
"ments for adoption by end users. Against this back-",
"The possess various attractive features - (1) they do",
"APE to induce cluster-specific prompts. Apart from",
"prompt candidates in each iteration. Some methods",
"words are then used as candidate tokens from which",
"the task-weighted accuracy",
"racy. Text generation tasks (summarization, transla-",
"based measures such as BERTScore (",
"Zhang* et al.",
"and using that it optimizes the specific task prompt.",
"numeric scores is to use textual feedback generated",
"sisted of clear sections like “Task description”, “Do-",
"vival of the Safest (SOS) (",
") added",
"well-functioning prompts, StraGo (",
"SCULPT (",
") introduces a system-",
"then back-synthesized into a new prompt candidate.",
"cess itself, allowing for more dynamic and adaptive",
"prompt to highlight flaws in the generated response",
"sion, and content alignment. Thereafter it leverages",
"ences via",
"hints",
"to instill improvements into a single",
"questions and infer human preferences conditioned",
"on the history of free-form interaction.",
"Cheng et al.",
"prompts based on user preference feedback, achiev-",
"sekgonul et al.",
") leverage",
"textual “gradients”",
"In this step, one or more candidate prompts are gen-",
"ment in a metric of interest",
". The approaches",
"expert persona to ensure consistency of the style of",
"sampling to explore combinatorial discrete solution",
"spaces in an incremental fashion - it samples multi-",
"candidates, and spawns paraphrases as monte-carlo",
") uses a tree-variant called Monte Carlo",
"tiple diverse domains, languages, and tasks without",
"their synonyms can yield significant improvements.",
"long prompts that are already optimized using other",
"leveraging 4 basic edit operations -add, delete, para-",
"duce output. The (input, output) pairs are evaluated",
"Both generator and the discriminator are jointly op-",
"timized using adversarial loss, by utilizing a prompt",
"clusters and retain top-2000 words closest to cluster",
"mutual information (PMI) to retain top co-occuring",
") proposes a meta-prompt design",
"quality and structured initial prompts (contain task-",
"evaluation-set",
"and then enlists each of them in",
"the meta-instruction in an if-then-else format using",
"BPO (",
") trains a smaller 7B model",
"task get represented in the final prompt. It designs a",
"human-like (manual) prompt engineering approach",
"improving instructions and demonstrations for each",
"A set of user-defined node mutation rules guide the",
"Expert-Prompts where each expert is a task-prompt",
"tion, the top-K best-performing candidates on mini-",
"batch of data instances",
"are retained for further",
"lead to biases in the selection procedure and finally",
"cast the candidate prompt selection problem as that",
"Bounds (UCB, Algorithm",
") which balances explo-",
"ration with exploitation. In each iteration of prompt",
"estimate of the optimality of each arm (i.e. prompt).",
"ear UCB (",
"2010",
") which uses a closed form",
"ing through demonstrations, and a compiler that op-",
"ence, where the learnable parameters for each layer",
"ity, leading to failure in yielding improved prompts.",
"More studies are needed to better uncover the mech-",
") concludes search when",
"Protegi only needed",
"10 minutes per task. Similarly,",
"AlignPro (",
"Trivedi et al.",
") establishes an upper",
"bound on the gains realizable from discrete prompt",
"transformer that can approximate any sequence-to-",
"sequence Lipschitz function. They also showed the",
"Mañas et al.",
"All the surveyed APO methods assume that the task",
"single unifying framework might risk broad catego-",
"tokens belonging to a vocabulary V, and generating a floating point array representation of dimension",
"The best performing prompt based on the metric score on validation",
"Below we offer a comprehensive comparison of all the surveyed methods against our framework, covering",
"Since the advent of large language models",
"(LLMs), prompt engineering has been a cru-",
"However, prompt engineering remains an im-",
"pediment for end users due to rapid advances",
"tasks. In this paper, we present a comprehen-",
"sive survey summarizing the current progress",
"vide a formal definition of APO, a 5-part uni-",
"fying framework, and then proceed to rigor-",
"ously categorize all relevant works based on",
"Andy McGovern, Aleksandr Nisnevich, Adam Pauls,",
"Dmitrij Petters, Brent Read, Dan Roth, Subhro Roy,",
"Jesse Rusak, Beth Ann Short, Div Slomin, B Snyder,",
"son, A. A. Vorobev, Izabela Witoszko, Jason Wolfe,",
"Trapit Bansal, Rishikesh Jha, and Andrew McCallum.",
"language classification tasks",
". In",
"International Confer-",
"and Matt Thomson. 2024.",
"What’s the magic word? a",
"Gao, and Yejin Choi. 2019.",
"Piqa: Reasoning about",
"physical commonsense in natural language",
"AAAI",
"Samuel R Bowman, Gabor Angeli, Christopher Potts,",
"and Christopher D Manning. 2015. A large annotated",
"corpus for learning natural language inference.",
"arXiv",
"Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav",
"Magazine, Tanuja Ganu, and Akshay Nambi. 2024.",
"Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind",
"Neelakantan, Pranav Shyam, Girish Sastry, Amanda",
"pher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,",
"Scott Gray, Benjamin Chess, Jack Clark, Christopher",
"and Dario Amodei. 2020.",
"Language models are few-",
"2020. Asset: A dataset for tuning and evaluation of",
"transformations. In",
"Proceedings of the 58th Annual",
"Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang",
"Empirical Methods in Natural Language Processing",
", pages 9954–9972, Bangkok, Thailand. Associa-",
"task 1: Semantic textual similarity multilingual and",
"pre, Stephen G. Pulman, and Srinivas Chappidi. 2020.",
"via question rewriting",
"North American Chapter of",
"Mauro Cettolo, Marcello Federico, Luisa Bentivogli,",
"Niehues Jan, Stüker Sebastian, Sudoh Katsuitho,",
"Yoshino Koichiro, and Federmann Christian. 2017.",
"Jacob Andreas,",
"Johannes Bufe,",
"David Burkett,",
"Charles C. Chen, Joshua Clausman, Jean Crawford,",
"Kate Crim, Jordan DeLoach, Leah Dorner, Jason Eis-",
"ner, Hao Fang, Alan Guo, David Leo Wright Hall,",
"Kristin Delia Hayes, Kellie Hill, Diana Ho, Wendy",
"Nicholas Roy, and Chuchu Fan. 2024.",
"PRompt opti-",
"mization in multi-step tasks (PROMST): Integrating",
"Ido Dagan, Oren Glickman, and Bernardo Magnini.",
"2005.",
"The pascal recognising textual entailment chal-",
"ceedings of the 2024 Conference on Empirical Meth-",
"Miami, Florida, USA. Association for Computational",
"dith Tonhauser. 2019.",
"The commitmentbank: Investi-",
"Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongn-",
"ing Wang, Yuxiao Dong, Jie Tang, and Minlie Huang.",
"language models without model training",
"Proceed-",
"Computational Linguistics (Volume 1: Long Papers)",
"Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,",
"Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan",
"Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al.",
"Robert C. Detrano, András Jánosi, Walter Steinbrunn,",
"1989.",
"International application of a new probability",
"algorithm for the diagnosis of coronary artery disease.",
"Shizhe Diao, Zhichao Huang, Ruijia Xu, Xuechun Li,",
"Yong Lin, Xiao Zhou, and Tong Zhang. 2022. Black-",
"box prompt learning for pre-trained language models.",
"Rezarta Islamaj Do˘gan, Robert Leaman, and Zhiyong",
"Lu. 2014. Ncbi disease corpus: a resource for disease",
"Yunseon Choi, Sangmin Bae, Seonghyun Ban, Min-",
"Bian, and Kee-Eung Kim. 2024.",
"Hard prompts made",
"ically constructing a corpus of sentential paraphrases",
"Christopher Cieri, Mark Liberman, Sunghye Cho,",
"Stephanie Strassel, James Fiumara, and Jonathan",
"Wright. 2022.",
"Reflections on 30 years of language re-",
"Thirteenth Language Resources and Evaluation Con-",
"ference",
", pages 543–550, Marseille, France. European",
"Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu,",
"guage Processing",
", pages 1107–1128, Miami, Florida,",
"Ashish Sabharwal, Carissa Schoenick, and Oyvind",
"Tafjord. 2018.",
"Think you have solved question an-",
"swering? try arc, the ai2 reasoning challenge",
"ArXiv",
"Ge Li. 2024b.",
"PACE: Improving prompt with actor-",
"the Association for Computational Linguistics: ACL",
", pages 7304–7323, Bangkok, Thailand. Associa-",
"Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,",
"2021. Training verifiers to solve math word problems.",
"Yingjun Du, Wenfang Sun, and Cees GM Snoek.",
"ing the world’s first truly open instruction-tuned llm.",
"Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel",
"Stanovsky, Sameer Singh, and Matt Gardner. 2019.",
"Han He, Qianchu Liu, Lei Xu, Chaitanya Shivade,",
"Yi Zhang, Sundararajan Srinivasan, and Katrin Kirch-",
"hoff. 2025.",
"Crispo: Multi-aspect critique-suggestion-",
"Mihaela G˘aman, Mihai Daniel Ilie, Andrei Pruteanu,",
"Sebastian Ruder. 2021.",
"Liro: Benchmark and leader-",
"board for romanian language tasks",
"In",
"NeurIPS",
"Ibrahim Abu Farha and Walid Magdy. 2020a.",
"From",
"arabic sentiment analysis to sarcasm detection: The",
"Dan Hendrycks, Collin Burns, Steven Basart, Andy",
"Zou, Mantas Mazeika, Dawn Xiaodong Song, and Ja-",
"cob Steinhardt. 2020.",
"Measuring massive multitask",
"Ibrahim Abu Farha and Walid Magdy. 2020b.",
"Steinhardt. Measuring mathematical problem solving",
"with the math dataset. In",
"Thirty-fifth Conference on",
"Neural Information Processing Systems Datasets and",
"Chrisantha",
"Fernando,",
"Dylan",
"Banarse,",
"Henryk",
"Michalewski,",
"Simon Osindero,",
"and Tim Rock-",
"täschel. 2023.",
"Promptbreeder:",
"Self-referential",
"self-improvement via prompt evolution",
"Or Honovich, Uri Shaham, Samuel R. Bowman, and",
"Omer Levy. 2022.",
"Instruction induction: From few",
"Rory A. Fisher. 1936.",
"The use of multiple measure-",
"Omer Levy. 2023.",
"pages 1935–1952, Toronto, Canada. Association for",
"Tripp, José Miguel Hernández-Lobato, Andreas Ben-",
"der, and Sergio Bacallado. 2021.",
"Dockstring: Easy",
"Etzioni, and Nate Kushman. 2014.",
"Learning to solve",
"and Laura Perez-Beltrachini. 2017.",
"Creating training",
"corpora for nlg micro-planners",
"Annual Meeting of",
"reasoning strategies",
"Transactions of the Association",
"Cho-Jui Hsieh, Si Si, Felix Yu, and Inderjit Dhillon.",
"ACL 2024",
", page 10672—10685, Bangkok, Thailand.",
"Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and",
"Aleksander Wawer. 2019. Samsum corpus: A human-",
"annotated dialogue dataset for abstractive summariza-",
"Minqing Hu and Bing Liu. 2004.",
"Mining and sum-",
"marizing customer reviews",
"Proceedings of the tenth",
"1: Noetic end-to-end response selection",
"Proceedings",
"Yejin Choi. 2019. Cosmos qa: Machine reading com-",
"prehension with contextual commonsense reasoning.",
"Proceedings of the 2019 Conference on Empirical",
"Methods in Natural Language Processing and the 9th",
"International Joint Conference on Natural Language",
"2024.",
"Connecting large language models with evolu-",
"The Twelfth International Conference on Learning",
"Yin, and Zhou Zhao. 2023. Make-an-audio: Text-to-",
"Omar Khattab, Arnav Singhvi, Paridhi Maheshwari,",
"Moazam, Heather Miller, Matei Zaharia, and Christo-",
"Berg-Kirkpatrick. 2024.",
"Morl-prompt: An empirical",
"analysis of multi-objective reinforcement learning for",
"Johannes Kiesel, Maria Mestre, Rishabh Shukla, Em-",
"manuel Vincent, Payam Adineh, D. Corney, Benno",
"Hyperpartisan news detection",
"International Work-",
"Yatai Ji, Jiacheng Zhang, Jie Wu, Shilong Zhang,",
"Prompt your video diffusion model via preference-",
"taka Matsuo, and Yusuke Iwasawa. 2023.",
"Large lan-",
"Yichen Jiang, Shikha Bordia, Zheng Zhong, Charles",
"Dognin, Maneesh Kumar Singh, and Mohit Bansal.",
"2020.",
"Hover: A dataset for many-hop fact extraction",
"Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish",
"actions of the Association for Computational Linguis-",
"Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang,",
"Wujiang Xu, Ligong Han, Jiahui Zhao, Kai Zhong,",
"Sanguthevar Rajasekaran, and Dimitris N. Metaxas.",
"Weize Kong, Spurthi Amba Hombaiah, Mingyang",
"Zhang, Qiaozhu Mei, and Michael Bendersky. 2024.",
"Khandelwal, Bishal Santra, Parag Agrawal, and Man-",
"ish Gupta. 2024.",
"Sculpt: Systematic tuning of long",
"Hanyi Fang, and Peter Szolovits. 2020.",
"What disease",
"tion answering dataset from medical exams",
"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-",
"field, Michael Collins, Ankur Parikh, Chris Alberti,",
"ton Lee, et al. 2019. Natural questions: a benchmark",
"for question answering research.",
"Transactions of the",
"Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William",
"Cohen, and Xinghua Lu. 2019. Pubmedqa: A dataset",
"for biomedical research question answering. In",
"Pro-",
"in Natural Language Processing and the 9th Interna-",
"Eduard Hovy. 2017. Race: Large-scale reading com-",
"prehension dataset from examinations.",
"arXiv preprint",
"2019.",
"Latent retrieval for weakly supervised open do-",
"Hideaki Joko, Shubham Chatterjee, Andrew Ramsay,",
"Arjen P De Vries, Jeff Dalton, and Faegheh Hasibi.",
"2024. Doing personal laps: Llm-augmented dialogue",
"construction for personalized multi-session conversa-",
"and Amit Sharma. 2024. Task facet learning: A struc-",
"ical Methods in Natural Language Processing",
", pages",
"McFarland, and Dan Jurafsky. 2018.",
"Measuring the",
"evolution of a scientific field through citation frames",
"Omar Khattab, Keshav Santhanam, Xiang Lisa Li,",
"Zaharia. 2022.",
"Demonstrate-search-predict:",
"Com-",
"posing retrieval and language models for knowledge-",
"Hany Hassan, Arul Menezes, Tong Xiao, Jiang Bian,",
"and Chaowei Xiao. 2024c.",
"Automatic and universal",
"Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu,",
"Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang,",
"and Xing Xie. 2023b. Large language models under-",
"et al. 2024d. What do you want? user-centric prompt",
"generation for text-to-image synthesis via multi-turn",
"Lihong Li, Wei Chu, John Langford, and Robert E.",
"Schapire. 2010.",
"A contextual-bandit approach to per-",
"of the 19th International Conference on World Wide",
"James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi,",
"Michael Shieh, and Junxian He. 2024.",
"Prompt opti-",
"mization via adversarial in-context learning",
"Moxin Li, Wenjie Wang, Fuli Feng, Yixin Cao, Jizhi",
"shifts",
"Proceedings of the 2023 Conference on Em-",
"Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle",
"Pineau. 2015.",
"The ubuntu dialogue corpus: A large",
"Jianfeng Gao, and Xifeng Yan. 2023d. Guiding large",
"language models via directional stimulus prompting.",
"ular fine-tuning schema",
"Proceedings of the 31st",
"Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.",
"hoods. In",
"Proceedings of the 60th Annual Meeting of",
"and Pontus Stenetorp. 2021.",
"Fantastically ordered",
"Tsung-Yi Lin, Michael Maire, Serge Belongie, James",
"C Lawrence Zitnick. 2014. Microsoft coco: Common",
"objects in context. In",
"Computer Vision–ECCV 2014:",
"Xiaoqiang Lin, Zhongxiang Dai, Arun Verma, See-",
"Yao Lu, Jiayi Wang, Raphael Tang, Sebastian Riedel,",
"(Volume 1: Long Papers)",
", page 2221—2231, Mexico",
"City, Mexico. Association for Computational Linguis-",
"Yi Luan, Luheng He, Mari Ostendorf, and Hannaneh",
"Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paran-",
"jape, Michele Bevilacqua, Fabio Petroni, and Percy",
"els use long contexts.",
"Andrew Maas, Raymond E Daly, Peter T Pham, Dan",
"Huang, Andrew Y Ng, and Christopher Potts. 2011.",
"Learning word vectors for sentiment analysis. In",
"for computational linguistics: Human language tech-",
"Shengcai Liu, Caishun Chen, Xinghua Qu, Ke Tang,",
"and Yew Soon Ong. 2023.",
"Large language models as",
"Shihong Liu, Samuel Yu, Zhiqiu Lin, Deepak Pathak,",
"Oscar Mañas, Pietro Astolfi, Melissa Hall, Can-",
"dace Ross, Jack Urbanek, Adina Williams, Aish-",
"Drozdzal. 2024. Improving text-to-image consistency",
"via automatic prompt optimization.",
"and Richard Socher. 2018. The natural language de-",
"cathlon: Multitask learning as question answering.",
"Christiano, Jan Leike, and Ryan Lowe. 2022.",
"Train-",
"Rimon Melamed, Lucas H. McCabe, Tanay Wakhare,",
"Yejin Kim, H. Howie Huang, and Enric Boix-Adsera.",
"Sankarasubbu. 2022. Medmcqa: A large-scale multi-",
"subject multi-choice dataset for medical domain ques-",
"M Jehanzeb Mirza, Mengjie Zhao, Zhuoyuan Mao,",
"wald, Shiqi Yang, Saurav Jha, Hiromi Wakaki, et al.",
"Rui Pan, Shuo Xing, Shizhe Diao, Wenhe Sun, Xiang",
"Linguistics: ACL 2024",
", page 2177—2197, Bangkok,",
"Swaroop Mishra, Daniel Khashabi, Chitta Baral, and",
"Hannaneh Hajishirzi. 2021.",
"Cross-task generalization",
"via natural language crowdsourcing instructions",
"Annual Meeting of the Association for Computational",
"Sentiment analysis using subjectivity summarization",
"Ioannis Mollas, Zoe Chrysopoulou, Stamatis Karlos,",
"and Grigorios Tsoumakas. 2020.",
"Ethos:",
"an on-",
"line hate speech detection dataset.",
"Bo Pang and Lillian Lee. 2005.",
"Seeing stars: Exploit-",
"Arkil Patel, S. Bhattamishra, and Navin Goyal. 2021.",
"Are nlp models really able to solve simple math word",
"Ramesh Nallapati, Bowen Zhou, Cícero Nogueira",
"dos Santos, Çaglar Gülçehre, and Bing Xiang. 2016.",
"Abstractive text summarization using sequence-to-",
"sequence rnns and beyond",
"Conference on Com-",
"Shashi Narayan, Shay B. Cohen, and Mirella Lapata.",
"2018.",
"Don’t give me the details, just the summary!",
"ings of the 2019 Conference of the North American",
"tics: Human Language Technologies, Volume 1 (Long",
"estimation from bird’s-eye view point cloud. In",
"2019",
"Silviu Pitis, Michael R Zhang, Andrew Wang, and",
"Edoardo Maria Ponti, Goran Glavaš, Olga Majewska,",
"Qianchu Liu, Ivan Vuli´c, and Anna Korhonen. 2020.",
"Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit",
"Reid Pryzant, Dan Iter, Jerry Li, Yin Lee, Chenguang",
"Broman, Christopher Potts, Matei Zaharia, and Omar",
"Khattab. 2024.",
"Optimizing instructions and demon-",
"Padmanabhan, and Graham Neubig. 2018.",
"When and",
"roll L. Wainwright, Pamela Mishkin, Chong Zhang,",
"Sandhini Agarwal, Katarina Slama, Alex Ray, John",
"Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,",
"Percy Liang. 2016.",
"Squad: 100,000+ questions for",
"Noah Shinn, Federico Cassano, Ashwin Gopinath,",
"Language agents with verbal reinforcement learning.",
"Advances in Neural Information Processing Systems",
"Michael, and Samuel R. Bowman. 2023.",
"Gpqa: A",
"graduate-level google-proof q&a benchmark",
"Mohit",
"Shridhar,",
"Xingdi",
"Yuan,",
"Marc-Alexandre",
"Côté, Yonatan Bisk, Adam Trischler, and Matthew",
"Hausknecht. 2020. Alfworld: Aligning text and em-",
"bodied environments for interactive learning.",
"Melissa Roemmele, Cosmin Adrian Bejan, and An-",
"An evaluation of commonsense causal reasoning. In",
"Ankita Sinha, Wendi Cui, Kamalika Das, and Jiaxin",
"Zhang. 2024.",
"Survival of the safest: Towards secure",
"evolution",
"Proceedings of the 2024 Conference on",
"Empirical Methods in Natural Language Processing:",
"Maarten Sap, Hannah Rashkin, Derek Chen, Ronan",
"Le Bras, and Yejin Choi. 2019. Social iqa: Common-",
"sense reasoning about social interactions. In",
"ings of the 2019 Conference on Empirical Methods",
"Richard Socher, Alex Perelygin, Jean Wu, Jason",
"Chuang, Christopher D Manning, Andrew Y Ng, and",
"Gizem Sogancioglu, Hakime Öztürk, and Arzucan",
"Özgür. 2017.",
"Biosses: a semantic sentence similarity",
"Christoph Schuhmann, Romain Beaumont, Richard",
"Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti,",
"Matheus Pereira, Adam Trischler, Ziang Xiao, Arian",
"Hosseini, Friederike Niedtner, and Nicolas Le Roux.",
"2023.",
"Joint prompt optimization of stacked llms us-",
"mation Processing Systems",
", volume 36, pages 58128–",
"Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane",
"rious features in prompt design or: How i learned to",
"Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,",
"Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch,",
"Adam R Brown, Adam Santoro, Aditya Gupta, Adrià",
"Quantifying and extrapolating the capabilities of lan-",
"Yang, and Yongfeng Zhang. 2024.",
"Robustness-aware",
"Hao Sun, Alihan Hüyük, and Mihaela van der Schaar.",
"2024a.",
"Query-dependent prompt evaluation and opti-",
"Hong Sun, Xue Li, Yinchuan Xu, Youkow Homma,",
"Qi Cao, Min Wu, Jian Jiao, and Denis Charles. 2023.",
"Taylor Shin, Yasaman Razeghi, Robert L. Logan IV,",
"Eric Wallace, and Sameer Singh. 2020.",
"AutoPrompt:",
"win Gopinath, Karthik Narasimhan, and Shunyu Yao.",
"Reflexion: Language agents with verbal rein-",
"Jingwei Sun, Ziyue Xu, Hongxu Yin, Dong Yang,",
"Holger R. Roth. 2024b. Fedbpt: efficient federated",
"Proceedings of the 41st International Conference on",
"Chowdhery, Quoc Le, Ed Chi, Denny Zhou, et al.",
"tion for Computational Linguistics: ACL 2023",
"Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh",
"the 61st Annual Meeting of the Association for Com-",
"Yushi Wang, Jonathan Berant, and Percy Liang. 2015.",
"Alon Talmor, Jonathan Herzig, Nicholas Lourie, and",
"Jonathan Berant. 2019.",
"Commonsenseqa: A question",
"Vaneet Aggarwal, Amrit Singh Bedi, and George K.",
"Zhichao Wang, Bin Bi, Shiva Kumar Pentyala, Kiran",
"Zhu, Xiang-Bo Mao, Sitaram Asur, Na, and Cheng.",
"Nirali Vaghani and Mansi Thummar. 2023. Flipkart",
"man. 2018.",
"Neural network acceptability judgments",
"question answering test collection. In",
"Proceedings of",
"the 23rd annual international ACM SIGIR conference",
"Annotating expressions of opinions and emotions in",
"Xingchen Wan, Ruoxi Sun, Hootan Nakhost, and Ser-",
"can O. Arik. 2024.",
"Teach better or show smarter? on",
"instructions and exemplars in automatic prompt opti-",
"Adina Williams, Nikita Nangia, and Samuel R. Bow-",
"man. 2017.",
"A broad-coverage challenge corpus for",
"sentence understanding through inference",
"North",
"Ruochen Wang, Sohyun An, Minhao Cheng, Tianyi",
"prompt is not enough: automated construction of a",
"mixture-of-expert prompts.",
"Proceedings of the",
"41st International Conference on Machine Learning",
"Xiaodi Sun, Sheng Yang, Jian-Guang Lou, Zhiming",
"Ding, and Linjun Yang. 2024.",
"StraGo: Harnessing",
"strategic guidance for prompt optimization",
"Find-",
"EMNLP 2024",
", pages 10043–10061, Miami, Florida,",
"agent smarter than a 5th grader?",
"Jasper Xian, Saron Samuel, Faraz Khoubsirat, Ronak",
"Pradeep, Md Arafat Sultan, Radu Florian, Salim",
"William Yang Wang. 2017.",
"“liar, liar pants on fire”:",
"A new benchmark dataset for fake news detection",
"Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Wang",
"netic prompt search for efficient few-shot learning. In",
"Zhiting Hu. 2024a.",
"Promptagent: Strategic planning",
"mization",
"The Twelfth International Conference on",
"Wei Xu, Alan Ritter, William B. Dolan, Ralph Grish-",
"Hajishirzi. 2022b.",
"Self-instruct: Aligning language",
"models with self-generated instructions",
"Annual",
"jic. 2024. Reprompting: automated chain-of-thought",
"ings of the 41st International Conference on Machine",
"Quoc V. Le, Denny Zhou, and Xinyun Chen. 2024a.",
"Lechen Zhang, Tolga Ergen, Lajanugen Logeswaran,",
"Moontae Lee, and David Jurgens. 2024b.",
"Sprig: Im-",
"proving large language model performance by system",
"Quoc V Le, Denny Zhou, and Xinyun Chen. 2024b.",
"Large language models as optimizers",
"The Twelfth",
"ing text generation with bert",
"ming Gao, Junqi Zhang, Yangyang Li, and Fuli Feng.",
"2024c.",
"Dual-phase accelerated prompt optimization",
"Findings of the Association for Computational Lin-",
"guistics: EMNLP 2024",
", pages 12163–12173, Miami,",
"Sheng Yang, Yurong Wu, Yan Gao, Zineng Zhou,",
"37th International Conference on Neural Information",
"Processing Systems",
", NIPS ’23, Red Hook, NY, USA.",
"pher D. Manning. 2018.",
"Hotpotqa: A dataset for di-",
"verse, explainable multi-hop question answering",
"Han Zhou, Xingchen Wan, Ivan Vuli´c, and Anna Ko-",
"Efficient black-box prompt search via clustering and",
"pruning",
"Findings of the Association for Computa-",
"Qinyuan Ye, Maxamed Axmed, Reid Pryzant, and",
"Fereshte Khani. 2024.",
"Prompt engineering a prompt",
"Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,",
"Mert Yuksekgonul, Federico Bianchi, Joseph Boen,",
"Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali",
"Farhadi, and Yejin Choi. 2019. Hellaswag: Can a ma-",
"57th Annual Meeting of the Association for Computa-",
"Pengwei Zhan, Zhen Xu, Qian Tan, Jie Song, and",
"Combinatorial optimization for prompt enhancement",
"Conference on Empirical Methods in Natural Lan-",
"Chenrui Zhang, Lin Liu, Chuyuan Wang, Xiao",
"Sun, Hongyu Wang, Jinpeng Wang, and Mingchen",
"Cai. 2024a.",
"Prefer: prompt ensemble learning via",
"feedback-reflect-refine",
"Proceedings of the Thirty-",
"Thirty-Sixth Conference on Innovative Applications",
"of Artificial Intelligence and Fourteenth Symposium",
"on Educational Advances in Artificial Intelligence",
"their salient features therein. We hope to spur",
"modelling. In",
"Proceedings of the 2018 Conference on",
"name recognition and concept normalization.",
"Journal",
"tionary algorithms yields powerful prompt optimizers",
"Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-",
"2019. Wic: the word-in-context dataset for evaluating",
"Boxnet: A deep learning method for 2d bounding box",
"that use various automated techniques to help",
"and Zhiting Hu. 2022.",
"Rlprompt: Optimizing discrete",
"Adriana Stan, Luciana Morogan, Traian Rebedea, and",
"Symposium: Logical Formalizations of Commonsense",
"mization with “gradient descent” and beam search",
"critic editing for large language model",
"Findings of",
"ings of the Association for Computational Linguistics:",
"A new benchmark for natural language understanding",
"Wortsman, et al. 2022. Laion-5b: An open large-scale",
"13484–13508, Toronto, Canada. Association for Com-",
"Marie-Catherine de Marneffe, Mandy Simons, and Ju-",
"Black-box prompt optimization: Aligning large",
"Drop: A reading comprehension benchmark requiring",
"guided automatic prompt optimization for text genera-",
"Miguel Garc’ia-Orteg’on, Gregor N. C. Simm, Austin",
"and JingBo Zhu. 2023a.",
"Deliberate then generate: En-",
"Eliciting Knowledge from Language Models with Au-",
"tomatically Generated Prompts",
"Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Hao-",
"Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jo-",
"tion (APO) techniques have recently emerged",
"Theo Lanman, Percy Liang, C. H. Lin, Ilya Lintsbakh,",
"Open-domain question answering goes conversational",
"Minje Choi, Jiaxin Pei, Sagar Kumar, Chang Shu, and",
"Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,",
"Yasaman Jafari, Dheeraj Mekala, Rose Yu, and Taylor",
"Web",
", WWW ’10, page 661–670, New York, NY, USA.",
"prompt optimization with preference dataset and mod-",
"prompt order sensitivity",
"Annual Meeting of the As-",
"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan",
"strations for multi-stage language model programs",
"Noah Shinn, Federico Cassano, Edward Berman, Ash-",
"Yanggang, Haiyu Li, and Zhilin Yang. 2022. Gps: Ge-",
"To mitigate this, Automatic Prompt Optimiza-",
"Claire Gardent, Anastasia Shimorina, Shashi Narayan,",
"The power of scale for parameter-efficient prompt tun-",
"ing",
"Proceedings of the 2021 Conference on Empir-",
"optimizers for vision language models.",
"Jimmy Ba. 2023. Boosted prompt ensembles for large",
"els with self-generated instructions",
"Zhou, Sung Ju Hwang, and Cho-Jui Hsieh. 2025. One",
"Eighth AAAI Conference on Artificial Intelligence and",
"William B. Dolan and Chris Brockett. 2005.",
"Automat-",
"Maddie Simens, Amanda Askell, Peter Welinder, Paul",
"tics",
"Findings of the Association for Computational",
"mantic compositionality over a sentiment treebank. In",
"and Milica Gasic. 2018. Multiwoz-a large-scale multi-",
"Franck Dernoncourt and Ji Young Lee. 2017.",
"Pubmed",
"Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul",
"examples to natural language task descriptions",
"Jingzhou Du, Duan Li, Jian Gao, Li Zhang, Hao Yang,",
"problems?",
"North American Chapter of the Associa-",
"mization with offline inverse RL",
"The Twelfth Inter-",
"of-thought can solve them. In",
"Findings of the Associa-",
"improve the performance of LLMs on various",
"Matthias Emil Pfisterer, Johann-Jakob Schmid, Sarbjit",
"Zaharia, and Reynold Xin. 2023. Free dolly: Introduc-",
"arithmetic word problems with verb categorization",
"Zekun Li, Baolin Peng, Pengcheng He, Michel Galley,",
"Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and",
"dataset for training next generation image-text models.",
"ing variational inference",
"Advances in Neural Infor-",
"in-context learning",
"Annual Meeting of the Associa-",
"Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Fan",
"Daguang Xu, Yudong Liu, Zhixu Du, Yiran Chen, and",
"prompt inference through gibbs sampling. In",
"Florida, USA. Association for Computational Linguis-",
"Aman Bhargava, Cameron Witkowski, Shi-Zhuo Looi,",
"evolutionary optimizers",
"2024 IEEE Congress on Evo-",
"warya Agrawal, Adriana Romero-Soriano, and Michal",
"on Research and development in information retrieval",
"des, Carolina Scarton, Benoît Sagot, and Lucia Specia.",
"Meeting of the Association for Computational Linguis-",
"Chapter of the Association for Computational Linguis-",
"tional Joint Conference on Natural Language Process-",
"Hector J. Levesque, Ernest Davis, and L. Morgenstern.",
"David Hall, Percy Liang, Christopher Potts, and Matei",
"Junru Lu, Siyu An, Min Zhang, Yulan He, Di Yin, and",
"Liang. 2024a. Lost in the middle: How language mod-",
"2017.",
"The e2e dataset: New challenges for end-to-end",
"Industry Track",
", pages 1016–1027, Miami, Florida, US.",
"Alessandro Sordoni, Eric Yuan, Marc-Alexandre Côté,",
"2023. Challenging big-bench tasks and whether chain-",
"Building a semantic parser overnight",
"Annual Meet-",
"Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q.",
"2022.",
"Large language models are human-level prompt",
"Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie",
"4 with 90%* chatgpt quality.",
"See https://vicuna. lmsys.",
"tured approach to prompt optimization.",
"Xing Sun. 2025.",
"FIPO: Free-form instruction-oriented",
"ceedings of the 49th annual meeting of the association",
"Task-oriented dialogue as dataflow synthesis",
"Transac-",
"tions of the Association for Computational Linguistics",
"Afra Amini, Tim Vieira, and Ryan Cotterell. 2024.",
"Di-",
"A survey on in-context learning",
"tional search. In",
"Proceedings of the 47th International",
"David Jurgens, Srijan Kumar, Raine Hoover, Daniel A.",
"Xiaogeng Liu, Zhiyuan Yu, Yizhe Zhang, Ning Zhang,",
"Xuan Do Long, Yiran Zhao, Hannah Brown, Yuxi Xie,",
"Bansal. 2023.",
"Grips: Gradient-free, edit-based instruc-",
"Suhr. Quantifying language models’ sensitivity to spu-",
"Weinberger, and Yoav Artzi. 2020.",
"Bertscore: Evaluat-",
"human feedback and heuristic-based sampling",
"pages 3201–3219, Bangkok, Thailand. Association for",
"Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,",
"pages 7308–7327, Bangkok, Thailand. Association for",
"1539–1554, Singapore. Association for Computational",
"ings of the IEEE/CVF Conference on Computer Vision",
"2024. Glov: Guided large language models as implicit",
"Ehsan Nezhadarya, Yang Liu, and Bingbing Liu. 2019.",
"son Petty, Richard Yuanzhe Pang, Julien Dirani, Julian",
"and Atticus Geiger. 2023.",
"Scone: Benchmarking nega-",
"tional Linguistics: EMNLP 2023",
", pages 13064–13077,",
"Stephon Striplin, Yu Su, Zachary Tellman, Sam Thom-",
"sentence simplification models with multiple rewriting",
"chan Jeong, Chuheng Zhang, Lei Song, Li Zhao, Jiang",
"Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan,",
"Zhu, and Michael Zeng. 2023.",
"Automatic prompt opti-",
"machine comprehension of text",
"Conference on Em-",
"Tobias Schnabel and Jennifer Neville. 2024.",
"Symbolic",
"putational Linguistics (Volume 1: Long Papers)",
"Automatic multi-branched prompt optimization.",
"Ru Xie. 2024.",
"Unveiling the lexical sensitivity of llms:",
"Fernando Alva-Manchego, Louis Martin, Antoine Bor-",
"Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang,",
"Leyang Cui, Yu Wu, Shujie Liu, Yue Zhang, and Ming",
"som. 2017.",
"Program induction by rationale generation:",
"Ankit Pal, Logesh Kumar Umapathi, and Malaikannan",
"in models, tasks, and associated best practices.",
"Zhou. 2020.",
"Mutual: A dataset for multi-turn dialogue",
"context-sensitive meaning representations. In",
"Alex Warstadt, Amanpreet Singh, and Samuel R. Bow-",
"the 2022 Conference on Empirical Methods in Natural",
"Lopez-Gazpio, and Lucia Specia. 2017.",
"Semeval-2017",
"molecular docking yields better benchmarks for ligand",
"Sabharwal, Oren Etzioni, and Siena Dumas Ang. 2015.",
"Apeer: Automatic prompt engineering enhances",
"ing Ding, Anbang Hu, Yuan Fang, et al. 2024d. Ampo:",
"further research guided by our framework.",
"Figure 1: Taxonomy of Automatic Prompt Optimization",
"Figure 2: Representative APO system",
"Table 1: Comparison of some APO techniques under our framework (Tables",
"show full comparison)",
"8:556–571.",
"ence on Computational Linguistics",
"control theory of llm prompting",
"Conference on Artificial Intelligence",
"preprint arXiv:1508.05326",
"work",
"shot learners",
", pages 4668–4679.",
"pages 5016–5026.",
"tion for Computational Linguistics.",
"shop on Semantic Evaluation",
"the Association for Computational Linguistics",
"lenge",
"Machine Learning Challenges Workshop",
"Linguistics.",
"gating projection in naturally occurring discourse",
"text prompts with reinforcement learning",
"ings of the 62nd Annual Meeting of the Association for",
"Computational Linguistics.",
"on Natural Language Processing",
"2023. Vicuna: An open-source chatbot impressing gpt-",
"org (accessed 14 April 2023)",
", 2(3):6.",
"The American journal of cardiology",
", 64 5:304–10.",
"Processing",
", pages 11370–11403.",
"arXiv preprint arXiv:2201.08531",
"of biomedical informatics",
", 47:1–10.",
"tuning with rl",
"Language Resources Association.",
"USA. Association for Computational Linguistics.",
"abs/1803.05457.",
"arXiv preprint arXiv:2110.14168",
"language models.",
"arXiv preprint arXiv:2410.15397",
"Company Blog of Databricks",
"reasoning",
", abs/2004.04494.",
"tion",
"Datasets and Benchmarks",
"arsarcasm dataset",
"OSACT",
"language understanding",
", abs/2009.03300.",
"Benchmarks Track (Round 2)",
"abs/2309.16797.",
"abs/2205.10782.",
"ics",
", 7:179–188.",
"Vision",
", pages 92–108.",
"62:3486 – 3502.",
"ICML’23. JMLR.org.",
"for Computational Linguistics",
", 9:346–361.",
"Association for Computational Linguistics.",
"tiers in Summarization",
", pages 70–79.",
"discovery and data mining",
"Polymenakos, and Walter S. Lasecki. 2019.",
"Dstc7 task",
"of the First Workshop on NLP for Conversational AI",
"Processing (EMNLP-IJCNLP)",
", pages 2391–2401.",
"Representations",
"pages 13916–13932. PMLR.",
"model calls into self-improving pipelines.",
"discrete prompt optimization",
"aligned llm.",
"arXiv preprint arXiv:2412.15156",
"guage models are zero-shot reasoners",
"and claim verification",
"Findings",
", 3:585–597.",
"large language model reranking",
"abs/2009.13081.",
"Association for Computational Linguistics",
", 7:453–466.",
"ing (EMNLP-IJCNLP)",
", pages 2567–2577.",
"arXiv:1704.04683",
"main question answering",
", abs/1906.00300.",
"in Information Retrieval",
", pages 796–806.",
"arXiv:2406.10504",
"lic. Association for Computational Linguistics.",
"guistics",
", 6:391–406.",
"Reasoning",
"intensive nlp.",
"arXiv preprint arXiv:2212.14024",
"hanced prompting framework for text generation",
"preprint arXiv:2307.11760",
"guidance.",
"arXiv preprint arXiv:2408.12910",
"Association for Computing Machinery.",
"systems",
"SIGDIAL Conference",
"arXiv preprint arXiv:2302.11520",
"1: Long Papers)",
", pages 3214–3252.",
"sociation for Computational Linguistics",
"Springer.",
"Kiong Ng, Patrick Jaillet, and Bryan Kian Hsiang Low.",
"Prompt optimization with human feedback",
"tics.",
"Linguistics",
"construction",
", abs/1808.09602.",
", 12:157–173.",
"nologies",
", pages 142–150.",
"lutionary Computation (CEC)",
", pages 1–8.",
"and Pattern Recognition",
", pages 12687–12697.",
"arXiv:2403.17804",
"arXiv preprint arXiv:1806.08730",
"feedback",
"Prompts have evil twins",
"learning",
", pages 248–260. PMLR.",
"arXiv:2410.06154",
"Thailand. Association for Computational Linguistics.",
"based on minimum cuts",
", cs.CL/0409058.",
"arXiv:2006.08328",
"ciation for Computational Linguistics",
"tion for Computational Linguistics",
"putational Natural Language Learning",
"topic-aware convolutional neural networks for extreme",
"summarization",
", abs/1808.08745.",
"and Short Papers)",
", pages 1267–1273.",
"1564. IEEE.",
"arXiv preprint arXiv:2304.05970",
", abs/1910.14599.",
"reasoning.",
"arXiv preprint arXiv:2005.00333",
"generation",
", abs/1706.09254.",
"tion search for prompting large language models",
"Singapore. Association for Computational Linguistics.",
"machine translation?",
", abs/1804.06323.",
"pirical Methods in Natural Language Processing",
"36.",
"abs/2311.12022.",
"preprint arXiv:2010.03768",
"2011 AAAI spring symposium series",
"metic word problems",
", abs/1608.01413.",
", pages 4463–4473.",
"ods in natural language processing",
", pages 1631–1642.",
"efficient compile-time prompt optimization",
"matics",
", 33:i49 – i58.",
"35:25278–25294.",
"58151. Curran Associates, Inc.",
"guage models.",
"arXiv preprint arXiv:2206.04615",
"automatic prompt optimization",
"national Conference on Learning Representations",
"eration.",
"arXiv preprint arXiv:2307.07415",
"forcement learning",
"Machine Learning",
", ICML’24. JMLR.org.",
"13003–13051.",
"putational Linguistics.",
"ing of the Association for Computational Linguistics",
", abs/1811.00937.",
"optimization for llm alignment",
"niques: Rlhf, rlaif, ppo, dpo and more",
"product reviews with sentiment dataset.",
", 7:625–641.",
"pages 200–207.",
"210.",
"ICML’24. JMLR.org.",
"Language Processing",
", pages 11279–11298.",
"with 10 gold labels.",
"arXiv preprint arXiv:2406.11706",
"May 7-11, 2024",
". OpenReview.net.",
"Learning",
"prompt optimization",
", abs/2410.14826.",
"time prompting via reinforcement learning",
"ence on Learning Representations",
"cation",
"Neural Information Processing Systems",
"preprint arXiv:2410.08696",
"Curran Associates Inc.",
"engineer",
"engineers",
"Textgrad: Automatic \"differentiation\" via text",
"ming",
"AAAI/IAAI, Vol. 2",
"tional Linguistics",
", pages 4791–4800.",
"AAAI’24/IAAI’24/EAAI’24. AAAI Press.",
"Table 2: Comparison of all APO techniques based on our framework",
"Table 3: Comparison of all APO techniques based on our framework",
"Table 4: Comparison of all APO techniques based on our framework",
"Table 5: Tasks covered in the different papers",
"Table 6: Tasks covered in the different papers",
"Table 7: Tasks covered in the different papers",
"Table 8: Automatic prompt optimization for LLM-as-a-Judge methods, text gradients (",
") and PE2 (",
"Table 9: Automatic prompt optimization for LLM-as-a-Judge methods, Hints (",
"Table 10: Automatic prompt optimization for LLM-as-a-Judge methods, Critique (",
"Table 11: Automatic prompt optimization for LLM-as-a-Judge methods, Reflection (",
"Cieri et al.",
"Table 12: Automatic prompt optimization for LLM-as-a-Judge methods, Safety Score (",
"of the Association for Computational Linguistics: ACL",
"els. In",
"International Conference on Machine Learning",
"Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-",
"Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.",
"Transactions of the Association for Computational Lin-",
"Bei Li, Rui Wang, Junliang Guo, Kaitao Song, Xu Tan,",
"drew S Gordon. 2011. Choice of plausible alternatives:",
"William W. Cohen, Ruslan Salakhutdinov, and Christo-",
"Iwaszuk, Smriti Jha, Dan Klein, Jayant Krishnamurthy,",
"interpretable: Sparse entropy regularization for prompt",
"lations, and coreference for scientific knowledge graph",
"Ellen M Voorhees and Dawn M Tice. 2000. Building a",
"rhonen. 2023.",
"Survival of the most influential prompts:",
"ous Natural Language Processing (NLP) tasks.",
"in medical abstracts",
"International Joint Conference",
"Sandhu, Kern Guppy, Stella Lee, and Victor Froelicher.",
"Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao",
"the Association for Computational Linguistics (Volume",
"Proceedings of the 2013 conference on empirical meth-",
"Roukos, Avirup Sil, Christopher Potts, and Omar Khat-",
"rameters: Training best-in-class ir models from scratch",
"Learning Representations, ICLR 2024, Vienna, Austria,",
"Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba.",
"ACM SIGKDD international conference on Knowledge",
"audio generation with prompt-enhanced diffusion mod-",
"respect to rating scales",
"Annual Meeting of the Asso-",
"Christopher Potts. 2013. Recursive deep models for se-",
"International Conference on Learning Representations",
"Jingyuan Selena She, Christopher Potts, Sam Bowman,",
"2024b.",
"A comprehensive survey of llm alignment tech-",
"urmans, and Joseph E. Gonzalez. 2022.",
"Tempera: Test-",
"Promptwizard: Task-aware prompt optimization frame-",
"domain wizard-of-oz dataset for task-oriented dialogue",
"crosslingual focused evaluation",
"edge? evaluating the sociability of large language mod-",
"els with socket benchmark. In",
"Proceedings of the 2023",
"ceedings of the 61st Annual Meeting of the Association",
"Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.",
"Bryan McCann, Nitish Shirish Keskar, Caiming Xiong,",
"Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-",
"tab. 2024. Prompts as auto-optimized training hyperpa-",
"and remaining challenges in this field. We pro-",
"source development and sharing",
"Stein, and Martin Potthast. 2019.",
"Semeval-2019 task 4:",
"ACM SIGIR Conference on Research and Development",
"stand and can be enhanced by emotional stimuli.",
"putational Linguistics: Human Language Technologies",
"Liu, KaShun Shum, Jipeng Zhang, Renjie Pi, and Tong",
"why are pre-trained word embeddings useful for neural",
"prompt program search: A structure-aware approach to",
"black-box prompt tuning for large language models. In",
"discrete reasoning over paragraphs",
"North American",
"Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,",
"does this patient have? a large-scale open domain ques-",
"prompt injection attacks against large language models",
"dataset for research in unstructured multi-turn dialogue",
"prompts and where to find them: Overcoming few-shot",
"ing language models to follow instructions with human",
"Plum: Prompt learning using metaheuris-",
"Jekaterina Novikova, Ondrej Dusek, and Verena Rieser.",
"Character-level convolutional networks for text classifi-",
"Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng",
"Saiful Haq, Ashutosh Sharma, Thomas T. Joshi, Hanna",
"mization for large language models against distribution",
"IEEE Intelligent Vehicles Symposium (IV)",
", pages 1557–",
"David Rein, Betty Li Hou, Asa Cooper Stickland, Jack-",
"with language models enables expert-level prompt opti-",
"Learning to few-shot learn across diverse natural",
"Overview of the iwslt 2017 evaluation campaign",
"In-",
"Parsing algebraic word problems into equations",
"Trans-",
"start worrying about prompt formatting. In",
"tion reasoning in language models with fine-tuning and",
"guage Processing (EMNLP)",
", pages 4222–4235, Online.",
"Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan",
"Yihong Dong, Kangcheng Luo, Xue Jiang, Zhi Jin, and",
"and Pontus Stenetorp. 2024.",
"Strings from the library of",
"Learning to solve and explain algebraic word problems",
"estimation system for the biomedical domain",
"Bioinfor-",
"David Jurgens. 2023. Do llms understand social knowl-",
"and Deva Ramanan. 2024b. Language models as black-",
"Jason Weston, and Douwe Kiela. 2019.",
"Adversarial nli:",
"Xcopa: A multilingual dataset for causal commonsense",
"Prithviraj Ammanabrolu. 2022a. Scienceworld: Is your",
"Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schu-",
"Automatic engineering of long prompts",
"ternational Workshop on Spoken Language Translation",
"Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie,",
"Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and",
"Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang",
"Zhang, and Tat-Seng Chua. 2023c.",
"Robust prompt opti-",
"page 11029—11047, Abu Dhabi, UAE. Association for",
"Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-",
"Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa",
"rect preference optimization with an offset",
"Dan Roth, and Jonathan Berant. 2021.",
"Did aristotle use",
"Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu",
"Sivan Doveh, Wei Lin, Paul Gavrikov, Michael Dorken-",
"Hajishirzi. 2023.",
"Self-instruct: Aligning language mod-",
"Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,",
"Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan",
"mura. 2020. A dataset and baselines for visual question",
"3045–3059, Online and Punta Cana, Dominican Repub-",
"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and",
"with mt-bench and chatbot arena. In",
"Noa Garcia, Chentao Ye, Zihua Liu, Qingtao Hu, Mayu",
"Truthfulqa: Measuring how models mimic human false-",
"ods in Natural Language Processing",
", pages 8162–8171.",
"Krueger, Tom Henighan, Rewon Child, Aditya Ramesh,",
"200k rct: a dataset for sequential sentence classification",
"tion. In",
"Proceedings of the 2nd Workshop on New Fron-",
"Shoufa Chen, Chongjian GE, Peize Sun, Weifeng Chen,",
"Prewrite: Prompt rewriting with reinforcement learning",
"ceedings of the 2019 Conference on Empirical Methods",
"optimisation",
"Proceedings of the 2024 Conference of",
", pages 3859–3920,",
"Stefan Daniel Dumitrescu, Petru Rebeja, Beáta L˝orincz,",
"ments in taxonomic problems",
"Annals of Human Genet-",
"ber 6-12, 2014, Proceedings, Part V 13",
", pages 740–755.",
"Subhro Roy and Dan Roth. 2016.",
"Solving general arith-",
"Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell",
"tian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha",
"International Conference on Computational Linguistics",
"Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. 2015.",
"Bin Benjamin Zhu, Xiaodi Sun, Jian-Guang Lou, Zhim-",
"han Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E.",
"Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,",
"Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren",
"2011.",
"The winograd schema challenge",
"AAAI Spring",
"box optimizers for vision-language models. In",
"Karthik Narasimhan, and Shunyu Yao. 2024. Reflexion:",
"Ruoyao Wang, Peter Jansen, Marc-Alexandre Côté, and",
"cial step for eliciting desired responses for vari-",
"A. G. Wray, Yuchen Zhang, and Alexander Zotov. 2020.",
"Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen",
"Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christo-",
"Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ramadan,",
"Daniel Matthew Cer, Mona T. Diab, Eneko Agirre, Iñigo",
"R. Anantha, Svitlana Vakulenko, Zhucheng Tu, S. Long-",
"Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing,",
"Conference on Empirical Methods in Natural Language",
"Baobao Chang, Xu Sun, Lei Li, and Zhifang Sui. 2024a.",
"2024 Conference on Empirical Methods in Natural Lan-",
"Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plap-",
"pert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al.",
"2024. Ipo: Interpretable prompt optimization for vision-",
"Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei",
"Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob",
"Otani, Chenhui Chu, Yuta Nakashima, and Teruko Mita-",
"answering on art. In",
"European Conference on Computer",
"for Computational Linguistics (Volume 1: Long Papers)",
"design",
"Journal of Chemical Information and Modeling",
"Bairu Hou, Joe O’Connor, Jacob Andreas, Shiyu Chang,",
"and Yang Zhang. 2023. Promptboosting: black-box text",
"classification with ten forward passes. In",
"the 40th International Conference on Machine Learning",
"a laptop? a question answering benchmark with implicit",
"Chulaka Gunasekara, Jonathan K. Kummerfeld, Lazaros",
"Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren,",
"Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu Yang.",
"pher Potts. 2024. Dspy: Compiling declarative language",
"Wenqi Shao, Xuefeng Xiao, et al. 2024. Prompt-a-video:",
"Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and",
"Gurusha Juneja, Nagarajan Natarajan, Hua Li, Jian Jiao,",
"Yilun Liu, Minggui He, Feiyu Yao, Yuhe Ji, Shimin Tao,",
"sonalized news article recommendation",
"ceedings of the 62nd Annual Meeting of the Association",
"Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,",
"13th European Conference, Zurich, Switzerland, Septem-",
"babel: Random sampling as a strong baseline for prompt",
"the North American Chapter of the Association for Com-",
"Hajishirzi. 2018.",
"Multi-task identification of entities, re-",
"tion answering. In",
"Conference on health, inference, and",
"Bo Pang and Lillian Lee. 2004.",
"A sentimental education:",
"ing class relationships for sentiment categorization with",
"Mohammad Taher Pilehvar and Jose Camacho-Collados.",
"Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,",
"Proceedings of the 2023 Conference on Empirical Meth-",
", page 7957—7968,",
"Krista Opsahl-Ong, Michael J Ryan, Josh Purtell, David",
"Proceedings of the 2024 Conference on Empirical Meth-",
", page 9340—9366,",
"Ye Qi, Devendra Singh Sachan, Matthieu Felix, Sarguna",
"prompt optimization through interleaved multi-objective",
"Garriga-Alonso, et al. 2022. Beyond the imitation game:",
"Autohint: Automatic prompt optimization with hint gen-",
"2020 Conference on Empirical Methods in Natural Lan-",
"Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebas-",
"answering challenge targeting commonsense knowledge",
"Prashant Trivedi, Souradip Chakraborty, Avinash Reddy,",
"Atia. 2025.",
"Align-pro: A principled approach to prompt",
"Ramnath, Sougata Chaudhuri, Shubham Mehrotra, Zixu,",
"Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005.",
"language",
"Language Resources and Evaluation",
", 39:165–",
"American Chapter of the Association for Computational",
"Yurong Wu, Yan Gao, Bin Benjamin Zhu, Zineng Zhou,",
"Proceedings of the 2022 Conference on Empirical Meth-",
"tian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P. Xing, and",
"man, and Colin Cherry. 2012.",
"Paraphrasing for style",
"Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,",
"Muchen Yang, Moxin Li, Yongle Li, Zijun Chen, Chong-",
"Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuo-",
"Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge",
"Sheng Liu, Zhi Huang, Carlos Guestrin, and James Zou.",
"John M. Zelle and Raymond J. Mooney. 1996.",
"to parse database queries using inductive logic program-",
"chine really finish your sentence? In"
],
"tables": [
"|Paper|Seed instructions|Iteration depth|Inference evaluation|Candidate generation|Search+filter strategy|\n|---|---|---|---|---|---|\n|ProTeGi<br>(Pryzant<br>et al., 2023)|Manually created|Fixed|LLM feedback +<br>Task accuracy|LLM rewriter|UCB for trees|\n|APE (Zhou et al.,<br>2022)|Instruction induction|Fixed|Task accuracy|N/A|UCB|\n|CRISPO (He et al.,<br>2025)|Manually created|Fixed|LLM feedback +<br>Task accuracy|LLM rewriter|TopK selection|\n|MOP (Wang et al.,<br>2025)|Instruction induction|Fixed|Task accuracy|Mixture of experts|Region-based<br>joint search|\n|DSPY<br>(Khattab<br>et al., 2024)|Manually created +<br>Instruction induction|Variable|LLM feedback +<br>Task accuracy|Program Synthesis|TopK selection|\n|OPRO (Yang et al.,<br>2024a)|Manually created|Variable|LLM feedback +<br>Task accuracy|Metaprompt design|TopK selection|\n|GATE (Joko et al.,<br>2024)|Manually created|Variable|Human feedback|LLM rewriter|N/A|",
"|Candidate generation Optimization time SNo. Method Inference evaluation Search+fliter strategy Iteration depth Target models Seed instruc- Prompt genera- tions complexity tion model|T0|InstructGPT|InstructGPT, GPT-3|1/ BERT, 2/ GPT-2|RoBERTa-large|PaLM text-bison|InstructGPT, GPT-3|GPT-4|RoBERTa, GPT-3|text-curie-001, text-curie-003, GPT-3.5, code-davinci-002|Vicuna-7b-v1.3, vicuna-13b-v1.3, llama-1-7b, llama-1-13b|Flan-T5 large and base|ChatGPT, Codex, InstructGPT|GPT-3 (text-davinci-003), GPT-4|LM: GPT-3.5, Retrieval: ColBERTv2|Col17|GPT-4|gpt-3.5-turbo-0301|text-davinci-002, text-davinci-003, (gpt-3.5-turbo), GPT-4|ChatGPT|GPT-3.5, GPT-4, PaLM-2|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**||PEGASUS<br>para-<br>phrase model|InstructGPT, GPT-3|RoBERTa-large<br>Reward<br>model-<br>DistilBERT|RoBERTa-large|PaLM 2-L|InstructGPT, GPT-<br>3, T5,<br>InsertGPT||RoBERTa, GPT-3|text-curie-001, text-<br>curie-003, GPT-3.5,<br>code-davinci-002|Llama2-7b-chat|Flan-T5|T5, GPT-2|GPT-3<br>(text-<br>davinci-003),<br>GPT-4|GPT-3.5||GPT-4|gpt-3.5-turbo-0301|gpt-3.5-turbo<br>(0301)|ChatGPT|GPT-4|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|_O_(_T ∗N ∗k ∗λi_)|_O_(_k ∗N ∗|Dval| ∗_<br>_B_)|_O_(_|ρ| ∗λi_)|_O_(_N ∗ρ ∗|V | ∗λi_)|_O_(_N ∗k ∗|V | ∗C_)|_O_(_N ∗ρ ∗k ∗|D| ∗_<br>_λi_)|_O_(_N ∗k ∗|Dval| ∗_<br>_λi_)|_O_(_T ∗|D| ∗λi_)|_O_(_N ∗k ∗λi_)|_O_(_N ∗k ∗λi_)|_O_(_λt_ +_ |Dval| ∗λi_)|_O_(_N ∗k ∗|V | ∗λi_)|_O_(_λt_)|_O_(_N ∗k ∗|Dtrain|_)|_O_(_N ∗k ∗λi_)|_O_(_N ∗k ∗B ∗λi_)|_O_(_N_<br>_∗_<br>(_λm_<br>+<br>_|Dval| ∗λi_))|_O_(_N ∗C ∗|V |∗B ∗_<br>_E_)|_O_(_N ∗|ρ| ∗|Dval|_)|_O_(_N ∗|ρ| ∗|Dval|_)|_O_(_N ∗k ∗λi_)|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Fixed|Fixed|Fixed|Fixed|Fixed|Fixed|Fixed|Fixed|Variable|Variable|NA|Variable|Variable|Fixed|Fixed|Variable|Open-ended||< 3|Fixed|Fixed|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Metaheuristic ensemble|rase<br>TopK selection||TopK selection||Beam search|TopK selection|TopK selection|TopK selection|TopK selection|NA|TopK selection||TopK selection|TopK selection|TopK selection||TopK selection|TopK selection|TopK selection|UCT-based bandit-search|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Genetic Algorithm:<br>Back<br>translation,<br>Cloze,<br>Sentence continuation|Phrase level<br>add/remove/swap/paraph|LLM-rewriter|RL-based trained NN|RL-trained NN|Genetic algorithm:<br>LLM-mutator|No new candidates|LLM rewriter|RL-trained NN|Ensemble<br>based<br>method|Finetuned LLMs|Genetic Algorithm:<br>Mutation + Crossover|RL-trained NN|LLM mutator|Program Synthesis|Program Synthesis|LLM rewriter|Metaprompt-design|LLM-rewriter|LLM-rewriter +<br>Ensemble method|LLM rewriter|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Task accuracy|Entropy-based score+<br>Task accuracy|Accuracy +<br>BERTScore|Task accuracy +<br>Reward model score|Task accuracy|Task accuracy|Task accuracy|Task accuracy +<br>LLM-feedback|Task accuracy|Task accuracy|LLMaaJ (pairwise)|Entropy-based score+<br>Task accuracy|BLEU, BERTScore|Task accuracy + NLL|Task accuracy|Task accuracy +<br>LLM-feedback|Human feedback|Task-Accuracy and F1|NLL + Task accuracy -<br>BLEU and BERTScore|Task accuracy|Task accuracy +<br>LLM-feedback|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Manually<br>created|Manually<br>created|Instruction<br>induction|Manually<br>created|Manually<br>created|Manually<br>created|Instruction<br>induction|Manually<br>created|Manually<br>created|Instruction-<br>induction|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Instruction<br>induction|Manually<br>cre-<br>ated +<br>Instruction<br>Induction|Manually<br>created|Instruction<br>induction|Manually<br>created|Manually<br>created|Manually<br>created|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|GPS (Xu et al., 2022)|GRIPS<br>(Prasad<br>et<br>al.,<br>2023)|Instruction induction<br>(Honovich et al., 2023)|RLPrompt (Deng et al.,<br>2022)|TEMPERA (Zhang et al.,<br>2022)|AELP (Hsieh et al., 2024)|APE (Zhou et al., 2022)|AutoHint<br>(Sun<br>et<br>al.,<br>2023)|BDPL (Diao et al., 2022)|Boosted Prompting<br>(Pitis et al., 2023)|BPO (Cheng et al., 2024)|CLAPS<br>(Zhou<br>et<br>al.,<br>2023)|Directional-stimulus (Li<br>et al., 2023d)|DLN<br>(Sordoni<br>et<br>al.,<br>2023)|DSP (Khattab et al., 2022)|DSPy<br>(Khattab<br>et<br>al.,<br>2024)|GATE (Joko et al., 2024)|GPO (Li et al., 2023c)|PACE (Dong et al., 2024b)|PREFER (Zhang et al.,<br>2024a)|Promptagent (Wang et al.,<br>2024a)|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|",
"|Candidate generation Optimization time SNo. Method Inference evaluation Search+fliter strategy Iteration depth Target models Seed instruc- Prompt genera- tions complexity tion model|RoBERTa-large|text-davinci-003, PaLM 2-L|GPT-3.5-turbo|GPT2 Large, GPT2 XL, Mistral 7B, Mistral 7B Instruct, Llama-Alpaca 7B, Llama2 7B. Llama2 7B Chat, ChatGPT|GPT-3.5-Turbo, Llama-2-70B- chat|text-davinci-002, vicuna, Chat- GPT|GPT-4-turbo|GPT4, GPT3.5, Llama3, Qwen2|DALLE-3, ChatGPT|GPT-3.5-turbo, GPT-4o-mini, Llama2-7b|Llama-2-7B-chat , Mistral-7B-Instruct-v0.1, ChatGPT (gpt-3.5-turbo-0125)|Claude Instant, Claude 3 Sonnet, Mistral 7B, Llama3 8B|GPT-3.5-Turbo, Baichuan2, GPT-4|Mistral 7b, Mistral 7b (Instruct), Llama 2 70b, Llama 2 70b (chat), Llama 3 8b, Llama 3 8b (In- struct), gpt-3.5-turbo|Alpaca-7b, GPT-3.5|Llama2-7B, Tulu2-13B, Baichuan2-13B|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|T5|text-davinci-003,<br>PaLM 2-L|GPT-3.5-Turbo|GPT2 Large, GPT2<br>XL,<br>Mistral 7B, Mistral<br>7B Instruct,<br>Llama-Alpaca 7B,<br>Llama2 7B.<br>Llama2 7B Chat,<br>ChatGPT|GPT-4|text-davinci-002,<br>vicuna,<br>ChatGPT|GPT-4-turbo||ChatGPT|GPT-3.5-turbo|RoBERTa<br>(filling masked to-<br>kens)|Claude Instant,<br>Claude 3 Sonnet,<br>Mistral 7B, Llama3<br>8B|GPT-3.5-Turbo,<br>Baichuan2,<br>GPT-4|Mistral 7b, Mistral<br>7b (Instruct),<br>Llama 2 70b, Llama<br>2 70b (chat),<br>Llama 3 8b, Llama<br>3 8b (Instruct),<br>gpt-3.5-turbo||Tulu-13B,<br>Tulu-<br>70B|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|_O_(_λm_)|_O_(_ρ ∗N ∗|V | ∗λi_)|_O_(_N ∗C ∗|Dval| ∗_<br>_λi_)|_O_(_N ∗k ∗λ_)|_O_(_B ∗N ∗λi_)|_O_(_N ∗k ∗λi_)|_O_(_N ∗C ∗λi_)|_O_(_N ∗|ρ|∗|Dval|_)|_O_(_N ∗T_)|_O_(_N ∗|D|∗|ρ|∗λi_)|_O_(_N ∗|I| ∗k ∗_<br>_|Dval| ∗λi_)|_O_(_N∗k∗_(_|Dtrain|∗_<br>_λi_ +_ λm_))|_O_(_N ∗k ∗λi_)|_O_(_B ∗k ∗N_)|_O_(_N ∗k ∗T ∗λi_)|_O_(_λt_+_|Dval|∗λi_))|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Early Stopping|Fixed|Fixed|Fixed steps|Fixed Steps|Fixed|Variable|Used 3 epochs|Fixed|Fixed|Variable|Fixed|Fixed|Fixed|Early Stopping||\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Beam-search|Metaheuristic Ensemble|UCT-based bandit-search|TopK selection|TopK selection|Top-1 selection|TopK selection||Linear UCB|TopK selection||TOP-K greedy search|Top-1 selection|Beam search|Metaheuristic ensemble||\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Ensemble<br>based<br>method|Genetic Algorithm:<br>Mutate + Crossover<br>(LLM-edits)|LLM rewriter|LLM-rewriter|LLM-rewriter|LLM-rewriter|Coverage-based|Feedback + preference<br>optimization|LLM rewriter|LLM rewriter|Token edits using<br>MLM|LLM rewriter|LLM-rewriter|LLM rewriter|Genetic Algorithm:<br>Mutation operators+<br>Crossover|Finetuned LLMs|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Accuracy, F1 Score|LLM Feedback +<br>Task accuracy|Task accuracy +<br>LLM-feedback|Task accuracy|Task accuracy +<br>LLM-feedback|LLM Feedback|Task accuracy +<br>F1 score|Task accuracy-nDCG|Task accuracy +<br>Human feedback|Task accuracy +<br>LLM-feedback|Task accuracy|LLM feedback +<br>ROUGE-1/2/L<br>F-<br>measure,<br>AlignScore|Task accuracy|Reward model score +<br>LLM Feedback|Task Accuracy +<br>ROUGUE+ SARI|Task accuracy|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Instruction-<br>induction|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>cre-<br>ated +<br>Instruction<br>Induction|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>cre-<br>ated +<br>Instruction<br>Induction|Manually<br>created|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Promptboosting<br>(Hou<br>et al., 2023)|Promptbreeder (Fernando<br>et al., 2023)|ProTeGi (Pryzant et al.,<br>2023)|Random separators (Lu<br>et al., 2024)|ABO (Yang et al., 2024b)|Adv-ICL (Long et al.,<br>2024)|AMPO<br>(Yang<br>et<br>al.,<br>2024d)|APEER (Jin et al., 2024)|APOHF (Lin et al., 2024)|BATPrompt (Shi et al.,<br>2024)|COPLE<br>(Zhan<br>et<br>al.,<br>2024)|CRISPO (He et al., 2025)|DAPO (Yang et al., 2024c)|DRPO<br>(Amini<br>et<br>al.,<br>2024)|EVOPROMPT (Guo et al.,<br>2024)|FIPO (Lu et al., 2025)|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|",
"|Candidate generation Optimization time Inference evaluation Target models SNo. Method Search+fliter strategy Iteration depth Seed instruc- Prompt genera- tions complexity tion model|GPT-3.5-turbo-0613|Llama-3-8B (task LM)|GPT-3.5-Turbo|GPT-2 (style transfer), fl an-T5-small (translation)|Llama2-7B-chat, Tigerbot-13B-chat, gpt3.5-turbo|PaLM family models|text-davinci-003|RoBERTa-large (classification), OPT models (others)|GPT-3-babbage|PaLM 2-L|GPT3.5/GPT4/Llama-70B|GPT-3.5, GPT-4|gpt-3.5-turbo, textdavinci-003|Mixtral7x8B, Llama-2 70B, GPT3.5, GPT4|GPT-4o and Llama3.1-8B|GPT-3.5-turbo, Llama3-8B, Mistral-7B|raLplhara msae 3.1-8B Instruct, Mistral Nemo Instruct 2407, Qwen 2.5-7B Instruct, Llama 70B, Qwen 2.5-72B, Mistral Large 2407.|GPT-3.5-turbo or GPT-4|GPT-3.5, GPT-4o|GPT-3.5|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**||GPT-3.5 (proposer<br>LM)|GPT-3.5-Turbo|distilGPT-2|GPT4|PaLM<br>2-L,<br>text-<br>bison,<br>gpt-3.5-turbo<br>and<br>GPT-4|GPT-4|OPT|GPT-3-babbage|PaLM 2-S|GPT3.5/GPT4|GPT-4|gpt-3.5-turbo,<br>textdavinci-003||GPT-4o|GPT-3.5-turbo,<br>Llama3-8B,<br>Mistral-7B|tuner007/pegasus_pa|GPT-4||Fine-tuned Llama2-<br>13B|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|_O_(_N ∗k ∗λi_)|_O_(_N ∗|Dval| ∗k ∗_<br>_λi_)|_O_(_C ∗N ∗|Dval|_)|_O_(_N ∗C ∗|V | ∗k_)|_O_(_|Dtrain|∗ρ∗λi_+<br>_λt_ +_ |Dval| ∗λi_)|_O_(_N ∗k ∗λi_)|_O_(_N ∗k ∗λi_)|_O_(_N ∗|V |∗λi ∗C_)|_O_(_N ∗C ∗k ∗λi_)|_O_(_N ∗C ∗λi ∗|V |_)|_O_(_N ∗C ∗λi_)|_O_(_N ∗k ∗λi_)|_O_(_N ∗k ∗|ρ|_)|_O_(_N ∗k ∗λi_)|_O_(_N ∗k ∗|ρ| ∗_<br>_|Dval|_)|_O_(_N ∗C ∗k ∗λi_)|_O_(_N ∗B∗T ∗k∗λi_)|_O_(_N ∗k ∗T ∗λi_)|_O_(_N ∗|Dval| ∗λi_)|_O_(_N ∗k ∗λi_)|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Fixed|Fixed|Fixed<br>steps<br>per-<br>cluster|Fixed||Variable|Fixed|Fixed|Fixed steps|Fixed|Fixed|Fixed|Fixed or until con-<br>vergence|Fixed|Fixed|Fixed|Fixed|Early Stopping|Variable|Early Stopping|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|TopK selection|TopK selection|TopK selection|||TopK selection|TopK selection|TopK selection|Metaheuristics|TopK selection|TopK selection|TopK selection|Rejection sampling<br>with exploration|TopK selection|UCB bandit search|TopK selection|Beam-search|Bandit Search (UCB)||Beam Search|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Genetic Algorithm:<br>Mutate + Crossover<br>(LLM-edits)|Program Synthesis|APE for each cluster|RL-based trained NN|LLM rewriter|Metaprompt design|Metaprompt design|RL-trained LLM|Genetic Algorithm:<br>Mutate + crossover|RL-trained LLM|Genetic Algorithm:<br>Mutate + Crossover<br>(LLM-edits)|LLM rewriter|LLM-rewriter|Program synthesis|LLM-rewriter|LLM-mutator|Genetic Algorithm:<br>Mutate + Crossover (to-<br>kens)|Genetic Algorithm:<br>Mutate + CrossOver<br>(tokens)|LLM rewriter|LLM-rewriter|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Numeric Score-based|Task accuracy|Task Accuracy|Task accuracy +<br>Reward score|Task accuracy +<br>Reward model score|Task accuracy +<br>LLM-feedback|Task accuracy +<br>LLM-feedback|Task accuracy|Task accuracy|Task accuracy +<br>Reward model score|Task accuracy +<br>LLM-feedback|Task accuracy +<br>Human feedback|Task accuracy|Task accuracy|Task accuracy +<br>LLM-feedback|Task accuracy +<br>LLM-feedback|Task accuracy|Task accuracy +<br>LLM-feedback|Task accuracy +<br>LLM-feedback|Task accuracy +<br>LLM-feedback|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|Manually<br>created|Manually<br>created|Instruction<br>induction|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>cre-<br>ated +<br>Instruction<br>Induction|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|LLM generated<br>CoT process.|Manually<br>created|Instruction<br>induction<br>on<br>task-<br>README|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>created|Manually<br>cre-<br>ated +<br>Instruction<br>Induction|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|LMEA (Liu et al., 2023)|MIPRO<br>(Opsahl-Ong<br>et al., 2024)|MOP (Wang et al., 2025)|MORL-Prompt<br>(Jafari<br>et al., 2024)|OIRL (Sun et al., 2024a)|OPRO (Yang et al., 2024a)|PE2 (Ye et al., 2024)|PIN (Choi et al., 2024)|PLUM (Pan et al., 2024)|PRewrite (Kong et al.,<br>2024)|PROMPTWIZARD<br>(Agarwal et al., 2024)|PROMST (Chen et al.,<br>2024)|Reprompting (Xu et al.,<br>2024)|SAMMO (Schnabel and<br>Neville, 2024)|SCULPT (Kumar et al.,<br>2024)|SOS (Sinha et al., 2024)|SPRIG<br>(Zhang<br>et<br>al.,<br>2024b)|StraGo (Wu et al., 2024)|TextGrad<br>(Yuksekgonul<br>et al., 2024)|UNIPROMPT<br>(Juneja<br>et al., 2024)|\n|**SNo.**<br>**Method**<br>**Seed**<br>**instruc-**<br>**tions**<br>**Inference evaluation**<br>**Candidate generation**<br>**Search+filter strategy**<br>**Iteration depth**<br>**Optimization time**<br>**complexity**<br>**Prompt**<br>**genera-**<br>**tion model**<br>**Target models**|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|",
"|SNo. Paper Tasks|Col2|Col3|\n|---|---|---|\n|1|GPS (Xu et al., 2022)|10 unseen tasks from the T0 benchmark, which span:<br>1. Natural Language Inference: ANLI R1, R2, R3, CB, RTE (Nie et al., 2019; Dagan et al.,<br>2005).<br>2. Coreference Resolution: WSC, Winogrande.(Levesque et al., 2011)<br>3. Sentence Completion: COPA(Roemmele et al., 2011) , HellaSwag (Zellers et al., 2019).<br>4. Word Sense Disambiguation: WiC (Pilehvar and Camacho-Collados, 2019).|\n|2|GRIPS (Prasad et al., 2023)|8 classification tasks from NaturalInstructions (Mishra et al., 2021)|\n|3|Instruction induction (Honovich et al., 2022)|1. Spelling, 2. Syntax, 3. Morpho-syntax, 4. Lexical semantics,<br>5. Phonetics, 6. Knowledge, 7. Semantics, 8. Style|\n|4|RLPrompt (Deng et al., 2022)|1. Classification<br>2. Text-style transfer|\n|5|TEMPERA (Zhang et al., 2022)|Classification|\n|6|AELP (Hsieh et al., 2024)|Big Bench Hard (Suzgun et al., 2023)|\n|7|APE (Zhou et al., 2022)|1. 24 Instruction induction tasks (Honovich et al., 2022) 2. 21 BIG Bench Hard tasks (Suzgun<br>et al., 2023)|\n|8|AutoHint (Sun et al., 2023)|BIG-Bench Instruction Induction (Epistemic Reasoning, Logical Fallacy Detection, Implica-<br>tures, Hyperbaton, Causal Judgment, Winowhy) (Zhou et al., 2022)|\n|9|BDPL (Diao et al., 2022)|1. MNLI (Williams et al., 2017), 2. QQP (Cer et al., 2017), 3. SST-2 (Socher et al., 2013), 4.<br>MRPC (Dolan and Brockett, 2005), 5. CoLA (Warstadt et al., 2018), 6. QNLI (Rajpurkar et al.,<br>2016), 7. RTE (Dagan et al., 2005), 8. CitationIntent (Jurgens et al., 2018), 9. SciERC (Luan<br>et al., 2018), 10. RCT (Dernoncourt and Lee, 2017), 11. HyperPartisan (Kiesel et al., 2019)|\n|10|Boosted Prompting (Pitis et al., 2023)|GSM8K (Cobbe et al., 2021) and AQuA (Garcia et al., 2020)|\n|11|BPO (Cheng et al., 2024)|Generation: Dolly Eval (Conover et al., 2023), Vicuna Eval (Chiang et al., 2023), Self-Instruct<br>Eval (Wang et al., 2022b)|\n|12|CLAPS (Zhou et al., 2023)||\n|13|Directional-stimulus (Li et al., 2023d)|MultiWOZ (Budzianowski et al., 2018)|\n|14|DLN (Sordoni et al., 2023)|1. Mpqa Sentiment analysis (Lu et al., 2021)<br>2. Trec Question type classification (Lu et al., 2021)<br>3. Subj Determine whether a sentence is subjective or objective (Lu et al., 2021)<br>4. Leopard (Bansal et al., 2019)- Disaster Determine whether a sentence is relevant to a disaster.<br>5. Leopard (Bansal et al., 2019)- Airline Airline tweet sentiment analysis.<br>6. BBH (Suzgun et al., 2023)- (Hyper, Nav, Date, Logic datasets)|\n|15|DSP (Khattab et al., 2022)|1. open-domain question answering (Open-SQuAD) (Lee et al., 2019)<br>2. multi-hop question answering (HotPotQA) (Yang et al., 2018)<br>3. conversational question answering (QReCC) (Anantha et al., 2020)|\n|16|DSPy (Khattab et al., 2024)||\n|17|GATE (Joko et al., 2024)|LAPS (Joko et al., 2024) (1. Content Recommendation (user likes to read a given held-out<br>article or not) 2. Moral Reasoning, 3. Email Verification)|\n|18|GPO (Li et al., 2023c)|1. Sentiment analysis - Yelp (Zhang et al., 2015), Flipkart (Vaghani and Thummar, 2023),<br>IMDB (Maas et al., 2011), Amazon (Zhang et al., 2015)<br>2. NLI - MNLI (Williams et al., 2017), ANLI (Nie et al., 2019) 3.Entailment - RTE (Dagan<br>et al., 2005), 4. CommonsenseQA - SocialIQA (Sap et al., 2019)<br>5. Multi-turn dialog - DSTC7 (Gunasekara et al., 2019), Ubuntu Dialog (Lowe et al., 2015),<br>MuTual (Cui et al., 2020)<br>6. NumericalQA - DROP (Dua et al., 2019)|\n|19|PACE (Dong et al., 2024b)|BBH (Suzgun et al., 2023), instruction induction tasks (24 tasks) (Honovich et al., 2022) and<br>translation tasks (en-de, en-es, en-fr)|\n|20|PREFER (Zhang et al., 2024a)|1. NLI tasks including SNLI (Bowman et al., 2015), MNLI (Williams et al., 2017), QNLI<br>(Rajpurkar et al., 2016), RTE (Dagan et al., 2005)<br>2. Classification: Ethos (Mollas et al., 2020), liar (Wang, 2017), ArSarcasm (Farha and Magdy,<br>2020a)|\n|21|Promptagent (Wang et al., 2024a)|1. BigBenchHard (BBH) (Suzgun et al., 2023) - 6 BBH tasks that emphasize a blend of domain<br>knowledge<br>2. Biomedical - Disease NER (NCBI) (Do˘gan et al., 2014), MedQA (Jin et al., 2020), Bio<br>similar sentences (Sogancioglu et al., 2017)<br>3. 2 classification - TREC (Voorhees and Tice, 2000) + Subj. (Pang and Lee, 2004) 1 NLI(CB)<br>(de Marneffe et al., 2019)|\n|22|Promptboosting (Hou et al., 2023)|Text Classification|\n|23|Promptbreeder (Fernando et al., 2023)|1. Arithmetic Reasoning: Benchmarks: GSM8K (Cobbe et al., 2021), MultiArith (Roy and<br>Roth, 2016), AddSub (Hosseini et al., 2014),<br>SVAMP (Patel et al., 2021), SingleEq (Koncel-Kedziorski et al., 2015), AQuA-RAT (Ling et al.,<br>2017).<br>2. Commonsense Reasoning: Benchmarks: CommonSenseQA (CSQA) (Talmor et al., 2019),<br>StrategyQA (SQA) (Geva et al., 2021).<br>3. Hate Speech Classification: Dataset: ETHOS (Mollas et al., 2020).<br>4. Instruction Induction (Honovich et al., 2022): Tasks: 24 datasets spanning<br>sentence similarity, style transfer, sentiment analysis, and more|",
"|SNo. Paper Tasks|Col2|Col3|\n|---|---|---|\n|24|ProTeGi (Pryzant et al., 2023)|Jailbreak (Pryzant et al., 2023), Liar (Wang, 2017), Sarcasm (Farha and Magdy, 2020b), Ethos<br>(Mollas et al., 2020)|\n|25|Random separators (Lu et al., 2024)|1. SST-2, SST-5,(Socher et al., 2013) 3. DBPedia (Zhang et al., 2015), 4. MR (Pang and Lee,<br>2005), 5. CR (Hu and Liu, 2004), 6. MPQA (Wiebe et al., 2005), 7. Subj (Pang and Lee, 2004),<br>8. TREC (Voorhees and Tice, 2000), 9. AGNews (Zhang et al., 2015)|\n|26|ABO (Yang et al., 2024b)|BigBenchHard tasks (Suzgun et al., 2023): Object Counting, Navigate, Snarks, Question<br>Selection|\n|27|Adv-ICL (Long et al., 2024)|Summarization (XSUM (Narayan et al., 2018), CNN/Daily Mail (Nallapati et al., 2016)),<br>Data-to-Text (WebNLG (Gardent et al., 2017), E2E NLG (Novikova et al., 2017)), Translation<br>(LIRO (Dumitrescu et al., 2021), TED Talks (Qi et al., 2018)), Classification (YELP-5 (Zhang<br>et al., 2015), WSC (Levesque et al., 2011)), Reasoning (GSM8k (Cobbe et al., 2021), SVAMP<br>(Patel et al., 2021))|\n|28|AMPO (Yang et al., 2024d)|Text classification task TREC (Voorhees and Tice, 2000),<br>sentiment classification task SST-5 (Socher et al., 2013),<br>largescale reading comprehension task RACE (Lai et al., 2017),<br>medical question-answering tasks MedQA (Jin et al., 2020) and MedMCQA (Pal et al., 2022)|\n|29|APEER (Jin et al., 2024)|Passage reranking|\n|30|APOHF (Lin et al., 2024)|1. User instruction optimization using tasks from Instructzero, 2. Text-to-image , 3. Response<br>optimization|\n|31|BATPrompt (Shi et al., 2024)|1. Language understanding, 2. Text summarization, 3. Text simplification|\n|32|COPLE (Zhan et al., 2024)|GLUE - SST2 (Socher et al., 2013), COLA (Warstadt et al., 2018), MNLI (Williams et al.,<br>2017), QNLI (Rajpurkar et al., 2016), RTE (Dagan et al., 2005), MRPC (Dolan and Brockett,<br>2005), QQP (Cer et al., 2017) MMLU (Hendrycks et al., 2020) - STEM, Humanities, Social<br>Sciences and Other|\n|33|CRISPO (He et al., 2025)|Summarization, QA|\n|34|DAPO (Yang et al., 2024c)|1. Sentiment classification, 2. topic classification, 3. News, 4. TREC (Voorhees and Tice,<br>2000), 5. subjectivity classification (Pang and Lee, 2004), 6. Logic Five, 7. Hyperbaton, 8.<br>Disambiguation, 9. Salient, 10.Translation|\n|35|DRPO (Amini et al., 2024)|Alignment benchmark|\n|36|EVOPROMPT (Guo et al., 2024)|1. Language Understanding: Sentiment classification (e.g., SST-2, SST-5, CR, MR (Socher<br>et al., 2013; Hu and Liu, 2004; Pang and Lee, 2005)), 2. Topic classification (e.g., AGNews<br>(Zhang et al., 2015), TREC (Voorhees and Tice, 2000)), Subjectivity classification (Subj (Pang<br>and Lee, 2004)). 3. Language Generation: Summarization (SAMSum (Gliwa et al., 2019)).<br>Simplification (ASSET (Alva-Manchego et al., 2020)). 4. Reasoning (BIG-Bench Hard Tasks)<br>(Suzgun et al., 2023): Multi-step reasoning tasks from BBH, such as logical deduction, causal<br>judgment, and object tracking.|\n|37|FIPO (Lu et al., 2025)|1. Generation: GSM8K (Cobbe et al., 2021), BBH (Suzgun et al., 2023) 2. Multiple Choice:<br>PiQA (Bisk et al., 2019), CosmosQA (Huang et al., 2019), MMLU (Hendrycks et al., 2020)|\n|38|LMEA (Liu et al., 2023)|Traveling Salesman Problems (TSPs)|\n|39|MIPRO (Opsahl-Ong et al., 2024)|1. Question Answering (HotPotQA)(Yang et al., 2018) 2. Classification (Iris (Fisher, 1936),<br>Heart Disease (Detrano et al., 1989)) 3. Entailment (ScoNe) (She et al., 2023) 4. Multi-hop<br>Fact Extraction and Claim Verification (HoVer) (Jiang et al., 2020)|\n|40|MOP (Wang et al., 2025)|50 tasks comprising of Instruction Induction (Honovich et al., 2022), Super Natural Instructions<br>(Mishra et al., 2021), BBH (Suzgun et al., 2023)|\n|41|MORL-Prompt (Jafari et al., 2024)|1. Unsupervised Text Style Transfer: Shakespearean data (Xu et al., 2012) 2. Supervised<br>Machine Translation: iwslt2017 (Cettolo et al., 2017)|\n|42|OIRL (Sun et al., 2024a)|Arithmetic reasoning: GSM8K (Cobbe et al., 2021), MAWPS, SVAMP (Patel et al., 2021)|\n|43|OPRO (Yang et al., 2024a)|GSM8K (Cobbe et al., 2021), BBH (23 tasks) (Suzgun et al., 2023), MultiArith (Roy and Roth,<br>2016), AQuA (Garcia et al., 2020)|\n|44|PE2 (Ye et al., 2024)|1. MultiArith and GSM8K for math reasoning (Cobbe et al., 2021),<br>2. Instruction Induction (Honovich et al., 2022),<br>3. BIG-bench Hard for challenging LLM tasks (Suzgun et al., 2023)<br>4. Counterfactual Evaluation<br>5. Production Prompt|\n|45|PIN (Choi et al., 2024)|1. Classification: SST-2 and etc (Socher et al., 2013)<br>2. Unsupervised Text Style transfer: Yelp (Zhang et al., 2015)<br>3.Textual Inversion From Images: MSCOCO (Lin et al., 2014), LAION (Schuhmann et al.,<br>2022)|\n|46|PLUM (Pan et al., 2024)|Natural-Instructions datasets v2.6 (Mishra et al., 2021)|\n|47|PRewrite (Kong et al., 2024)|1. Classification: AG News (Zhang et al., 2015), SST-2 (Socher et al., 2013)<br>2. Question answering: NQ (Kwiatkowski et al., 2019)<br>3. Arithmetic reasoning: GSM8K (Cobbe et al., 2021)|\n|48|PROMPTWIZARD (Agarwal et al., 2024)|1. BIG-Bench Instruction Induction (BBII) (Honovich et al., 2022)<br>2. GSM8k (Cobbe et al., 2021), AQUARAT (Ling et al., 2017), and SVAMP (Patel et al., 2021)<br>3. BIG-Bench Hard (BBH) (Suzgun et al., 2023)<br>4. MMLU (Hendrycks et al., 2020), Ethos (Mollas et al., 2020), PubMedQA (Jin et al., 2019),<br>MedQA (Jin et al., 2020)|\n|49|PROMST (Chen et al., 2024)|11 multistep tasks: 1. Webarena, 2. Alfworld (Shridhar et al., 2020), 3. Scienceworld (Wang<br>et al., 2022a), 4. BoxNet1 (Nezhadarya et al., 2019), 5. BoxNet2,<br>6. BoxLift, 7. Warehouse, 8. Gridworld 1, 9. Gridworld 2, 10. Blocksworld, 11. Logistics|\n|50|Reprompting (Xu et al., 2024)|BBH(Suzgun et al., 2023), GSM8K(Cobbe et al., 2021), MATH(Hendrycks et al.)|",
"|SNo. Paper Tasks|Col2|Col3|\n|---|---|---|\n|51|SAMMO (Schnabel and Neville, 2024)|1. BigBench zero-shot classification tasks (Srivastava et al., 2022)<br>2. GeoQuery (Zelle and Mooney, 1996), SMCalFlow (Andreas et al., 2020), Overnight (Wang<br>et al., 2015) 3. Super-NaturalInstructions (Mishra et al., 2021)|\n|52|SCULPT (Kumar et al., 2024)|BBH (23 tasks) (Suzgun et al., 2023), RAI (Kumar et al., 2024)|\n|53|SOS (Sinha et al., 2024)|1. Sentiment Analysis 2. Orthography Analysis, 3. Taxonomy of Animals, 4. Disambiguation<br>QA, 5. Logical Five, 6. Color Reasoning|\n|54|SPRIG (Zhang et al., 2024b)|1. Reasoning: Tasks requiring multi-step logic or causal reasoning.<br>2. Math: Arithmetic and logical deduction problems.<br>3. Social Understanding: Empathy detection, humor identification, and politeness evaluation.<br>4. Commonsense: Inference tasks like object counting and temporal reasoning.<br>5. Faithfulness: Ensuring generated outputs align with input data.<br>6. Knowledge: Open-domain QA and knowledge recall tasks.<br>7. Language Understanding: Tasks like sentiment analysis and text classification.<br>8. Popular benchmarks include MMLU (Hendrycks et al., 2020), BBH (Suzgun et al., 2023),<br>TruthfulQA (Lin et al., 2022), XCOPA (Ponti et al., 2020), SocKET (Choi et al., 2023), and<br>others, covering 47 task types across multiple languages and domains.|\n|55|StraGo (Wu et al., 2024)|BBH (Suzgun et al., 2023)(five challenging tasks within Big-Bench Hard) 2. SST-5 (Socher<br>et al., 2013)(fine-grained sentiment classification) 3. TREC (Voorhees and Tice, 2000)(question-<br>type classification). 4. MedQA (Jin et al., 2020),MedMCQA (Pal et al., 2022) (medical-domain<br>QA) 5. Personalized Intent Query (an internal industrial scenario)|\n|56|TextGrad (Yuksekgonul et al., 2024)|LeetCode Hard (Shinn et al., 2024), Google-proof QA (Rein et al., 2023), MMLU (Hendrycks<br>et al., 2020) (Machine Learning, College Physics), BBH (Suzgun et al., 2023) (Object Count-<br>ing, Word Sorting), GSM8k (Cobbe et al., 2021), DOCKSTRING (Garc’ia-Orteg’on et al.,<br>2021)(molecule evaluation)|\n|57|UNIPROMPT (Juneja et al., 2024)|(1) Ethos (Mollas et al., 2020), (2) ARC (Clark et al., 2018) , (3) MedQA (Jin et al., 2020), (4)<br>GSM8K (Cobbe et al., 2021) and (5) one real-world task: Search Query Intent (Juneja et al.,<br>2024)|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2502.16923v2.pdf"
}