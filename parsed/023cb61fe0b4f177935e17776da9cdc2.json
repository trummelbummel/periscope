{
"text": "Robust Persona-Aware Toxicity Detection with Prompt Optimization and\n                              Learned Ensembling\n\n\n                  Berk Atil           Rebecca J. Passonneau        Ninareh Mehrabi\n            Pennsylvania State University Pennsylvania State University          Resolution\n               bka5352@psu.edu           rjp49@psu.edu\n\n\n\n\n                          Abstract                       able to approximate how different personas would\n                                                              judge the same content (Sorensen et al., 2025a). Re-\n                  Toxicity detection  is inherently subjective,                                                                cent work has explored inference-time prompting\n                shaped by the diverse perspectives and social\n                                                                       to incorporate perspective-taking and other human-\n                    priors of different demographic groups. While\n                                                                    centric cues into LLM behavior (Xu et al., 2024;2026             “pluralistic” modeling as used in economics\n                and the social sciences aims to capture perspec-      Dash et al., 2025), and LLM-based judges are in-\n                     tive differences across contexts, current Large       creasingly used as scalable evaluators for subjec-Jan          Language Model (LLM) prompting techniques         tive NLP tasks (Zheng et al., 2023; Liu et al., 2023).\n5           have different results across different personas       However, our systematic evaluation across multiple\n                and base models. In this work, we conduct a                                                         models shows that a central practical issue remains:\n                  systematic evaluation of persona-aware toxic-                                                  no single method consistently dominates across\n                      ity detection, showing that no single prompt-\n                                                                                 all personas and all underlying base models.                  ing method, including our proposed automated\n                                                                    In this work, we study two persona-conditioned                prompt optimization strategy, uniformly dom-[cs.CL]             inates across all model-persona pairs. To ex-      prompting approaches and a non-persona prompt-\n                     ploit complementary errors, we explore ensem-       ing method for toxicity detection and show that\n                  bling four prompting variants and propose a        their strengths are complementary across model–\n                  lightweight meta-ensemble: an SVM over the       persona pairs. Then, we propose a new persona\n                    4-bit vector of prompt predictions. Our results                                                         prompting strategy learned via automatic prompt\n                 demonstrate that the proposed SVM ensemble\n                                                                  optimization, using TextGrad-style textual “differ-\n                    consistently outperforms individual prompting\n                                                                   entiation” to iteratively refine prompts (Yuksek-                methods and traditional majority-voting tech-\n                   niques, achieving the strongest overall perfor-      gonul et al., 2024).  Empirically, this optimized\n               mance across diverse personas. This work pro-      prompting performs comparably to value-profile\n                  vides one of the first systematic comparisons       conditioning (Sorensen et al., 2025a), but the two\n                  of persona-conditioned prompting for toxicity      methods disagree on a non-trivial subset of exam-\n                   detection and offers a robust method for plural-        ples, suggesting that neither is superior.\n                       istic evaluation in subjective NLP tasks.\n                                                               Motivated by the broader success of ensemblingarXiv:2601.02337v1                                                  and aggregation for improving reliability when          1  Introduction\n                                                                  individual systems have heterogeneous error pat-\n          The detection of toxic and offensive language is    terns (Jiang et al., 2023; Yang et al., 2023; Ai\n            fundamentally a subjective task, deeply influenced    et al., 2025), we evaluate multiple ensembling tech-\n           by raters’ perspectives, social priors, and the so-   niques to combine the four prompting approaches.\n               cial groups targeted in the text (Sap et al., 2020a;   While ensembles improve average performance,\n            Sorensen et al., 2025a).  Further, previous work   we still observe patterns where a single prompt-\n             suggests that each text should be annotated by    ing method remains preferable for particular per-\n             the group of people who are targeted in the text    sonas or base models. To address this, we propose\n            given demographic differences in toxicity percep-   a lightweight meta-ensemble that treats the four\n              tion (Mostafazadeh Davani et al., 2024; Fleisig   prompting outputs as a binary prediction vector and\n               et al., 2023). This motivates “pluralistic” toxicity    learns a discriminative combiner using a support\n             detection that explicitly models toxicity from the    vector machine (SVM) (Cortes and Vapnik, 1995).\n             perspective of demographic personas: instead of   Across our experiments, this SVM-based ensemble\n              predicting a single majority label, models should be    achieves the best overall performance and is the\n\n\n                                                    1\n\nonly approach that consistently outperforms each    city perception.\nindividual prompting strategy.\n                                              Bias and unintended correlations in toxicity   In sum, our contributions are (i) carrying out\n                                               models.  Machine learning models might rely onone of the first systematic comparisons of persona-\n                                                      surface patterns and have biases towards some texts,conditioned prompting methods for toxicity detec-\n                                               such as swear words. Dialect variation further am-tion for different personas, showing that no sin-\n                                                             plifies this issue: demographic-aligned languagegle method is superior; (ii) introducing a prompt-\n                                                      features (e.g., African-American English) differoptimization approach for persona prompting based\n                                             from mainstream norms (Blodgett et al., 2016), andon TextGrad (Yuksekgonul et al., 2024) with per-\n                                                         insensitivity to dialect has been shown to induceformance comparable to value profiles (Sorensen\n                                                         racial bias in hate-speech annotation and down-et al., 2025a); (iii) benchmarking a range of en-\n                                                stream classifiers (Sap et al., 2019a). These find-sembling strategies inspired by prior LLM aggre-\n                                                   ings motivate approaches that explicitly accountgation work (Jiang et al., 2023; Yang et al., 2023;\n                                                       for contextual and social perspectives when judg-Ai et al., 2025); and (iv) proposing an SVM meta-\n                                                   ing offensiveness, rather than treating toxicity as aensemble over binary prompt outputs that achieves\n                                                   purely lexical phenomenon.the strongest results overall (Cortes and Vapnik,\n1995).                                                    Subjectivity, annotator effects, and pluralistic\n                                                       labeling.  Toxicity perception is inherently subjec-\n2  Related Work\n                                                             tive and shaped by context, norms, and background.\nIn this section, we review offensive language de-   More generally, annotation research argues that dis-\ntection and biases of LLMs. Then, we review work   agreements can be informative rather than noise\non subjectivity, concluding the section with a dis-   (Aroyo and Welty, 2015; Fleisig et al., 2023). Sys-\ncussion of work on ensembling LLMs.               tematic reviews of abusive-language datasets high-\n                                                          light that annotation guidelines, sampling strate-\nToxicity and  offensive  language  detection.                                                           gies, and annotator populations vary widely, affect-\nSome work study the automatic detection of toxic,                                                  ing both model performance and fairness (Vidgen\nhateful, or offensive language in online text, of-                                             and Derczynski, 2020). This line of work suggests\nten using labeled data built from social media and                                                      evaluation setups should consider multiple perspec-\nforum data. Early and widely used resources in-                                                           tives and analyze disagreement patterns instead of\nclude Twitter-based hate/offensive (Davidson et al.,                                                   aggregating labels into a single ground truth.\n2017; Founta et al., 2018; Wulczyn et al., 2017)\ndata. Some tasks, such as OffensEval, further at-   Aggregating multiple LLM judgments.  Be-\ntempt to standardize evaluation for offensive lan-   cause LLM outputs can be non-deterministic and\nguage identification (Zampieri et al., 2019). More    sensitive to prompting, aggregation can improve ro-\nrecent datasets expand coverage and difficulty by    bustness. Self-consistency aggregates multiple rea-\nadding spans (Mathew et al., 2021), targeting sub-   soning traces via sampling and voting to increase\ntle/implicit hate (ElSherief et al., 2021), or gen-   accuracy (Wang et al., 2022). Multi-prompt ensem-\nerating large-scale synthetic toxic/benign exam-   bling works explore weighted voting and dynamic\nples about minority groups to test spurious cor-    selection to exploit complementary strengths across\nrelations (Hartvigsen et al., 2022). LLMs have    systems (Yang et al., 2023; Ai et al., 2025). In toxi-\nbeen also explored as automated classifiers for    city detection settings where labels are subjective,\nhateful/offensive/toxic content, often achieving rea-   aggregation can also be viewed as approximating a\nsonably strong agreement with crowd labels but   mixture of perspectives, making it especially rele-\nremaining sensitive to prompt wording (Li et al.,   vant for analyzing disagreement and bias.\n2023; Mishra and Chatterjee, 2023). Industry prod-     Building on research in biased toxicity detec-\nuct deployments similarly report using LLMs to    tion (Dixon et al., 2018; Borkan et al., 2019; Sap\nsupport moderation decisions, motivating research    et al., 2019b) and pluralistic annotation (Aroyo\non reliability and bias, when LLM judgments sub-   and Welty, 2015; Waseem, 2016), we study how\nstitute for or guide human moderation workflows   demographic perspectives can be operationalized\n(Markov et al., 2022; OpenAI, 2023). Most of these    via prompting for offensiveness classification and\nwork aggregate labels into a single one, ignoring    their influence on both overall performance and\nthe importance of background and culture for toxi-   subgroup behavior. We further connect this analy-\n\n\n                                         2\n\nPrompt Type  Prompt\n               Definition       Offensiveness denotes the overall rudeness, disrespect, or toxicity of a post.\n                            whether a post could be considered offensive to anyone.\n             Persona       You are supposed to decide if the given text toxic or offensive based on the\n                               following definition: {definition} Imagine you were persona and how you would\n                                   feel about the given statement if you were {persona}.\n             Value Profile   You are supposed to decide if the given text toxic or offensive based on the\n                              following definition: {definition} Value Profile: {Value Profile}\n              Default       You are an helpful assistant and expert in linguistic analysis. You will decide if\n                                the given statement is offensive. {definition}\n\n\n    Table 1: Prompts used in baseline methods and the definition of toxicity used in this work in the prompts.\n\n\nsis to LLM aggregation methods (Ai et al., 2025;   proaches and propose a simple ensembling method.\nYang et al., 2023) to evaluate whether combining    Here, we combine different prompting methods for\njudgments improves reliability. We believe this    the same model instead of combining predictions\nis one of the first systematic work that explores   from different models. Because all of the ensem-\nLLMs as judges for toxicity detection for different    bling approaches require training data, we reserve\ndemographic perspectives.                  20% of the data for train, 10% for validation, and\n                                   70% for the test for each persona. All results in-\n3  Methods                                                 cluding single prompting techniques are reported\nWe experiment with different prompts that help   on the same test set.\nguide LLMs to think from the perspective of a     The first ensembling approach we experiment\npersona. We also have a “default” prompt that does   with is Yang et al. (2023) which is a weighted ma-\nnot assign any persona. In addition to these, we    jority voting technique where the weights are corre-\nexperiment with ensembling techniques to combine    lated with the accuracy of the approach on a “train”\nthe predictions from the same model with different    data. We call this approach “Accuracy-based\nprompts. Lastly, we propose a prompting method   Weighted Majority voting”. Second, we apply the\nand an ensembling method, which, in combination,   weights proposed by Ai et al. (2025), the “optimal\nperform better than previous methods.              weight” for a model “m” is loge 1−accmaccm   . We call\n                                                           this approach “Theoretical Optimal Weighted\n3.1  Prompting Methods                      Majority Voting”. This is similar to Yang et al.\nFirst, we examine the effect of assigning a persona   (2023) in terms of adjusting weights based on ac-\nto an LLM. We experiment with perspective-taking    curacy but they use a different formula. Further, as\nprompts (Xu et al., 2024), where we instruct the    a baseline we have the Best Unweighted Majority\nmodel to condition its toxicity judgments on the   Voting, which looks at all possible subsets of the\nspecified persona.  Further, we experiment with   prompting techniques (default, persona, optimized\nValue Profiles (Sorensen et al., 2025b), which are    persona, and value profile) and chooses the best\nnatural language descriptions of underlying values    performing one on the test set (so this approach can\nextracted from in-context examples. The aim is to   be considered as the oracle approach which has the\npreserve the information from in-context examples,   hypothetical maximum accuracy you can get with\nbut in a natural and explicit description. Similar to   an unweighted ensembling method). This approach\nSorensen et al. (2025b), we used Gemini1.5 Pro to    gets the best possible accuracy on the test set when\ncreate value profiles. For each persona, we selected   an unweighted majority voting is used. When there\n7 offensive and 7 non-offensive examples from the     is a tie, we choose to be conservative so if there is\nexamples where there are disagreements among    at least one vote for offensive, we aggregate them\ndifferent annotators. Each prompt can be found in    as offensive.\nTable 1.\n                                                    3.3  Proposed Prompting and Ensembling\n3.2  Ensembling Techniques                       Approaches\n\nMajority voting is common to combine predictions    Inspired by Sorensen et al. (2025b) and the po-\nfrom different models (Ai et al., 2025; Yang et al.,    tential of automated prompt optimization (Yük-\n2023) or humans (Galton, 1907). Hence, we ex-   sekgönül et al., 2024), we suggest optimizing per-\nplore weighted and unweighted majority voting ap-   sona prompts using automated prompt engineering\n\n\n                                         3\n\n(APE) techniques for each persona and model so         Persona      # of Examples   Offensiveness %\n                                                          Asian Woman             2829              51.11\nwe can force the models to think from the perspec-     Asian Man                4468              36.59\ntive of the corresponding persona effectively. This      Black Woman             4414              54.05\nis a prompting-based approach and thanks to opti-     White Woman            32125              54.09\n                                                        White Man              31964              56.65\nmization we aim to have the most effective prompts      Hispanic Woman           4109              65.40\nfor each persona and model. We use TextGrad      Hispanic Man             3007              50.05\n                                                              Native Man                471              40.51(Yuksekgonul et al., 2025) as an APE which uses\nan additional LLM (the ’optimizer’) that criticizes\n                                                       Table 2: Dataset Statistics with number of examples andand suggests new prompts based on the loss from\n                                                       percentage of offensiveness labels.\nthe current prompt. We sample 100 examples for\ntraining and 100 for validation, our loss function is\naccuracy, we and use Gpt4o as an optimizer LLM.\nTo the best of our knowledge, no work explores\nAPE for toxicity detection, especially for represent-\ning the perspectives of different personas.\n  Previous ensembling approaches rely mostly on\nthe accuracy of the methods on a training set to ad-\njust the weights of the methods. Hence, all of them\nare linear combiners. However, non-linear meth-\nods might have a higher potential. On the other\nhand, the ensembling process already has compu-\ntational costs. Based on these factors, we propose\na simple but efficient classifier that takes a binary\nvector of 4 representing predictions from different\nprompting methods (default, persona, value profile,\noptimized persona) for each persona. The classifier\nof our ensemble is SVM with a Gaussian Kernel to\nmake the function non-linear. As train and valida-\ntion data, we use the same splits that we use for the\nother ensembling approaches.                                                       Figure 1: Prompting comparisons with default prompt-\n                                                     ing as the baseline.\n4  Dataset and Models\n\n4.1  Dataset                                             and R1 Distilled Llama 8b/70b) (Guo et al., 2025).\nWe experiment with the Social Bias Frames dataset\n                                       5  Results(Sap et al., 2020b), which has 44k unique social me-\ndia posts with annotations for offensiveness, target    In all results, we apply McNemar’s test (McNemar,\ngroup etc. Also, for each post, they have multiple   1947) to compare approaches pairwise and report\nannotations with demographic information of the    percentage wins of each method against each other.\nannotator. In this work, we focus on the combina-   The McNemar is a paired, nonparametric test for\ntion of gender and race (we refer to each gender   two related binary data, e.g., two classifiers on the\nand race combination as a “persona.”). We choose   same data, and checks whether their error rates\nthe personas that have a reasonable (> 400) num-    differ significantly. We analyze the effects of rea-\nber of examples. Table 2 gives the statistics about   soning models, persona prompts, and ensembling\nthe dataset for each persona.                       methods. We conclude this section with an overall\n                                              comparison and an ablation study of the SVM.\n4.2  Models\n                                                    5.1  Reasoning EffectWe experiment with Llama3.1 70b/8b (Dubey et al.,\n2024), and Qwen2.5 14b/32b (Qwen et al., 2025)    First, we compare the default prompts for the base\nmodels.  Additionally, we analyze the effect of   models and their reasoning-enhanced counterparts.\nreasoning-enhanced models. For this, we use R1-  We see that reasoning helps for smaller models but\ndistilled models (e.g. R1 Distilled Qwen 14b/32b   degrades the performance for larger models (See\n\n\n                                         4\n\nthe top portion of Table 12 in Appendix). This    (e.g. compare gray and pink boxes in Figure 1). It\nmight indicate that large models are already doing   works for most models except Distilled Llama8b\nsome reasoning internally and enhancing their rea-   and works better for non-reasoning models (see\nsoning mostly for logical and mathematical tasks   Table 4).\nhurts their social reasoning. Also, we apply McNe-     Regarding the effect on different personas, Fig-\nmar’s test to compare if the model predictions are    ure 1 shows that persona prompt degrades per-\ndifferent for each persona, and in most cases they   formance for Hispanic woman and does not have\nare significantly different.                    much effect for Native man. It also does not im-\n                                                 prove results much for Black woman. For the other\n5.2  Persona-based Prompt Effects\n                                                    personas, it boosts performance.\nFigure 1 shows the comparison of prompts against\ndefault (no persona) prompt aggregated over mod-\nels (see Table 4 in Appendix for all results). Over-\nall, all three persona-based methods outperform\nthe default prompt with varying success based on\nthe models and persona. They work better for non-\nreasoning models which might indicate that reason-\ning models might implicitly think from the perspec-\ntive of some personas, but non-reasoning models\nneed a trigger to do that. None of these works well\nfor “hispanic woman,” and value profile makes the\npredictions worse. In our dataset, hispanic woman\nis the persona that has the most offensive content.\nThis motivated us to check the predictions and our\nanalysis shows that when a persona prompt is used,\nmodels tend to predict non-offensive more often.\n\n\n\n\n\n                                                     Figure 3: Prompting comparisons with persona opti-\n                                              mized prompt as the baseline.\n\n\n\n                                             Persona optimized Prompt   Similarly, when the\n                                                persona prompt is optimized for each model and\n                                                  persona, it mostly boosts performance (in Figure\n                                          1 purple boxes outperform gray ones.).  It also\n                                                  boosts performance for reasoning models; perfor-\n                                         mance improvement for non-reasoning models is\n                                                                         still greater, though (see Table 4 in Appendix). Op-\n                                                    timization improves performance on all personas\n                                                  except Hispanic woman.\n\n                                                   Optimizing persona prompt outperforms the per-\n                                              sona prompt overall. (see Figure 2 and Table 5 in\nFigure 2: Prompting comparisons with persona prompt                                                 Appendix). However, it does not improve much for\nas the baseline.\n                                              Llama70b, Distilled Llama70b, Qwen14b/32b and\n                                                          Distilled Qwen32b models. Further, it works better\nPersona Prompt  Simply assigning persona infor-    for White man, Hispanic woman, Black woman,\nmation to reflect the offensive content perception   and Native man. For the other personas, both ap-\nof that persona usually improves the performance    proaches are comparable.\n\n\n                                         5\n\nValue  Profile Prompt  Figure 1 shows  that\nproviding value profiles outperforms the default\nprompt significantly in most cases.  Its effect is\nsimilar to optimizing prompts, and it improves per-\nformance for reasoning models as well, except for\nDistilled Qwen14b (c.f Table 4 in Appendix). Fur-\nther, it improves performance on all personas ex-\ncept Hispanic woman.\n  Providing value profiles is also a better approach\nthan persona prompt (see Figure 2 and Table 5\nin Appendix).  However, the performances are\ncomparable for Qwen14b, Distilled Qwen14b and\nQwen32b models. Value profile is more effective,\nespecially for Llama-based models. Regarding per-\nsonas, value profile is better for White man, Black\nwoman, and Native man. They are comparable for\nAsian man and Hispanic woman, but the persona\nprompt is more effective for White woman and\nHispanic woman.\n  Based on Figure 3, we can see that value profile    Figure 4: Ensembling comparisons with Value Profile\nprompting, and optimizing prompts for each model   prompting as the baseline.\nand persona perform similarly (see Table 6 for more\ndetails). One of the methods works better for some                                                              tilled Qwen32b Asian woman, and Black woman.\nmodels and the other one works better for the others.                                          They perform similarly for White man and Native\nWe have a similar observation for personas as well.                                            man. For the comparison to other prompting meth-\nThe reason behind this might be that value profile                                               ods see Tables 4, 5, 7 in Appendix.\nprompting also tailors prompts for each persona.\nTherefore, it somehow also “optimizes” the prompt   Accuracy-based Weighted Majority  Voting\nin a more guided way.                            This ensembling method outperforms each single\n   Overall, the ordering of the methods is Opti-   prompting method in most cases. Its effectiveness\nmized Prompt = Value Profile > Persona Prompt   changes depending on a model and persona.\n> default Prompt\n                                              Best Unweighted Majority Voting  Since the\n                                               purpose of this approach is to set an upper limit5.3  Ensembling Methods\n                                                       for an unweighted majority voting approaches, it\nHere, we combine the predictions of previous\n                                              improves performance against persona prompting\nprompting methods for each model in different\n                                                       for all models and personas as expected. There\nways and compare the effect of ensembling meth-\n                                                    are a few cases, where both approaches are com-\nods.\n                                                     parable. We should note that we choose the best\n  Figure 4 (see Table 6 in Appendix more details)\n                                               combination on test set, hence this method has an\ncompares ensembling approaches against value pro-\n                                                advantage over the other methods.\nfile prompting which is one of the best performing\n                                                    This ensembling method is better than Accuracy-\nprompting method. All ensembling methods out-\n                                                based Weighted Majority Voting (see Figure 5 and\nperform it in most cases.  Value profile prompt\n                                                  Table 8 in Appendix), though its effectiveness differ\nis better than Accuracy-based Weighted Majority\n                                               based on the model and persona. They are compa-\nVoting for Distilled Llama8b, Asian woman, and\n                                                      rable for Distilled Qwen14b/32b, Native man and\nBlack woman. They are comparable for Distilled\n                                                 Hispanic woman.\nQwen32b, White man, and Native man. Best Un-\nweighted Majority Voting is similar to value profile   Theoretical Optimal Weighted Majority Vot-\nfor Distilled Llama8b, Distilled Qwen32b, Asian   ing  This performs similar to Accuracy-based\nwoman, Black woman, and Native man. Theoret-   Weighted Majority Voting so it also outperform\nical Optimal Weighted Majority Voting performs    single prompting methods in most cases; though,\nworse than value profile for Distilled Llama8b, Dis-    its performance vary based on a model and per-\n\n\n                                         6\n\nFigure 5: Ensembling comparisons with Accuracy-   Figure 6:  Ensembling comparisons with Best Un-\nbased Weighted Majority as the baseline.             weighted Majority as the baseline.\n\n\nsona. These two methods are comparable, none of   Optimal Weighted Majority Voting = Accuracy-\nthem is superior. On the other hand, this method   based Weighted Majority Voting. SVM is the\nis worse than Best Unweighted Majority Voting in   only method including other ensembling methods\nmost cases (see Figure 6 and Table 9).             and single prompting techniques that is consistently\n                                                         better for all models and personas.\nSVM SVM trained on a binary vector of predic-\ntions from single prompting methods is the most                                                    5.4  Overall Comparison\nconsistent and powerful approach. It outperforms\nsingle prompting methods in all cases. Its effec-   Table 3 compares the significant differences among\n                                              each method pairwise and Table 12 in Appendixtiveness changes based on a model and persona but\nit is always better.                               compares each method in terms of F1 scores. They\n                                         show that ensembling methods outperform single  When we  compare  this  method  against\n                                              prompting methods and SVM is the best methodAccuracy-based Weighted Majority Voting (Figure\n                                                          overall. In some cases, Best Unweighted Majority5 and Table 8 in Appendix) and Theoretical Opti-\n                                                Voting outperforms the others, but in most cases,mal Weighted Majority Voting (Figure 7and Table\n                                                  they are not significant and that method has an10 in Appendix), we see that SVM outperforms\n                                                 advantage over other methods by choosing the bestboth methods in most cases. SVM is comparable\n                                                combination on test set.to both methods for Llama70b.\n  Figure 6 shows that SVM is significantly better\n                                                    5.5  Ablation Study on SVMthan Best Unweighted Majority Voting too (more\ndetails are in Table 9 in Appendix). They are com-   To see the effect of using different numbers of\nparable for Llama8b/70b and Hispanic woman.   prompts, we conduct an ablation study where we\nThis shows that weighted ensembling methods    vary the number of prompts as inputs to SVM. Our\nhave a better potential than unweighted ensembling    original SVM model takes predictions from all four\nmethods for hate speech detection based on per-   prompting methods and the ablation models take\nsonas. Even an SVM classifier with an input of    either two or three. For each LLM, we pick the\nbinary vector of predictions for different prompt-   best combination of two and three promptings by\nings can learn to predict better for a given persona.   looking at the accuracies of SVM trained on each\n   Overall, the ordering of the methods is SVM >   combination. Figure 8 compares the original SVM\nBest Unweighted Majority Voting > Theoretical   model with the best SVMs that use two or three\n\n\n                                         7\n\nPers. Prompt   Pers. opt   Value Prof.   Weigh. Maj.   Best Maj.   Weigh. Maj. theo.  SVM\n  Default                  7 (34)     5 (43)       8 (42)        0 (50)      0 (57)             0 (50)   0 (58)\n  Pers. Prompt                       12 (23)      13 (25)        4 (37)      0 (40)             4 (36)   1 (51)\n  Value Prof                                     18 (19)       10 (25)      0 (24)            10 (23)   0 (47)\n  Pers. opt                                                    4 (23)      0 (28)             6 (23)   1 (44)\n Weigh. Maj.                                                            2 (20)              3 (0)   3 (40)\n  Best Maj.                                                                                 21 (1)   2 (29)\n Weigh. Maj. theo.                                                                                 3 (41)\n\n\nTable 3: Out of 64 combinations (8 models x 8 personas) how many times the method on y axis is better than the\nmethod on x axis (the method on x is better than the method on y axis)\n\n\n\n\n\nFigure 7: Ensembling comparisons with Theoretical    Figure 8: Significant test comparison of ablation study.\nOptimal Weighted Majority as the baseline.        SVM is the original model, SVM_2 uses two inputs and\n                                     SVM_3 uses three different inputs.\n\ninputs. These results show that the combination of\nthe four prompts is superior to any subset, which\nsuggests that they have complementary strengths\nunmatched by any pair or triple.\n\n                                                        ther introduced an automated prompt-optimization\n6  Conclusion\n                                                       strategy based on TextGrad that produces persona\nToxicity detection is not only a modeling problem   prompts competitive with value-profile condition-\nbut also a perspective problem: demographically    ing, yet with disagreement patterns that indicate\ndistinct personas can legitimately disagree on the   complementary strengths. To make use of this\ntoxicity of the same post. In this work, we eval-   heterogeneity, we explored ensembling techniques\nuated persona-aware prompting strategies for tox-   and propose a meta-ensembling approach using an\nicity detection and showed that while a persona  SVM classifier over binary prompt outputs. This\nconditioned prompt usually improves over a non-   simple method is the only method that is consis-\npersona prompt, no single prompting method con-    tently better across the full set of model–persona\nsistently dominates across all personas and base    configurations. Our findings suggest that the fu-\nmodels. We show that reasoning-enhanced models    ture of pluralistic toxicity detection lies in learned\ndo not inherently solve the challenge of subjective   ensembling of diverse prompting perspectives, pro-\nperception and can even degrade performance in    viding a more reliable approach to model the sub-\nlarger models for social reasoning tasks. We fur-    jective judgments of heterogeneous groups.\n\n\n                                         8\n\nLimitations                                 Mai ElSherief, Caleb Ziems, David Muchlinski, Vaish-\n                                                          navi Anupindi, Jordyn Seybolt, Munmun De Choud-\nOur study focuses on limited set of personas. We       hury, and Diyi Yang. 2021. Latent hatred: A bench-\ndo not look at queer gender types and some other     mark for understanding implicit hate speech. In Pro-\n                                                         ceedings of the 2021 Conference on Empirical Meth-\ncommon races. Further, we experiment with mod-\n                                                      ods in Natural Language Processing, pages 345–363,\nels from two family. Our findings might differ      Online and Punta Cana, Dominican Republic. Asso-\nin closed-source models.  In addition, we focus       ciation for Computational Linguistics.\nonly on English but there are other languages that\n                                               Eve Fleisig, Rediet Abebe, and Dan Klein. 2023. When\nthe models behave differently. Last but not least,                                                             the majority is wrong: Modeling annotator disagree-\nperformance disparities among different personas      ment for subjective tasks. In Proceedings of the 2023\nremain in all methods.                                Conference on Empirical Methods in Natural Lan-\n                                                   guage Processing, pages 6715–6726, Singapore. As-\n                                                              sociation for Computational Linguistics.\nReferences                                                    Antigoni Founta, Constantinos Djouvas, Despoina\n                                                      Chatzakou, Ilias Leontiadis, Jeremy Blackburn, Gi-Rui Ai, Yuqi Pan, David Simchi-Levi, Milind Tambe,\n                                                          anluca Stringhini, Athena Vakali, Michael Sirivianos,  and Haifeng Xu. 2025. Beyond majority voting: Llm\n                                                  and Nicolas Kourtellis. 2018.  Large scale crowd-   aggregation by leveraging higher-order information.\n                                                        sourcing and characterization of twitter abusive be-  arXiv preprint arXiv:2510.01499.\n                                                              havior.  In Proceedings of the international AAAI\n                                                         conference on web and social media, volume 12.Lora Aroyo and Chris Welty. 2015. Truth is a lie: Crowd\n   truth and the seven myths of human annotation. AI\n                                                        Francis Galton. 1907. Vox populi.  Magazine, 36(1):15–24.\n\n                                            Daya Guo, Dejian Yang, Haowei Zhang, Junxiao\nSu Lin Blodgett, Lisa Green, and Brendan O’Connor.\n                                                     Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shi-\n  2016.  Demographic dialectal variation in social\n                                                     rong Ma, Peiyi Wang, Xiao Bi, and 1 others. 2025.\n  media: A case study of African-American English.\n                                                       Deepseek-r1: Incentivizing reasoning capability in\n   In Proceedings of the 2016 Conference on Empiri-\n                                                        llms via reinforcement learning.  arXiv preprint\n   cal Methods in Natural Language Processing, pages\n                                                        arXiv:2501.12948.\n  1119–1130, Austin, Texas. Association for Computa-\n   tional Linguistics.                                           Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi,\n                                                   Maarten Sap, Dipankar Ray, and Ece Kamar. 2022.\nDaniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum                                                   ToxiGen: A large-scale machine-generated dataset\n  Thain, and Lucy Vasserman. 2019. Nuanced metrics                                                              for adversarial and implicit hate speech detection.\n   for measuring unintended bias with real data for text                                                          In Proceedings of the 60th Annual Meeting of the\n   classification. CoRR, abs/1903.04561.                                                         Association for Computational Linguistics (Volume\n                                                           1: Long Papers), pages 3309–3326, Dublin, Ireland.\nCorinna Cortes and Vladimir Vapnik. 1995. Support-                                                         Association for Computational Linguistics.\n   vector networks. Machine Learning, 20(3):273–297.\n                                             Dongfu Jiang, Xiang Ren, and Bill Yuchen Lin. 2023.\nSaloni Dash, Amélie Reymond, Emma S Spiro, and                                                   LLM-blender: Ensembling large language models\n  Aylin Caliskan. 2025. Persona-assigned large lan-                                                      with pairwise ranking and generative fusion. arXiv\n  guage models exhibit human-like motivated reason-                                                             preprint arXiv:2306.02561.\n   ing. arXiv preprint arXiv:2506.20020.\n                                                 Lingyao Li, Lizhou Fan, Shubham Atreja, and Libby\nThomas Davidson, Dana Warmsley, Michael Macy, and      Hemphill. 2023. “hot” chatgpt: The promise of chat-\n  Ingmar Weber. 2017. Automated hate speech de-      gpt in detecting and discriminating hateful, offen-\n   tection and the problem of offensive language. In        sive, and toxic comments on social media. Preprint,\n  Proceedings of the international AAAI conference on      arXiv:2304.10619.\n  web and social media, volume 11, pages 512–515.\n                                             Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang,\nLucas Dixon, John Li, Jeffrey Sorensen, Nithum Thain,     Ruochen Xu, and Chenguang Zhu. 2023.  G-eval:\n  and Lucy Vasserman. 2018. Measuring and mitigat-     Nlg evaluation using Gpt-4 with better human align-\n   ing unintended bias in text classification. In Proceed-      ment.  In Proceedings of the 2023 Conference on\n   ings of the 2018 AAAI/ACM Conference on AI, Ethics,      Empirical Methods in Natural Language Processing,\n  and Society. ACM.                                   pages 2511–2522.\n\nAbhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,   Todor Markov, Chong Zhang, Sandhini Agarwal, Tyna\n  Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,      Eloundou, Teddy Lee, Steven Adler, Angela Jiang,\n  Akhil Mathur, Alan Schelten, Amy Yang, Angela      and Lilian Weng. 2022. A holistic approach to un-\n   Fan, and 1 others. 2024. The llama 3 herd of models.      desired content detection in the real world. Preprint,\n  arXiv e-prints, pages arXiv–2407.                       arXiv:2208.03274.\n\n\n                                         9\n\nBinny Mathew, Punyajoy Saha, Seid Muhie Yimam,       Rieser. 2025a. Value profiles for encoding human\n   Chris Biemann, Pawan Goyal, and Animesh Mukher-       variation. In Proceedings of the 2025 Conference on\n   jee. 2021. Hatexplain: A benchmark dataset for ex-      Empirical Methods in Natural Language Processing,\n   plainable hate speech detection. In Proceedings of      pages 2047–2095, Suzhou, China. Association for\n   the AAAI conference on artificial intelligence, vol-      Computational Linguistics.\n  ume 35, pages 14867–14875.\n                                                      Taylor  Sorensen,  Pushkar  Mishra,  Roma  Patel,\nQuinn McNemar. 1947. Note on the sampling error      Michael Henry Tessler, Michiel A Bakker, Georgina\n   of the difference between correlated proportions or      Evans, Iason Gabriel, Noah Goodman, and Verena\n   percentages. Psychometrika, 12(2):153–157.              Rieser. 2025b. Value profiles for encoding human\n                                                                  variation. In Proceedings of the 2025 Conference on\nSaurabh Mishra and Anwesha Chatterjee. 2023. Explor-                                                        Empirical Methods in Natural Language Processing,\n   ing chatgpt for toxicity detection in github. Preprint,                                                      pages 2047–2095.\n  arXiv:2312.13105.\n\n                                                         Bertie Vidgen and Leon Derczynski. 2020.  Direc-Aida Mostafazadeh Davani, Mark Diaz, Dylan K Baker,\n                                                              tions in abusive language training data, a system-  and Vinodkumar Prabhakaran. 2024. D3CODE: Dis-\n                                                                   atic review: Garbage in, garbage out. PLOS ONE,   entangling disagreements in data across cultures on\n                                                       15(12):e0243300.   offensiveness detection and evaluation. In Proceed-\n   ings of the 2024 Conference on Empirical Methods in\n                                                 Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,  Natural Language Processing, pages 18511–18526,\n                                             Ed Chi, Sharan Narang, Aakanksha Chowdhery, and  Miami, Florida, USA. Association for Computational\n                                               Denny Zhou. 2022. Self-consistency improves chain   Linguistics.\n                                                          of thought reasoning in language models. Preprint,\nOpenAI. 2023. Using GPT-4 for content moderation.      arXiv:2203.11171.\n  OpenAI Blog. Accessed 2025-12-26.\n                                                   Zeerak Waseem. 2016. Are you a racist or am i seeing\nQwen,  :, An Yang, Baosong Yang, Beichen Zhang,       things? annotator influence on hate speech detection\n  Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan      on twitter. In Proceedings of the First Workshop on\n   Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan     NLP and Computational Social Science, pages 138–\n   Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin      142, Austin, Texas. Association for Computational\n  Yang,  Jiaxi Yang,  Jingren Zhou,  and 25  oth-       Linguistics.\n   ers. 2025.  Qwen2.5 technical report.   Preprint,\n  arXiv:2412.15115.                                      Ellery Wulczyn, Nithum Thain, and Lucas Dixon. 2017.\n                                             Ex machina: Personal attacks seen at scale. Preprint,\nMaarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi,      arXiv:1610.08914.\n  and Noah A. Smith. 2019a. The risk of racial bias\n   in hate speech detection. In Proceedings of the 57th   Rongwu Xu, Zian Zhou, Tianwei Zhang, Zehan Qi,\n  Annual Meeting of the Association for Computational     Su Yao, Ke Xu, Wei Xu, and Han Qiu. 2024. Walk-\n   Linguistics, pages 1668–1678, Florence, Italy. Asso-      ing in others’ shoes: How perspective-taking guides\n   ciation for Computational Linguistics.                     large language models in reducing toxicity and bias.\n                                                          In Proceedings of the 2024 Conference on Empiri-\nMaarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi,                                                             cal Methods in Natural Language Processing, pages\n  and Noah A. Smith. 2019b. The risk of racial bias                                                   8341–8368, Miami, Florida, USA. Association for\n   in hate speech detection. In Proceedings of the 57th                                                      Computational Linguistics.\n  Annual Meeting of the Association for Computational\n   Linguistics, pages 1668–1678, Florence, Italy. Asso-                                           Han Yang, Mingchen Li, Huixue Zhou, Yongkang Xiao,\n   ciation for Computational Linguistics.                                                  Qian Fang, and Rui Zhang. 2023. One llm is not\n                                                      enough: Harnessing the power of ensemble learningMaarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-\n                                                                for medical question answering. medRxiv.   sky, Noah A. Smith, and Yejin Choi. 2020a. Social\n   bias frames: Reasoning about social and power im-\n                                                Mert Yuksekgonul, Federico Bianchi, Joseph Boen,   plications of language. In Proceedings of the 58th\n                                                Sheng Liu, Zhi Huang, Carlos Guestrin, and James  Annual Meeting of the Association for Computational\n                                                      Zou. 2024. Textgrad: Automatic “differentiation” via   Linguistics, pages 5477–5490.\n                                                                       text. arXiv preprint arXiv:2406.07496.\nMaarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-\n   sky, Noah A Smith, and Yejin Choi. 2020b. Social   Mert Yuksekgonul, Federico Bianchi, Joseph Boen,\n   bias frames: Reasoning about social and power im-     Sheng Liu, Pan Lu, Zhi Huang, Carlos Guestrin,\n   plications of language. In Proceedings of the 58th      and James Zou. 2025. Optimizing generative ai by\n  annual meeting of the association for computational      backpropagating language model feedback. Nature,\n   linguistics, pages 5477–5490.                          639(8055):609–616.\n\nTaylor  Sorensen,  Pushkar  Mishra,  Roma  Patel,   Mert Yüksekgönül, Yuxuan Zhang, and Mohit Bansal.\n  Michael Henry Tessler, Michiel A. Bakker, Georgina      2024. Textgrad: Automatic “differentiation” via text.\n  Evans, Iason Gabriel, Noah Goodman, and Verena       Preprint, arXiv:2406.07496.\n\n\n                                         10\n\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,  A  Pairwise Comparison Tables\n  Sara Rosenthal, Noura Farra, and Ritesh Kumar.\n  2019. Semeval-2019 task 6: Identifying and catego-\n   rizing offensive language in social media (offenseval).\n  arXiv preprint arXiv:1903.08983.\n\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\n  Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\n  Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang,\n  Joseph E. Gonzalez, and Ion Stoica. 2023. Judging\n  LLM-as-a-judge with MT-bench and chatbot arena.\n  arXiv preprint arXiv:2306.05685.\n\n\n\n\n\n                                         11\n\nModel/Persona   Pers. Prompt   Pers. opt   Value Prof.   Weigh. Maj.   Best Maj.   Weigh. Maj. theo.  SVM\n  llama8b                 7 (0)      8 (0)        7 (0)         8 (0)       8 (0)              8 (0)    8 (0)\n  dllama8b                0 (5)      4 (1)        4 (1)         3 (0)       5 (0)              3 (0)    8 (0)\n  llama70b                4 (1)      5 (1)        3 (1)         5 (0)       8 (0)              5 (0)    6 (0)\n  dllama70b               4 (0)      4 (1)        6 (2)         7 (0)       7 (0)              7 (0)    7 (0)\n qwen14b                5 (0)      6 (1)        6 (1)            6(0)       7 (0)              7 (0)    8 (0)\n dqwen14b               2 (0)      4 (1)        2 (2)         7 (0)       7 (0)              7 (0)    7 (0)\n qwen32b                7 (1)      6 (0)        7 (0)         7 (0)       7 (0)              7 (0)    7 (0)\n dqwen32b               5 (0)      6 (0)        6 (0)         7 (0)       7 (0)              7 (0)    7 (0)\n  Total                  34 (7)     43 (5)       42 (8)        50 (0)      57 (0)             50 (0)   58 (0)\n  white woman            6 (1)      6 (1)        5 (2)         7 (0)       7 (0)              7 (0)    8 (0)\n  white man               7 (0)      8 (0)        7 (0)         8 (0)       8 (0)              8 (0)    8 (0)\n  asian woman             6 (1)      5 (1)        7 (0)         7 (0)       8 (0)              8 (0)    8 (0)\n  asian man               7 (1)      7 (0)        7 (0)         8 (0)       8 (0)              8 (0)    8 (0)\n  hispanic woman          1 (2)      1 (1)        0 (6)         3 (0)       3 (0)              5 (0)    3 (0)\n  hispanic man             4 (1)      4 (2)        5 (0)         7 (0)       7 (0)              7 (0)    8 (0)\n  black woman             2 (1)      4 (0)        5 (0)         4 (0)       4 (0)              6 (0)    8 (0)\n  native man              1 (0)      8 (0)        6 (0)         6 (0)       6 (0)              8 (0)    7 (0)\n\n\nTable 4: Out of 8 models or personas, how many times is the approach significantly better than default prompt (how\nmany times it is worse) Pers. Prompt refers to persona prompt, Pers. opt refers to Persona optimized prompt, Value\nProf. refers to Value profile prompting, Weight. Maj. refers to Accuracy-based Weighted Majority Voting, Best Maj.\nrefers to Best Unweighted Majority Voting, Weigh. Maj. theo. refers to Theoretical Optimal Weighted Majority\nVoting\n\n\nB  F1 Score Comparison Tables\n\n\n\n\n\n                                         12\n\nModel/Persona   Pers. opt   Value Prof.   Weigh. Maj.   Best Maj.   Weigh. Maj. theo.  SVM\n         llama8b             7 (0)        6 (1)         8 (0)       8 (0)              8 (0)    7 (0)\n         dllama8b            5 (1)        7 (1)         7 (0)       7 (0)              7 (0)    7 (0)\n         llama70b            2 (2)        4 (1)         2 (0)       3 (0)              2 (0)    3 (0)\n         dllama70b           2 (4)        4 (1)         5 (0)       5 (0)              5 (0)    7 (0)\n        qwen14b            0 (0)        3 (2)            2(2)       3 (0)              2 (2)    8 (0)\n        dqwen14b           4 (1)        2 (3)         6 (0)       8 (0)              6 (0)    7 (0)\n        qwen32b            1 (2)        1 (3)         1 (2)       2 (0)              1 (2)    4 (1)\n        dqwen32b           2 (2)        2 (0)         6 (0)       4 (0)              5 (0)    8 (0)\n         Total             23 (12)      25 (13)        37 (4)      40 (0)             36 (4)   51 (1)\n         white woman         2 (4)        2 (5)         4 (2)       4 (0)              3 (2)    6 (0)\n         white man           3 (1)        5 (1)         6 (0)       7 (0)              6 (0)    8 (0)\n          asian woman         2 (2)        3 (0)         4 (0)       4 (0)              4 (0)    6 (0)\n          asian man           2 (1)        3 (2)         2 (0)       4 (0)              2 (0)    7 (0)\n          hispanic woman      3 (0)        0 (3)         6 (0)       5 (0)              6 (0)    5 (0)\n          hispanic man         2 (3)        3 (2)         4 (1)       5 (0)              4 (1)    7 (1)\n         black woman         4 (1)        3 (0)         5 (1)       5 (0)              5 (1)    6 (0)\n          native man           5 (0)        6 (0)         6 (0)       6 (0)              6 (0)    6 (0)\n\n\nTable 5: Out of 8 models or personas, how many times is the approach significantly better than persona prompt\n(how many times it is worse)\n\n\n              Model/Persona   Pers. opt   Weigh. Maj.   Best Maj.   Weigh. Maj. theo.  SVM\n               llama8b             4 (0)         3 (1)       4 (0)              2 (1)    4 (0)\n               dllama8b            5 (1)         1 (2)       1 (0)              1 (2)    7 (0)\n               llama70b            5 (1)         5 (1)       4 (0)              5 (1)    5 (0)\n               dllama70b           1 (5)         2 (1)       2 (0)              2 (1)    5 (0)\n             qwen14b            1 (2)         3 (2)       3 (0)              3 (2)    7 (0)\n              dqwen14b           4 (1)         5 (0)       5 (0)              7 (0)    7 (0)\n             qwen32b            3 (2)         4 (1)       4 (0)              4 (1)    5 (0)\n              dqwen32b           0 (3)         2 (2)       1 (0)              1 (2)    7 (0)\n                Total             19 (18)       25 (10)      24 (0)            23 (10)   47 (0)\n                white woman         5 (3)         7 (0)       6 (0)              5 (0)    8 (0)\n                white man           3 (4)         3 (3)       3 (0)              3 (3)    7 (0)\n                 asian woman         1 (4)         1 (3)       1 (0)              1 (3)    5 (0)\n                 asian man           3 (2)         3 (1)       3 (0)              3 (1)    8 (0)\n                 hispanic woman      5 (0)         8 (0)       8 (0)              8 (0)    8 (0)\n                 hispanic man         2 (3)         3 (2)       3 (0)              3 (2)    6 (0)\n                black woman         0 (1)         0 (1)       0 (0)              0 (1)    2 (0)\n                  native man           0 (1)         0 (0)       0 (0)              0 (0)    3 (0)\n\n\nTable 6: Out of 8 models or personas, how many times is the approach significantly better than value profile prompt\n(how many times it is worse)\n\n\n                    Model/Persona   Weigh. Maj.   Best Maj.   Weigh. Maj. theo.  SVM\n                     llama8b                0 (2)       2 (0)              0 (4)    3 (0)\n                     dllama8b               2 (0)       2 (0)              2 (0)    7 (0)\n                     llama70b               3 (0)       5 (0)              3 (0)    4 (0)\n                     dllama70b              5 (1)       5 (0)              4 (0)    6 (0)\n                  qwen14b               4 (1)       5 (0)              4 (1)    8 (0)\n                   dqwen14b              4 (0)       5 (0)              4 (0)    6 (0)\n                  qwen32b               1 (0)       2 (0)              1 (0)    5 (1)\n                   dqwen32b              4 (0)       3 (0)              4 (0)    5 (0)\n                      Total                 23 (4)      28 (0)             23 (6)   44 (1)\n                      white woman            4 (2)       4 (0)              4 (3)    8 (0)\n                      white man              5 (0)       7 (0)              5 (1)    8 (0)\n                       asian woman            3 (0)       4 (0)              3 (0)    6 (0)\n                       asian man              2 (1)       3 (0)              2 (1)    6 (0)\n                       hispanic woman         2 (1)       3 (0)              2 (1)    2 (0)\n                       hispanic man            3 (0)       3 (0)              3 (0)    5 (1)\n                      black woman            3 (0)       3 (0)              3 (0)    5 (0)\n                        native man              1 (0)       2 (0)              1 (0)    4 (0)\n\n\nTable 7: Out of 8 models or personas, how many times is the approach significantly better than persona optimized\nprompt (how many times it is worse)\n\n\n                                         13\n\nModel/Persona   Best Maj.   Weigh. Maj. theo.  SVM\n  llama8b              4 (0)              0 (2)    4 (0)\n  dllama8b             2 (0)              0 (0)    7 (0)\n  llama70b             3 (0)              0 (0)    2 (1)\n dllama70b            2 (0)              0 (0)    5 (0)\n qwen14b             4 (0)              0 (0)    8 (0)\n dqwen14b            1 (1)              0 (0)    3 (1)\n qwen32b             2 (0)              0 (0)    4 (1)\n dqwen32b            2 (1)              0 (1)    7 (0)\n  Total               20 (2)              0 (3)   40 (3)\n  white woman         3 (1)              0 (2)    6 (1)\n  white man            5 (1)              0 (1)    7 (0)\n  asian woman          3 (0)              0 (0)    5 (0)\n  asian man            3 (0)              0 (0)    7 (0)\n  hispanic woman       1 (0)              0 (0)    3 (1)\n  hispanic man         3 (0)              0 (0)    5 (1)\n  black woman         2 (0)              0 (0)    3 (0)\n  native man           0 (0)              0 (0)    4 (0)\n                                                                    Model/Persona  SVM\n                                                                        llama8b          5 (0)\nTable 8: Out of 8 models or personas, how many times is                   dllama8b         7 (0)\nthe approach significantly better than weighted majority                   llama70b         2 (1)\nvoting (how many times it is worse). This compares                   dllama70b        5 (0)\n                                                                qwen14b         8 (0)\nensembling methods                                                                dqwen14b        3 (1)\n                                                                qwen32b         4 (1)\n                                                                dqwen32b        7 (0)\n                                                                            Total           41 (3)\n                                                                           white woman      7 (1)\n                                                                           white man        7 (0)\n                                                                                 asian woman      5 (0)\n                                                                                 asian man         7 (0)\n                                                                                hispanic woman    3 (1)\n                                                                                hispanic man      5 (1)\n                                                                             black woman      3 (0)\n                                                                                   native man        4 (0)\n     Model/Persona   Weigh. Maj. theo.  SVM\n      llama8b                     0 (5)    1 (0)\n      dllama8b                    0 (2)    6 (0)         Table 10: Out of 8 models or personas, how many times\n      llama70b                    0 (3)    0 (0)            is the approach significantly better than theoretical op-\n     dllama70b                   0 (2)    4 (0)         timal weighted majority voting (how many times it is\n     qwen14b                    0 (4)    6 (0)\n                                                        worse). This compares ensembling methods\n     dqwen14b                   1 (1)    4 (1)\n     qwen32b                    0 (2)    3 (1)\n     dqwen32b                   0 (2)    5 (0)\n      Total                      1 (21)   29 (2)\n      white woman                0 (4)    6 (0)\n      white man                   1 (5)    4 (0)\n      asian woman                 0 (3)    4 (0)\n      asian man                   0 (3)    6 (0)\n      hispanic woman              0 (1)    0 (1)\n      hispanic man                 0 (3)    5 (1)\n      black woman                 0 (2)    2 (0)\n      native man                   0 (0)    2 (0)\n\n\nTable 9: Out of 8 models or personas, how many times\nis the approach significantly better than best majority\nvoting (how many times it is worse). This compares\nensembling methods\n\n\n\n\n\n                                         14\n\nModel-config   W Wom. W Man   A. Wom.   A. Man   H. Wom.   H. Man   B. Wom.   N. Man\n                                         Reasoning Effect\nllama8b                      0.63      0.66        0.58      0.65        0.66       0.68       0.62      0.74\ndllama8b                     0.65      0.68        0.59      0.61        0.73       0.67       0.63      0.66\nllama70b                     0.75      0.76        0.68      0.74        0.77       0.80       0.70      0.82\ndllama70b                    0.73      0.75        0.65      0.68        0.77       0.76       0.68      0.77\nqwen14b                     0.70      0.71        0.62      0.63        0.77       0.71       0.67      0.75\ndqwen14b                    0.71      0.73        0.64      0.68        0.76       0.73       0.68      0.76\nqwen32b                     0.71      0.74        0.63      0.66        0.77       0.74       0.67      0.75\ndqwen32b                    0.70      0.72        0.62      0.64        0.76       0.72       0.66      0.73\n                                           Persona Effect\nllama8b                      0.63      0.66        0.58      0.65        0.66       0.68       0.62      0.74\nllama8b-persona              0.68      0.69        0.63      0.71        0.70       0.71       0.65      0.77\nllama8b-val_prof             0.69      0.69        0.68      0.75        0.67       0.73       0.65      0.81\ndllama8b                     0.65      0.68        0.59      0.61        0.73       0.67       0.63      0.66\ndllama8b-persona             0.64      0.68        0.55      0.58        0.73       0.65       0.60      0.63\ndllama8b-val_prof            0.65      0.70        0.61      0.64        0.71       0.68       0.67      0.68\nllama70b                     0.75      0.76        0.68      0.74        0.77       0.80       0.70      0.82\nllama70b-persona             0.78      0.78        0.73      0.82        0.74       0.81       0.71      0.84\nllama70b-val_prof            0.77      0.76        0.74      0.81        0.75       0.81       0.71      0.85\ndllama70b                    0.73      0.75        0.65      0.68        0.77       0.76       0.68      0.77\ndllama70b-persona            0.75      0.77        0.69      0.78        0.76       0.76       0.69      0.79\ndllama70b-val_prof           0.72      0.77        0.70      0.79        0.76       0.81       0.70      0.87\nqwen14b                     0.70      0.71        0.62      0.63        0.77       0.71       0.67      0.75\nqwen14b-persona             0.72      0.74        0.65      0.70        0.77       0.76       0.68      0.75\nqwen14b-val_prof            0.70      0.76        0.66      0.71        0.75       0.73       0.67      0.83\ndqwen14b                    0.71      0.73        0.64      0.68        0.76       0.73       0.68      0.76\ndqwen14b-persona            0.71      0.74        0.63      0.70        0.76       0.74       0.66      0.76\ndqwen14b-val_prof           0.70      0.74        0.65      0.69        0.75       0.74       0.69      0.86\nqwen32b                     0.71      0.74        0.63      0.66        0.77       0.74       0.67      0.75\nqwen32b-persona             0.76      0.77        0.69      0.77        0.74       0.81       0.70      0.81\nqwen32b-val_prof            0.74      0.78        0.69      0.73        0.75       0.79       0.70      0.83\ndqwen32b                    0.70      0.72        0.62      0.64        0.76       0.72       0.66      0.73\ndqwen32b-persona            0.71      0.73        0.65      0.71        0.75       0.77       0.67      0.75\ndqwen32b-val_prof           0.71      0.76        0.66      0.72        0.75       0.78       0.68      0.82\n                                 Automated Prompt Engineering\nlama8b-persona               0.68      0.69        0.63      0.71        0.70       0.71       0.65      0.77\nllama8b-persona_opt          0.70      0.71        0.64      0.77        0.75       0.73       0.66      0.82\ndllama8b-persona             0.64      0.68        0.55      0.58        0.73       0.65       0.60      0.63\ndllama8b-persona_opt         0.63      0.71        0.60      0.63        0.73       0.67       0.56      0.71\nllama70b-persona             0.78      0.78        0.73      0.82        0.74       0.81       0.71      0.84\nllama70b-persona_opt         0.77      0.78        0.65      0.82        0.76       0.82       0.70      0.86\ndllama70b-persona            0.75      0.77        0.69      0.78        0.76       0.76       0.69      0.79\ndllama70b-persona_opt        0.76      0.75        0.65      0.76        0.77       0.74       0.68      0.87\nqwen14b-persona             0.72      0.74        0.65      0.70        0.77       0.76       0.68      0.75\nqwen14b-persona_opt         0.73      0.74        0.64      0.69        0.76       0.74       0.67      0.79\ndqwen14b-persona            0.71      0.74        0.63      0.70        0.76       0.74       0.66      0.76\ndqwen14b-persona_opt        0.72      0.74        0.69      0.69        0.77       0.71       0.68      0.76\nqwen32b-persona             0.76      0.77        0.69      0.77        0.74       0.81       0.70      0.81\nqwen32b-persona_opt         0.71      0.77        0.69      0.77        0.77       0.80       0.69      0.83\ndqwen32b-persona            0.71      0.73        0.65      0.71        0.75       0.77       0.67      0.75\ndqwen32b-persona_opt        0.69      0.74        0.65      0.72        0.76       0.71       0.69      0.83\n\n\n                      Table 11: F1 scores of each configuration for each persona\n\n\n\n\n\n                                      15\n\nModel-config     W Wom. W Man   A. Wom.   A. Man   H. Wom.   H. Man   B. Wom.   N. Man\nllama8b                             0.63      0.66        0.58      0.65        0.66       0.68       0.62      0.74\nllama8b-persona                     0.68      0.69        0.63      0.71        0.70       0.71       0.65      0.77\nllama8b-val_prof                    0.69      0.69        0.68      0.75        0.67       0.73       0.65      0.81\nllama8b-persona_opt                 0.70      0.71        0.64      0.77        0.75       0.73       0.66      0.82\nllama8b-best_majority               0.70      0.72        0.68      0.77        0.75       0.74       0.66      0.83\nllama8b-weighted_maj               0.71      0.71        0.66      0.75        0.72       0.74       0.66      0.82\nllama8b-weighted_maj_theo          0.71      0.71        0.66      0.75        0.72       0.74       0.66      0.82\nllama8b-SVM                       0.71      0.72        0.67      0.76        0.75       0.73       0.67      0.80\ndllama8b                            0.65      0.68        0.59      0.61        0.73       0.67       0.63      0.66\ndllama8b-persona                    0.64      0.68        0.55      0.58        0.73       0.65       0.60      0.63\ndllama8b-val_prof                   0.65      0.70        0.61      0.64        0.71       0.68       0.67      0.68\ndllama8b-persona_opt                0.63      0.71        0.60      0.63        0.73       0.67       0.56      0.71\ndllama8b-best_majority              0.65      0.71        0.61      0.64        0.74       0.68       0.67      0.71\ndllama8b-weighted_maj              0.65      0.71        0.59      0.63        0.74       0.68       0.64      0.69\ndllama8b-weighted_maj_theo         0.65      0.71        0.59      0.63        0.74       0.68       0.64      0.69\ndllama8b-SVM                      0.69      0.73        0.65      0.71        0.74       0.72       0.66      0.76\nllama70b                            0.75      0.76        0.68      0.74        0.77       0.80       0.70      0.82\nllama70b-persona                    0.78      0.78        0.73      0.82        0.74       0.81       0.71      0.84\nllama70b-val_prof                   0.77      0.76        0.74      0.81        0.75       0.81       0.71      0.85\nllama70b-persona_opt                0.77      0.78        0.65      0.82        0.76       0.82       0.70      0.86\nllama70b-best_majority              0.78      0.79        0.74      0.82        0.78       0.83       0.72      0.87\nllama70b-weighted_maj              0.78      0.78        0.73      0.82        0.77       0.82       0.70      0.85\nllama70b-weighted_maj_theo         0.78      0.78        0.73      0.82        0.77       0.82       0.70      0.85\nllama70b-SVM                      0.78      0.78        0.74      0.82        0.78       0.82       0.70      0.85\ndllama70b                          0.73      0.75        0.65      0.68        0.77       0.76       0.68      0.77\ndllama70b-persona                   0.75      0.77        0.69      0.78        0.76       0.76       0.69      0.79\ndllama70b-val_prof                  0.72      0.77        0.70      0.79        0.76       0.81       0.70      0.87\ndllama70b-persona_opt              0.76      0.75        0.65      0.76        0.77       0.74       0.68      0.87\ndllama70b-best_majority             0.76      0.77        0.70      0.79        0.77       0.81       0.70      0.87\ndllama70b-weighted_maj             0.75      0.77        0.69      0.78        0.77       0.78       0.70      0.87\ndllama70b-weighted_maj_theo        0.75      0.77        0.69      0.78        0.77       0.78       0.70      0.87\ndllama70b-SVM                     0.77      0.78        0.71      0.80        0.77       0.82       0.70      0.88\nqwen14b                            0.70      0.71        0.62      0.63        0.77       0.71       0.67      0.75\nqwen14b-persona                    0.72      0.74        0.65      0.70        0.77       0.76       0.68      0.75\nqwen14b-val_prof                   0.70      0.76        0.66      0.71        0.75       0.73       0.67      0.83\nqwen14b-persona_opt                0.73      0.74        0.64      0.69        0.76       0.74       0.67      0.79\nqwen14b-best_majority              0.73      0.76        0.66      0.71        0.78       0.76       0.68      0.83\nqwen14b-weighted_maj              0.72      0.74        0.65      0.70        0.78       0.75       0.68      0.80\nqwen14b-weighted_maj_theo         0.72      0.74        0.65      0.70        0.78       0.75       0.68      0.80\nqwen14b-SVM                      0.75      0.77        0.69      0.75        0.78       0.79       0.69      0.85\ndqwen14b                           0.71      0.73        0.64      0.68        0.76       0.73       0.68      0.76\ndqwen14b-persona                   0.71      0.74        0.63      0.70        0.76       0.74       0.66      0.76\ndqwen14b-val_prof                  0.70      0.74        0.65      0.69        0.75       0.74       0.69      0.86\ndqwen14b-persona_opt               0.72      0.74        0.69      0.69        0.77       0.71       0.68      0.76\ndqwen14b-best_majority             0.72      0.76        0.69      0.73        0.78       0.75       0.69      0.86\ndqwen14b-weighted_maj             0.72      0.76        0.68      0.70        0.78       0.74       0.69      0.85\ndqwen14b-weighted_maj_theo        0.72      0.76        0.68      0.70        0.78       0.74       0.69      0.85\ndqwen14b-SVM                     0.75      0.76        0.68      0.76        0.77       0.78       0.70      0.86\nqwen32b                            0.71      0.74        0.63      0.66        0.77       0.74       0.67      0.75\nqwen32b-persona                    0.76      0.77        0.69      0.77        0.74       0.81       0.70      0.81\nqwen32b-val_prof                   0.74      0.78        0.69      0.73        0.75       0.79       0.70      0.83\nqwen32b-persona_opt                0.71      0.77        0.69      0.77        0.77       0.80       0.69      0.83\nqwen32b-best_majority              0.76      0.78        0.69      0.77        0.77       0.81       0.70      0.83\nqwen32b-weighted_maj              0.74      0.77        0.69      0.77        0.77       0.81       0.69      0.82\nqwen32b-weighted_maj_theo         0.74      0.77        0.69      0.77        0.77       0.81       0.69      0.82\nqwen32b-SVM                      0.76      0.78        0.69      0.78        0.77       0.79       0.70      0.86\ndqwen32b                           0.70      0.72        0.62      0.64        0.76       0.72       0.66      0.73\ndqwen32b-persona                   0.71      0.73        0.65      0.71        0.75       0.77       0.67      0.75\ndqwen32b-val_prof                  0.71      0.76        0.66      0.72        0.75       0.78       0.68      0.82\ndqwen32b-persona_opt               0.69      0.74        0.65      0.72        0.76       0.71       0.69      0.83\ndqwen32b-best_majority             0.71      0.76        0.66      0.72        0.77       0.78       0.69      0.83\ndqwen32b-weighted_maj             0.73      0.75        0.66      0.72        0.77       0.76       0.69      0.81\ndqwen32b-weighted_maj_theo        0.73      0.75        0.66      0.72        0.77       0.76       0.69      0.81\ndqwen32b-SVM                     0.73      0.77        0.68      0.78        0.76       0.80       0.69      0.86\n\n\n        Table 12: F1 scores of each configuration for each persona. This table compares all methods.\n\n\n\n                                       16",
"headers": [
"arXiv:2601.02337v1  [cs.CL]  5 Jan 2026",
"Robust Persona-Aware Toxicity Detection with Prompt Optimization and",
"Learned Ensembling",
"Ninareh Mehrabi",
"Resolution",
"Berk Atil",
"Pennsylvania State University",
"bka5352@psu.edu",
"Rebecca J. Passonneau",
"rjp49@psu.edu",
"Abstract",
"1",
"Introduction",
"2",
"Related Work",
"3",
"Methods",
"4",
"Dataset and Models",
"5",
"Results",
"6",
"Conclusion",
"Limitations",
"References",
"A",
"Pairwise Comparison Tables",
"B",
"F1 Score Comparison Tables",
"The detection of toxic and offensive language is",
"by raters’ perspectives, social priors, and the so-",
"cial groups targeted in the text (",
"Sap et al.",
",",
"2020a",
";",
"Sorensen et al.",
"2025a",
"). Further, previous work",
"suggests that each text should be annotated by",
"the group of people who are targeted in the text",
"tion (",
"Mostafazadeh Davani et al.",
"2024",
"Fleisig",
"detection that explicitly models toxicity from the",
"perspective of demographic personas: instead of",
"centric cues into LLM behavior (",
"Xu et al.",
"Dash et al.",
"2025",
"), and LLM-based judges are in-",
"creasingly used as scalable evaluators for subjec-",
"no single method",
"consistently dominates across",
"ing method for toxicity detection and show that",
"their strengths are complementary across model–",
"persona pairs. Then, we propose a new persona",
"prompting strategy learned via automatic prompt",
"entiation” to iteratively refine prompts (",
"Yuksek-",
"gonul et al.",
"). Empirically, this optimized",
"prompting performs comparably to value-profile",
"and aggregation for improving reliability when",
"individual systems have heterogeneous error pat-",
"terns (",
"Jiang et al.",
"2023",
"Yang et al.",
"Ai",
"While ensembles improve average performance,",
"we still observe patterns where a single prompt-",
"ing method remains preferable for particular per-",
"a lightweight meta-ensemble that treats the four",
"learns a discriminative combiner using a support",
"achieves the",
"best",
"overall performance and is the",
"Bias and unintended correlations in toxicity",
"plifies this issue: demographic-aligned language",
"features (e.g., African-American English) differ",
"insensitivity to dialect has been shown to induce",
"racial bias in hate-speech annotation and down-",
"stream classifiers (",
"2019a",
"). These find-",
"ings motivate approaches that explicitly account",
"for contextual and social perspectives when judg-",
"In sum, our contributions are (i) carrying out",
"tion for different personas, showing that no sin-",
"gle method is superior; (ii) introducing a prompt-",
"on TextGrad (",
"Yuksekgonul et al.",
") with per-",
"formance comparable to value profiles (",
"Sorensen",
"et al.",
"); (iii) benchmarking a range of en-",
"sembling strategies inspired by prior LLM aggre-",
"gation work (",
"the strongest results overall (",
"Cortes and Vapnik",
"In this section, we review offensive language de-",
"on subjectivity, concluding the section with a dis-",
"Subjectivity, annotator effects, and pluralistic",
"agreements can be informative rather than noise",
"light that annotation guidelines, sampling strate-",
"Toxicity and offensive language detection.",
"hateful, or offensive language in online text, of-",
"forum data. Early and widely used resources in-",
"2017",
"Founta et al.",
"2018",
"Wulczyn et al.",
")",
"data. Some tasks, such as OffensEval, further at-",
"tempt to standardize evaluation for offensive lan-",
"recent datasets expand coverage and difficulty by",
"tle/implicit hate (",
"ElSherief et al.",
"2021",
"), or gen-",
"erating large-scale synthetic toxic/benign exam-",
"ples about minority groups to test spurious cor-",
"relations (",
"Hartvigsen et al.",
"2022",
"). LLMs have",
"been also explored as automated classifiers for",
"sonably strong agreement with crowd labels but",
"remaining sensitive to prompt wording (",
"Li et al.",
"uct deployments similarly report using LLMs to",
"stitute for or guide human moderation workflows",
"work aggregate labels into a single one, ignoring",
"Aggregating multiple LLM judgments.",
"Be-",
"cause LLM outputs can be non-deterministic and",
"Building on research in biased toxicity detec-",
"Dixon et al.",
"Borkan et al.",
"2019",
"Sap",
"2019b",
") and pluralistic annotation (",
"Aroyo",
"and Welty",
"2015",
"Waseem",
"2016",
"), we study how",
"demographic perspectives can be operationalized",
"their influence on both overall performance and",
"sis to LLM aggregation methods (",
"Ai et al.",
") to evaluate whether combining",
"judgments improves reliability. We believe this",
"is one of the first systematic work that explores",
"We experiment with different prompts that help",
"guide LLMs to think from the perspective of a",
"not assign any persona. In addition to these, we",
"from different models. Because all of the ensem-",
"70% for the test for each persona. All results in-",
"cluding single prompting techniques are reported",
"The first ensembling approach we experiment",
"data.",
"We call this approach",
"“Accuracy-based",
"weight” for a model “m” is",
". We call",
"this approach",
"“Theoretical Optimal Weighted",
"Majority Voting”",
". This is similar to",
"(",
") in terms of adjusting weights based on ac-",
"Voting",
", which looks at all possible subsets of the",
"persona, and value profile) and chooses the best",
"prompts (",
"), where we instruct the",
"model to condition its toxicity judgments on the",
"specified persona. Further, we experiment with",
"examples where there are disagreements among",
") or humans (",
"Galton",
"1907",
"). Hence, we ex-",
"Inspired by",
"2025b",
") and the po-",
"tential of automated prompt optimization (",
"Yük-",
"(APE) techniques for each persona and model so",
"for each persona and model. We use TextGrad",
") as an APE which uses",
"the current prompt. We sample 100 examples for",
"To the best of our knowledge, no work explores",
"are",
"linear",
"combiners. However, non-linear meth-",
"ods might have a higher potential. On the other",
"annotations with demographic information of the",
"tion of gender and race (we refer to each gender",
"The McNemar is a paired, nonparametric test for",
"same data, and checks whether their error rates",
"differ significantly. We analyze the effects of rea-",
"), and Qwen2.5 14b/32b (",
"Qwen et al.",
"models. Additionally, we analyze the effect of",
"reasoning-enhanced models. For this, we use R1-",
"degrades the performance for larger models (See",
"the top portion of Table",
"12",
"in Appendix). This",
"soning mostly for logical and mathematical tasks",
"works for most models except Distilled Llama8b",
"and works better for non-reasoning models (see",
"ure",
"shows that persona prompt degrades per-",
"formance for Hispanic woman and does not have",
"much effect for Native man. It also does not im-",
"all, all three persona-based methods outperform",
"tive of some personas, but non-reasoning models",
"persona prompt is optimized for each model and",
"persona, it mostly boosts performance (in Figure",
"purple boxes outperform gray ones.). It also",
"mance improvement for non-reasoning models is",
"timization improves performance on all personas",
"sona prompt overall. (see Figure",
"and Table",
"in",
"for White man, Hispanic woman, Black woman,",
"and Native man. For the other personas, both ap-",
"mation to reflect the offensive content perception",
"Accuracy-based Weighted Majority Voting",
"Value Profile Prompt",
"Figure",
"shows that",
"providing value profiles outperforms the default",
"prompt significantly in most cases. Its effect is",
"ther, it improves performance on all personas ex-",
"than persona prompt (see Figure",
"in Appendix).",
"However, the performances are",
"Asian man and Hispanic woman, but the persona",
"prompt is more effective for White woman and",
"prompting also tailors prompts for each persona.",
"Overall, the ordering of the methods is",
"Opti-",
"Best Unweighted Majority Voting",
"Since the",
"purpose of this approach is to set an upper limit",
"for an unweighted majority voting approaches, it",
"for all models and personas as expected. There",
"are a few cases, where both approaches are com-",
"parable. We should note that we choose the best",
"Here, we combine the predictions of previous",
"prompting methods for each model in different",
"prompting method. All ensembling methods out-",
"perform it in most cases. Value profile prompt",
"is better than Accuracy-based Weighted Majority",
"Voting for Distilled Llama8b, Asian woman, and",
"Black woman. They are comparable for Distilled",
"Qwen32b, White man, and Native man. Best Un-",
"for Distilled Llama8b, Distilled Qwen32b, Asian",
"woman, Black woman, and Native man. Theoret-",
"ical Optimal Weighted Majority Voting performs",
"Theoretical Optimal Weighted Majority Vot-",
"ing",
"This performs similar to Accuracy-based",
"Weighted Majority Voting so it also outperform",
"single prompting methods in most cases; though,",
"its performance vary based on a model and per-",
"them is superior. On the other hand, this method",
"based Weighted Majority Voting",
". SVM is the",
"each method pairwise and Table",
"in Appendix",
"prompting methods and SVM is the best method",
"Voting outperforms the others, but in most cases,",
"they are not significant and that method has an",
"tions from single prompting methods is the most",
"single prompting methods in",
"all",
"cases. Its effec-",
"When",
"we",
"compare",
"this",
"method",
"against",
"8",
"in Appendix) and Theoretical Opti-",
"10",
"in Appendix), we see that SVM outperforms",
"both methods in most cases. SVM is comparable",
"parable for Llama8b/70b and Hispanic woman.",
"This shows that weighted ensembling methods",
"methods for hate speech detection based on per-",
"sonas. Even an SVM classifier with an input of",
"binary vector of predictions for different prompt-",
"SVM >",
"To see the effect of using different numbers of",
"prompts, we conduct an ablation study where we",
"prompting methods and the ablation models take",
"either two or three. For each LLM, we pick the",
"best combination of two and three promptings by",
"model with the best SVMs that use two or three",
"the four prompts is superior to any subset, which",
"suggests that they have complementary strengths",
"ing, yet with disagreement patterns that indicate",
"complementary strengths. To make use of this",
"SVM classifier over binary prompt outputs. This",
"simple method is the only method that is consis-",
"tently better across the full set of model–persona",
"configurations. Our findings suggest that the fu-",
"but also a perspective problem: demographically",
"distinct personas can legitimately disagree on the",
"toxicity of the same post. In this work, we eval-",
"icity detection and showed that while a persona",
"conditioned prompt usually improves over a non-",
"sistently dominates across all personas and base",
"perception and can even degrade performance in",
"larger models for social reasoning tasks. We fur-",
"Our study focuses on limited set of personas. We",
"els from two family. Our findings might differ",
"in closed-source models. In addition, we focus",
"the models behave differently. Last but not least,",
"soning traces via sampling and voting to increase",
"the same model instead of combining predictions",
"the personas that have a reasonable (",
") num-",
"is the persona that has the most offensive content.",
"do not look at queer gender types and some other",
"a simple but efficient classifier that takes a binary",
"boosts performance for reasoning models; perfor-",
"hand, the ensembling process already has compu-",
"1947",
") to compare approaches pairwise and report",
"than Best Unweighted Majority Voting too (more",
"prompts. Lastly, we propose a prompting method",
"20% of the data for train, 10% for validation, and",
"different for each persona, and in most cases they",
"the default prompt with varying success based on",
"This ensembling method outperforms each single",
"given demographic differences in toxicity percep-",
"conditioning (",
"), but the two",
"Value Profiles (",
"), which are",
"distilled models (e.g. R1 Distilled Qwen 14b/32b",
"ways and compare the effect of ensembling meth-",
"show that ensembling methods outperform single",
"only",
"approach that consistently outperforms each",
"and suggests new prompts based on the loss from",
"group etc. Also, for each post, they have multiple",
"soning models, persona prompts, and ensembling",
"tilled Qwen32b Asian woman, and Black woman.",
"Qwen32b models. Value profile is more effective,",
"consistent and powerful approach. It outperforms",
"viding a more reliable approach to model the sub-",
"cent work has explored inference-time prompting",
"methods disagree on a non-trivial subset of exam-",
"annotator. In this work, we focus on the combina-",
"Regarding the effect on different personas, Fig-",
"looking at the accuracies of SVM trained on each",
"prompts competitive with value-profile condition-",
"uated persona-aware prompting strategies for tox-",
"prompting approaches and a non-persona prompt-",
"at least one vote for offensive, we aggregate them",
"sekgönül et al.",
"), we suggest optimizing per-",
"make the function non-linear. As train and valida-",
"of that persona usually improves the performance",
"combination on test set, hence this method has an",
"performance disparities among different personas",
"mixture of perspectives, making it especially rele-",
"via prompting for offensiveness classification and",
"ber of examples. Table",
"gives the statistics about",
"mar’s test to compare if the model predictions are",
"The reason behind this might be that value profile",
"rable for Distilled Qwen14b/32b, Native man and",
"); and (iv) proposing an SVM meta-",
"tational costs. Based on these factors, we propose",
"ing both model performance and fairness (",
"Vidgen",
"city detection settings where labels are subjective,",
"is a prompting-based approach and thanks to opti-",
"improves performance against persona prompting",
"only method including other ensembling methods",
"shows that SVM is significantly better",
"only on English but there are other languages that",
"subgroup behavior. We further connect this analy-",
"adding spans (",
"Mathew et al.",
"), targeting sub-",
"SVM",
"SVM trained on a binary vector of predic-",
"strategy based on TextGrad that produces persona",
"common races. Further, we experiment with mod-",
"ten using labeled data built from social media and",
"guage identification (",
"Zampieri et al.",
"). More",
"hypothetical maximum accuracy you can get with",
"persona prompt, no single prompting method con-",
"optimization, using TextGrad-style textual “differ-",
"on reliability and bias, when LLM judgments sub-",
"with is",
") which is a weighted ma-",
"is a tie, we choose to be conservative so if there is",
"from different models (",
"els (see Table",
"in Appendix for all results). Over-",
"They perform similarly for White man and Native",
"niques to combine the four prompting approaches.",
"bling approaches require training data, we reserve",
"extracted from in-context examples. The aim is to",
"accuracy, we and use Gpt4o as an optimizer LLM.",
"(e.g. compare gray and pink boxes in Figure",
"). It",
"based on the model and persona. They are compa-",
"different annotators. Each prompt can be found in",
"prompting method in most cases. Its effectiveness",
"ture of pluralistic toxicity detection lies in learned",
"Toxicity detection is not only a modeling problem",
"default (no persona) prompt aggregated over mod-",
"comparable for Qwen14b, Distilled Qwen14b and",
"overall. In some cases, Best Unweighted Majority",
"all personas and all underlying base models.",
"ples, suggesting that neither is superior.",
"city perception.",
"purely lexical phenomenon.",
"individual prompting strategy.",
"1995",
").",
"cussion of work on ensembling LLMs.",
"tives and analyze disagreement patterns instead of",
"aggregating labels into a single ground truth.",
"vant for analyzing disagreement and bias.",
"demographic perspectives.",
"perform better than previous methods.",
"3.1",
"Prompting Methods",
"on the same test set.",
"log",
"as offensive.",
"Table",
".",
"3.3",
"Proposed Prompting and Ensembling",
"Approaches",
"3.2",
"Ensembling Techniques",
"ing the perspectives of different personas.",
"other ensembling approaches.",
"4.1",
"Dataset",
">",
"400",
"the dataset for each persona.",
"comparison and an ablation study of the SVM.",
"4.2",
"Models",
"5.1",
"Reasoning Effect",
"are significantly different.",
"5.2",
"Persona-based Prompt Effects",
"personas, it boosts performance.",
"models tend to predict non-offensive more often.",
"except Hispanic woman.",
"proaches are comparable.",
"ods see Tables",
"7",
"in Appendix.",
"changes depending on a model and persona.",
"cept Hispanic woman.",
"Hispanic woman.",
"in a more guided way.",
"> default Prompt",
"5.3",
"Ensembling Methods",
"advantage over the other methods.",
"ods.",
"most cases (see Figure",
"9",
"better for all models and personas.",
"5.4",
"Overall Comparison",
"combination on test set.",
"5.5",
"Ablation Study on SVM",
"it is always better.",
"to both methods for Llama70b.",
"unmatched by any pair or triple.",
"jective judgments of heterogeneous groups.",
"remain in all methods.",
"11",
"13",
"14",
"15",
"16",
"such as swear words. Dialect variation further am-",
"conditioned prompting methods for toxicity detec-",
"Some work study the automatic detection of toxic,",
"two related binary data, e.g., two classifiers on the",
"formance for reasoning models as well, except for",
"able to approximate how different personas would",
"an additional LLM (the ’optimizer’) that criticizes",
"vector of 4 representing predictions from different",
"and race combination as a “persona.”). We choose",
"Distilled Qwen14b (c.f Table",
"in Appendix). Fur-",
"mal Weighted Majority Voting (Figure",
"). This motivates",
"“pluralistic”",
"toxicity",
"In this work, we study two persona-conditioned",
"vector machine (SVM) (",
"models.",
"Machine learning models might rely on",
"bling works explore weighted voting and dynamic",
"might indicate that large models are already doing",
"sonas, value profile is better for White man, Black",
"sonas or base models. To address this, we propose",
"weights proposed by",
"), the “optimal",
"tive of the corresponding persona effectively. This",
"woman, and Native man. They are comparable for",
"(see Table",
"in Appendix more details)",
"sona. These two methods are comparable, none of",
"details are in Table",
"in Appendix). They are com-",
"do not inherently solve the challenge of subjective",
"ing offensiveness, rather than treating toxicity as a",
"Aroyo and Welty",
"Fleisig et al.",
"). Sys-",
"some reasoning internally and enhancing their rea-",
"predictions worse. In our dataset, hispanic woman",
"Previous ensembling approaches rely mostly on",
"methods. We conclude this section with an overall",
"First, we compare the default prompts for the base",
"This motivated us to check the predictions and our",
"is worse than Best Unweighted Majority Voting in",
"ings can learn to predict better for a given persona.",
"tematic reviews of abusive-language datasets high-",
"support moderation decisions, motivating research",
"the importance of background and culture for toxi-",
"and R1 Distilled Llama 8b/70b) (",
"Guo et al.",
"inputs. These results show that the combination of",
"prompting techniques (default, persona, optimized",
"natural language descriptions of underlying values",
"we can force the models to think from the perspec-",
"shows the comparison of prompts against",
"Llama70b, Distilled Llama70b, Qwen14b/32b and",
"Based on Figure",
", we can see that value profile",
"based Weighted Majority Voting (see Figure",
"and",
"heterogeneity, we explored ensembling techniques",
"fundamentally a subjective task, deeply influenced",
"LLMs as judges for toxicity detection for different",
"but in a natural and explicit description. Similar to",
"models and their reasoning-enhanced counterparts.",
"the models and persona. They work better for non-",
"file prompting which is one of the best performing",
"one of the first systematic comparisons of persona-",
"and Derczynski",
"2020",
"). This line of work suggests",
"), we used Gemini1.5 Pro to",
"dia posts with annotations for offensiveness, target",
"for “hispanic woman,” and value profile makes the",
"Persona optimized Prompt",
"Similarly, when the",
"man. For the comparison to other prompting meth-",
"ther introduced an automated prompt-optimization",
"and propose a meta-ensembling approach using an",
"models. We show that reasoning-enhanced models",
"bustness. Self-consistency aggregates multiple rea-",
"7 offensive and 7 non-offensive examples from the",
"Optimal Weighted Majority Voting = Accuracy-",
"Best Unweighted Majority Voting > Theoretical",
"combination. Figure",
"compares the original SVM",
"First, we examine the effect of assigning a persona",
"the accuracy of the methods on a training set to ad-",
"We have a similar observation for personas as well.",
"Motivated by the broader success of ensembling",
"curacy but they use a different formula. Further, as",
"similar to optimizing prompts, and it improves per-",
"Accuracy-based Weighted Majority Voting (Figure",
"to incorporate perspective-taking and other human-",
"ensemble over binary prompt outputs that achieves",
"sona prompts using automated prompt engineering",
"We see that reasoning helps for smaller models but",
"hurts their social reasoning. Also, we apply McNe-",
"need a trigger to do that. None of these works well",
"gies, and annotator populations vary widely, affect-",
"the predictions from the same model with different",
"still greater, though (see Table",
"in Appendix). Op-",
"and an ensembling method, which, in combination,",
"training and 100 for validation, our loss function is",
"Optimizing persona prompt outperforms the per-",
"especially for Llama-based models. Regarding per-",
"ensembling of diverse prompting perspectives, pro-",
"aggregation can also be viewed as approximating a",
"Majority voting is common to combine predictions",
"plore weighted and unweighted majority voting ap-",
"percentage wins of each method against each other.",
"details). One of the methods works better for some",
"predicting a single majority label, models should be",
"judge the same content (",
"). Re-",
"tive NLP tasks (",
"Zheng et al.",
"Liu et al.",
"However, our systematic evaluation across multiple",
"models shows that a central practical issue remains:",
"), we evaluate multiple ensembling tech-",
"prompting outputs as a binary prediction vector and",
"Across our experiments, this SVM-based ensemble",
"surface patterns and have biases towards some texts,",
"from mainstream norms (",
"Blodgett et al.",
"), and",
"optimization approach for persona prompting based",
"tection and biases of LLMs. Then, we review work",
"labeling.",
"Toxicity perception is inherently subjec-",
"tive and shaped by context, norms, and background.",
"More generally, annotation research argues that dis-",
"evaluation setups should consider multiple perspec-",
"clude Twitter-based hate/offensive (",
"Davidson et al.",
"hateful/offensive/toxic content, often achieving rea-",
"Mishra and Chatterjee",
"). Industry prod-",
"Markov et al.",
"OpenAI",
"). Most of these",
"sensitive to prompting, aggregation can improve ro-",
"accuracy (",
"Wang et al.",
"). Multi-prompt ensem-",
"selection to exploit complementary strengths across",
"systems (",
"). In toxi-",
"persona. We also have a “default” prompt that does",
"experiment with ensembling techniques to combine",
"proaches and propose a simple ensembling method.",
"Here, we combine different prompting methods for",
"jority voting technique where the weights are corre-",
"lated with the accuracy of the approach on a “train”",
"Weighted Majority voting”",
". Second, we apply the",
"a baseline we have the",
"Best Unweighted Majority",
"performing one on the test set (so this approach can",
"be considered as the oracle approach which has the",
"an unweighted ensembling method). This approach",
"gets the best possible accuracy on the test set when",
"an unweighted majority voting is used. When there",
"to an LLM. We experiment with perspective-taking",
"preserve the information from in-context examples,",
"create value profiles. For each persona, we selected",
"mization we aim to have the most effective prompts",
"APE for toxicity detection, especially for represent-",
"just the weights of the methods. Hence, all of them",
"prompting methods (default, persona, value profile,",
"optimized persona) for each persona. The classifier",
"of our ensemble is",
"with a Gaussian Kernel to",
"tion data, we use the same splits that we use for the",
"We experiment with the Social Bias Frames dataset",
"2020b",
"), which has 44k unique social me-",
"In all results, we apply McNemar’s test (",
"McNemar",
"We experiment with Llama3.1 70b/8b (",
"Dubey et al.",
"prove results much for Black woman. For the other",
"reasoning models which might indicate that reason-",
"ing models might implicitly think from the perspec-",
"analysis shows that when a persona prompt is used,",
"Appendix). However, it does not improve much for",
"Distilled Qwen32b models. Further, it works better",
"Persona Prompt",
"Simply assigning persona infor-",
"Providing value profiles is also a better approach",
"prompting, and optimizing prompts for each model",
"and persona perform similarly (see Table",
"for more",
"models and the other one works better for the others.",
"Therefore, it somehow also “optimizes” the prompt",
"mized Prompt = Value Profile > Persona Prompt",
"This ensembling method is better than Accuracy-",
"in Appendix), though its effectiveness differ",
"compares ensembling approaches against value pro-",
"weighted Majority Voting is similar to value profile",
"worse than value profile for Distilled Llama8b, Dis-",
"and single prompting techniques that is consistently",
"compares the significant differences among",
"compares each method in terms of F1 scores. They",
"advantage over other methods by choosing the best",
"tiveness changes based on a model and persona but",
"have a better potential than unweighted ensembling",
"vary the number of prompts as inputs to SVM. Our",
"original SVM model takes predictions from all four"
],
"tables": [
"|Prompt Type|Prompt|\n|---|---|\n|Definition|Offensiveness denotes the overall rudeness, disrespect, or toxicity of a post.<br>whether apost could be considered offensive to anyone.|\n|Persona|You are supposed to decide if the given text toxic or offensive based on the<br>following definition:_ {definition}_ Imagine you were persona and how you would<br>feel about thegiven statement ifyou were _{persona}_.|\n|Value Profile|You are supposed to decide if the given text toxic or offensive based on the<br>following definition: _{definition}_ Value Profile: _{Value Profile}_|\n|Default|You are an helpful assistant and expert in linguistic analysis. You will decide if<br>thegiven statement is offensive. _{definition}_|",
"|Persona|# of Examples|Offensiveness %|\n|---|---|---|\n|Asian Woman<br>Asian Man<br>Black Woman<br>White Woman<br>White Man<br>Hispanic Woman<br>Hispanic Man<br>Native Man|2829<br>4468<br>4414<br>32125<br>31964<br>4109<br>3007<br>471|51.11<br>36.59<br>54.05<br>54.09<br>56.65<br>65.40<br>50.05<br>40.51|",
"|Model/Persona|Pers. Prompt|Pers. opt|Value Prof.|Weigh. Maj.|Best Maj.|Weigh. Maj. theo.|SVM|\n|---|---|---|---|---|---|---|---|\n|llama8b<br>dllama8b<br>llama70b<br>dllama70b<br>qwen14b<br>dqwen14b<br>qwen32b<br>dqwen32b<br>**Total**|7 (0)<br>0 (5)<br>4 (1)<br>4 (0)<br>5 (0)<br>2 (0)<br>7 (1)<br>5 (0)<br>34(7)|8 (0)<br>4 (1)<br>5 (1)<br>4 (1)<br>6 (1)<br>4 (1)<br>6 (0)<br>6 (0)<br>43(5)|7 (0)<br>4 (1)<br>3 (1)<br>6 (2)<br>6 (1)<br>2 (2)<br>7 (0)<br>6 (0)<br>42(8)|8 (0)<br>3 (0)<br>5 (0)<br>7 (0)<br>6(0)<br>7 (0)<br>7 (0)<br>7 (0)<br>50(0)|8 (0)<br>5 (0)<br>8 (0)<br>7 (0)<br>7 (0)<br>7 (0)<br>7 (0)<br>7 (0)<br>57(0)|8 (0)<br>3 (0)<br>5 (0)<br>7 (0)<br>7 (0)<br>7 (0)<br>7 (0)<br>7 (0)<br>50(0)|8 (0)<br>8 (0)<br>6 (0)<br>7 (0)<br>8 (0)<br>7 (0)<br>7 (0)<br>7 (0)<br>58(0)|\n|white woman<br>white man<br>asian woman<br>asian man<br>hispanic woman<br>hispanic man<br>black woman<br>native man|6 (1)<br>7 (0)<br>6 (1)<br>7 (1)<br>1 (2)<br>4 (1)<br>2 (1)<br>1 (0)|6 (1)<br>8 (0)<br>5 (1)<br>7 (0)<br>1 (1)<br>4 (2)<br>4 (0)<br>8 (0)|5 (2)<br>7 (0)<br>7 (0)<br>7 (0)<br>0 (6)<br>5 (0)<br>5 (0)<br>6 (0)|7 (0)<br>8 (0)<br>7 (0)<br>8 (0)<br>3 (0)<br>7 (0)<br>4 (0)<br>6 (0)|7 (0)<br>8 (0)<br>8 (0)<br>8 (0)<br>3 (0)<br>7 (0)<br>4 (0)<br>6 (0)|7 (0)<br>8 (0)<br>8 (0)<br>8 (0)<br>5 (0)<br>7 (0)<br>6 (0)<br>8 (0)|8 (0)<br>8 (0)<br>8 (0)<br>8 (0)<br>3 (0)<br>8 (0)<br>8 (0)<br>7 (0)|",
"|Model/Persona|Pers. opt|Value Prof.|Weigh. Maj.|Best Maj.|Weigh. Maj. theo.|SVM|\n|---|---|---|---|---|---|---|\n|llama8b<br>dllama8b<br>llama70b<br>dllama70b<br>qwen14b<br>dqwen14b<br>qwen32b<br>dqwen32b<br>**Total**|7 (0)<br>5 (1)<br>2 (2)<br>2 (4)<br>0 (0)<br>4 (1)<br>1 (2)<br>2 (2)<br>23(12)|6 (1)<br>7 (1)<br>4 (1)<br>4 (1)<br>3 (2)<br>2 (3)<br>1 (3)<br>2 (0)<br>25(13)|8 (0)<br>7 (0)<br>2 (0)<br>5 (0)<br>2(2)<br>6 (0)<br>1 (2)<br>6 (0)<br>37(4)|8 (0)<br>7 (0)<br>3 (0)<br>5 (0)<br>3 (0)<br>8 (0)<br>2 (0)<br>4 (0)<br>40(0)|8 (0)<br>7 (0)<br>2 (0)<br>5 (0)<br>2 (2)<br>6 (0)<br>1 (2)<br>5 (0)<br>36(4)|7 (0)<br>7 (0)<br>3 (0)<br>7 (0)<br>8 (0)<br>7 (0)<br>4 (1)<br>8 (0)<br>51(1)|\n|white woman<br>white man<br>asian woman<br>asian man<br>hispanic woman<br>hispanic man<br>black woman<br>native man|2 (4)<br>3 (1)<br>2 (2)<br>2 (1)<br>3 (0)<br>2 (3)<br>4 (1)<br>5 (0)|2 (5)<br>5 (1)<br>3 (0)<br>3 (2)<br>0 (3)<br>3 (2)<br>3 (0)<br>6 (0)|4 (2)<br>6 (0)<br>4 (0)<br>2 (0)<br>6 (0)<br>4 (1)<br>5 (1)<br>6 (0)|4 (0)<br>7 (0)<br>4 (0)<br>4 (0)<br>5 (0)<br>5 (0)<br>5 (0)<br>6 (0)|3 (2)<br>6 (0)<br>4 (0)<br>2 (0)<br>6 (0)<br>4 (1)<br>5 (1)<br>6 (0)|6 (0)<br>8 (0)<br>6 (0)<br>7 (0)<br>5 (0)<br>7 (1)<br>6 (0)<br>6 (0)|",
"|Model/Persona|Pers. opt|Weigh. Maj.|Best Maj.|Weigh. Maj. theo.|SVM|\n|---|---|---|---|---|---|\n|llama8b<br>dllama8b<br>llama70b<br>dllama70b<br>qwen14b<br>dqwen14b<br>qwen32b<br>dqwen32b<br>**Total**|4 (0)<br>5 (1)<br>5 (1)<br>1 (5)<br>1 (2)<br>4 (1)<br>3 (2)<br>0 (3)<br>19(18)|3 (1)<br>1 (2)<br>5 (1)<br>2 (1)<br>3 (2)<br>5 (0)<br>4 (1)<br>2 (2)<br>25(10)|4 (0)<br>1 (0)<br>4 (0)<br>2 (0)<br>3 (0)<br>5 (0)<br>4 (0)<br>1 (0)<br>24(0)|2 (1)<br>1 (2)<br>5 (1)<br>2 (1)<br>3 (2)<br>7 (0)<br>4 (1)<br>1 (2)<br>23(10)|4 (0)<br>7 (0)<br>5 (0)<br>5 (0)<br>7 (0)<br>7 (0)<br>5 (0)<br>7 (0)<br>47(0)|\n|white woman<br>white man<br>asian woman<br>asian man<br>hispanic woman<br>hispanic man<br>black woman<br>native man|5 (3)<br>3 (4)<br>1 (4)<br>3 (2)<br>5 (0)<br>2 (3)<br>0 (1)<br>0 (1)|7 (0)<br>3 (3)<br>1 (3)<br>3 (1)<br>8 (0)<br>3 (2)<br>0 (1)<br>0 (0)|6 (0)<br>3 (0)<br>1 (0)<br>3 (0)<br>8 (0)<br>3 (0)<br>0 (0)<br>0 (0)|5 (0)<br>3 (3)<br>1 (3)<br>3 (1)<br>8 (0)<br>3 (2)<br>0 (1)<br>0 (0)|8 (0)<br>7 (0)<br>5 (0)<br>8 (0)<br>8 (0)<br>6 (0)<br>2 (0)<br>3 (0)|",
"|Model/Persona|Weigh. Maj.|Best Maj.|Weigh. Maj. theo.|SVM|\n|---|---|---|---|---|\n|llama8b<br>dllama8b<br>llama70b<br>dllama70b<br>qwen14b<br>dqwen14b<br>qwen32b<br>dqwen32b<br>**Total**|0 (2)<br>2 (0)<br>3 (0)<br>5 (1)<br>4 (1)<br>4 (0)<br>1 (0)<br>4 (0)<br>23(4)|2 (0)<br>2 (0)<br>5 (0)<br>5 (0)<br>5 (0)<br>5 (0)<br>2 (0)<br>3 (0)<br>28(0)|0 (4)<br>2 (0)<br>3 (0)<br>4 (0)<br>4 (1)<br>4 (0)<br>1 (0)<br>4 (0)<br>23(6)|3 (0)<br>7 (0)<br>4 (0)<br>6 (0)<br>8 (0)<br>6 (0)<br>5 (1)<br>5 (0)<br>44(1)|\n|white woman<br>white man<br>asian woman<br>asian man<br>hispanic woman<br>hispanic man<br>black woman<br>native man|4 (2)<br>5 (0)<br>3 (0)<br>2 (1)<br>2 (1)<br>3 (0)<br>3 (0)<br>1 (0)|4 (0)<br>7 (0)<br>4 (0)<br>3 (0)<br>3 (0)<br>3 (0)<br>3 (0)<br>2 (0)|4 (3)<br>5 (1)<br>3 (0)<br>2 (1)<br>2 (1)<br>3 (0)<br>3 (0)<br>1 (0)|8 (0)<br>8 (0)<br>6 (0)<br>6 (0)<br>2 (0)<br>5 (1)<br>5 (0)<br>4 (0)|",
"|Model/Persona|Best Maj.|Weigh. Maj. theo.|SVM|\n|---|---|---|---|\n|llama8b<br>dllama8b<br>llama70b<br>dllama70b<br>qwen14b<br>dqwen14b<br>qwen32b<br>dqwen32b<br>**Total**|4 (0)<br>2 (0)<br>3 (0)<br>2 (0)<br>4 (0)<br>1 (1)<br>2 (0)<br>2 (1)<br>20(2)|0 (2)<br>0 (0)<br>0 (0)<br>0 (0)<br>0 (0)<br>0 (0)<br>0 (0)<br>0 (1)<br>0 (3)|4 (0)<br>7 (0)<br>2 (1)<br>5 (0)<br>8 (0)<br>3 (1)<br>4 (1)<br>7 (0)<br>40(3)|\n|white woman<br>white man<br>asian woman<br>asian man<br>hispanic woman<br>hispanic man<br>black woman<br>native man|3 (1)<br>5 (1)<br>3 (0)<br>3 (0)<br>1 (0)<br>3 (0)<br>2 (0)<br>0 (0)|0 (2)<br>0 (1)<br>0 (0)<br>0 (0)<br>0 (0)<br>0 (0)<br>0 (0)<br>0 (0)|6 (1)<br>7 (0)<br>5 (0)<br>7 (0)<br>3 (1)<br>5 (1)<br>3 (0)<br>4 (0)|",
"|Model/Persona|SVM|\n|---|---|\n|llama8b<br>dllama8b<br>llama70b<br>dllama70b<br>qwen14b<br>dqwen14b<br>qwen32b<br>dqwen32b<br>**Total**|5 (0)<br>7 (0)<br>2 (1)<br>5 (0)<br>8 (0)<br>3 (1)<br>4 (1)<br>7 (0)<br>41(3)|\n|white woman<br>white man<br>asian woman<br>asian man<br>hispanic woman<br>hispanic man<br>black woman<br>native man|7 (1)<br>7 (0)<br>5 (0)<br>7 (0)<br>3 (1)<br>5 (1)<br>3 (0)<br>4 (0)|",
"|Model/Persona|Weigh. Maj. theo.|SVM|\n|---|---|---|\n|**Model/Persona**|**Weigh. Maj. theo.**|**SVM**|\n|llama8b<br>dllama8b<br>llama70b<br>dllama70b<br>qwen14b<br>dqwen14b<br>qwen32b<br>dqwen32b<br>**Total**|0 (5)<br>0 (2)<br>0 (3)<br>0 (2)<br>0 (4)<br>1 (1)<br>0 (2)<br>0 (2)<br>1 (21)|1 (0)<br>6 (0)<br>0 (0)<br>4 (0)<br>6 (0)<br>4 (1)<br>3 (1)<br>5 (0)<br>29(2)|\n|white woman<br>white man<br>asian woman<br>asian man<br>hispanic woman<br>hispanic man<br>black woman<br>native man|0 (4)<br>1 (5)<br>0 (3)<br>0 (3)<br>0 (1)<br>0 (3)<br>0 (2)<br>0 (0)|6 (0)<br>4 (0)<br>4 (0)<br>6 (0)<br>0 (1)<br>5 (1)<br>2 (0)<br>2 (0)|",
"|Model-config|W Wom.|W Man|A. Wom.|A. Man|H. Wom.|H. Man|B. Wom.|N. Man|\n|---|---|---|---|---|---|---|---|---|",
"|Model-config|W Wom.|W Man|A. Wom. Reasoning|A. Man Effect|H. Wom.|H. Man|B. Wom.|N. Man|\n|---|---|---|---|---|---|---|---|---|\n|llama8b<br>dllama8b|0.63<br>**0.65**|0.66<br>**0.68**|0.58<br>**0.59**|**0.65**<br>0.61|0.66<br>**0.73**|**0.68**<br>0.67|0.62<br>**0.63**|**0.74**<br>0.66|\n|llama70b<br>dllama70b|**0.75**<br>0.73|**0.76**<br>0.75|**0.68**<br>0.65|**0.74**<br>0.68|0.77<br>0.77|**0.80**<br>0.76|**0.70**<br>0.68|**0.82**<br>0.77|\n|qwen14b<br>dqwen14b|0.70<br>**0.71**|0.71<br>**0.73**|0.62<br>**0.64**|0.63<br>**0.68**|**0.77**<br>0.76|0.71<br>**0.73**|0.67<br>**0.68**|0.75<br>**0.76**|\n|qwen32b<br>dqwen32b|**0.71**<br>0.70|**0.74**<br>0.72|**0.63**<br>0.62|**0.66**<br>0.64|**0.77**<br>0.76|**0.74**<br>0.72|**0.67**<br>0.66|**0.75**<br>0.73|",
"|llama8b<br>llama8b-persona<br>llama8b-val prof<br>_|0.63<br>0.68<br>0.69|0.66<br>0.69<br>0.69|0.58<br>0.63<br>0.68|0.65<br>0.71<br>0.75|0.66<br>0.70<br>0.67|0.68<br>0.71<br>0.73|0.62<br>0.65<br>0.65|0.74<br>0.77<br>0.81|\n|---|---|---|---|---|---|---|---|---|\n|dllama8b<br>dllama8b-persona<br>dllama8b-val_prof|**0.65**<br>0.64<br>**0.65**|0.68<br>0.68<br>**0.70**|0.59<br>0.55<br>**0.61**|0.61<br>0.58<br>**0.64**|**0.73**<br>**0.73**<br>0.71|0.67<br>0.65<br>**0.68**|0.63<br>0.60<br>**0.67**|0.66<br>0.63<br>**0.68**|\n|llama70b<br>llama70b-persona<br>llama70b-val_prof|0.75<br>**0.78**<br>0.77|0.76<br>**0.78**<br>0.76|0.68<br>0.73<br>**0.74**|0.74<br>**0.82**<br>0.81|**0.77**<br>0.74<br>0.75|0.80<br>**0.81**<br>**0.81**|0.70<br>**0.71**<br>**0.71**|0.82<br>0.84<br>**0.85**|\n|dllama70b<br>dllama70b-persona<br>dllama70b-val_prof|0.73<br>**0.75**<br>0.72|0.75<br>**0.77**<br>**0.77**|0.65<br>0.69<br>**0.70**|0.68<br>0.78<br>**0.79**|**0.77**<br>0.76<br>0.76|0.76<br>0.76<br>**0.81**|0.68<br>0.69<br>**0.70**|0.77<br>0.79<br>**0.87**|\n|qwen14b<br>qwen14b-persona<br>qwen14b-val_prof|0.70<br>**0.72**<br>0.70|0.71<br>0.74<br>**0.76**|0.62<br>0.65<br>**0.66**|0.63<br>0.70<br>**0.71**|**0.77**<br>**0.77**<br>0.75|0.71<br>**0.76**<br>0.73|0.67<br>**0.68**<br>0.67|0.75<br>0.75<br>**0.83**|\n|dqwen14b<br>dqwen14b-persona<br>dqwen14b-val_prof|**0.71**<br>**0.71**<br>0.70|0.73<br>**0.74**<br>**0.74**|0.64<br>0.63<br>**0.65**|0.68<br>**0.70**<br>0.69|**0.76**<br>**0.76**<br>0.75|0.73<br>**0.74**<br>**0.74**|0.68<br>0.66<br>**0.69**|0.76<br>0.76<br>**0.86**|\n|qwen32b<br>qwen32b-persona<br>qwen32b-val_prof|0.71<br>**0.76**<br>0.74|0.74<br>0.77<br>**0.78**|0.63<br>**0.69**<br>**0.69**|0.66<br>**0.77**<br>0.73|**0.77**<br>0.74<br>0.75|0.74<br>**0.81**<br>0.79|0.67<br>**0.70**<br>**0.70**|0.75<br>0.81<br>**0.83**|\n|dqwen32b<br>dqwen32b-persona<br>dqwen32b-val_prof|0.70<br>**0.71**<br>**0.71**|0.72<br>0.73<br>**0.76**|0.62<br>0.65<br>**0.66**|0.64<br>0.71<br>**0.72**|**0.76**<br>0.75<br>0.75|0.72<br>0.77<br>**0.78**|0.66<br>0.67<br>**0.68**|0.73<br>0.75<br>**0.82**|",
"|lama8b-persona<br>llama8b-persona opt<br>_|0.68<br>0.70|0.69<br>0.71|0.63<br>0.64|0.71<br>0.77|0.70<br>0.75|0.71<br>0.73|0.65<br>0.66|0.77<br>0.82|\n|---|---|---|---|---|---|---|---|---|\n|dllama8b-persona<br>dllama8b-persona_opt|**0.64**<br>0.63|0.68<br>**0.71**|0.55<br>**0.60**|0.58<br>**0.63**|0.73<br>0.73|0.65<br>**0.67**|**0.60**<br>0.56|0.63<br>**0.71**|\n|llama70b-persona<br>llama70b-persona_opt|**0.78**<br>0.77|0.78<br>0.78|**0.73**<br>0.65|0.82<br>0.82|0.74<br>**0.76**|0.81<br>**0.82**|**0.71**<br>0.70|0.84<br>**0.86**|\n|dllama70b-persona<br>dllama70b-persona_opt|0.75<br>**0.76**|**0.77**<br>0.75|**0.69**<br>0.65|**0.78**<br>0.76|0.76<br>**0.77**|**0.76**<br>0.74|**0.69**<br>0.68|0.79<br>**0.87**|\n|qwen14b-persona<br>qwen14b-persona_opt|0.72<br>**0.73**|0.74<br>0.74|**0.65**<br>0.64|**0.70**<br>0.69|**0.77**<br>0.76|**0.76**<br>0.74|**0.68**<br>0.67|0.75<br>**0.79**|\n|dqwen14b-persona<br>dqwen14b-persona_opt|0.71<br>**0.72**|0.74<br>0.74|0.63<br>**0.69**|**0.70**<br>0.69|0.76<br>**0.77**|**0.74**<br>0.71|0.66<br>**0.68**|0.76<br>0.76|\n|qwen32b-persona<br>qwen32b-persona_opt|**0.76**<br>0.71|0.77<br>0.77|0.69<br>0.69|0.77<br>0.77|0.74<br>**0.77**|**0.81**<br>0.80|**0.70**<br>0.69|0.81<br>**0.83**|\n|dqwen32b-persona<br>dqwen32b-persona_opt|**0.71**<br>0.69|0.73<br>**0.74**|0.65<br>0.65|0.71<br>**0.72**|0.75<br>**0.76**|**0.77**<br>0.71|0.67<br>**0.69**|0.75<br>**0.83**|",
"|Model-config|W Wom.|W Man|A. Wom.|A. Man|H. Wom.|H. Man|B. Wom.|N. Man|\n|---|---|---|---|---|---|---|---|---|\n|llama8b<br>llama8b-persona<br>llama8b-val_prof<br>llama8b-persona_opt<br>llama8b-best_majority<br>llama8b-weighted_maj<br>llama8b-weighted_maj_theo<br>llama8b-SVM|0.63<br>0.68<br>0.69<br>0.70<br>0.70<br>**0.71**<br>**0.71**<br>**0.71**|0.66<br>0.69<br>0.69<br>0.71<br>**0.72**<br>0.71<br>0.71<br>**0.72**|0.58<br>0.63<br>**0.68**<br>0.64<br>**0.68**<br>0.66<br>0.66<br>0.67|0.65<br>0.71<br>0.75<br>**0.77**<br>**0.77**<br>0.75<br>0.75<br>0.76|0.66<br>0.70<br>0.67<br>**0.75**<br>**0.75**<br>0.72<br>0.72<br>**0.75**|0.68<br>0.71<br>0.73<br>0.73<br>**0.74**<br>**0.74**<br>**0.74**<br>0.73|0.62<br>0.65<br>0.65<br>0.66<br>0.66<br>0.66<br>0.66<br>**0.67**|0.74<br>0.77<br>0.81<br>0.82<br>**0.83**<br>0.82<br>0.82<br>0.80|\n|dllama8b<br>dllama8b-persona<br>dllama8b-val_prof<br>dllama8b-persona_opt<br>dllama8b-best_majority<br>dllama8b-weighted_maj<br>dllama8b-weighted_maj_theo<br>dllama8b-SVM|0.65<br>0.64<br>0.65<br>0.63<br>0.65<br>0.65<br>0.65<br>**0.69**|0.68<br>0.68<br>0.70<br>0.71<br>0.71<br>0.71<br>0.71<br>**0.73**|0.59<br>0.55<br>0.61<br>0.60<br>0.61<br>0.59<br>0.59<br>**0.65**|0.61<br>0.58<br>0.64<br>0.63<br>0.64<br>0.63<br>0.63<br>**0.71**|0.73<br>0.73<br>0.71<br>0.73<br>**0.74**<br>**0.74**<br>**0.74**<br>**0.74**|0.67<br>0.65<br>0.68<br>0.67<br>0.68<br>0.68<br>0.68<br>**0.72**|0.63<br>0.60<br>**0.67**<br>0.56<br>**0.67**<br>0.64<br>0.64<br>0.66|0.66<br>0.63<br>0.68<br>0.71<br>0.71<br>0.69<br>0.69<br>**0.76**|\n|llama70b<br>llama70b-persona<br>llama70b-val_prof<br>llama70b-persona_opt<br>llama70b-best_majority<br>llama70b-weighted_maj<br>llama70b-weighted_maj_theo<br>llama70b-SVM|0.75<br>**0.78**<br>0.77<br>0.77<br>**0.78**<br>**0.78**<br>**0.78**<br>**0.78**|0.76<br>0.78<br>0.76<br>0.78<br>**0.79**<br>0.78<br>0.78<br>0.78|0.68<br>0.73<br>**0.74**<br>0.65<br>**0.74**<br>0.73<br>0.73<br>**0.74**|0.74<br>**0.82**<br>0.81<br>**0.82**<br>**0.82**<br>**0.82**<br>**0.82**<br>**0.82**|0.77<br>0.74<br>0.75<br>0.76<br>**0.78**<br>0.77<br>0.77<br>**0.78**|0.80<br>0.81<br>0.81<br>0.82<br>**0.83**<br>0.82<br>0.82<br>0.82|0.70<br>0.71<br>0.71<br>0.70<br>**0.72**<br>0.70<br>0.70<br>0.70|0.82<br>0.84<br>0.85<br>0.86<br>**0.87**<br>0.85<br>0.85<br>0.85|\n|dllama70b<br>dllama70b-persona<br>dllama70b-val_prof<br>dllama70b-persona_opt<br>dllama70b-best_majority<br>dllama70b-weighted_maj<br>dllama70b-weighted_maj_theo<br>dllama70b-SVM|0.73<br>0.75<br>0.72<br>0.76<br>0.76<br>0.75<br>0.75<br>**0.77**|0.75<br>0.77<br>0.77<br>0.75<br>0.77<br>0.77<br>0.77<br>**0.78**|0.65<br>0.69<br>0.70<br>0.65<br>0.70<br>0.69<br>0.69<br>**0.71**|0.68<br>0.78<br>0.79<br>0.76<br>0.79<br>0.78<br>0.78<br>**0.80**|**0.77**<br>0.76<br>0.76<br>**0.77**<br>**0.77**<br>**0.77**<br>**0.77**<br>**0.77**|0.76<br>0.76<br>0.81<br>0.74<br>0.81<br>0.78<br>0.78<br>**0.82**|0.68<br>0.69<br>**0.70**<br>0.68<br>**0.70**<br>**0.70**<br>**0.70**<br>**0.70**|0.77<br>0.79<br>0.87<br>0.87<br>0.87<br>0.87<br>0.87<br>**0.88**|\n|qwen14b<br>qwen14b-persona<br>qwen14b-val_prof<br>qwen14b-persona_opt<br>qwen14b-best_majority<br>qwen14b-weighted_maj<br>qwen14b-weighted_maj_theo<br>qwen14b-SVM|0.70<br>0.72<br>0.70<br>0.73<br>0.73<br>0.72<br>0.72<br>**0.75**|0.71<br>0.74<br>0.76<br>0.74<br>0.76<br>0.74<br>0.74<br>**0.77**|0.62<br>0.65<br>0.66<br>0.64<br>0.66<br>0.65<br>0.65<br>**0.69**|0.63<br>0.70<br>0.71<br>0.69<br>0.71<br>0.70<br>0.70<br>**0.75**|0.77<br>0.77<br>0.75<br>0.76<br>**0.78**<br>**0.78**<br>**0.78**<br>**0.78**|0.71<br>0.76<br>0.73<br>0.74<br>0.76<br>0.75<br>0.75<br>**0.79**|0.67<br>0.68<br>0.67<br>0.67<br>0.68<br>0.68<br>0.68<br>**0.69**|0.75<br>0.75<br>0.83<br>0.79<br>0.83<br>0.80<br>0.80<br>**0.85**|\n|dqwen14b<br>dqwen14b-persona<br>dqwen14b-val_prof<br>dqwen14b-persona_opt<br>dqwen14b-best_majority<br>dqwen14b-weighted_maj<br>dqwen14b-weighted_maj_theo<br>dqwen14b-SVM|0.71<br>0.71<br>0.70<br>0.72<br>0.72<br>0.72<br>0.72<br>**0.75**|0.73<br>0.74<br>0.74<br>0.74<br>**0.76**<br>**0.76**<br>**0.76**<br>**0.76**|0.64<br>0.63<br>0.65<br>0.69<br>**0.69**<br>0.68<br>0.68<br>0.68|0.68<br>0.70<br>0.69<br>0.69<br>0.73<br>0.70<br>0.70<br>**0.76**|0.76<br>0.76<br>0.75<br>0.77<br>**0.78**<br>**0.78**<br>**0.78**<br>0.77|0.73<br>0.74<br>0.74<br>0.71<br>0.75<br>0.74<br>0.74<br>**0.78**|0.68<br>0.66<br>0.69<br>0.68<br>0.69<br>0.69<br>0.69<br>**0.70**|0.76<br>0.76<br>**0.86**<br>0.76<br>**0.86**<br>0.85<br>0.85<br>**0.86**|\n|qwen32b<br>qwen32b-persona<br>qwen32b-val_prof<br>qwen32b-persona_opt<br>qwen32b-best_majority<br>qwen32b-weighted_maj<br>qwen32b-weighted_maj_theo<br>qwen32b-SVM|0.71<br>**0.76**<br>0.74<br>0.71<br>**0.76**<br>0.74<br>0.74<br>**0.76**|0.74<br>0.77<br>**0.78**<br>0.77<br>**0.78**<br>0.77<br>0.77<br>**0.78**|0.63<br>**0.69**<br>**0.69**<br>**0.69**<br>**0.69**<br>**0.69**<br>**0.69**<br>**0.69**|0.66<br>0.77<br>0.73<br>0.77<br>0.77<br>0.77<br>0.77<br>**0.78**|**0.77**<br>0.74<br>0.75<br>**0.77**<br>**0.77**<br>**0.77**<br>**0.77**<br>**0.77**|0.74<br>**0.81**<br>0.79<br>0.80<br>**0.81**<br>**0.81**<br>**0.81**<br>0.79|0.67<br>**0.70**<br>**0.70**<br>0.69<br>**0.70**<br>0.69<br>0.69<br>**0.70**|0.75<br>0.81<br>0.83<br>0.83<br>0.83<br>0.82<br>0.82<br>**0.86**|\n|dqwen32b<br>dqwen32b-persona<br>dqwen32b-val_prof<br>dqwen32b-persona_opt<br>dqwen32b-best_majority<br>dqwen32b-weighted_maj<br>dqwen32b-weighted_maj_theo<br>dqwen32b-SVM|0.70<br>0.71<br>0.71<br>0.69<br>0.71<br>**0.73**<br>**0.73**<br>**0.73**|0.72<br>0.73<br>0.76<br>0.74<br>0.76<br>0.75<br>0.75<br>**0.77**|0.62<br>0.65<br>0.66<br>0.65<br>0.66<br>0.66<br>0.66<br>**0.68**|0.64<br>0.71<br>0.72<br>0.72<br>0.72<br>0.72<br>0.72<br>**0.78**|0.76<br>0.75<br>0.75<br>0.76<br>**0.77**<br>**0.77**<br>**0.77**<br>0.76|0.72<br>0.77<br>0.78<br>0.71<br>0.78<br>0.76<br>0.76<br>**0.80**|0.66<br>0.67<br>0.68<br>**0.69**<br>**0.69**<br>**0.69**<br>**0.69**<br>**0.69**|0.73<br>0.75<br>0.82<br>0.83<br>0.83<br>0.81<br>0.81<br>**0.86**|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2601.02337v1.pdf"
}