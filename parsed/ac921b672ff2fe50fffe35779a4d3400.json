{
"text": "Improving Text-to-Image Consistency via\n       Automatic Prompt Optimization\n                Oscar Mañas1,2,3,∗, Pietro Astolfi1,∗, Melissa Hall1, Candace Ross1, Jack Urbanek1, Adina Williams1,\n                Aishwarya Agrawal2,3,5, Adriana Romero-Soriano1,2,4,5, Michal Drozdzal1\n\n              1FAIR at Meta, 2Mila, 3Université de Montréal, 4McGill University, 5Canada CIFAR AI Chair\n                 ∗Contributed equally\n\n\n                 Impressive advances in text-to-image (T2I) generative models have yielded a plethora of high performing\n                models which are able to generate aesthetically appealing, photorealistic images. Despite the progress,\n                 these models still struggle to produce images that are consistent with the input prompt, oftentimes\n                    failing to capture object quantities, relations and attributes properly. Existing solutions to improve2024          prompt-image consistency suffer from the following challenges: (1) they oftentimes require model\n                   fine-tuning, (2) they only focus on nearby prompt samples, and (3) they are affected by unfavorable\n                   trade-offs among image quality, representation diversity, and prompt-image consistency. In this paper,Mar         we address these challenges and introduce a T2I optimization-by-prompting framework, OPT2I, which\n                  leverages a large language model (LLM) to improve prompt-image consistency in T2I models. Our\n26          framework starts from a user prompt and iteratively generates revised prompts with the goal of\n                maximizing a consistency score. Our extensive validation on two datasets, MSCOCO and PartiPrompts,\n                shows that OPT2I can boost the initial consistency score by up to 24.9% in terms of DSG score while\n                 preserving the FID and increasing the recall between generated and real data. Our work paves the\n              way toward building more reliable and robust T2I systems by harnessing the power of LLMs.[cs.CV]            Date: March 27, 2024\n                  Correspondence: Oscar Mañas at oscar.manas@mila.quebec\n\n\n         1  Introduction                               have explored avenues such as adjusting the sampling\n                                                               guidance scale (Ho and Salimans, 2022), modifying\n             In  recent  years, we have witnessed remarkable    cross-attention operations (Feng et al., 2022; Epstein\n             progress in text-to-image (T2I) generative mod-    et al., 2023; Liu et al., 2022; Chefer et al., 2023; Wu\n                els (Ramesh  et  al., 2022; Saharia  et  al., 2022;    et al., 2023a), fine-tuning models (Lee et al., 2023;\n           Rombach et al., 2022b; Podell et al., 2023; Dai et al.,  Wu et al., 2023c; Sun et al., 2023), leveraging addi-\n             2023b). The photorealistic quality and aesthetics    tional input modalities such as layouts (Cho et al.,\n               of generated images has positioned T2I generative    2023b; Lian et al., 2023), and selecting images post-\n            models at the center of the current AI revolution.   hoc (Karthik et al., 2023). Most of these approaches\n            However, progress in image quality has come at    require access to the model’s weights and are notarXiv:2403.17804v1       the expense of model representation diversity and    applicable when models are only accessible through\n            prompt-image consistency (Hall et al., 2023). From a    an API interface, e.g., (Betker et al., 2023). The only\n               user’s perspective, the fact that not all the elements    two approaches that are applicable to API-accessible\n               of the input text prompt are properly represented in    models are guidance scale modification and post-hoc\n             the generated image is particularly problematic as it    image selection. However, these approaches rely on\n             induces a tedious and time-consuming trial-and-error    a single text prompt – the one provided by the user\n             process with the T2I model to refine the initial   – so their ability to generate diverse images is limited\n           prompt in order to generate the originally intended    to resampling of the input noise,  i.e., changing\n            image. Common consistency failure modes of the    the random seed. Perhaps more importantly, both\n            T2I generative models include missing objects, wrong    these approaches have unfavorable trade-offs, as they\n              object cardinality, missing or mixed object attributes,   improve prompt-image consistency at the expense\n           and non-compliance with requested spatial relation-    of image quality and diversity – e.g., high guidance\n              ships among objects in the image (Wu et al., 2023a).    scales lead to reduced image quality and diversity,\n                                                                  while post-hoc selecting the most consistent images\n          To improve prompt-image consistency, researchers\n\n\n                                                           1\n\nOptimized prompt\n                               User prompt\n                                                                                                                       A cultured raccoon, wearing formal attire and a\n           A raccoon wearing formal clothes, wearing a tophat                                                        tophat, proudly holds a cane, while a nearby garbage\n          and holding a cane. The raccoon is holding a garbage                                                          bag is artistically included in the scene. The\n           bag. Oil painting in the style of Vincent Van Gogh                                                        painting reflects the vibrant colors and textures of\n                                                                                                                              Vincent Van Gogh's oil paintings.\n\n                                 T2I                                             T2I prompt optimizer                                         T2I\n\n\n\n\n\n                                                            T2I             Scorer\n\n\n\n                                           LLM\n\n\n\n                               Scorer                                                                                               Scorer\n\n\n             1. Is there a raccoon? Yes                                                                                 1. Is there a raccoon? Yes\n             2. Is the raccoon holding a cane? Yes                                                                      2. Is the raccoon holding a cane? Yes\n             3. Is the raccoon wearing a tophat? Yes                                                                    3. Is the raccoon wearing a tophat? Yes\n             4. Is there a garbage bag? No                                                                              4. Is there a garbage bag? Yes\n             5. Is the raccoon holding a garbage bag? No                                                                5. Is the raccoon holding a garbage bag? Yes\n             ...                                                                                                        ...\n             Score: 0.6667                                                                                              Score: 1.0000\n\n\n    Figure 1  Overview of our backpropagation-free text-to-image optimization by prompting approach that\n    rewrites user prompts with the goal of improving prompt-image consistency. Our framework is composed\n     of a text-to-image generative model (T2I), a large language model (LLM) and a consistency objective (Scorer).\n   The LLM iteratively leverages a history of prompt-score pairs to suggest revised prompts. In the depicted\n    example, our system improves the consistency score by over 30% in terms of Davidsonian Scene Graph score.\n\n\n\n\ndecreases significantly the representation diversity.     to refine it. Recently, and once again in the NLP\n                                                 domain, optimization-by-prompting (OPRO) (Yang\nAt the same time, the natural language processing                                                           et al., 2023) has extended previous ICL approaches\n(NLP) community has explored large language models                                              by iteratively optimizing instruction prompts to\n(LLMs) as prompt optimizers for NLP tasks (Pryzant                                               maximize task accuracy based on a dataset  of\net al., 2023; Yang et al., 2023; Guo et al., 2023;                                                    input-output examples, leveraging feedback from\nFernando et  al., 2023), showing that LLMs can                                                       past instructions and their respective task accuracies.\nrelieve humans from the manual and tedious task\nof prompt-engineering. One particularly interesting    In this work, we propose the first ICL-based method\napproach is in-context learning (ICL) (Dong et al.,    to improve prompt-image consistency in T2I mod-\n2023), where an LLM can learn to solve a new     els.   In particular, we leverage optimization-by-\ntask from just a handful of in-context examples    prompting and introduce a novel inference-time op-\nprovided in the input prompt. Notably, LLMs can    timization framework for T2I prompts, which con-\naccomplish this without requiring parameter updates    structs a dataset of in-context examples on-the-fly.\n– e.g., LLMs can solve simple regression tasks when   Our framework, OPtimization for T2I generative\nprovided with a few input-output examples (Mirchan-   models (OPT2I), involves a pre-trained T2I model,\ndani et al., 2023). ICL enables rapid task adaptation   an LLM, and an automatic prompt-image consis-\nby changing the problem  definition  directly  in    tency score – e.g., CLIPScore (Hessel et al., 2021) or\nthe prompt.  However, ICL commonly relies on    Davidsonian Scene Graph score (DSG) (Cho et al.,\npredefined datasets of examples (input-output pairs),    2023a). Through ICL, the LLM iteratively improves\nwhich might be challenging to obtain. To the best of    a user-provided text prompt by suggesting alternative\nour knowledge, ICL has not yet been explored in the    prompts that lead to images that are more aligned\ncontext of T2I generative models, which pose unique    with the user’s intention, as measured by the con-\nchallenges: (1) the in-context examples of prompts    sistency score. At each optimization iteration, the\nand the associated scores are not readily available,    in-context examples are updated to include the best\nand (2) the LLM needs to ground the prompt in    solutions found so far.  Intuitively, we expect our\nthe generated images in order to understand how   method to explore the space of possible prompt para-\n\n\n                                               2\n\nphrases and gradually discover the patterns in its                                                                                                                               User\npreviously suggested prompts that lead to highly-                                         Generated           prompt                                                                   T2I             image\nconsistent images. Crucially, the optimized prompts\nwill produce more consistent images on expectation,\nacross multiple input noise samples. OPT2I is de-\nsigned to be a versatile approach that works as a plug-         Revised                                     Consistency\nand-play solution with diverse T2I models, LLMs,         prompt                                            Metric\nand scoring functions since it does not require any\nparameter updates. An overview of our framework is\npresented in Figure 1.                                                                                 Meta-prompt\n                                                 LLM            Task description\nThrough extensive experiments, we show that OPT2I                                                +\nconsistently  outperforms  paraphrasing  baselines                                              Prompt history\n                                                                                         Prompt\n(e.g., random paraphrasing and Promptist (Hao                           optimization\net al., 2022)), and boosts the prompt-image con-\nsistency by up to 12.2% and 24.9% on MSCOCO     Figure 2 Our prompt optimization framework, OPT2I,\n(Lin et  al., 2014) and PartiPrompts (Yu et  al.,   composed  of  (1)  a  text-to-image  (T2I)  generative\n2022) datasets, respectively.  Notably, we achieve    model that generates images from text prompts, (2) a\nthis improvement  while  preserving  the  Fréchet    consistency metric that evaluates the fidelity between the\n                                                        generated images and the user prompt, and (3) a largeInception Distance (FID) (Heusel et al., 2017) and\n                                                       language model (LLM) that leverages task descriptionincreasing the recall between generated and real data.\n                                                 and a history of prompt-score tuples to provide revised\nMoreover, we observe that OPT2I achieves consistent\n                                                      prompts.  At the beginning, the revised prompt  is\nimprovements for diverse T2I models and is robust                                                                     initialized with the user prompt.\nto the choice of LLM. Our qualitative results reveal\nthat the optimized prompts oftentimes emphasize\nthe elements of the  initial prompt that do not\n                                                        score between each generated image and the user\nappear in the generated images by either providing\n                                                prompt, and average the scores. We then initialize\nadditional details about those or reordering elements\n                                                    the meta-prompt history with the user prompt andin the prompt to place the ignored elements at the\n                                                                      its associated consistency score. Finally, we feed the\nbeginning. In summary, our contributions are:\n                                              meta-prompt to the LLM, which proposes a set of\n  • We  propose  OPT2I,  a  training-free  T2I    revised prompts. To start a new optimization step,\n    optimization-by-prompting  framework  that   we feed the revised prompts back to the T2I model\n     provides refined prompts for a T2I model that    that generate new images. Note that the consistency\n    improve prompt-image consistency.                score is always computed w.r.t. the user prompt.\n                                            At each optimization step, the meta-prompt history\n  • OPT2I is a versatile framework as it is not tied to\n                                                                        is updated to include the top-k most consistent    any particular T2I model and is robust to both\n                                                prompts (among revised prompts and user prompt),\n     the choice of LLM as well as consistency metric.\n                                                    along with their consistency score.  The prompt\n  • We show that OPT2I consistently outperforms    optimization process terminates when a maximum\n    paraphrasing  baselines and  can  boost  the   number of iterations is reached, or when a perfect/-\n    prompt-image consistency by up to 24.9%.         target consistency score is achieved. Finally, the best\n                                              prompt is selected, namely, the optimized prompt.\n2  OPT2I: Optimization by prompting\n    for T2I                                     2.1  Problem formulation\n\nFigure 2 depicts our T2I optimization-by-prompting   We assume access to an LLM, f, and a pre-trained\nframework, which is composed of a pre-trained T2I    T2I generative model, g. Given a text prompt, p, we\nmodel and an LLM that work together to optimize    can generate an image I conditioned on the prompt\na prompt-image consistency score. Our framework    with our T2I generator, I = g(p).  Let us define\nstarts from a user prompt and iteratively generates    the set of all possible paraphrases from p that can\nrevised prompts with the goal of maximizing the cho-   be obtained with an LLM as P = {pi}, and let us\nsen consistency score. More concretely, we start by    introduce a prompt-image consistency score, S(p, I).\nfeeding the user prompt to the T2I model to generate   Our objective is to find a prompt paraphrase ˆp ∈P\nmultiple images. Next, we compute the consistency    that maximizes the expected consistency score of\n\n\n                                               3\n\nsampled images:                          DSG assesses prompt-image consistency based on a\n                                                     question generation and answering approach, simi-\n                 ˆp = argmax  E   [S(p0, I)] ,                 lar to TIFA (Hu et al., 2023). In particular, DSG\n                 pi∼P   I∼g(pi)\n                                                      generates atomic and unique binary questions from\nwhere p0 denotes the user prompt. We approach    the user prompt that are organized into semantic\nthe optimization problem with ICL by iteratively   dependency graphs. For example, “a bike lying on\nsearching for revised prompts generated by the LLM,    the ground, covered in snow”  is decomposed into:\n                                                        (1) “Is there a bike?”; (2) “Is the bike lying on the\n        Pt = f(C({p0} ∪P1, . . . , ∪Pt−1)),            ground?”; (3) “Is the bike covered in snow?”. In this\n                                                           case, questions (2) and (3) depend on (1), and so\nwhere Pi is the set of prompts generated at iteration    (1) is used to validate (2) and (3). These questions\ni, t is the current iteration, and C is a function that    are then answered by an off-the-shelf VQA model\ndefines the context of prompt-score pairs fed to the    based on the generated image. We include the re-\nLLM.                                                     sulting question-answer pairs in our meta-prompt. A\n                                                        global score per prompt-image pair is computed by\n2.2  Meta-prompt design                         averaging across answer scores.\nWe adapt LLMs for T2I prompt optimization via ICL.   Decomposed CLIPScore computes a partial consis-\n                                                     tency score for each noun phrase present in the userWe denote meta-prompt the prompt which instructs\n                                                prompt. For example, “a bike lying on the ground,the LLM to optimize prompts for T2I models. Our\n                                                    covered in snow” is decomposed into “a bike”, “themeta-prompt is composed of a task instruction and\n                                                  ground” and “snow”.  Each noun phrase  is thena history of past revised prompt-score pairs. The list\n                                                       scored against the generated image using CLIPScore,of meta-prompts used can be found in Appendix A.\n                                                         resulting in a  list of pairs of noun phrases and\nThe meta-prompt provides context about T2I models,    their associated scores, which are included in our\nthe consistency metric and the optimization problem.   meta-prompt. A global score per prompt-image\nAdditionally, it contains a history of prompt-score    pair is computed by averaging across subscores. We\npairs that provides context about which paraphrases    provide examples of decomposed CLIPScore and\nworked best in the past for a particular T2I model,  DSG outputs in Appendix A.\nencouraging the LLM to build upon the most suc-\ncessful prompts and removing the need for explicitly\n                                            2.4  Exploration-exploitation trade-offspecifying how to modify the T2I prompt. The con-\nsistency score is normalized to an integer between 0    During the optimization process, OPT2I requires con-\nand 100, and we only keep in the history the top-k     trollability over the LLM’s exploration-exploitation\nscoring prompts found so far, sorted by increasing     trade-off, as the LLM could either focus on exploring\nscore.                                                     possible revised prompts or on exploiting the context\n                                                   provided in the meta-prompt history. On the one\n2.3  Optimization objective                     hand, too much exploration would hamper the\n                                                       optimization as it could be hard to find a high quality\nA critical part of our framework is feeding visual                                                           solution. On the other hand, too much exploitation\nfeedback to the LLM. The visual feedback is captured                                                 would limit the exploration to prompts that are very\nby the consistency score, which determines how good                                                         similar to the ones already presented in the meta-\nthe candidate prompt is at generating consistent                                               prompt history. We control this balance by adjusting\nimages. Although OPT2I can work with any – even                                                    the number of generated revised prompts per itera-\nnon-differentiable – consistency score, we argue that                                                         tion and the LLM sampling temperature. Moreover,\nthe consistency score must be detailed enough for                                                      as our objective is to find prompts that work well\nthe LLM to infer how to improve the candidate                                                         across different T2I input noise samples, we generate\nprompt. While CLIPScore (Hessel et al., 2021) is                                                       multiple images per prompt at each iteration.\narguably the most popular metric for measuring\nprompt-image consistency, in our initial experiments\nwe found that scoring a prompt with a single scalar  3  Experiments\nis too coarse for our purposes. Thus, we opt for two\nmetrics that provide finer-grained information about  We first introduce our experimental setting. Next,\nthe prompt-image consistency:  (1) Davidsonian   we validate the effectiveness of OPT2I in improving\nScene Graph (DSG) score (Cho et al., 2023a), and    prompt-image consistency, compare it to paraphras-\n(2) our proposed decomposed CLIPScore.               ing baselines (random paraphrasing and Promptist),\n\n\n                                               4\n\nand show some qualitative results. Then, we explore    et al., 2022). For the LLM, we experiment with the\nthe trade-offs with image quality and diversity. And   open source Llama-2-70B- chat (Llama-2) (Tou-\nfinally, we ablate OPT2I components and touch on    vron et al., 2023) and with GPT-3.5-Turbo-0613\npost-hoc image selection.                           (GPT-3.5) (Brown et al., 2020).\n\n                                                  Implementation details.  Unless stated otherwise,\n3.1  Experimental setting                   OPT2I runs for at most 30 iterations generating 5\n                                            new revised prompts per iteration, while the random\nBenchmarks. We run experiments using prompts\n                                                     paraphrasing baseline generates 150 prompts at once\nfrom MSCOCO (Lin et al., 2014) and PartiPrompts\n                                                            (see Section 3.4 for a discussion about the relationship\n(P2) (Yu et al., 2022). For MSCOCO, we use the\n                                                  between #iters and #prompts/iter). We instruct the\n2000 captions from the validation set as in (Hu et al.,\n                                 LLM to generate revised prompts by enumerating\n2023). These captions represent real world scenes\n                                            them in a single response to prevent duplication,\ncontaining common objects. PartiPrompts, instead,\n                                                      rather than making multiple calls with a sampling\nis a collection of 1600 artificial prompts, often un-\n                                                  temperature greater than 0.  In the optimization\nrealistic, divided into categories to stress different\n                                                meta-prompt, we set the history length to 5. To\ncapabilities of T2I generative models. We select our\n                                                  speed up image generation, we use DDIM (Song\nPartiPrompts subset by merging the first 50 prompts\n                                                          et al., 2020) sampling. We perform 50 inference\nfrom the most challenging categories: “Properties &\n                                                          steps with LDM-2.1, while for CDM-M we perform 100\nPositioning”, “Quantity”, “Fine-grained Detail”, and\n                                                         steps with the low-resolution generator and 50 steps\n“Complex”.  This results in a set of 185 complex\n                                                  with the super-resolution network – following the\nprompts.\n                                                          default parameters in both cases. The guidance scale\nBaselines. We compare OPT2I against a random     for both T2I models is kept to the suggested value\nparaphrasing baseline, where the LLM is asked to     of 7.5. Finally, in our experiments, we fix the initial\ngenerate diverse paraphrases of the user prompt,   random seeds across iterations and prompts wherever\nwithout any context about the consistency of the    possible, i.e. we fix 4 random seeds for sampling\nimages generated from it. The meta-prompt used to     different prior/noise vectors to generate 4 images\nobtain paraphrases is provided in Appendix A. We    from the same prompt. However, we note that CDM-M\nalso compare to Promptist Hao et al. (2022), which    does not allow batched generation with fixed seeds.\nrelies on a dataset of initial and target prompts to    Experiments without seed-fixing are reported in\nfinetune an LLM to rewrite user prompts with the   Appendix B as we observe no substantial differences.\ngoal of improving image aesthetics, while trying to\nmaintain prompt-image consistency.\n                                              3.2  Main results\nEvaluation metrics. We measure the quality of a\n                                                    T2I optimization by prompting. In Figure 3, we plotT2I prompt by averaging prompt-image consistency\n                                                      the prompt optimization curves with LDM-2.1/CDM-Mscores  across  multiple  image  generations  (i.e.,\n                                                      as T2I models, Llama-2/GPT-3.5 as LLM, and de-multiple random seeds for the initial noise).  For\n                                             composed CLIPscore (dCS)/DSG as the scorer foreach generated image, we compute its consistency\n                                               prompts from MSCOCO and PartiPrompts. Eachwith the user prompt. We consider our proposed\n                                                  data point corresponds to the mean/max relativedecomposed CLIPScore (dCS) and the recent DSG\n                                               improvement in consistency score (w.r.t. the userscore (Cho et al., 2023a) as consistency metrics (see\n                                               prompt) achieved by revised prompts generated inSection 2.3 for more details). For DSG score, we use\n                                                     that iteration, averaged across the full dataset ofInstruct-BLIP (Dai et al., 2023a) as the VQA model.\n                                                  prompts.  The optimization curves show an over-To assess the trade-off between prompt-image con-\n                                                                     all upward trend, which confirms that the LLM insistency, image quality and diversity, we additionally\n                                         OPT2I is capable of optimizing T2I prompts. Thesecompute FID score (Heusel et al., 2017), precision\n                                                improvements are especially noticeable in the maxand recall metrics (Naeem et al., 2020).\n                                                      consistency score. The initial dip in mean consis-\nLLMs and T2I models. For the T2I model, we consider    tency score is expected due to the initial exploration,\n(1) a state-of-the-art latent diffusion model, namely    since the LLM has limited context provided only\nLDM-2.1 (Rombach et al., 2022a), which uses a CLIP   by the user prompt (1-shot ICL). As the optimiza-\ntext encoder for conditioning, and (2) a cascaded    tion progresses, the LLM generates more consistent\npixel-based diffusion model, CDM-M, which instead re-    revised prompts at each iteration, as its context is in-\nlies on the conditioning from a large language model,    creasingly enriched with the performance of previous\nT5-XXL (Raffel et al., 2020), similarly to (Saharia    revised prompts. Notably, achieving a positive mean\n\n\n                                               5\n\nParaphr w/ Llama-2, LDM-2.1      Paraphr w/ GPT-3.5, LDM-2.1      Paraphr w/ Llama-2, CDM-M\n                          OPT2I w/ Llama-2, LDM-2.1        OPT2I w/ GPT-3.5, LDM-2.1        OPT2I w/ Llama-2, CDM-M\n(%)   max                      max                      max                      max                                                                    8\n   6                               6                                                             15\n                                                                    6\n   4                               4                                                             10consistency                                                                 4\n                                    2                               2                               5Relative 2   0                               0                               0                               0\n(%) 2 mean                         2 mean                         5 mean                         5 mean\n\n                                    0\n   0                                                              0                                                                                                    0consistency                                 2\n   2\n                                    4Relative                                                                 5                               5\n   4                               6     0     10    20    30      0       10      20      30      0       10      20      30      0       10      20      30\n              iteration                             iteration                              iteration                              iteration\n      (a) dCS (MSCOCO)               (b) dCS (P2)              (c) DSG (MSCOCO)             (d) DSG (P2)\n\nFigure 3 OPT2I curves with different consistency objectives (dCS vs. DSG), LLMs, and T2I models. Each plot track\neither the max or the mean relative improvement in consistency across revised prompts per iteration.\n\n\nrelative consistency starting from a single in-context     Table 1 Relative improvement in T2I consistency between\nexample is a very challenging task (Wei et al., 2023),    the user prompt and the best prompt found, averaged\n                                                              across all prompts in the dataset. Every method generatesand OPT2I achieves this goal for all configurations ex-\n                                                          the same total number of prompts (and images).\ncept for Llama-2 and GPT-3.5 in the dCS(P2) setting\n(Figure 3b), where it only get close to 0. As men-                                                                                                                                Dataset\ntioned Section 3.1, PartiPrompts is a hard benchmark       Method        Objective   LLM       T2I                                                                               MSCOCO    P2\ncontaining highly detailed and complex prompts, so it       Paraphrasing                                 +9.96     +8.00\nis perhaps unsurprising that decomposed CLIPScore      OPT2I        dCS     Llama-2   LDM-2.1   +11.88   +10.34\nfalls short (with improvements < 7% in the max case,       Paraphrasing   DSG     Llama-2   LDM-2.1    +10.67    +19.22\nand < 2% in the mean case) – given the imperfect      OPT2I                                 +11.21   +22.24\n\n                                                                         dCS     GPT-3.5   LDM-2.1decomposition into noun-phrases. We also explored a        ParaphrasingOPT2I                                       +9.81     +8.06                                                                                                     +10.35   +9.33\nhierarchical version of decomposed CLIPscore lever-       Paraphrasing                                 +10.53    +19.09\naging constituency trees, which did not show any      OPT2I       DSG     GPT-3.5   LDM-2.1   +10.85   +19.77\nimprovement over our noun-phrase based decompo-       Paraphrasing    dCS     Llama-2    CDM-M     +11.00    +10.29\nsition, further reinforcing the criticism that CLIP      OPT2I                                 +12.21   +12.13\n                                                                            Paraphrasing                                 +10.53    +22.24\nbehaves as a bag-of-words and is unable to properly      OPT2I       DSG     Llama-2    CDM-M    +11.07   +24.93\ncapture object attributes and relations (Yuksekgonul\net al., 2022; Yamada et al., 2022). Instead, using a\nmore detailed consistency score during the prompt\noptimization process, such as DSG, results in more   we can see that both paraphrasing and optimization\nsignificant improvements (< 17% in the max case,    get around a 10% boost in consistency improvement\nand < 5% in the mean case).                     when using DSG as optimization objective instead of\nComparison to paraphrasing baselines. Table 1 shows   dCS for P2 but not for MSCOCO. This highlights\nour proposed OPT2I framework is robust to the    again that more complex prompts, such as those from\nchoice of LLM, T2I model and optimization/eval-   PartiPrompts, benefit from a more accurate consis-\nuation objective.  In particular, for dCS, we re-   tency metric. We note that some prompts might\nport relative improvement as scorebest/scoreinit −1.    already have a fairly high initial consistency score\nFor DSG score, since the initial score can be zero    (see App. B.2), so there is little room for improvement.\nand it is already a percentage, we instead report    For instance, prompts from MSCOCO evaluated with\nscorebest −scoreinit. We observe that OPT2I consis-  DSG have an average initial score of 86.54%, which\ntently outperforms the random paraphrasing baseline   means that the improvement in this setting has an\nacross different LLMs and T2I models. Additionally,   upper bound of 13.46%.\n\n\n                                               6\n\nTable 2 Distributional metrics on the MSCOCO dataset.\n\n\n                                                           FID (↓)          Prec. (↑)         Rec. (↑)\n                 Prompt    Obj.    LLM        T2I\n                                                  IV3   CLIP   IV3   CLIP   IV3   CLIP\n\n                       Initial        -            -     LDM-2.1   34.6    16.0   81.6   85.9    47.2    22.8\n\n              OPT2I   dCS   Llama-2   LDM-2.1    34.6    14.9    70.7    81.0   55.6   30.0\n\n              OPT2I  DSG   Llama-2   LDM-2.1   33.3    15.4    79.0    84.3    54.4    27.0\n\n              OPT2I   dCS   GPT-3.5   LDM-2.1    34.1   14.3    74.9    84.0    53.9    27.3\n\n              OPT2I  DSG   GPT-3.5   LDM-2.1   33.4    15.6    80.3    85.4    50.5    21.7\n\n                       Initial        -            -       CDM-M     41.2   15.2   82.2   85.6    38.8    26.0\n\n              OPT2I   dCS   Llama-2    CDM-M    39.8   15.2    77.1    80.9   45.4   29.5\n\n              OPT2I  DSG   Llama-2    CDM-M    39.9   15.2    79.6    82.5    39.9    25.0\n\n\n\nIn addition to random paraphrasing, we compare   and that images generated by CDM-M from user\nOPT2I to Promptist (Hao et al., 2022) on MSCOCO    prompts are generally more consistent than those\nprompts by generating images from  initial/best    generated by LDM-2.1, which we attribute to the use\nprompts (4 images/prompt) with SD-1.4 (Promp-    of a stronger text encoder (T5-XXL instead of CLIP).\ntist’s reference model) and LDM-2.1, evaluating con-\nsistency with DSG score. We observe Promptist de-   3.3  Trade-offs with image quality and diver-\ncreases the consistency score by −3.56%/−3.29% on          sity\nSD-1.4/LDM-2.1, while OPT2I (Llama-2) improves\n                                                       Following common practice in the T2I community, weconsistency by +14.16%/+11.21%. This aligns with\n                                                        evaluate the quality of OPT2I generations by comput-the results reported in (Hao et al., 2022), which show\n                                                       ing image generation metrics such as FID, precisionthat optimizing prompts primarily for aesthetics ac-\n                                                       (P), and recall (R). We use the 2000 prompts fromtually decreases prompt-image consistency.\n                                                      the MSCOCO validation set that are included in the\nQualitative results. In Figure 4, we provide examples   TIFAv1 benchmark (Hu et al., 2023), and generate 4\nof images generated from user and optimized prompts    images for each initial and best prompt. To ensure\nwith OPT2I for different LLMs and T2I models. We    robust conclusions, we use two feature extractors\nobserve OPT2I is capable of finding paraphrases    in our metrics: Inception-v3 (IV3) (Szegedy et al.,\nof the user prompt which considerably improve the    2016) and CLIP (Radford et al., 2021). Results in\nconsistency between the generated images and the    Table 2 show that the FID of prompts optimized\ninitial, user-provided prompt, as measured by DSG    with OPT2I is either on-par or better compared to\nin this case. These examples suggest the optimized    that of initial prompts, validating that our method\nprompts are capable of steering the T2I model    does not trade image quality for consistency. Hence,\ntowards generating visual elements that were ignored   we conclude FID is not affected by our optimization\nwith the  initial phrasing.  From our qualitative    strategy. However, in terms of precision and recall,\nanalysis, we observed the LLM uses several strategies   we observe that optimized prompts reach higher re-\nto emphasize the missing visual elements, such as pro-     call at the expense of lower precision compared to the\nviding a more detailed description of those elements    user prompt. This is explainable as rephrasing the\n(e.g., “a flower” →“a vibrant flower arrangement”,    input prompt allows to generate more diverse images\n“a vase filled with fresh blossoms”) or placing them    (higher recall), which may occasionally fall outside\nat the beginning of the sentence (e.g., “four teacups     of the manifold of natural images (lower precision).\nsurrounding a kettle” →“surround a kettle placed    This phenomenon can be observed in Fig. 12 (Ap-\nat the center with four teacups”). We note a perfect    pendix B), where optimizing for consistency leads to\nconsistency score does not ensure perfectly aligned    a change of artistic style.\nimages  (e.g.,  for the user prompt “four teacups\nsurrounding a kettle”, all optimized prompts reach a   3.4  Ablations\nDSG score of 100% while the cardinality of teacups\nremains incorrect), which highlights the limitations   We perform ablations with Llama-2 and LDM-2.1\nof current prompt-image consistency scores. We also   on PartiPrompts using default parameters unless\nobserve that prompts optimized by Llama-2 tend to    otherwise specified. Figure 5 illustrates the trade-off\nbe longer than those from GPT-3.5 (see App. B.5),   between exploration and exploitation, implemented\n\n\n                                               7\n\nA horse and several cows feed on hay. (0.4643)                                                     A horse and several cows feed on hay. (0.5000)\n\n\n\n\n\n         0.4286                 0.7143                 0.1429                 0.5714                                        0.2857                 0.5714                 0.2857                 0.8571\n\n                                                                                                     A horse is seated on a stack of hay, surrounded by a herd of cows feasting on\n       A horse and multiple cows feed on a stack of hay together. (0.8929)                                          the hay, creating a festive atmosphere. (0.8571)\n\n\n\n\n\n         0.7143                 0.8571                 1.0000                 1.0000                                        0.8571                 0.8571                 0.7143                 1.0000\n\n           A bowl full of tomatoes sitting next to a flower. (0.6667)                                         A bowl full of tomatoes sitting next to a flower. (0.6667)\n\n\n\n\n\n         0.6667                 0.6667                 0.6667                 0.6667                                        0.6667                 0.6667                 0.6667                 0.6667\n\n   A ceramic bowl, overflowing with plump tomatoes, is placed beside a vibrant                         A bowl of tomatoes, topped with a beautiful flower, sitting next to a vase\n      flower arrangement, creating a visually appealing contrast. (1.0000)                                                filled with fresh blooms. (1.0000)\n\n\n\n\n\n         1.0000                 1.0000                 1.0000                 1.0000                                        1.0000                 1.0000                 1.0000                 1.0000\n\n            (a) LLM: Llama-2, T2I: LDM-2.1                                      (b) LLM: Llama-2, T2I: CDM-M\n\n   A raccoon wearing formal clothes, wearing a tophat and holding a cane. The                         A raccoon wearing formal clothes, wearing a tophat and holding a cane. The\n   raccoon is holding a garbage bag. Oil painting in the style of pointilism.                         raccoon is holding a garbage bag. Oil painting in the style of pointilism.\n                                    (0.4722)                                                                                           (0.4722)\n\n\n\n\n\n A sophisticated0.5556    raccoon, attired0.5556 in formal wear0.1111and a tophat, poses0.6667with poise                                 0.5556                 0.5556                 0.1111                 0.6667\n  and panache, holding a cane and a garbage bag, against a stunning pointilism-                        An oil painting in the style of pointillism depicting a raccoon elegantly\n    style oil painting, showcasing the raccoon's cultured appearance and the                          dressed in formal clothes, with a top hat and cane, holding a garbage bag.\n                     painting's elaborate details. (0.7500)                                                                            (0.6944)\n\n\n\n\n\n         0.5556                 0.8889                 0.6667                 0.8889                                        0.5556                 0.4444                 0.8889                 0.8889\n\n                    four teacups surounding a kettle (0.5000)                                                          four teacups surounding a kettle (0.5000)\n\n\n\n\n\n         0.0000                 0.5000                 0.7500                 0.7500                                        0.0000                 0.5000                 0.7500                 0.7500\n\n  Four teacups encircle a kettle, forming a cohesive and picturesque tea setup.\n                                    (1.0000)                                                              Surround a kettle placed at the center with four teacups. (1.0000)\n\n\n\n\n\n         1.0000                 1.0000                 1.0000                 1.0000                                        1.0000                 1.0000                 1.0000                 1.0000\n\n            (c) LLM: Llama-2, T2I: LDM-2.1                                    (d) LLM: GPT-3.5, T2I: LDM-2.1\n\nFigure 4 Selected qualitative results for prompts from MSCOCO (a-b) and P2 (c-d) datasets, using DSG as consistency\nmetric. For each setup, we display four rows (from the top): initial prompt #1, optimized prompt #1, initial prompt\n#2, and optimized prompt #2. Each column corresponds to a different T2I model random seed. We report average\nconsistency score across seeds in between parenthesis.\n\n\n                                               8\n\n10                                                95\n                                                     90\n    8\n                                                     85(%)                                                                                score\ndCS 6                                                80                                                   DSG\n                                                     75\n    4                                      Paraphr, it=1, p/it=150        70Relative                                        OPT2I, it=1, p/it=150                                            OPT2I, it=5, p/it=30                  Average65    2                                            OPT2I, it=15, p/it=10                                  Initial\n                                            OPT2I, it=30, p/it=5          60        Paraphr.\n    0                                     OPT2I, it=150, p/it=1         55       OPT2I\n       0      30     60     90     120    150           4    10   25   50   100  200  400  600\n                   #revised prompts                                          k\n\nFigure 5 Cumulative max relative dCS as a function of     Figure 6 Average DSG score for the top-k most consistent\n#revised prompts = #iterations · #prompts/iter.         images among 600.\n\n\nTable 3 Meta-prompt ablations.                                             3.5  Post-hoc image selection\n\n  Conciseness   Prioritize  Reasoning   Structure  dCS (%)    We emphasize OPT2I aims to optimize prompts to\n    ✓         ✗        ✗        ✗       +9.68       generate more consistent images on expectation. How-\n    ✓       ✓        ✗        ✗     +10.34      ever, for the sake of completeness, we also evaluate the\n    ✓       ✓      ✓        ✗      +10.23                                                            setting where we generate the same amount of images\n    ✓       ✓        ✗      ✓       +9.99\n                                                  from the initial prompt and select the most consistent\n                                                          ones. In particular, we generate 600 images from Par-\n                                                   tiPrompts using either random image sampling from\nas the number of revised prompts per iteration    the initial prompt, paraphrasing, or OPT2I, and se-\n(#prompts/iter) and the number of optimization it-    lect the top-k most consistent images based on DSG\nerations (#iterations), respectively. Generating more     score. In Fig. 6, we observe that OPT2I consistently\nprompts at each iteration increases the exploration    outperforms both baselines. Interestingly, sampling\nof multiple solutions given the same context, while    from the initial prompt outperforms paraphrasing,\nby increasing the number of iterations, the LLM can    which might be due to random paraphrases deviating\nexploit more frequent feedback from the T2I model    too much from the user’s intent.\nand the consistency score. We observe that increasing\nnumber of iterations leads to a higher consistency\nimprovement. In other words, more exploitation is  4  Related work\nbeneficial with a fixed budget of 150 prompt gener-\nations. However, pushing exploitation too much, i.e.,    Improving consistency in T2I models. Several recent\n#it = 150 and #p/it = 1, becomes harmful.          works propose extensions to T2I models to improve\n                                                             their faithfulness to user prompts. Some studies focus\nIn table 3, we report relative consistency (dCS) when    on improving the guidance with cross-attention (Feng\nablating for different task instructions in the meta-    et al., 2022; Epstein et al., 2023; Liu et al., 2022;\nprompt. We explore four instruction additions to be    Chefer et al., 2023; Wu et al., 2023a). Other studies\ncombined with our base meta-prompt. Conciseness     first convert a textual prompt into a layout before\nencourages to explore paraphrases beyond just adding    feeding it to a layout-to-image generative model (Cho\ndetails/adjectives; Prioritize encourages focusing on    et al., 2023b; Lian et al., 2023). Recent works also\nmissing/low-score elements; Reasoning encourages    finetune T2I models on human (Lee et al., 2023; Wu\nto reason about the in-context examples; and Struc-    et al., 2023c; Wallace et al., 2023) or AI model (Sun\nture asks for simple vocabulary informative of the    et al., 2023) feedback, or perform post-hoc image\nstructure of images, e.g., foreground and background    selection (Karthik et al., 2023). In contrast, OPT2I\n(full meta-prompts are provided in Appendix A). We    acts exclusively at the level of input prompt in text\nobserve that Prioritize achieves slightly better perfor-    space, without accessing model weights, making it\nmance over Reasoning and Structure, yet the LLM re-    applicable to a wider range of T2I models, including\nmains fairly robust to specific meta-prompt phrasing.    those only accessible through an API.\n\n\n                                               9\n\nLLMs as prompt optimizers. Several recent works ex-    in PartiPrompts appear to significantly benefit from\nplore the role of LLMs as prompt optimizers for NLP   more detailed scores such as DSG. Qualitatively, we\ntasks. Some use LLMs to directly optimize the task    observed that optimizing prompts for prompt-image\ninstruction for ICL (Zhou et al., 2022; Pryzant et al.,    consistency oftentimes translates into emphasizing\n2023; Yang et al., 2023). Other studies use LLMs     initially ignored elements in the generated images,\nto mutate prompts for evolutionary algorithms (Guo    by either providing additional details about those or\net al., 2023; Fernando et al., 2023). A crucial differ-    rewording the prompt such that the ignored elements\nence between these works and our method is that    appear at the beginning. Interestingly, such prompt\nthey optimize a task instruction prompt by using a    modifications steer the generated images away from\ntraining set, which is subsequently applied across test    the learned modes, resulting in a higher recall w.r.t.\nexamples, while we perform multimodal inference-    the real data distribution.\ntime optimization on individual T2I prompts. More\nsimilar to our work, other studies rewrite prompts\nfor T2I models using an LLM. (Hao et al., 2022)\nfinetunes an LLM with reinforcement learning to im-    Limitations. One limitation of our method is that\nprove image aesthetics, while (Valerio et al., 2023)     it expects prompt-image consistency scores to work\nfocuses on filtering out non-visual prompt elements.    reasonably well. However, this assumption might not\nIn contrast, OPT2I aims to improve prompt-image    hold in some cases. For instance, it has been shown\nconsistency via optimization-by-prompting.            that CLIP (used for CLIPScore) sometimes behaves\n                                                                   like a bag-of-words (Yuksekgonul et al., 2022; YamadaEvaluating prompt-image consistency. Several metrics\n                                                           et al., 2022). VQA-based prompt-image consistency\nhave been  proposed  to  evaluate prompt-image\n                                                     metrics such as TIFA or DSG also suffer from limi-\nconsistency. CLIPScore (Hessel et al., 2021) is the\n                                                          tations in generating questions (e.g., the question “Is\nde facto standard for measuring the compatibility of\n                                                      the horse on the hay?”  is generated from the prompt\nimage-caption pairs, used both for image captioning\n                                              “A horse and several cows feed on hay.”) or in answer-\nand text-conditioned image generation.  However,\n                                                         ing them with a VQA model (e.g., for the prompt “ACLIPScore provides a single global score, which can\n                                               bowl full of tomatoes sitting next to a flower.”, the\nbe too coarse to understand failures in the generated\n                                 VQA model answers that there is a flower when it is\nimages. Consequently, subsequent metrics such as\n                                                            in fact a bouquet made of tomatoes). Moreover, usingTIFA (Hu et al., 2023), VQ2 (Yarom et al., 2023) or\n                                                       these metrics as optimization objectives might exac-\nDSG (Cho et al., 2023a) propose generating pairs of\n                                                       erbate their failure modes by finding prompts which\nquestions and answers from T2I prompts and using\n                                                     generate images that fulfill the requirements for a\noff-the-shelf VQA models to evaluate each of them\n                                                     high score in an adversarial way. This highlights the\non the generated images, providing a fine-grained\n                                                 need for further research in developing more robust\nscore. Other recent studies suggest directly learning\n                                                 prompt-image consistency metrics which can be used\na prompt-image consistency metric from human\n                                                       as optimization objectives in addition to evaluation.\nfeedback (Xu et al., 2023; Wu et al., 2023b; Kirstain\net al., 2023).  However, none of these metrics are\nwithout flaws and human judgment remains the most\nreliable way of evaluating prompt-image consistency.\n                                               Another limitation of our approach is its runtime,\n                                                 which is a consequence of performing inference-time\n5  Conclusions                                   optimization. For instance, running the optimization\n                                                      process with Llama-2, LDM-2.1 and DSG score,\nIn  this  paper,  we  introduced  the   first  T2I    generating 5 prompt paraphrases per iteration and\noptimization-by-prompting framework to improve    4 images per prompt with 50 diffusion steps, takes\nprompt-image consistency. Through extensive eval-    7.34/20.27 iterations on average for COCO/Par-\nuations, we showed that OPT2I can be effectively    tiPrompts, which translates to ∼10/28 minutes\napplied to different combinations of LLM, T2I models   when using NVIDIA V100 GPUs.  However, we\nand consistency metrics, consistently outperforming    emphasize that (1) OPT2I  is designed to be a\nparaphrasing baselines and yielding prompt-image    versatile approach that works as a plug-and-play\nconsistency improvements of up to 24.9% over the    solution with diverse T2I models and LLMs since\nuser prompt, while maintaining the FID between gen-     it does not require any parameter updates nor\nerated and real images. By contrasting MSCOCO and    training data, and (2) optimizing T2I prompts with\nPartiPrompts results, we highlighted the importance    our automatic framework relieves humans from the\nof the choice of consistency score: complex prompts   manual and tedious task of prompt-engineering.\n\n\n                                              10\n\nprompt evolution. arXiv preprint arXiv:2309.16797,References\n                                                             2023.\n\nJames Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng                                                  Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao\n  Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce                                                         Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu\n  Lee, Yufei Guo, et al. Improving image generation                                                      Yang. Connecting large language models with evolu-\n  with better captions. Computer Science. https://cdn.                                                              tionary algorithms yields powerful prompt optimizers.\n  openai. com/papers/dall-e-3. pdf, 2(3):8, 2023.                                                        arXiv preprint arXiv:2309.08532, 2023.\n\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-                                                         Melissa Hall, Candace Ross, Adina Williams, Nicolas\n   biah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-                                                             Carion, Michal Drozdzal, and Adriana Romero Soriano.\n  lakantan, Pranav Shyam, Girish Sastry, Amanda Askell,                                                       Dig in: Evaluating disparities in image generations with\n   et al. Language models are few-shot learners. Advances                                                                indicators for geographic diversity, 2023.\n  in neural information processing systems, 33:1877–1901,\n  2020.                                             Yaru Hao, Zewen Chi, Li Dong, and Furu Wei. Optimizing\n                                                     prompts for text-to-image generation. arXiv preprint\nHila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, and                                                           arXiv:2212.09611, 2022.\n  Daniel Cohen-Or. Attend-and-excite: Attention-based\n  semantic guidance for text-to-image diffusion models.    Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le\n ACM Transactions on Graphics (TOG), 42(4):1–10,       Bras, and Yejin Choi. Clipscore: A reference-free eval-\n  2023.                                                   uation metric for image captioning.  arXiv preprint\n                                                           arXiv:2104.08718, 2021.\nJaemin Cho, Yushi Hu, Roopal Garg, Peter Anderson,\n  Ranjay Krishna, Jason Baldridge, Mohit Bansal, Jordi    Martin Heusel, Hubert Ramsauer, Thomas Unterthiner,\n  Pont-Tuset, and Su Wang. Davidsonian scene graph:      Bernhard Nessler, and Sepp Hochreiter. Gans trained\n  Improving reliability in fine-grained evaluation for text-      by a two time-scale update rule converge to a local nash\n  image generation. arXiv preprint arXiv:2310.18235,       equilibrium. Advances in neural information processing\n  2023a.                                                     systems, 30, 2017.\n\nJaemin Cho, Abhay Zala, and Mohit Bansal. Visual pro-    Jonathan Ho and Tim Salimans. Classifier-free diffusion\n  gramming for text-to-image generation and evaluation.      guidance, 2022.\n  arXiv preprint arXiv:2305.15328, 2023b.\n                                                       Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari\nWenliang  Dai,  Junnan  Li,  Dongxu  Li,  Anthony       Ostendorf, Ranjay Krishna, and Noah A. Smith. Tifa:\n  Meng Huat Tiong, Junqi Zhao, Weisheng Wang,      Accurate and interpretable text-to-image faithfulness\n  Boyang Li, Pascale Fung, and Steven Hoi. Instructblip:       evaluation with question answering. In Proceedings of\n  Towards general-purpose vision-language models with       the IEEE/CVF International Conference on Computer\n   instruction tuning, 2023a.                                Vision (ICCV), pages 20406–20417, October 2023.\n\nXiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang    Shyamgopal  Karthik,  Karsten  Roth,  Massimiliano\n  Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende,      Mancini, and Zeynep Akata.   If at first you don’t\n  Xiaofang Wang, Abhimanyu Dubey, et al. Emu: En-      succeed, try, try again: Faithful diffusion-based text-\n  hancing image generation models using photogenic nee-      to-image generation by  selection.   arXiv preprint\n   dles in a haystack. arXiv preprint arXiv:2309.15807,      arXiv:2305.13308, 2023.\n  2023b.\n                                                     Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong      Matiana, Joe Penna, and Omer Levy. Pick-a-pic: An\n  Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and      open dataset of user preferences for text-to-image gen-\n  Zhifang Sui. A survey on in-context learning, 2023.          eration. arXiv preprint arXiv:2305.01569, 2023.\n\nDave Epstein, Allan Jabri, Ben Poole, Alexei A Efros,   Kimin Lee, Hao Liu, Moonkyung Ryu, Olivia Watkins,\n  and Aleksander Holynski.   Diffusion self-guidance      Yuqing Du, Craig Boutilier, Pieter Abbeel, Mohammad\n   for controllable image generation.  arXiv preprint      Ghavamzadeh, and Shixiang Shane Gu. Aligning text-\n  arXiv:2306.00986, 2023.                                   to-image models using human feedback. arXiv preprint\n                                                           arXiv:2302.12192, 2023.\nWeixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Ar-\n  jun Reddy Akula, Pradyumna Narayana, Sugato Basu,   Long Lian, Boyi Li, Adam Yala, and Trevor Darrell. Llm-\n  Xin Eric Wang, and William Yang Wang. Training-      grounded diffusion: Enhancing prompt understanding\n   free structured diffusion guidance for compositional        of text-to-image diffusion models with large language\n  text-to-image synthesis. In The Eleventh International       models. arXiv preprint arXiv:2305.13655, 2023.\n  Conference on Learning Representations, 2022.\n                                                    Tsung-Yi Lin, Michael Maire, Serge Belongie, James\nChrisantha   Fernando,   Dylan   Banarse,   Henryk      Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and\n  Michalewski, Simon Osindero, and Tim Rocktäschel.    C Lawrence Zitnick. Microsoft coco: Common objects\n  Promptbreeder: Self-referential self-improvement via       in context.  In Computer Vision–ECCV 2014: 13th\n\n\n                                              11\n\nEuropean Conference, Zurich, Switzerland, September    Chitwan Saharia, William Chan, Saurabh Saxena, Lala\n  6-12, 2014, Proceedings, Part V 13, pages 740–755.       Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed\n  Springer, 2014.                                       Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi,\n                                                Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho,\nNan Liu, Shuang Li, Yilun Du, Antonio Torralba, and                                                     David J Fleet, and Mohammad Norouzi. Photorealis-\n  Joshua B Tenenbaum. Compositional visual generation                                                                           tic text-to-image diffusion models with deep language\n  with composable diffusion models. In European Con-                                                           understanding, 2022.\n   ference on Computer Vision, pages 423–439. Springer,\n  2022.                                              Jiaming Song, Chenlin Meng, and Stefano Ermon. De-\n                                                              noising diffusion implicit models.   arXiv preprint\nSuvir Mirchandani, Fei Xia, Pete Florence, Danny Driess,                                                           arXiv:2010.02502, 2020.\n  Montserrat Gonzalez Arenas, Kanishka Rao, Dorsa\n  Sadigh, Andy Zeng, et al. Large language models as    Jiao Sun, Deqing Fu, Yushi Hu, Su Wang, Royi Rassin,\n  general pattern machines. In 7th Annual Conference      Da-Cheng Juan, Dana Alon, Charles Herrmann, Sjo-\n  on Robot Learning, 2023.                                  erd van Steenkiste, Ranjay Krishna, et al. Dreamsync:\n                                                           Aligning text-to-image generation with image under-\nMuhammad Ferjad Naeem, Seong Joon Oh, Youngjung                                                          standing feedback. arXiv preprint arXiv:2311.17946,\n  Uh, Yunjey Choi, and Jaejun Yoo. Reliable fidelity and                                                             2023.\n   diversity metrics for generative models. In International\n  Conference on Machine Learning, pages 7176–7185.    Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon\n  PMLR, 2020.                                                Shlens, and Zbigniew Wojna. Rethinking the inception\n                                                              architecture for computer vision.  In Proceedings of\nLarge Model Systems Organization. Chatbot arena leader-      the IEEE conference on computer vision and pattern\n  board.    https://huggingface.co/spaces/lmsys/       recognition, pages 2818–2826, 2016.\n  chatbot-arena-leaderboard.\n                                               Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,\nDustin  Podell,  Zion  English, Kyle Lacey, Andreas     Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov,\n  Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna,     Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,\n  and Robin Rombach.  Sdxl: Improving latent diffu-       et al. Llama 2: Open foundation and fine-tuned chat\n   sion models for high-resolution image synthesis. arXiv       models. arXiv preprint arXiv:2307.09288, 2023.\n  preprint arXiv:2307.01952, 2023.\n                                                      Rodrigo Valerio, Joao Bordalo, Michal Yarom, Yonattan\nReid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang       Bitton, Idan Szpektor, and Joao Magalhaes. Transfer-\n  Zhu, and Michael Zeng. Automatic prompt optimiza-       ring visual attributes from natural language to verified\n  tion with\" gradient descent\" and beam search. arXiv      image generation. arXiv preprint arXiv:2305.15026,\n  preprint arXiv:2305.03495, 2023.                           2023.\n\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya   Bram Wallace, Meihua Dang, Rafael Rafailov, Linqi Zhou,\n  Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-     Aaron Lou, Senthil Purushwalkam, Stefano Ermon,\n   try, Amanda Askell, Pamela Mishkin, Jack Clark, et al.      Caiming Xiong, Shafiq Joty, and Nikhil Naik. Diffusion\n  Learning transferable visual models from natural lan-      model alignment using direct preference optimization.\n  guage supervision. In International conference on ma-      arXiv preprint arXiv:2311.12908, 2023.\n  chine learning, pages 8748–8763. PMLR, 2021.\n                                                         Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine      Webson,  Yifeng Lu, Xinyun Chen, Hanxiao Liu,\n  Lee, Sharan Narang, Michael Matena, Yanqi Zhou,     Da Huang, Denny Zhou, et al. Larger language mod-\n  Wei Li, and Peter J Liu. Exploring the limits of trans-        els do in-context learning differently. arXiv preprint\n   fer learning with a unified text-to-text transformer.      arXiv:2303.03846, 2023.\n  The Journal of Machine Learning Research, 21(1):5485–\n                                                   Qiucheng Wu, Yujian Liu, Handong Zhao, Trung Bui,  5551, 2020.\n                                                  Zhe Lin, Yang Zhang, and Shiyu Chang. Harnessing\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey       the spatial-temporal attention of diffusion models for\n  Chu, and Mark Chen. Hierarchical text-conditional        high-fidelity text-to-image synthesis. In Proceedings of\n  image generation with clip latents, 2022.                    the IEEE/CVF International Conference on Computer\n                                                              Vision, pages 7766–7776, 2023a.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz,\n  Patrick Esser, and Björn Ommer. High-resolution im-    Xiaoshi Wu, Yiming Hao, Keqiang Sun, Yixiong Chen,\n  age synthesis with latent diffusion models. In Proceed-      Feng Zhu, Rui Zhao, and Hongsheng Li. Human prefer-\n  ings of the IEEE/CVF conference on computer vision       ence score v2: A solid benchmark for evaluating human\n  and pattern recognition, pages 10684–10695, 2022a.          preferences of text-to-image synthesis. arXiv preprint\n                                                           arXiv:2306.09341, 2023b.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz,\n  Patrick Esser, and Björn Ommer.  High-resolution    Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, and Hong-\n  image synthesis with latent diffusion models, 2022b.       sheng Li. Better aligning text-to-image models with\n\n\n                                              12\n\nhuman preference. arXiv preprint arXiv:2303.14420,\n  2023c.\n\nJiazheng Xu, Xiao Liu, Yuchen Wu, Yuxuan Tong, Qinkai\n   Li, Ming Ding, Jie Tang, and Yuxiao Dong.  Im-\n  agereward:  Learning and evaluating human prefer-\n  ences for text-to-image generation.  arXiv preprint\n  arXiv:2304.05977, 2023.\n\nYutaro Yamada, Yingtian Tang, and Ilker Yildirim. When\n  are lemons purple? the concept association bias of clip.\n  arXiv preprint arXiv:2212.12043, 2022.\n\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao\n  Liu, Quoc V Le, Denny Zhou, and Xinyun Chen.\n  Large language models as optimizers. arXiv preprint\n  arXiv:2309.03409, 2023.\n\nMichal Yarom, Yonatan Bitton, Soravit Changpinyo,\n  Roee Aharoni, Jonathan Herzig, Oran Lang, Eran Ofek,\n  and Idan Szpektor. What you see is what you read?\n  improving text-image alignment evaluation.  arXiv\n  preprint arXiv:2305.10400, 2023.\n\nJiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong,\n  Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander\n  Ku, Yinfei Yang, Burcu Karagol Ayan, et al. Scaling\n  autoregressive models for content-rich text-to-image\n  generation. arXiv preprint arXiv:2206.10789, 2022.\n\nMert Yuksekgonul, Federico Bianchi, Pratyusha Kalluri,\n  Dan Jurafsky, and James Zou. When and why vision-\n  language models behave like bags-of-words, and what to\n  do about it? In The Eleventh International Conference\n  on Learning Representations, 2022.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\n  Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\n  Ba. Large language models are human-level prompt\n  engineers. In The Eleventh International Conference\n  on Learning Representations, 2022.\n\n\n\n\n\n                                              13\n\nA  Additional method details\n\nA.1  Meta-prompts\n\nMeta-prompts 1-5 include all the prompts used in our\nwork. The teal text is fed to the LLM as a system\nprompt, and the purple text denotes placeholders to\nbe dynamically filled.\n\n\n\n\n    Decompose the following sentence into\n    individual noun phrases. Ignore prefixes such\n    as ’a photo of’, ’a picture of’, ’a portrait\n    of’, etc. Your response should only be a list\n    of comma separated values, eg: ’foo, bar, baz’\n\n\n    {prompt}\n\n\n\nPrompt 1 Meta-prompt used for decomposing prompts\ninto noun phrases for dCS.\n\n\n\n\n\n    Generate {num_solutions} paraphrases of the\n    following image description while keeping the\n    semantic meaning: \"{user_prompt}\". Respond\n    with each new prompt in between <PROMPT> and\n    </PROMPT>, eg:\n\n\n    1. <PROMPT>paraphrase 1</PROMPT>\n    2. <PROMPT>paraphase 2</PROMPT>\n    ...\n    {num_solutions}. <PROMPT>paraphrase {\n    num_solutions}</PROMPT>\n\n\n\nPrompt2 Meta-prompt used for the paraphrasing baseline.\n\n\nA.2  Examples of prompt decompositions\n\nTable 4 shows a few examples of outputs generated\nby dCS (noun phrases) and DSG (binary questions)\nfrom the input prompt. These outputs are then used\nto compute a fine-grained consistency score w.r.t. the\ngenerated image, either with a multimodal encoder\n(dCS) or a VQA model (DSG).\n\n\n\n\n\n                                              14\n\nYou are an expert prompt optimizer for text-to-image models. Text-to-image models take a text prompt as\n    input and generate images depicting the prompt as output. You translate prompts written by humans into\n    better prompts for the text-to-image models. Your answers should be concise and effective.\n\n\n    Your task is to optimize this initial prompt written by a human: \"{user_prompt}\". Below are some\n    previous prompts with a decomposition of their visual elements. Each element is paired with a score\n    indicating its presence in the generated image. The prompts are arranged in ascending order based on\n    their scores, which range from 0 to 100. Higher scores indicate higher likelihood of presence.\n\n\n    1. {revised_prompt_1}\n    score: {avg_score_1}\n    visual elements:\n    {subprompt_1_1} {clip_score_1_1}\n    {subprompt_1_2} {clip_score_1_2}\n    (... more questions ...)\n\n\n    (... more examples ...)\n\n\n    Generate {num_solutions} paraphrases of the initial prompt which keep the semantic meaning and that have\n     higher scores than all the prompts above. Prioritize optimizing for object with lowest scores. Favor\n    substitutions and reorderings over additions. Respond with each new prompt in between <PROMPT> and </\n    PROMPT>, eg:\n\n\n    1. <PROMPT>paraphrase 1</PROMPT>\n    2. <PROMPT>paraphase 2</PROMPT>\n    ...\n    {num_solutions}. <PROMPT>paraphrase {num_solutions}</PROMPT>\n\n\n\nPrompt 3 Meta-prompt used for OPT2I with dCS as scorer.\n\n\n\n\n    You are an expert prompt optimizer for text-to-image models. Text-to-image models take a text prompt as\n    input and generate images depicting the prompt as output. You translate prompts written by humans into\n    better prompts for the text-to-image models. Your answers should be concise and effective.\n\n\n    Your task is to optimize this initial prompt written by a human: \"{user_prompt}\". Below are some\n    previous prompts with the consistency of each prompt’s visual elements in the generated image via a set\n    of binary questions. The prompts are arranged in ascending order based on their overall consistency\n    score, which ranges from 0 to 100 (higher is better).\n\n\n    1. {revised_prompt_1}\n    overall score: {dsg_score_1}\n    evaluation questions:\n    {question_1_1} {vqa_score_1_1}\n    {question_1_2} {vqa_score_1_2}\n    (... more questions ...)\n\n\n    (... more examples ...)\n\n\n    Generate {num_solutions} paraphrases of the initial prompt which keep the semantic meaning and that have\n     higher scores than all the prompts above. Focus on optimizing for the visual elements that are not\n    consistent. Favor substitutions and reorderings over additions. Respond with each new prompt in between\n    <PROMPT> and </PROMPT>, eg:\n\n\n    1. <PROMPT>paraphrase 1</PROMPT\n    2. <PROMPT>paraphase 2</PROMPT>\n    ...\n    {num_solutions}. <PROMPT>paraphrase {num_solutions}</PROMPT>\n\n\n\nPrompt 4 Meta-prompt used for OPT2I with DGS as scorer.\n\n\n\n\n                                              15\n\nConciseness:\n\n\n\n\n    (... more examples ...)\n\n\n    Generate {num_solutions} paraphrases of the initial prompt which keep the semantic meaning and that have\n     higher scores than all the prompts above. Favor substitutions and reorderings over additions. Respond\n    with each new prompt in between <PROMPT> and </PROMPT>, eg:\n    ...\n\n\n\n                                       Conciseness + prioritize:\n\n\n\n\n    (... more examples ...)\n\n\n    Generate {num_solutions} paraphrases of the initial prompt which keep the semantic meaning and that have\n     higher scores than all the prompts above. Prioritize optimizing for object with lowest scores.  Favor\n    substitutions and reorderings over additions. Respond with each new prompt in between <PROMPT> and </\n    PROMPT>, eg:\n    ...\n\n\n\n                                 Conciseness + prioritize + reasoning:\n\n\n\n\n    (... more examples ...)\n\n\n    Briefly reason (max two sentences) about the prompts above to understand why certain objects have higher\n     or lower scores in certain prompts. Then, based on this reasoning, generate {num_solutions} paraphrases\n     of the initial prompt which keep the semantic meaning and that have higher scores than all the prompts\n    above. Prioritize optimizing for objects with lowest scores while keeping high scores for the other\n    objects. Favor substitutions and reorderings over additions. Respond with each new prompt in between <\n    PROMPT> and </PROMPT>, eg:\n    ...\n\n\n\n                                 Conciseness + prioritize + structure:\n\n\n\n\n    (... more examples ...)\n\n\n    Generate {num_solutions} paraphrases of the initial prompt which keep the semantic meaning and that have\n     higher scores than all the prompts above. PRIORITIZE optimizing for objects with lowest scores while\n    keeping high scores for the other objects. FAVOR substitutions and reorderings over additions. USE\n    simple words/concepts, understable from a text-to-image model, e.g., distinguish foreground and\n    background. Respond with each new prompt in between <PROMPT> and </PROMPT>, eg:\n    ...\n\n\n\nPrompt 5 Meta-prompt ablations. Modifications w.r.t. the base meta-prompt are denoted with different colors.\n\n\n\n\n\n                                              16\n\nTable 4 Prompt decompositions into noun phrases (dCS) and binary questions (DGS).\n\n  Prompt                   dCS                   DSG\n\n   “A ginger cat is sleeping next to   “ginger cat”, “window”               “Is there a cat?”, “Is the cat ginger?”, “Is the cat sleeping?”,\n   the window.”                                                                   “Is there a window?”, “Is the cat next to the window?”\n\n  “Many electronic wires pass over   “electronic wires”, “road”, “cars”   “Are there many electronic wires?”, “Is there a road?”, “Are\n   the road with few cars on it.”                                      there few cars?”, “Do the electronic wires pass over the\n                                                                         road?”, “Are the cars on the road?”\n\n   “there is a long hot dog that has   “long hot dog”, “toppings”           “Is there a hot dog?”, “Is the hot dog long?”, “Is the hot\n   toppings on it”                                              dog hot?”, “Are there toppings on the hot dog?”\n\n   “the mona lisa wearing a cowboy   “the mona lisa”, “a cowboy hat”,   “Is there the Mona Lisa?”, “Is the Mona Lisa wearing a\n   hat and screaming a punk song   “a punk song”, “a microphone”    cowboy hat?”, “Is the Mona Lisa holding a microphone?”,\n   into a microphone”                                                             “Is the hat a cowboy hat?”, “Is the Mona Lisa screaming?”,\n                                                                                        “Is the song the Mona Lisa is singing punk?”, “Is the Mona\n                                                                      Lisa screaming into the microphone?”\n\n   “a photograph of a bird wearing   “photograph”,   “bird”,   “head-   “Is this a photograph?”, “Is there a bird?”, “Does the bird\n   headphones and speaking into a   phones”, “microphone”, “record-  have headphones?”, “Does the bird have a microphone?”,\n   microphone in a recording stu-  ing studio”                            “Is there a recording studio?”, “Is the bird speaking into\n   dio”                                                             the microphone?”, “Is the bird wearing headphones?”, “Is\n                                                                    the bird in the recording studio?”\n\n   “concentric squares fading from   “concentric  squares”,  “yellow”,  “Are there squares?”, “Are the squares concentric?”, “Is the\n   yellow on the outside to deep or-  “outside”, “deep orange”, “inside”   outer square yellow?”, “Is the inner square deep orange?”,\n   ange on the inside”                                                             “Is the inner square inside the outer square?”, “Is the outer\n                                                                     square on the outside?”, “Is the inner square on the inside?”\n\n\n\n\n\n                                              17\n\nB  Additional results                             reinforce our previous claims: (1) the iterative proce-\n                                                    dure allows OPT2I to keep improving revised prompts\n                                                     over time, and (2) 1-shot ICL is challenging due to\nTable 5 Comparison with 1-shot in-context learning (ICL).                                                      the limited feedback provided to the LLM about how\nWe report relative improvement (%) in prompt-image\n                                                      to improve the user prompt, and thus only minor\nconsistency between the user prompt and the best prompt\n                                                improvements in prompt-image consistency can be\nfound, averaged across all prompts in the dataset.\n                                                    obtained over random paraphrasing.\n\n                                                       Dataset\n  Method        Objective   LLM        T2I\n                                MSCOCO    P2\n\n  Paraphrasing                                                +9.86     +8.00\n  1-shot ICL      dCS    Llama-2   LDM-2.1    +10.67                                                          +8.74     B.2  Filtering out already consistent user\n  OPT2I                                  +11.68   +10.34                                            prompts\n  Paraphrasing                                   +9.92     +19.22\n  1-shot ICL     DSG    Llama-2   LDM-2.1    +10.14    +19.69    When adopting the DSG objective, user prompts\n  OPT2I                                  +11.02   +22.24\n                                                might already achieve a perfect consistency score  Paraphrasing                                   +9.64     +8.06\n  1-shot ICL      dCS    GPT-3.5   LDM-2.1    +9.21∗     +8.72        initially, i.e., SDSG(p0, g(p0)) = 1. We observe this\n  OPT2I                                  +10.56   +9.33     phenomenon happens with higher frequency on the\n  Paraphrasing                                                +10.21                                                          +19.09      simpler MSCOCO prompts (∼40%), and with less fre-  1-shot ICL     DSG    GPT-3.5   LDM-2.1    +10.09∗                                                          +18.94∗\n  OPT2I                                  +11.19   +19.77     quency on the more complex PartiPrompts prompts\n  Paraphrasing                                  +11.38    +10.29     (∼10%). Since SDSG(p0, g(p0)) can be computed be-\n  1-shot       ICL      dCS    Llama-2    CDM-M                                                +12.19                                                          +11.34      forehand, we can avoid optimizing for those user  OPT2I                                         +12.65                                                  +12.13\n  Paraphrasing                                   +9.86     +22.24     prompts that have already a perfect initial SDSG\n  1-shot ICL     DSG    Llama-2    CDM-M     +10.10    +22.25     and better showcase the optimization performance of\n  OPT2I                                  +10.15   +24.93\n                                             OPT2I. We provide the updated optimization curves\n                                                            in Figure 7, and report the final results in Table 6. In\nB.1  1-shot in-context learning as baseline       both cases, we highlight results obtained by filtering\n                                                   out “perfect” user prompts with full colors, and con-\nIn this experiment, we compare OPT2I with 1-shot in-    trast them against results obtained with all prompts\ncontext learning (ICL), which we implement by run-    in faded colors (equivalent to Figure 3).\nning OPT2I with #iter = 1 and #prompts/iter = 150.\nNote that, in this setting, the LLM only receives feed-    In Table 6, we observe a higher relative improvement\nback about the performance of the user prompt. We     for both MSCOCO and PartiPrompts in all config-\nmaintain the same experimental setting described in    urations when filtering out “perfect” user prompts,\nSection 3, except we use 200 prompts for MSCOCO,   which is more prominent for MSCOCO because the\nand report the results in Table 5. First, we notice   number of excluded prompts is higher. In Figure 7,\nthat 1-shot ICL achieves higher prompt-image con-   we observe similar consistent and considerable in-\nsistency than random paraphrasing in all settings    creases of all optimization curves when considering\nexcept when using GPT-3.5, which performs on-par    both mean and max consistency improvement. In\nor slightly worse (marked with * in Table 5, see also    the mean case, we remark a reduction in the initial\nthe discussion in Section B.5). Second, and more    dip in relative consistency, especially in MSCOCO,\nimportantly, we observe that OPT2I outperforms the    where OPT2I reaches a positive relative consistency\n1-shot ICL baseline regardless of the consistency ob-   much earlier, i.e., it = [6, 2, 2] vs. it = [23, 8, 5] with\njective, LLM, or T2I model adopted. These results    Llama-2, GPT-3.5, and CDM-M, respectively.\n\n\nTable 6 Relative prompt-image consistency improvement between the user prompt and the best prompt found, averaged\nacross prompts.\n\n\n                                          MSCOCO                       P2\n         Method        LLM        T2I\n                                           SDSG(p0, g(p0)) < 1      All     SDSG(p0, g(p0)) < 1      All\n\n         Paraphrasing                             +17.74         +10.67         +21.95         +19.22\n                        Llama-2    LDM-2.1\n       OPT2I                             +18.63       +11.21       +25.39       +22.24\n\n         Paraphrasing                             +17.52         +10.53         +21.80         +19.09\n                        GPT-3.5    LDM-2.1\n       OPT2I                             +18.05       +10.85       +22.58       +19.77\n\n         Paraphrasing                             +18.65         +10.53         +26.54         +22.24\n                        Llama-2     CDM-M\n       OPT2I                             +19.61       +11.07       +29.19       +24.93\n\n\n\n                                              18\n\n**Paraphrasing        **Paraphrasing        **Paraphrasing\n                                 Paraphrasing          Paraphrasing          Paraphrasing\n                                **Llama-2_SD2.1      **GPT-3.5_SD2.1      **Llama-2_IF-M\n                               Llama-2_SD2.1        GPT-3.5_SD2.1        Llama-2_IF-M\n                       (%) 15 max                        20 max\n\n                                                        15\n                         10\n                                                        10                                                                                   consistency\n                          5\n                                                            Relative                                5                          0                              0\n                       mean                     mean                       (%)\n                          5                              5\n\n                          0                              0                                                                                   consistency\n\n                                                         5                                                            Relative 5\n                            0       10      20      30     0       10      20      30\n                                              iteration                             iteration\n\n                                      (a) DSG (MSCOCO)                    (b) DSG (P2)\n\nFigure 7 OPT2I optimization curves obtained with prompts having SDSG(p0) < 1, marked by “**” and full colors. In\ncontrast, faded-color curves consider all prompts. Each plot tracks either the max or the mean relative improvement\nin consistency across revised prompts per iteration.\n\n\nB.3  Impact  of   seed-fixing  and  #im-   the optimization curves, we notice that optimizing\n     ages/prompt                              a single image without fixing the seed is more dif-\n                                                                 ficult for OPT2I, which results in a noisy and less\nIn this experiment, we ablate the impact of fixing    steep trajectory, especially in the mean case. In con-\nthe random seed of the initial noise for the diffusion     trast, when OPT2I optimizes 4 or 10 images/prompt\nmodel throughout the optimization process when op-   with no fixed seed, both the max and mean curve\ntimizing different numbers of images/prompt. We use    remain similar w.r.t. to using a fixed seed. This sup-\nour default configuration with Llama-2 and LDM-2.1    ports our choice of generating 4 images/prompt, as\non MSCOCO. In Figure 8a, we show the optimiza-     it provides enough diversity in the generations while\ntion curves obtained when optimizing 1, 4 (default),    being substantially more computationally efficient\nand 10 images/prompt with fixed image seed. As    than generating 10.\nexpected, we observe no meaningful differences in\nmean consistency improvement. In contrast, the max\nconsistency improvement shows a clear distinction   B.4  Stratified PartiPrompts results\nbetween optimizing a single image (single seed) and                                                   Figure 9 shows the relative improvement in consis-\noptimizing 4 or 10, with the former achieving more                                                   tency score (dCS or DSG) on prompts from Par-\nsubstantial improvements. We argue that when opti-                                                 tiPrompts (P2), broken down by challenge aspect.\nmizing a single image seed, OPT2I is more sensitive                                                Note that we only sampled prompts from four of the\nto changes in the prompts, i.e., there is a higher                                              most difficult dimensions in P2: “Complex”, “Fine-\nvariance among the scores of revised prompts. We                                                     grained Detail”, “Quantity”, and “Properties & Posi-\nthen contrast the optimization curves with fixed seed                                                           tioning”. Intuitively, this plot shows what kinds of\n(8a) against the non-fixed seed ones (8b). Our hy-                                                 prompts are easier to optimize for OPT2I when using\npothesis is that optimizing, when not fixing the seed,                                                             different LLMs, T2I models and consistency scores.\ngenerating too few images/prompt leads to an un-\nstable/unreliable feedback for the LLM due to the   The most significant improvement in consistency is ob-\nhigh variance of the generations. Indeed, looking at    served for prompts related to “Properties & Position-\n\n\n                                              19\n\nOPT2I, #imgs/p=1, seed=0        OPT2I, #imgs/p=1, No seed\n                                  OPT2I, #imgs/p=4, seed=0        OPT2I, #imgs/p=4, No seed\n                                  OPT2I, #imgs/p=10, seed=0      OPT2I, #imgs/p=10, No seed\n                      (%) 10 max                        10 max\n                          8                              8\n                          6                              6                                                                                  consistency                          4                              4\n                          2                              2                                                            Relative                          0                              0\n                       mean                     mean                      (%)                          2                              2\n\n                          1                              1\n                                                                                  consistency 0                              0\n                          1                              1\n                                                            Relative                          2                              2\n                            0       10      20      30     0       10      20      30\n                                              iteration                             iteration\n\n                                          (a) fixed seed                      (b) non-fixed seed\n\nFigure 8 OPT2I optimization curves with (a) fixed or (b) non-fixed seed. Each curve uses optimizes a different number\nof images per prompt. Y-axis is aligned between (a) and (b). Curves obtained with Llama-2 and LDM-2.1 on 200 out\nof the 2000 prompts from MSCOCO.\n\n\ning” when using Llama-2 in conjunction with CDM-M    the exact same prompt with GPT-3.5. Hence, one\nand dCS. Similarly, the combination of Llama-2,    hypothesis for the observed phenomenon is that our\nCDM-M, and DSG yields the best results for prompts   meta-prompt is better optimized for Llama-2. An-\nabout “Quantity”. For other challenges, CDM-M con-    other hypothesis is that each LLM has a different\ntinues to provide the most substantial consistency    balance point between exploration and exploitation\nimprovement, although the margin is narrower com-    for the same sampling temperature of 1.0. In partic-\npared to LDM-2.1. Interestingly, GPT-3.5 shows the     ular, given the flatter optimization curves drawn by\nsmallest improvement in consistency for prompts    GPT-3.5, we conjecture that it explores less diverse\nabout “Quantity”, regardless of whether dCS or DGS    prompts than Llama-2. To verify this, we analyze\nmetrics are used.  Consistency improvements for   some text properties of the revised prompts generated\nprompts from the “Complex” and “Fine-grained De-   by both LLMs.\ntail” challenges are comparable, which is expected\ndue to their inherent similarities.                      Figure 10a tracks the length (in number of characters)\n                                                            of the revised prompts at each iteration, and Fig-\nB.5 Why is GPT-3.5 not as good as Llama-2?    ure 10b tracks CLIP text similarity between revised\n                                                prompts and the user prompt along the optimization\nIn Figure 3 and Table 1, we observe that OPT2I    process, both averaged over the revised prompts gen-\nachieves worse results when using GPT-3.5 as the    erated at the same iterations and over all prompts\nLLM. Notably, the optimization curves with GPT-3.5     in the dataset. We observe that when using Llama-2\nare flatter than when using Llama-2. This result is     for OPT2I, the revised prompts generated at each\nrather surprising, as current leaderboards ? indicate    iteration are longer and more semantically dissimi-\nthat GPT-3.5 generally outperforms Llama-2 on a     lar to the user prompt compared to those generated\nwide variety of NLP tasks. So, in this experiment,   by GPT-3.5. This means that OPT2I benefits from\nwe aim to shed light on the possible causes. Given    greater prompt diversity to find the best T2I prompts\nthe closed (and expensive) access to GPT-3.5, our    that lead to more consistent images, which is better\ninitial exploration of the meta-prompt structure and    achieved with Llama-2. Additionally, we note that\nphrasing was based on Llama-2, and later on we used    both the prompt length and the semantic similarity\n\n\n                                              20\n\nLlama-2, LDM-2.1         GPT-3.5, LDM-2.1         Llama-2, CDM-M\n\n          14                                                         31\n          13                                                         29\n        (%)12                                           (%)                                                         27\n        dCS11                                           DSG25\n          10                                             23\n           9                                             21                     Relative                                                                                                                        Relative\n           8                                             19\n           7                                             17\n           6                                             15\n               Overall ComplexFine-grainedQuantityProperties&         Overall ComplexFine-grainedQuantityProperties&                                  Detail          Positioning                           Detail          Positioning\n\nFigure 9 Relative improvement in prompt-image consistency between the user prompt and the best prompt found,\naveraged across PartiPrompts prompts and broken down by challenge aspect.\n\n\nwith the user prompt start plateauing around the    as the scorer. Since DSG is computed as an average\nmaximum number of iterations we set, which further    of binary scores, it is more coarse than CLIPScore\nvalidates our selected value of 30. We leave as fu-   and thus there are fewer leaps in consistency. Over-\nture work ablating for the sampling temperature with      all, we observe that the intermediate revised prompt\nboth LLMs.                                     manages to increase the consistency score in some of\n                                                    the generated images but not for all of them. The\n                                                     best prompt, however, usually manages to improve\nB.6  Additional qualitative examples                 all 4 generated images.\n\nFigures 11 and 12 show some additional selected ex-\n                                                     Figure 12 shows revised prompts generated with dCSamples of user prompt and revised prompts through-\n                                                      as the scorer.  In this case, we can see a gradualout the optimization process, along with the gener-\n                                                        increase in average dCS, which visually translatesated images and consistency scores. In particular,\n                                                       to generated images which are more consistent withwe select revised prompts such that the consistency\n                                                      the user prompt on average. The strong effect of thescore of the generated images (w.r.t. the user prompt)\n                                                                   initial latent noise in the image structure is evident,is strictly higher than the previous best score found\n                                                        yet substantial modifications in the format of the in-so far, i.e., the leaps in prompt-image consistency.\n                                                  put prompt used to condition the generation lead to\nFigure 11 shows revised prompts generated with DSG     significant changes in how the T2I model interprets\n\n                                                  1.00        175                                                                    llama-2\n                                                                                     gpt-3.5                                                  0.95        150\n                                                  0.90             (chars)125\n                                                  0.85        100                                                                                                       similarity           length                                        0.80\n         75                          llama-2\n                                        gpt-3.5      0.75\n         50\n            0       10       20       30        0       10       20       30\n                           iterations                                  iterations\n                             (a) Prompt length                            (b) Text similarity w/ user prompt\n\nFigure 10 Text analysis of revised prompts generated by Llama-2 and GPT-3.5.\n\n\n                                              21\n\nthe structure determined by the initial noise (e.g.,\nbetween rows 2-3 and 4-5 in the squirrel example).\nWe also note that dCS (CLIPScore averaged over sub-\nprompts) can occasionally fall short as an evaluation\nmetric for image-text consistency. This is primarily\nbecause dCS tends to focus on the presence of visual\nelements, overlooking other aspects such as spatial\nrelationships. In the toilet example, for instance, we\nobserve how the generated images progressively be-\ncome more consistent up to a certain point (around\nrow 6). Beyond this point, the revised prompts and\nthe generated images start degenerating (e.g., by\noveremphasizing certain elements), while dCS contin-\nues to improve. This highlights that, while dCS may\nserve as a useful fine-grained consistency metric to\nprovide visual feedback for T2I prompt optimization\nwith an LLM, it may not be as effective for evaluation\npurposes.\n\n\n\n\n\n                                              22\n\na cute wooden owl statue holding a large globe of the Earth above its head (0.3929)\n\n\n                    There is a pizza on the cutting board (0.5000)\n\n\n\n\n\n                                                                                                                0.2857                 1.0000                 0.1429                 0.1429\n\n                                                                                                  An owl statue made of wood, with a charming expression, holds a large Earth globe\n                                                                                                           above its head, boasting a precision-crafted surface. (0.7857)\n         1.0000                 0.3333                 0.3333                 0.3333\n                   A cutting board holds a delicious pizza. (0.8333)\n\n\n\n\n\n                                                                                                                1.0000                 1.0000                 0.1429                 1.0000\n                                                                                                  An enchanting wooden owl statue, with an endearing expression, cradles a massive\n         1.0000                 1.0000                 0.3333                 1.0000                 globe showcasing the Earth's diverse terrain, as it sits atop a pedestal, ensuring a\n       On a clean cutting board, a mouthwatering pizza awaits slicing. (1.0000)                        striking visual harmony, with the globe resting on its head. (1.0000)\n\n\n\n\n\n         1.0000                 1.0000                 1.0000                 1.0000                           1.0000                 1.0000                 1.0000                 1.0000\n\n                                                                                                  A punk rock squirrel in a studded leather jacket shouting into a microphone while\n                                                                                                                            standing on a stump (0.5000)\n A traffic light and a signpost at a crossroads intersection near a waterway. (0.3889)\n\n\n\n\n\n                                                                                                                0.3750                 0.6250                 0.3750                 0.6250\n          0.4444                 0.4444                 0.2222                 0.4444                 Atop a tree stump, a rebellious squirrel wears a leather jacket with metal studs and\n  A traffic light and signpost standing at a crossroads intersection, surrounded by a                holds a microphone, shouting into the wind with punk rock fervor. (0.7188)\n                                  waterway. (0.6667)\n\n\n\n\n\n                                                                                                                1.0000                 0.7500                 0.5000                 0.6250\n          0.8889                 0.8889                 0.4444                 0.4444                  A microphone-wielding squirrel, draped in a black leather jacket with silver studs,\n   A traffic light and signpost are positioned at a crossroads intersection, with a               passionately shouts into the wind while standing on a stump, epitomizing the DIY\n       beautiful waterway flowing nearby, producing a striking visual. (0.9167)                                     ethos and raw energy of punk rock. (0.9375)\n\n\n\n\n\n          0.8889                 1.0000                 0.8889                 0.8889                           1.0000                 0.8750                 0.8750                 1.0000\n\nFigure 11 Selected examples of initial prompts from MSCOCO (left) and PartiPrompts (right) and revised prompts\nacross the optimization, along with the generated images. The optimizer refines prompts for LDM-2.1 using Llama-2\nas LLM and DSG as scorer. We report DSG score averaged across images.\n\n\n\n\n\n                                              23\n\nA punk rock squirrel in a studded leather jacket shouting into a microphone while\n           Small white toilet with seashells sitting on top of it.  (0.1899)                                               standing on a lily pad (0.1690)\n\n\n\n\n\n                                                                                                  A rebellious squirrel wearing a studded leather jacket passionately sings into a\n           A clean white toilet adorned with seashells on its lid. (0.1985)                                      microphone while standing on a lily pad. (0.1813)\n\n\n\n\n\n                                                                                                A punk-rockin' squirrel stands atop a lily pad and belts into a microphone, wearing a\n               A small, pristine toilet crowned with seashells. (0.2341)                                        studded leather jacket that oozes attitude. (0.1859)\n\n\n\n\n\n                                                                                                  A punk rockin' squirrel, wearing a leather jacket adorned with metal studs, belts\n         A miniature white toilet graces a seashell-covered pedestal. (0.2480)                         into a microphone with conviction, positioned atop a lily pad. (0.1939)\n\n\n\n\n\n                                                                                                   A rebellious squirrel, clad in a black leather jacket adorned with metal studs,\n A miniature toilet, flawlessly white, is adorned with an array of vibrant seashells,           passionately sings into a microphone while standing on a lily pad, exuding punk rock\n                             elevating its charm. (0.2507)                                                                        spirit. (0.1988)\n\n\n\n\n\n                                                                                                   A rebellious squirrel, adorned in a black leather jacket featuring metal studs,\n   A miniature toilet, flawlessly white, is covered in a diverse array of seashells,            passionately sings into a microphone while standing on a lily pad, exuding punk rock\n           elevating its charm and creating a captivating display. (0.2527)                                                       spirit. (0.2017)\n\n\n\n\n\n                                                                                                A bold squirrel, adorned in a black leather jacket featuring metal studs, sings into\n A small, immaculate white toilet, covered in a diverse array of seashells, perches on           a microphone with intensity, standing on a lily pad, embracing the punk rock style.\n               a pedestal, boasting an eye-catching exhibition. (0.2605)                                                              (0.2053)\n\n\n\n\n\n                                                                                                   A rebellious squirrel, attired in a black leather jacket featuring metal studs,\n A miniature white toilet, adorned with an array of seashells, perches on a pedestal,            forcefully belts out a tune into a microphone on a sturdy lily pad, channeling the\n                    boasting an unforgettable exhibition. (0.2675)                                                       raw energy of punk rock. (0.2158)\n\n\n\n\n\nFigure 12 Selected examples of initial prompts from MSCOCO (left) and PartiPrompts (right) and revised prompts\nacross the optimization, along with the generated images. The optimizer refines prompts for LDM-2.1 using Llama-2\nas LLM and dCS as scorer. We report dCS score averaged across images.\n\n\n\n\n                                              24",
"headers": [
"arXiv:2403.17804v1  [cs.CV]  26 Mar 2024",
"Improving Text-to-Image Consistency via",
"Automatic Prompt Optimization",
"1",
"Introduction",
"2",
"for T2I",
"3",
"Experiments",
"4",
"Related work",
"5",
"Conclusions",
"References",
"A",
"Additional method details",
"B",
"Additional results",
"OPT2I: Optimization by prompting",
"Filtering out already consistent user",
"Impact",
"of",
"seed-fixing",
"and",
"#im-",
"Trade-offs with image quality and diver-",
"2.1",
"Problem formulation",
"2.2",
"Meta-prompt design",
"2.4",
"Exploration-exploitation trade-off",
"2.3",
"Optimization objective",
"3.1",
"Experimental setting",
"3.2",
"Main results",
"3.3",
"sity",
"3.4",
"Ablations",
"3.5",
"Post-hoc image selection",
"A.1",
"Meta-prompts",
"A.2",
"Examples of prompt decompositions",
"B.2",
"prompts",
"B.1",
"1-shot in-context learning as baseline",
"B.3",
"ages/prompt",
"B.4",
"Stratified PartiPrompts results",
"B.5",
"B.6",
"Additional qualitative examples",
"GPT-3.5",
"Llama-2",
"Why is",
"not as good as",
"?"
],
"tables": [
"|Col1|1. Is there a raccoon? Yes<br>2. Is the raccoon holding a cane? Yes<br>3. Is the raccoon wearing a tophat? Yes<br>4. Is there a garbage bag? No<br>5. Is the raccoon holding a garbage bag? No<br>...<br>Score: 0.6667|Col3|\n|---|---|---|",
"|)|Col2|Col3|\n|---|---|---|\n|0<br>2<br>4<br>6<br>max<br>0<br>10<br>20<br>30<br>iteration<br>4<br>2<br>0<br>2 mean<br>Relative consistency (%)<br>Relative consistency (%<br>0<br>2<br>4<br>6<br>max<br>0<br>10<br>20<br>iteration<br>6<br>4<br>2<br>0<br>2 mean|30<br>0<br>2<br>4<br>6<br>8 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5 mean<br>0<br>5<br>10<br>15<br>max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5 mean||\n|0<br>2<br>4<br>6<br>max<br>0<br>10<br>20<br>30<br>iteration<br>4<br>2<br>0<br>2 mean<br>Relative consistency (%)<br>Relative consistency (%<br>0<br>2<br>4<br>6<br>max<br>0<br>10<br>20<br>iteration<br>6<br>4<br>2<br>0<br>2 mean|30<br>0<br>2<br>4<br>6<br>8 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5 mean<br>0<br>5<br>10<br>15<br>max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5 mean||\n|0<br>2<br>4<br>6<br>max<br>0<br>10<br>20<br>30<br>iteration<br>4<br>2<br>0<br>2 mean<br>Relative consistency (%)<br>Relative consistency (%<br>0<br>2<br>4<br>6<br>max<br>0<br>10<br>20<br>iteration<br>6<br>4<br>2<br>0<br>2 mean|30<br>0<br>2<br>4<br>6<br>8 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5 mean<br>0<br>5<br>10<br>15<br>max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5 mean||",
"|Col1|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n||||||||\n||||||||\n||||Paraphr, i|Paraphr, i|t=1, p/it=150|t=1, p/it=150|\n|||||<br>OPT2I, it=<br>OPT2I, it=|<br> 1, p/it=150<br>5, p/it=30||\n|||||OPT2I, it=<br>OPT2I, it=<br>OPT2I it|15, p/it=10<br> 30, p/it=5<br> 150 /it=1||\n||||,|,|, p|, p|",
"|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|\n|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n|||Init<br>|ial<br>||||||||\n|||Par<br>OP|aphr.<br>2I||||||||\n||||||||||||",
"|Col1|**Paraphrasing **Paraphrasing **Paraphrasing<br>Paraphrasing Paraphrasing Paraphrasing<br>**Llama-2 SD2.1 **GPT-3.5 SD2.1 **Llama-2 IF-M<br>_ _ _<br>Llama-2 SD2.1 GPT-3.5 SD2.1 Llama-2 IF-M|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean||\n|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|||||\n|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|||||\n|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|||||\n|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|_<br>_<br>_<br>0<br>5<br>10<br>15 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean<br>Relative consistency (%)<br>Relative consistency (%)<br>0<br>5<br>10<br>15<br>20 max<br>0<br>10<br>20<br>30<br>iteration<br>5<br>0<br>5<br>mean|||||",
"|an|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|||||\n|||||\n|||||",
"|Col1|OPT2I, #imgs/p=1, seed=0 OPT2I, #imgs/p=1, No seed<br>OPT2I, #imgs/p=4, seed=0 OPT2I, #imgs/p=4, No seed<br>OPT2I, #imgs/p=10, seed=0 OPT2I, #imgs/p=10, No seed|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|max|||||0<br>2<br>4<br>6<br>8<br>10 max<br>2<br>1<br>0<br>1<br>2<br>mean|max||||\n|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|||||||||||\n|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|||||||mean||||\n|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|||||||||||\n|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)|0<br>2<br>4<br>6<br>8<br>10 max<br>0<br>10<br>20<br>30<br>iteration<br>2<br>1<br>0<br>1<br>2<br>mean<br>Relative consistency (%)<br>Relative consistency (%)||||||0<br>10<br>20<br>30<br>iteration<br>|0<br>10<br>20<br>30<br>iteration<br>|0<br>10<br>20<br>30<br>iteration<br>|0<br>10<br>20<br>30<br>iteration<br>|0<br>10<br>20<br>30<br>iteration<br>|",
"|mean|Col2|Col3|Col4|\n|---|---|---|---|\n|||||",
"|Llama-2, LDM-2.1 GPT-3.5, LDM-2.1 Llama-2, CDM-M|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|\n|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|9<br>|9<br>|9<br>|9<br>|9<br>|\n|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|5<br>|5<br>|5<br>|5<br>|5<br>|\n|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|9<br>1<br>|9<br>1<br>||||\n|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~|9<br>1<br>|||||\n|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~||||||\n|Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>Relative dCS (%)<br>Overall<br>Complex<br>Fine-grained<br>Detail<br>Quantity<br>Properties &<br>Positioning<br>15<br>17<br>19<br>21<br>23<br>25<br>27<br>29<br>31<br>Relative DSG (%)<br>ama~~-~~,~~-~~.<br>~~-~~.,~~-~~.<br>ama~~-~~,~~-~~||vera|ll<br>Co|mplex<br>Fine-grained<br>Detail<br>Qu|mplex<br>Fine-grained<br>Detail<br>Qu|\n|Relative improvement in prompt-image consistency betw<br> across PartiPrompts prompts and broken down by challe<br>  user prompt start plateauing around the<br> <br>as the<br>|Relative improvement in prompt-image consistency betw<br> across PartiPrompts prompts and broken down by challe<br>  user prompt start plateauing around the<br> <br>as the<br>|een<br>        nge<br>  sc<br>|the<br>         aspec<br>  orer.<br>|user prompt and<br>         t.<br>   Since DSG is c<br>|the best prom<br>      omputed as an<br>|",
"|2|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|0<br>1|0<br>1|0<br>1|||\n|8<br>9|||||\n|8<br>9|||||\n|8<br>9|||||\n|8<br>9|O|vera|ll<br>C|omplex<br>Fine-grained<br>Detail<br>Qua|\n|8<br>9|v<br> s|e i<br>  Par|e i<br>  Par|e i<br>  Par|",
"|175<br>150 (chars)<br>125<br>length<br>100<br>75<br>50<br>0 10 2<br>iterations|Col2|Col3|\n|---|---|---|\n|0<br>10<br>2<br>iterations<br>50<br>75<br>100<br>125<br>150<br>175<br>length (chars)|||\n|0<br>10<br>2<br>iterations<br>50<br>75<br>100<br>125<br>150<br>175<br>length (chars)|||\n|0<br>10<br>2<br>iterations<br>50<br>75<br>100<br>125<br>150<br>175<br>length (chars)|||\n|0<br>10<br>2<br>iterations<br>50<br>75<br>100<br>125<br>150<br>175<br>length (chars)|||\n|0<br>10<br>2<br>iterations<br>50<br>75<br>100<br>125<br>150<br>175<br>length (chars)|||",
"|Col1|Col2|\n|---|---|\n||llama~~-~~2<br>|\n||~~gpt-3.5~~|\n|||\n|||\n|||\n|||",
"|izza on the cutting board (0.5000)|Col2|\n|---|---|\n|.||\n|3333<br>0.3333<br>0.3333<br>dholdsadeliciouspizza.(0.8333)|3333<br>0.3333<br>0.3333<br>dholdsadeliciouspizza.(0.8333)|\n|<br>0000<br>0.3333|1.0000|\n|a mouthwatering pizza awaits slicing. (|1.0000)|",
"|at a crossroads intersection near a waterway. (0.3889)|Col2|\n|---|---|\n|4444<br>0.2222<br>0.4444<br>tanding at a crossroads intersection, surrounded by a<br>waterway. (0.6667)|4444<br>0.2222<br>0.4444<br>tanding at a crossroads intersection, surrounded by a<br>waterway. (0.6667)|\n|||\n|8889<br>0.4444<br>0.4444<br>areositionedatacrossroadsintersectionwitha|8889<br>0.4444<br>0.4444<br>areositionedatacrossroadsintersectionwitha|\n|p    <br>g nearby, producing a striking visual. (|,  <br>0.9167)|\n|0000<br>0.8889<br>0.8889|0000<br>0.8889<br>0.8889|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2403.17804v1.pdf"
}