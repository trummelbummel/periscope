{
"text": "Efficient Prompt Optimization Through the Lens\n                   of Best Arm Identification\n\n                       Chengshuai Shi∗1, Kun Yang∗1, Zihan Chen1,\n                       Jundong Li1, Jing Yang2, and Cong Shen1\n2024       1{cs7ync, ky9tc, brf3rx, jundong, cong}@virginia.edu, University of Virginia\nMay                2yangjing@psu.edu, The Pennsylvania State University\n30\n\n                                              Abstract\n\n                 The remarkable instruction-following capability of large language models (LLMs)\n                 has sparked a growing interest in automatically finding good prompts, i.e., prompt\n                   optimization. Most existing works follow the scheme of selecting from a pre-generated[stat.ML]            pool of candidate prompts. However, these designs mainly focus on the generation\n                    strategy, while limited attention has been paid to the selection method. Especially, the\n                    cost incurred during the selection (e.g., accessing LLM and evaluating the responses) is\n                    rarely explicitly considered. To overcome this limitation, this work provides a principled\n                 framework, TRIPLE, to efficiently perform prompt selection under an explicit budget\n                    constraint. TRIPLE is built on a novel connection established between prompt optimiza-\n                    tion and fixed-budget best arm identification (BAI-FB) in multi-armed bandits (MAB);\n                   thus, it is capable of leveraging the rich toolbox from BAI-FB systematically and also\n                   incorporating unique characteristics of prompt optimization. Extensive experiments on\n                   multiple well-adopted tasks using various LLMs demonstrate the remarkable performance\n                 improvement of TRIPLE over baselines while satisfying the limited budget constraints. As\n                an extension, variants of TRIPLE are proposed to efficiently select examples for few-shot\n                 prompts, also achieving superior empirical performance.arXiv:2402.09723v3\n       1  Introduction\n\n           Large language models (LLMs) have rapidly changed technology landscapes in our society (De-\n             vlin et al., 2018; Touvron et al., 2023a,b; Bubeck et al., 2023; OpenAI, 2023a). Researchers\n           continuously find effective ways to unlock their potential on various downstream tasks.\n        Among different research directions, the remarkable ability of LLMs to follow instructions has\n\n                 ∗indicates equal contributions, random order.\n\n\n                                                  1\n\nmotivated the study of searching for suitable prompts to interact with them (Liu et al., 2023).\nThis approach is particularly attractive as it does not require updating the inside parameters\nof an LLM, and is natural in the way of human conversations. Nevertheless, it has also been\nrecognized that the performance of an LLM is sensitive to the selected prompts (Zhao et al.,\n2021; Lu et al., 2021), and manually designing suitable prompts can be a labor-intensive\nprocess (Mishra et al., 2021). Thus, there is a growing interest to perform automatic prompt\noptimization (Zhou et al., 2022; Xu et al., 2022; Diao et al., 2022; Deng et al., 2022; Prasad\net al., 2022; Zhang et al., 2023a; Guo et al., 2023; Pan et al., 2023; Pryzant et al., 2023; Yang\net al., 2023).\n   While these studies have proposed different prompt optimization designs, they commonly\nfollow the approach of generating a pool of candidate prompts and then selecting from\nthem. With a deeper look, it can be recognized that the focus in these existing works largely\nleans towards how to generate the candidate pool, while limitation attention have been paid\ntowards how to select from the candidates. For example, many works (Jiang et al., 2020;\nXu et al., 2022; Guo et al., 2023; Prasad et al., 2022) directly evaluate all the generated\nprompts on the entire development dataset. However, this less-emphasized selection process\ntypically requires accesses to LLMs, which are often (1) financially costly (e.g., each OpenAI\nAPI access incurs a cost); (2) time-wise consuming (e.g., even a locally hosted LLM would\ntypically require seconds to respond); (3) under total usage limits (e.g., OpenAI has hard\nper-day and per-month limits on API accesses). Furthermore, it is often overlooked that\nevaluating the responses of an LLM for different candidate prompts can be costly as many\ntasks (e.g., writing improvement, mathematical reasoning, etc.) would require human (and\nsometimes domain expert) opinions. As a result, the prompt optimization process can incur\nan unaffordable cost without a proper selection method.\n   To make the learning process more accessible, this work proposes to study prompt\noptimization under an explicitly imposed budget constraint when interacting with the targeted\nLLM, in addition to the previously considered requirements (e.g., discrete, interpretable, and\nblack-box). To the best of our knowledge, budget constraints are only briefly mentioned\nin Zhou et al. (2022); Pryzant et al. (2023), and there are no systematic or principled\ninvestigations of how to address the limited budget constraint in prompt optimization. The\nmain contributions of this work are summarized as follows.\n   • The constraint of a limited budget is explicitly introduced into prompt optimization,\nwhich has been largely ignored before. As most of the prompt optimization methods rely\non selecting from a pre-generated candidate prompt pool, we focus our study on how to\ncarefully allocate budgets to test each candidate prompt so that the optimal one can be\nlearned efficiently and effectively.\n   • We propose a general solution framework, termed TRIPLE (besT aRm Identification\nfor Prompt LEarning), by establishing a novel connection between prompt optimization\nand multi-armed bandits (MAB) (Lattimore and Szepesvári, 2020). In particular, we focus\non harnessing the power of fixed-budget best arm identification (BAI-FB) (Audibert et al.,\n2010; Karnin et al., 2013) to address prompt optimization (especially, selection) with a\nlimited budget constraint. Two representative designs TRIPLE-SH and TRIPLE-CR, inspired by\n\n\n\n                                        2\n\ncelebrated BAI-FB algorithms, are presented. To improve scalability, two enhanced methods,\nTRIPLE-CLST and TRIPLE-GSE, are further proposed, where prompt embeddings are leveraged\nby exploiting the ideas of clustering and function approximation to accelerate the learning\nprocess.\n   • Extensive experimental results are reported using well-adopted prompt tasks and varying\nLLMs to demonstrate the superiority of TRIPLE over previous baselines. In particular, on\nGPT3.5 and Llama2, compared with baseline methods also not using prompt embeddings,\nthe basic TRIPLE-SH and TRIPLE-CR achieves performance improvements by (on average) 3%\nto 16%. When leveraging prompt embeddings, the enhanced TRIPLE-CLST and TRIPLE-GSE\nalso outperform corresponding baselines by (on average) 10% to 56% with fewer prompts\nthan budget and (on average) 16% to 45% with more prompts than budget. The gains are\nfurther evidenced on other LLMs, i.e., Gemma and Mistral. Moreover, the proposed methods\ncan be directly plugged into two popular prompt optimization pipelines, APE (Zhou et al.,\n2022) and APO (Pryzant et al., 2023), with end-to-end performances significantly improved\nover their original implementations.\n   • This work extends broadly to providing a new perspective of prompt optimization from\nMAB, and also a new application scenario of MAB in prompt optimization. This established\nconnection may spark further innovations in both fields. As one concrete example, we extend\nthe study to optimizing the selection of examples in few-shot prompts (Brown et al., 2020),\nwhich can be recognized as a BAI-FB problem in the setup of combinatorial bandits (Chen\net al., 2014; Bubeck et al., 2013). Experimental results illustrate that the extensions of\nTRIPLE achieve superior performance, demonstrating its rich potential.\n  Key Related Works. We discuss a few works that explicitly or implicitly touch upon the\nselection efficiency in prompt optimization, and a complete literature review can be found in\nAppendix A. First, Zhou et al. (2022) discusses a naive filtering strategy without theoretical\nor empirical justifications. Chen et al. (2023) leverages Bayesian optimization (BO) with\nexpected improvement (EI) as the acquisition function to select continuous soft prompts. BO\ncan be viewed as similar to BAI while mostly focusing on infinite-arm cases (Shahriari et al.,\n2015). Moreover, Pryzant et al. (2023); Lin et al. (2023) use specific MAB methods targeting\nregret minimization to perform prompt selection, which, as further illustrated in Sec. 3.3, are\nnot well-suited as they optimize the cumulative selection performance over a period instead\nof the final selection output. Thus, compared with this work, existing investigations either\nlack a comprehensive discussion of the connection between prompt optimization and MAB, or\nchoose unsuitable MAB techniques to tackle prompt optimization. Moreover, as illustrated\nin Sec. 5, the TRIPLE solution outperform the previously adopted methods empirically.\n\n2  Prompt Optimization under a Limited Budget\n\nFollowing Zhou et al. (2022); Chen et al. (2023), we present a concrete formulation of the\nproblem of prompt optimization. Consider that we are using an LLM f(·), which provides a\nmapping from any input X ∈V to a distribution ∆V over the language space V. The answer\nˆY ∈V given by the LLM is assumed to be sampled from f(X) as ˆY ∼f(X). Note that\n\n\n                                        3\n\ninstead of treating f(·) as a deterministic function providing a specific output answer, we\ngenerally consider the practical setting where the answers of LLM exhibit a certain level of\nrandomness.\n   For prompt optimization, we aim to find a prompt p such that when concatenated with\ninputs X of a certain task (i.e, as [p; X]), it provides good performance in expectation\nwith respect to the input distribution IX and the inherent randomness of LLM f(·). The\nperformance is measured as µ(p) := EX∼IXEˆY ∼f([p;X])[s(X, ˆY )], where s(X, ˆY ) denotes a\nscore function that measures the quality of the output ˆY for the input X.\n   Motivated by the common usage scenario of LLMs, recent studies have imposed several\nconstraints on this learning problem (Zhou et al., 2022; Pan et al., 2023; Chen et al., 2023;\nGuo et al., 2023), where the three key ones are (I) black-box: the method can be applied\nto black-box LLMs, i.e., only have access to an API f(·) and no access to the intermediate\nstructure or parameters inside (including gradients, output likelihood, etc.); (II) discrete:\nthe learned prompt must be discrete characters, instead of continuous values (i.e., soft\nprompts); and (III) interpretable: the learned prompt must be understandable by humans,\ninstead of gibberish words.\n    Intuitively, the process of learning a good prompt requires interactions with the LLM (i.e.,\nsample ˆY ∼f([p; X]) and evaluating its responses (i.e., obtain score s(X, ˆY )). However, as\nmentioned in Sec. 1, such interactions and evaluations are costly. Thus, besides the afore-\nmentioned constraints, we further explicitly take into account that the prompt optimization\nprocess should have (IV) a limited budget: the total number of trials with the LLM\nthat happen during the learning is at most N. Finally, the prompt optimization problem\nconsidered in this work can be formulated as: finding p∗with high performance µ(p∗) under\nconstraints of black-box, discrete, interpretable, and a limited budget.\n    Directly tackling this prompt optimization problem has been widely recognized as chal-\nlenging even without the constraint of a limited budget (Liu et al., 2023). As highlighted\nin Pryzant et al. (2023); Chen et al. (2023), it essentially requires performing a black-box\ndiscrete optimization. Instead, many proposed methods rely on the pipeline of first generating\na pool of candidate prompts and then selecting from it (Jiang et al., 2020; Zhou et al., 2022;\nXu et al., 2022; Prasad et al., 2022; Guo et al., 2023). The prompt generation can either be\nperformed manually or follow designed automatic protocols. For example, the famous APE\ndesign (Zhou et al., 2022) selects from prompts generated by an LLM using demonstrations.\nFrom a unified perspective, we can simplify the problem into generating a pool of prompts P\nand finding the optimal prompt in it: p∗:= arg maxp∈P µ(p).\n   While many efforts have been devoted along this line, we recognize that they are largely\nfocused on how to generate prompts, while limited attention has been paid to how to\nselect from the already generated prompts (as mentioned in Sec. 1 and further discussed in\nAppendix A). Naive treatments, such as uniformly evaluating all prompts, are understandable\nsince budget limitations are not considered previously, i.e., unlimited evaluations can be\nperformed. With an explicit budget limitation, however, we need to carefully allocate the\nbudgets to each prompt so that the optimal prompt (or at least a sufficiently good one) can\nbe correctly learned, which is the main focus of this work. An overview of the considered\n\n\n                                        4\n\nFigure 1: The commonly adopted prompt optimization pipeline. Previous works mostly investigate\nthe generation component and ignore costs during selection, where GrIPS and APE are proposed in\nPrasad et al. (2022); Zhou et al. (2022). This work, instead, focuses on the selection component\nunder an explicit budget constraint.\n\n\nprompt optimization pipeline and our focus is illustrated in Fig. 1.\n\n3  Connecting Prompt Optimization with Best Arm Iden-\n    tification\n\nWe provide a new perspective of prompt optimization through the lens of tools in multi-armed\nbandits (MAB) (Lattimore and Szepesvári, 2020; Lai and Robbins, 1985). In particular,\nprompt optimization under a limited budget is shown to be intrinsically aligned with the\nproblem of fixed-budget best-arm identification (BAI-FB) (Audibert et al., 2010; Karnin\net al., 2013). In the following, a brief introduction to MAB is first provided. Then, the\nconnection between prompt optimization (especially selection) and MAB (especially BAI-FB)\nis established. Based on this connection, we propose to fully leverage the rich toolbox from\nBAI-FB to perform efficient prompt optimization.\n\n3.1  Multi-armed Bandits\n\nThe research of multi-armed bandits (MAB) has a long and rich history; see representative\nsurveys of Lattimore and Szepesvári (2020); Bubeck et al. (2012). The most basic form of\nMAB, i.e., the finite-armed stochastic bandits, considers a system with a set K finite arms\n(i.e., actions) that provide stochastic rewards when pulled. When interacting with the system,\nthe agent can select one arm k ∈K to pull at each time, and she receives a stochastic reward:\nrk ∼distk(νk), where distk(νk) denotes the action k’s reward distribution with an unknown\nexpectation νk.\n   The learning objective of the agent in MAB can be roughly divided into two categories:\n(1) regret minimization, which maximizes the expected cumulative rewards collected by the\nagent (Auer et al., 2002; Audibert et al., 2009; Garivier and Cappé, 2011); (2) best arm\nidentification, which targets at outputting the best arm k∗= arg maxk∈K νk (Audibert et al.,\n2010; Garivier and Kaufmann, 2016; Jamieson and Nowak, 2014). These two objectives\noften require different learning strategies. Regret minimization typically relies on a carefully\n\n\n                                        5\n\nTable 1: Prompt Optimization and MAB.\n\n\n\n                Prompt Optimization   Multi-armed Bandits\n\n                   The pool of prompts P       The arm set K\n                       Interact LLM via prompt p         Pull arm k\n                           Score s(X, ˆY )             Reward rk\n                   Randomness in X and ˆY    Randomness in distk\n                        Performance µ(p)        Expected reward νk\n\n                    Learn the optimal prompt    Fixed-budget best arm\n                      under a limited budget      identification (BAI-FB)\n\n\n\n\ndesigned balance between exploration (i.e., obtaining new information) and exploitation (i.e.,\ncollecting higher rewards based on the previous information). Best arm identification, on\nthe other hand, is also called pure exploration as it only focuses on obtaining information\nto find the best arm. We here particularly note that although the designs targeting regret\nminimization often can converge to the optimal arm k∗given a sufficient period of time, they\nare known to be inefficient for the objective of best arm identification in the MAB studies.\n\n3.2 A Bandit View of Prompt Optimization\n\nBased on the above introduction, it can be intuitively understood that the prompt optimization\n(especially, selection) problem can be mapped into an MAB setting:\n• The pool of candidate prompts P is equivalent to the set of arms K;\n• Using a prompt p to interact with LLM can be viewed as selecting a bandit arm k to pull\n   in MAB;\n• The feedback of the score function, i.e., s(X, ˆY ), provides the reward signal rk, where\n  distk(νk) characterizes the randomness of X ∼IX and ˆY ∼f([p; X]). The expected\n  performance µ(p) is the counterpart of the expected reward νk in MAB.\nIt can be further recognized that the target of prompt optimization is more suitable to be\ncaptured as the best arm identification (BAI) problem, instead of a regret minimization one,\nas it only cares about finding the optimal prompt p∗instead of the cumulative performance\nof interactions performed during the learning process.\n   With the relationship between prompt optimization and BAI established, we further\nconsider the constraint of learning under a limited budget. We argue that this aligns with one\nof the main research directions in BAI called fixed-budget best arm identification (BAI-FB)\n(Karnin et al., 2013; Wang et al., 2023; Gabillon et al., 2012). BAI-FB particularly considers\nthe problem of maximizing the probability of correctly identifying the best arm k∗while not\npulling arms more than T times. It can be observed that this formulation matches the goal\nof prompt optimization under a limited budget; thus BAI-FB provides a perfect toolbox to\nenhance the commonly required prompt selection process. The connection between prompt\n\n\n                                        6\n\noptimization and MAB, in particular, BAI-FB, is further illustrated in Table 1. To avoid\nconfusion, in the remainder of this paper, we will adopt the notation of prompt optimization\nas introduced in Sec. 2.\n\n3.3  Harnessing the Power of BAI-FB\n\nAs mentioned, we recognize that prompt optimization under a limited budget is a matching\napplication scenario for BAI-FB. In this paper, we propose a general framework called TRIPLE\n(besT aRm Identification for Prompt LEarning) to harness the power of BAI-FB in solving\nthe prompt optimization problem. This is possible because BAI-FB has witnessed significant\ndevelopment over the years, with several efficient designs being proposed. As a first step,\nwe choose two popular and successful BAI-FB schemes and implement them for prompt\noptimization, which are briefly described below. Their complete descriptions are provided in\nAlgs. 2 and 3 of Appendix C.\n   Sequential Halving (SH). SH is one of the first provably efficient BAI-FB designs\n(Karnin et al., 2013) and remains popular after a decade of its proposal. It follows a protocol\nthat divides the total budget N into ⌈log2(|P|)⌉equal-length phases. In each phase, SH\nuniformly tries all active prompts (initialized as P) and eliminates half of them with the lower\nsample means for the next phase. The final active arm is output as the identified optimal\nprompt.\n   Continuously Reject (CR). CR is a recently proposed method (Wang et al., 2023),\nwhich can be viewed as an extension of the classical Successively Reject (SR) design (Audibert\net al., 2010). It uniformly explores active prompts (initialized as P) and performs potential\nelimination of poorly-performed prompts after each pull. The elimination is based on carefully\ndesigned criteria using the Large Deviation Principle. It can be observed that, without the\nphased structure, CR is more adaptive than SH (and SR), which makes it appealing both\ntheoretically and practically.\n   While MAB has found broad applications in recommender systems (Li et al., 2010),\nhealthcare (Shen et al., 2020), wireless communications (Gai et al., 2012), and beyond\n(Bouneffouf and Rish, 2019), a systematical connection between MAB and prompt optimization\nhas not been established before to the best of our knowledge, which may spark new research\nactivities (see discussions in Sec. 7). In addition, although SH and CR are selected as the\nrepresentatives, the connection between prompt optimization and MAB is fundamental. Any\nexisting or forthcoming BAI-FB designs can be flexibly incorporated into TRIPLE, e.g., the\nBayesian perspective provided in Komiyama et al. (2023); Atsidakou et al. (2022)\n\nRemark 3.1. As mentioned in Sec. 1, Pryzant et al. (2023); Lin et al. (2023) leverage specific\nMAB designs to perform prompt selection without a comprehensive discussion as above on\ntheir connection. Moreover, Pryzant et al. (2023) argues that UCB (Auer et al., 2002) is\nsuitable, while Lin et al. (2023) also uses a UCB-variant, NeuralUCB (Zhou et al., 2020), as\nthe core method. However, both of UCB and NeuralUCB are designed for regret minimization\n(i.e., optimizing the cumulative interaction performance during learning). As illustrated\nin Sec. 3.1, designs for regret minimization cannot achieve optimal performance for the\n\n\n                                        7\n\ngoal of identifying the optimal arm (i.e., BAI), which thus are not well-suited for prompt\noptimization.\n\n4  Handling Large Candidate Pools via Prompt Embed-\n   dings\n\nThe connection bulit in the last section provides us with the core idea of leveraging BAI-FB\ndesigns to tackle prompt optimization. As having been theoretically established (Audibert\net al., 2010), solving BAI-FB without additional structures, however, will unavoidably incur\nan identification error that is positively related to the number of candidate prompts |P|. In\nother words, given a larger pool of prompts, it becomes harder to find the optimal prompt with\nthe basic BAI-FB designs, which restricts their applicability to practical prompt optimization\nproblems (where possibly the number of prompts exceeds the budget).\n   The key reason behind this is that each candidate prompt is treated independently in the\nbasic BAI-FB. Thus, budgets need to be assigned to all the prompts and no information can\nbe shared among them, which is often not the case in prompt optimization. For a prompt\noptimization problem, the underlying task is often stable, e.g., rewriting emails, constructing\nTLDR, etc. The candidate prompts, regardless of their generation methods, should all reflect\nthe purpose of the underlying task and thus share similarities. For example, the candidate\nprompts generated via demonstrating LLMs (Zhou et al., 2022) often share similar structures\nand differ only in a few words or word orders.\n   With the above observation, we target sharing information among prompts during learning.\nTo achieve this, we propose to leverage an embedding model, denoted as embed : V →Rd, to\nobtain the sentence embedding of the prompts: e(p) := embed(p) ∈Rd,  E := {e(p) : p ∈P},\nwhere d refers to the embedding dimension. In the experiments, the OpenAI embedding API\nis adopted while, in general, any sufficiently expressive models can be incorporated. Also,\ndue to this flexibility, using embedding models is fundamentally different from requiring a\nwhite-box LLM (Chen et al., 2023; Lin et al., 2023). With the obtained prompt embeddings,\nwe propose two useful enhancements to further improve the learning effectiveness when the\npool of candidate prompts is large.\n\n4.1  Leveraging Similarities via Clustering\n\n   Since the key challenge is a large pool of candidate prompts, an intuitive idea is to\neffectively decrease the size of the pool. We thus propose a two-phased BAI-FB scheme\nfor prompt optimization. In Phase I, the entire pool of candidate prompts is clustered into\nseveral groups based on their embeddings, and BAI-FB is performed on the clusters with\nan initial target of finding the optimal cluster (or the few good clusters). Then, in Phase II,\nBAI-FB is performed on the prompts in the optimal cluster with the target of identifying\none final prompt. For both phases, different BAI-FB designs can be incorporated, e.g., SH\nand CR. The entire procedure, referred to as TRIPLE-CLST, is described in Alg. 1.\n\n\n\n                                        8\n\nAlgorithm 1 TRIPLE-CLST\n  1: Input: the pool of candidate prompts P and their embeddings E, overall budget N,\n    Phase I budget N1, number of clusters L\n  2: Cluster P into clusters C = {C1, · · · , CL} based on embeddings E (e.g., via k-means)\n  3: Obtain bC∗←BAI-FB(C, N1)                                         {Phase I }\n  4: Obtain ˆp∗←BAI-FB(bC∗, N −N1)                                   {Phase II }\n  5: Output: prompt ˆp∗\n\n\n   The effectiveness of TRIPLE-CLST relies on the clustering results produced in Phase I.\nIdeally, prompts with similar performances should be clustered together. Then, Phase I can\nquickly eliminate the prompts with poor performances, leaving a small pool of good prompts\nfor Phase II to process. In the experiments, this intuitive phenomenon is indeed observed. In\nparticular, in Fig. 8 of Appendix F.1, as expected, prompts in the same cluster share similar\nperformances.\n\n4.2  Sharing Information via Function Approximation\n\nBesides clustering, another idea to incorporate the prompt embeddings is to learn a common\nfunction (e.g., an MLP) to predict the prompt performances based on their embeddings.\nSimilar ideas of function approximation have also been widely adopted in MAB literature\nto share information among large action spaces, with functions ranging from linear ones\n(Abbasi-Yadkori et al., 2011; Yang and Tan, 2022) to neural networks (Zhu et al., 2021;\nZhou et al., 2020). In the setting considered in this work, we adopt a recently developed\nBAI-FB scheme as described in the following as TRIPLE-GSE, with details provided in Alg. 4\nof Appendix C.\n   GSE. The general phased elimination flow of SH described in 3.3 is inherited. The major\ndifference is that SH uses sample means to perform eliminations. GSE (Azizi et al., 2023), on\nthe other hand, leverages collected samples from previous phases to train a reward function\ngθ(·) : Rd →R that maps prompt embeddings to the predicted performance, which is further\nused to eliminate prompts.\n\n5  Experiments\n\nIn this section, extensive experimental results are reported to evaluate the efficiency of\nTRIPLE across diverse prompting tasks from two standard datasets: Instruction-Induction\nHonovich et al. (2022) and BigBench Suzgun et al. (2022). The results reported in this section\nare mainly collected from GPT-3.5, Llama2, Gemma, and Mistral (see the specific model\nnumbers listed in Appendix E.1). Full experimental details can be found in Appendix E. The\ncomplete results of 47 tasks are reported in Appendix F, while here we particularly focus on\n12 representative tasks, which are not too hard (i.e., all generated prompts achieve near-zero\nperformances) or too easy (i.e., all generated prompts achieve near-one performances).\n\n\n                                        9\n\nUCB        TRIPLE-SH        TRIPLE-CR          EI        NeuralUCB        TRIPLE-GSE        TRIPLE-CLST\n\nScore1.8\nEval1.2\nNorm.0.6\n   0.0                Cause     Common   Disambiguation Gender inc. DE  Hyperbaton      Larger        Movie        Object       Starts with     Question     Rhymes       Snarks\n                 and        concept        qa                                     animal   recommendation  counting                      selection\n                     effect\n\n                                                         1.9                                   2.2   3.13.3\nScore1.8\nEval1.2\nNorm.0.6\n   0.0                Cause     Common   Disambiguation Gender inc. DE  Hyperbaton      Larger        Movie        Object       Starts with     Question     Rhymes       Snarks\n                 and        concept        qa                                     animal   recommendation  counting                      selection\n                     effect\n\n(a) |P| = 30 candidates and budget N = 150: GPT-3.5 (top) and Llama2 (bottom). The reported\nresults (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform”\non that task.\n\n                                                                     NeuralUCB          EI        TRIPLE-GSE        TRIPLE-CLST\n                                                                      2.3   2.0                                                           2.1                                                              2.6\n Score1.8\n Eval1.2\n Norm.0.6\n    0.0                Cause      Common   Disambiguation Gender inc. DE  Hyperbaton       Larger        Movie         Object        Starts with      Question      Rhymes        Snarks\n                 and         concept         qa                                       animal    recommendation   counting                        selection\n                     effect\n\n                                                                                                             1.9\n Score1.8\n Eval1.2\n Norm.0.6\n    0.0                Cause      Common   Disambiguation Gender inc. DE  Hyperbaton       Larger        Movie         Object        Starts with      Question      Rhymes        Snarks\n                 and         concept         qa                                       animal    recommendation   counting                        selection\n                     effect\n\n(b) |P| = 150 candidates and budget N = 100: GPT-3.5 (top) and Llama2 (bottom). The reported\nresults (y-axis) are test accuracies of each method normalized to the mean performance of “NeuralUCB”\non that task.\n\nFigure 2: Performance comparisons of various prompt selection methods on the selected tasks. The\nreported results are aggregated over 20 independent runs. The full results on 47 tasks are reported\nin Appendix F.\n\n\n\n\n\n                                       10\n\n5.1  Evaluating TRIPLE with Fixed Prompt Pools\n\nAs TRIPLE main focuses on the prompt selection component, we perform initial evaluations\nin an isolated fashion of selecting from fixed pools of candidate prompts. For this experiment,\ncandidate pools of prompts are generated following the well-established APE design (Zhou\net al., 2022) with a high LLM temperature to ensure randomness. Then, under a limited\nbudget, the performances of TRIPLE algorithms are compared with the following four baselines,\nwhere the latter two (i.e., BO-EI and NeuralUCB) leverage prompt embeddings:\n• Uniform. Many previous designs choose to evaluate the entire candidate pool on all\n  development data (Guo et al., 2023; Prasad et al., 2022) which corresponds to uniformly\n  dividing the total budget to test all prompts.\n• UCB. The upper confidence bound (UCB) method is a famous design for regret minimiza-\n  tion in MAB. We evaluate UCB using its vanilla version from Auer et al. (2002), which is\n  reported to have good performance in Pryzant et al. (2023).\n• BO-EI. Bayesian optimization (BO) with expected improvement (EI) acquisition function\n   is adopted in Chen et al. (2023), which assumes a Gaussian process prior specified by\n  prompt embeddings to perform posterior updates and makes selection to maximize EI.\n• NeuralUCB. Lin et al. (2023) uses NeuralUCB Zhou et al. (2020) to perform prompt\n   selection, which extends UCB by training a reward function to predict prompt performances\n  based on embeddings.\n\nTable 2: Averaged performance ranks of baselines and TRIPLE on the selected tasks using GPT-3.5,\nwhich are computed separately for methods using embeddings or not, where the highest ranked\nmethods are marked bold.\n\n\n        Setup                    Without embeddings                            With embeddings\n    |P|, N, LLM   Uniform   UCB     SH     CR     BO-EI   NeuralUCB   CLST     GSE\n   30, 150, GPT 3.5   3.28 ± 0.99   2.50 ± 1.09  2.04 ± 1.01   2.29 ± 1.09   3.67 ± 0.49    3.00 ± 1.04     1.68 ± 0.67   1.60 ± 0.56\n    30, 150, Llama2    3.08 ± 0.79   2.66 ± 1.07  2.00 ± 1.27   2.25 ± 1.13   3.00 ± 0.95    3.25 ± 0.75    1.58 ± 0.67    2.16 ± 1.26\n    30, 150, Mistral    3.00 ± 0.95   2.50 ± 0.99   2.41 ± 1.31   2.08 ± 1.16   3.00 ± 1.04    2.58 ± 1.08    2.00 ± 0.85    2.41 ± 1.37\n   30, 150, Gemma    3.21 ± 1.03   2.46 ± 1.12  2.04 ± 1.01   2.29 ± 1.09   2.91 ± 0.96    3.16 ± 1.03     2.04 ± 1.05   1.87 ± 0.96\n  150, 100, GPT 3.5                 N/A                         2.58 ± 0.99    3.75 ± 0.45     2.08 ± 0.90   1.58 ± 0.79\n   150, 100, Llama2                 N/A                         2.91 ± 0.95    3.50 ± 0.65    1.41 ± 0.49    2.17 ± 0.98\n   150, 100, Gemma                 N/A                         2.75 ± 1.13    3.16 ± 0.93     2.33 ± 1.23    1.75 ± 0.75\n\n   Performance with fewer prompts than budget. We first test candidate pools with\n30 prompts per task. Results reported in Fig. 2(a) reflect the selection performance with\nan overall budget of 150. It can be observed that TRIPLE-SH and TRIPLE-CR achieve better\nperformance than Uniform (15% and 12% improvements on average for GPT-3.5; 15% and\n16% for Llama2) and UCB (5% and 3% improvements on average for GPT-3.5; 6% and 7%\nfor Llama2). Moreover, for methods using prompt embeddings, the enhanced TRIPLE-CLST\nand TRIPLE-GSE also demonstrate remarkable improvements over BO-EI (11% and 10% on\naverage for GPT-3.5; 56% and 52% for Llama2) and NeuralUCB (17% and 17% improvements\non average for GPT-3.5; 26% and 27% for Llama2). These results empirically evidence the\nsuperiority of TRIPLE with or without prompt embeddings.\n   Performance with more prompts than budget. In the above test, the budget is\n\n                                       11\n\nlarger than the number of candidate prompts. We further perform experiments in a more\ndifficult setting, i.e., there are more prompts than the budget. In particular, candidate pools\nwith 150 prompts per task are generated, and the overall budget is set as 100. In this scenario,\nonly the methods that can leverage embeddings (i.e., BO-EI, NeuralUCB, TRIPLE-CLST,\nTRIPLE-GSE) can be used, as otherwise the total budget is not sufficient to provide even one\nevaluation to initiate the performance estimation of each candidate prompt. Results are\nreported in Fig. 2(b). In particular, it can be observed that TRIPLE-CLST and TRIPLE-GSE\nsignificantly improve over BO-EI (21% and 28% on average for GPT-3.5; 31% and 42% for\nLlama2) and NeuralUCB (38% and 45% on average for GPT-3.5; 26% and 16% for Llama2).\n  A summary of the averaged performance ranks of the baselines and TRIPLE is listed in\nTable 2, which contains results on four LLMs (i.e., GPT-3.5, Llama2, Mistral, Gemma).\nIt can be observed that in varying setups and with different LLMs, the proposed TRIPLE\nmethods consistently obtain better performances than the previous baselines, remarking its\nefficiency and broad applicability.\n   Impact of the total budget. For a more comprehensive\nunderstanding, using candidate pools with 30 prompts, we fur-     30                                                                                                                   UCB\nther examine the impact of budgets, starting with 5 evaluations     25                             TRIPLE-SHTRIPLE-CR\nper prompt on average (i.e., 150 overall as adopted in Fig. 2(a)),  (%)                              TRIPLE-GSE\n                                                                                                    20                             TRIPLE-CLST\nand then gradually increasing to 30 (i.e., 900 overall, which\nis the same as the experiments in Zhou et al. (2022)). From     15                                                                                                                                                                                                                                                                                                                                                                                                                  Improvement\nthe results shown in Fig. 3, we see that the improvements of                                                                                                    10\nTRIPLE over baselines are more pronounced with lower budgets.      Relative\n                                                                                                     5\nIn particular, with a budget of 10 evaluations per prompt on\naverage, TRIPLE-CR, TRIPLE-CLST and TRIPLE-GSE maintain      0\n                                                                                                       5     10     15     20     25     30\nnotable 9.7%, 13.5% and 17.4% improvement over Uniform,                        Budget\nrespectively; when the budget escalates to 20 evaluations per   Figure 3: Relative gain of\nprompt on average, TRIPLE-CLST and TRIPLE-GSE still achieve   over Uniform under different\nan approximate 8% improvement. Once the budget reaches     budgets, collected with\n30 evaluations per prompt on average, all methods provide          GPT-3.5.\napproximately the same performance as they can all identify\nthe optimal prompts under this generous budget.\n\n5.2  Integrating TRIPLE into End-to-End Pipelines\n\nWe now explore whether TRIPLE can provide performance improvements when plugged into\nend-to-end prompt optimization pipelines that include both prompt generation and selection.\nTo this end, two end-to-end designs are considered, aiming to assess the performance of\nTRIPLE in more fluid and iterative settings, which are discussed in the following with our\nimplementation details.\n• APE. Proposed by Zhou et al. (2022), the APE pipeline lets LLMs generate prompt\n  candidates and then selects from them. In our experiments, for each task, following original\n  templates, 30 prompts are generated, followed by different methods to perform selection\n  with a budget of 5 evaluations per prompt on average (i.e., 150 LLM accesses overall).\n\n\n                                       12\n\nTable 3: Performances of integrating TRIPLE in the end-to-end pipelines using GPT-3.5. The\nbaseline methods reported in the original implementations are labeled as (b). For each task, the\nbest score across two pipelines is marked as red, and the best score in the remaining pipeline is\nhighlighted as yellow. TRIPLE-CR are selected over TRIPLE-SH due to its better performance observed\nin the previous experiments. TRILE-CLST is ignored in the tests with APO, as it is ineffective to\ncluster only 10 prompts.\n\n\n                               APE (Zhou et al., 2022)             APO (Pryzant et al., 2023)\n  Tasks                   Uniform (b)   CR     CLST    GSE   UCB (b)   CR     GSE\n   (#1) Cause and effect            0.65 ± 0.18    0.74 ± 0.06   0.75 ± 0.13    0.78 ± 0.08   0.78 ± 0.15   0.80 ± 0.05   0.80 ± 0.08\n   (#2) Common concept           0.09 ± 0.05    0.12 ± 0.06   0.10 ± 0.04    0.14 ± 0.05   0.12 ± 0.04   0.12 ± 0.05    0.14 ± 0.01\n   (#3) Disambiguation qa          0.83 ± 0.04    0.88 ± 0.10   0.97 ± 0.01   0.96 ± 0.01   0.95 ± 0.04   0.98 ± 0.02   0.96 ± 0.02\n   (#4) Gender inc. DE             0.74 ± 0.17    0.81 ± 0.10   0.85 ± 0.12   0.84 ± 0.14   0.69 ± 0.22   0.80 ± 0.17    0.88 ± 0.05\n   (#5) Hyperbaton                 0.78 ± 0.07    0.83 ± 0.11   0.84 ± 0.12    0.84 ± 0.11   0.59 ± 0.24   0.74 ± 0.21    0.79 ± 0.18\n   (#6) Larger animal              0.56 ± 0.24    0.64 ± 0.25   0.79 ± 0.06    0.84 ± 0.02   0.66 ± 0.13   0.73 ± 0.18    0.85 ± 0.15\n   (#7) Movie recommendation     0.61 ± 0.12    0.65 ± 0.18   0.76 ± 0.06   0.74 ± 0.14   0.67 ± 0.11   0.65 ± 0.15    0.71 ± 0.15\n   (#8) Object counting            0.41 ± 0.12    0.45 ± 0.08   0.50 ± 0.07   0.48 ± 0.12   0.44 ± 0.08   0.50 ± 0.09   0.49 ± 0.07\n   (#9) Orthography starts with    0.41 ± 0.21    0.65 ± 0.16   0.67 ± 0.12   0.66 ± 0.13   0.58 ± 0.13   0.64 ± 0.09    0.67 ± 0.17\n   (#10) Question selection         0.90 ± 0.04    0.91 ± 0.03   0.95 ± 0.01   0.93 ± 0.03   0.93 ± 0.06   0.92 ± 0.06    0.93 ± 0.03\n   (#11) Rhymes                   0.66 ± 0.30    0.68 ± 0.26   0.75 ± 0.20    0.78 ± 0.16   0.78 ± 0.12   0.83 ± 0.08    0.85 ± 0.13\n   (#12) Snarks                     0.44 ± 0.10    0.52 ± 0.19   0.57 ± 0.10    0.60 ± 0.21   0.49 ± 0.17   0.56 ± 0.15    0.67 ± 0.05\n  Avg. Performance Rank      4.00 ± 0.00    2.92 ± 0.28   1.58 ± 0.64   1.50 ± 0.50   2.75 ± 0.43   2.00 ± 0.71   1.25 ± 0.43\n\n\n  Zhou et al. (2022) suggest a non-iterative version with uniform evaluations of prompts,\n  which is taken as the baseline here.\n• APO. The APO pipeline (Pryzant et al., 2023) is an iterative one, letting LLMs criticize\n  the previous prompts. Here, following the original templates, three iterations are performed\n  and 10 prompts are generated per iteration. Different selection methods are then tested\n  with a budget of 50 per iteration so that an overall budget of 150 is used, aligning with that\n   of APE. Pryzant et al. (2023) have reported UCB as the most effective prompt selection\n  method, which is adopted as the baseline here.\n   The end-to-end experiment results are reported in Table 3, which reveal the consistently\nbetter performance of TRIPLE over the originally adopted baseline methods. This observation\nhighlights the applicability and flexibility of the TRIPLE framework, i.e., it can benefit any\nprompt optimization pipelines requiring a selection component.\n\n6  Extension: Selections of Examples for Few-shot Prompts\n\nBased on the general connection between prompt optimization and BAI-FB, the power\nof TRIPLE can be further extended beyond finding one good instructional prompt. In the\nfollowing, we provide discussions on how to leverage TRIPLE to efficiently select examples for\nfew-shot prompts.\n   As noticed in Brown et al. (2020), LLMs can perform varying tasks when prompted\nwith several related examples, i.e., few-shot prompting. It has been widely recognized that\na good choice of examples in few-shot prompts is important to obtain good downstream\nperformances (Liu et al., 2021a; Lu et al., 2021). Using the terminology introduced in Sec. 1,\n\n\n                                       13\n\nwe can formulate the problem of example selection as follows. From a set of examples G, we\ntarget at selecting M examples (g1, · · · , gM) to form a few-shot prompt, whose performance\nis measured as µ(g1, · · · , gM) := EX∼IXEˆY ∼f([g1,··· ,gM;X])[s(X, ˆY )]. The optimal selection of\nexamples can be defined as (g∗1, · · · , g∗M) := arg maxg1,··· ,gM∈G µ(g1, · · · , gM).\n   From the MAB perspective, the learning target can be interpreted as finding the optimal\ncombination of M arms from the overall arm set G, which is the focus of the study on\ncombinatorial MAB (CMAB) (Chen et al., 2013, 2016; Combes et al., 2015). Then, TRIPLE\ncan be further extended to incorporate BAI-FB designs from CMAB to perform the desired\nexample selection. In particular, based on some heuristics on the performance µ(g1, · · · , gM),\nTRIPLE-SAR and TRIPLE-CSAR are proposed, extending Chen et al. (2014); Gabillon et al.\n(2011), which are further discussed in Appendix D. The performances of these extensions are\npresented in Table 4, with more details and results provided in Appendix E.6 and F.\n\nTable 4: Performance comparisons of various example selection methods on different tasks using\nGPT-3.5 with |G| = 50 candidate examples, budget N = 100, and length M = 4. The tasks are\nnumbered according to Table 3. For each task, the best score across is marked as red, and the second\nbest as yellow.\n\n\n  Tasks  Random  Uniform   SAR   CSAR   Tasks  Random  Uniform   SAR   CSAR\n   #1    0.65± 0.07   0.63± 0.13   0.67± 0.07  0.66± 0.07   #7    0.98± 0.03   1.00± 0.00   1.00± 0.00   1.00± 0.00\n   #2    0.21± 0.06   0.26± 0.05   0.24± 0.07   0.27± 0.07   #8    0.35± 0.02   0.40± 0.05   0.38± 0.05   0.42± 0.06\n   #3    0.83± 0.06   0.90± 0.05   0.93± 0.07   0.91± 0.06   #9    0.55± 0.14   0.64± 0.12   0.65± 0.12   0.65± 0.14\n   #4    0.96± 0.02   0.96± 0.01   0.97± 0.01   0.97± 0.01   #10    0.84± 0.10   0.91± 0.05   0.95± 0.01   0.94± 0.05\n   #5    0.73± 0.11   0.80± 0.05   0.73± 0.05   0.84± 0.10   #11    0.41± 0.18   0.82± 0.20   0.68± 0.13   0.87± 0.20\n   #6    0.78± 0.10   0.79± 0.11   0.84± 0.04   0.82± 0.04   #12    0.65± 0.08   0.56± 0.07   0.62± 0.12   0.70± 0.09\n                             Avg. Performance Rank    3.75± 0.59   2.83± 0.69   2.08± 0.86  1.33± 0.47\n\n\n7  Conclusions\n\nPrompt optimization is an important problem for large language models (LLMs), but prior\nresearch has not considered the potential cost during prompt selection. We have explicitly\nincorporated a budget constraint to prompt optimization, and studied the problem of how\nto efficiently select prompts with the given budget. A systematical connection between\nmulti-armed bandits (MAB) and prompt optimization was established. Through this lens,\nwe proposed a general framework, termed TRIPLE, to fully harness the power of fixed-budget\nbest arm identification (BAI-FB) to perform prompt optimization. Besides standard BAI-FB\ndesigns, two embedding-based enhancements were proposed to accelerate learning. Extensive\nexperimental results demonstrated the superiority of TRIPLE over multiple representative\ntasks and various targeted LLMs. Furthermore, we showed that TRIPLE could be plugged into\npopular end-to-end prompt optimization pipelines, with better performance than previous\nimplementations, demonstrating its effectiveness and flexibility.\n    In addition to the technical contributions, we believe that the connection between prompt\noptimization and MAB may be of broader interest. It not only provides a rich set of tools\n\n\n                                       14\n\nfrom MAB to advance prompt optimization but also introduces a new application scenario\nfor MAB (especially BAI) research. In particular, the discussed extension to the selection\nof examples for few-shot prompts demonstrates the rich potential of TRIPLE. As future\nsteps, the research on contextual bandits (Li et al., 2010) may provide insights into selecting\ninput-dependent prompts (Wu et al., 2022). Also, the application of prompt optimization\nmay spark new research efforts in MAB, e.g., efficient BAI methods for correlated arms.\n\n\n\n\n\n                                       15\n\nReferences\n\nAbbasi-Yadkori, Y., Pál, D., and Szepesvári, C. (2011). Improved algorithms for linear\n  stochastic bandits. Advances in neural information processing systems, 24.\n\nAtsidakou, A., Katariya, S., Sanghavi, S., and Kveton, B. (2022). Bayesian fixed-budget\n  best-arm identification. arXiv preprint arXiv:2211.08572.\n\nAudibert, J.-Y., Bubeck, S., et al. (2009). Minimax policies for adversarial and stochastic\n  bandits. In COLT, volume 7, pages 1–122.\n\nAudibert, J.-Y., Bubeck, S., and Munos, R. (2010). Best arm identification in multi-armed\n  bandits. In COLT, pages 41–53.\n\nAuer, P., Cesa-Bianchi, N., and Fischer, P. (2002). Finite-time analysis of the multiarmed\n  bandit problem. Machine learning, 47:235–256.\n\nAzizi, M. J., Kveton, B., and Ghavamzadeh, M. (2023). Fixed-budget best-arm identification\n  in structured bandits. arXiv preprint arXiv:2106.04763.\n\nBouneffouf, D. and Rish, I. (2019). A survey on practical applications of multi-armed and\n  contextual bandits. arXiv preprint arXiv:1904.10040.\n\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A.,\n  Shyam, P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners.\n  Advances in neural information processing systems, 33:1877–1901.\n\nBubeck, S., Cesa-Bianchi, N., et al. (2012). Regret analysis of stochastic and nonstochastic\n  multi-armed bandit problems. Foundations and Trends® in Machine Learning, 5(1):1–122.\n\nBubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee,\n  Y. T., Li, Y., Lundberg, S., et al. (2023). Sparks of artificial general intelligence: Early\n  experiments with gpt-4. arXiv preprint arXiv:2303.12712.\n\nBubeck, S., Wang, T., and Viswanathan, N. (2013). Multiple identifications in multi-armed\n  bandits. In International Conference on Machine Learning, pages 258–265. PMLR.\n\nChen, L., Chen, J., Goldstein, T., Huang, H., and Zhou, T. (2023).  Instructzero:  Ef-\n   ficient instruction optimization for black-box large language models.  arXiv preprint\n  arXiv:2306.03082.\n\nChen, S., Lin, T., King, I., Lyu, M. R., and Chen, W. (2014). Combinatorial pure exploration\n  of multi-armed bandits. Advances in neural information processing systems, 27.\n\nChen, W., Hu, W., Li, F., Li, J., Liu, Y., and Lu, P. (2016). Combinatorial multi-armed\n  bandit with general reward functions. Advances in Neural Information Processing Systems,\n  29.\n\n\n                                       16\n\nChen, W., Wang, Y., and Yuan, Y. (2013). Combinatorial multi-armed bandit: General\n  framework and applications.  In International conference on machine learning, pages\n  151–159. PMLR.\n\nCombes, R., Talebi Mazraeh Shahi, M. S., Proutiere, A., et al. (2015). Combinatorial bandits\n   revisited. Advances in neural information processing systems, 28.\n\nDeng, M., Wang, J., Hsieh, C.-P., Wang, Y., Guo, H., Shu, T., Song, M., Xing, E. P., and\n  Hu, Z. (2022). Rlprompt: Optimizing discrete text prompts with reinforcement learning.\n  arXiv preprint arXiv:2205.12548.\n\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018). Bert: Pre-training of deep\n  bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\nDiao, S., Huang, Z., Xu, R., Li, X., Lin, Y., Zhou, X., and Zhang, T. (2022). Black-box\n  prompt learning for pre-trained language models. arXiv preprint arXiv:2201.08531.\n\nGabillon, V., Ghavamzadeh, M., and Lazaric, A. (2012). Best arm identification: A unified\n  approach to fixed budget and fixed confidence. Advances in Neural Information Processing\n  Systems, 25.\n\nGabillon, V., Ghavamzadeh, M., Lazaric, A., and Bubeck, S. (2011). Multi-bandit best arm\n   identification. Advances in Neural Information Processing Systems, 24.\n\nGai, Y., Krishnamachari, B., and Jain, R. (2012). Combinatorial network optimization with\n  unknown variables: Multi-armed bandits with linear rewards and individual observations.\n IEEE/ACM Transactions on Networking, 20(5):1466–1478.\n\nGao, T., Fisch, A., and Chen, D. (2020). Making pre-trained language models better few-shot\n  learners. arXiv preprint arXiv:2012.15723.\n\nGarivier, A. and Cappé, O. (2011). The kl-ucb algorithm for bounded stochastic bandits and\n  beyond. In Proceedings of the 24th annual conference on learning theory, pages 359–376.\n JMLR Workshop and Conference Proceedings.\n\nGarivier, A. and Kaufmann, E. (2016). Optimal best arm identification with fixed confidence.\n  In Conference on Learning Theory, pages 998–1027. PMLR.\n\nGuo, Q., Wang, R., Guo, J., Li, B., Song, K., Tan, X., Liu, G., Bian, J., and Yang, Y. (2023).\n  Connecting large language models with evolutionary algorithms yields powerful prompt\n  optimizers. arXiv preprint arXiv:2309.08532.\n\nHinton, G. E. and Roweis, S. (2002). Stochastic neighbor embedding. In Becker, S., Thrun, S.,\n  and Obermayer, K., editors, Advances in Neural Information Processing Systems, volume 15.\n  MIT Press.\n\n\n\n\n                                       17\n\nHonovich, O., Shaham, U., Bowman, S. R., and Levy, O. (2022). Instruction induction: From\n  few examples to natural language task descriptions. arXiv preprint arXiv:2205.10782.\n\nJamieson, K. and Nowak, R. (2014). Best-arm identification algorithms for multi-armed\n  bandits in the fixed confidence setting. In 2014 48th Annual Conference on Information\n  Sciences and Systems (CISS), pages 1–6. IEEE.\n\nJedra, Y. and Proutiere, A. (2020). Optimal best-arm identification in linear bandits. Advances\n  in Neural Information Processing Systems, 33:10007–10017.\n\nJiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., de las Casas, D.,\n  Bressand, F., Lengyel, G., Lample, G., Saulnier, L., Lavaud, L. R., Lachaux, M.-A., Stock,\n   P., Scao, T. L., Lavril, T., Wang, T., Lacroix, T., and Sayed, W. E. (2023). Mistral 7b.\n\nJiang, Z., Xu, F. F., Araki, J., and Neubig, G. (2020). How can we know what language\n  models know? Transactions of the Association for Computational Linguistics, 8:423–438.\n\nKanarios, K., Zhang, Q., and Ying, L. (2024). Cost aware best arm identification. arXiv\n  preprint arXiv:2402.16710.\n\nKarnin, Z., Koren, T., and Somekh, O. (2013). Almost optimal exploration in multi-armed\n  bandits. In International conference on machine learning, pages 1238–1246. PMLR.\n\nKomiyama, J., Ariu, K., Kato, M., and Qin, C. (2023). Rate-optimal bayesian simple regret\n  in best arm identification. Mathematics of Operations Research.\n\nLai, T. L. and Robbins, H. (1985). Asymptotically efficient adaptive allocation rules. Advances\n  in applied mathematics, 6(1):4–22.\n\nLattimore, T. and Szepesvári, C. (2020). Bandit algorithms. Cambridge University Press.\n\nLester, B., Al-Rfou, R., and Constant, N. (2021). The power of scale for parameter-efficient\n  prompt tuning. arXiv preprint arXiv:2104.08691.\n\nLevy,  I., Bogin, B., and Berant, J. (2023).  Diverse demonstrations improve in-context\n  compositional generalization. In Proceedings of the 61st Annual Meeting of the Association\n  for Computational Linguistics (Volume 1: Long Papers), pages 1401–1422.\n\nLi, L., Chu, W., Langford, J., and Schapire, R. E. (2010). A contextual-bandit approach\n  to personalized news article recommendation. In Proceedings of the 19th international\n  conference on World wide web, pages 661–670.\n\nLi, X., Lv, K., Yan, H., Lin, T., Zhu, W., Ni, Y., Xie, G., Wang, X., and Qiu, X. (2023).\n  Unified demonstration retriever for in-context learning. In Proceedings of the 61st Annual\n  Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages\n  4644–4668.\n\n\n\n                                       18\n\nLi, X. L. and Liang, P. (2021). Prefix-tuning: Optimizing continuous prompts for generation.\n  arXiv preprint arXiv:2101.00190.\n\nLin, X., Wu, Z., Dai, Z., Hu, W., Shu, Y., Ng, S.-K., Jaillet, P., and Low, B. K. H. (2023).\n  Use your instinct: Instruction optimization using neural bandits coupled with transformers.\n  arXiv preprint arXiv:2310.02905.\n\nLiu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., and Chen, W. (2021a). What makes good\n  in-context examples for gpt-3? arXiv preprint arXiv:2101.06804.\n\nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. (2023). Pre-train, prompt,\n  and predict: A systematic survey of prompting methods in natural language processing.\n ACM Computing Surveys, 55(9):1–35.\n\nLiu, X., Ji, K., Fu, Y., Tam, W. L., Du, Z., Yang, Z., and Tang, J. (2021b). P-tuning v2:\n  Prompt tuning can be comparable to fine-tuning universally across scales and tasks. arXiv\n  preprint arXiv:2110.07602.\n\nLu, Y., Bartolo, M., Moore, A., Riedel, S., and Stenetorp, P. (2021). Fantastically ordered\n  prompts and where to find them: Overcoming few-shot prompt order sensitivity. arXiv\n  preprint arXiv:2104.08786.\n\nMin, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., and Zettlemoyer,\n  L. (2022). Rethinking the role of demonstrations: What makes in-context learning work?\n  arXiv preprint arXiv:2202.12837.\n\nMishra, S., Khashabi, D., Baral, C., Choi, Y., and Hajishirzi, H. (2021). Reframing instruc-\n  tional prompts to gptk’s language. arXiv preprint arXiv:2109.07830.\n\nOpenAI (2023a). Gpt-3.5-turbo. https://platform.openai.com/docs/models/gpt-3-5.\n  Accessed: 2024-01-29.\n\nOpenAI (2023b). Text-embedding-ada-002. https://platform.openai.com/docs/models/\n  embeddings. Accessed: 2024-01-29.\n\nPan, R., Xing, S., Diao, S., Liu, X., Shum, K., Zhang, J., and Zhang, T. (2023). Plum:\n  Prompt learning using metaheuristic. arXiv preprint arXiv:2311.08364.\n\nPrasad, A., Hase, P., Zhou, X., and Bansal, M. (2022). Grips: Gradient-free, edit-based\n  instruction search for prompting large language models. arXiv preprint arXiv:2203.07281.\n\nPryzant, R., Iter, D., Li, J., Lee, Y. T., Zhu, C., and Zeng, M. (2023). Automatic prompt\n  optimization with “gradient descent” and beam search. arXiv preprint arXiv:2305.03495.\n\nRubin, O., Herzig, J., and Berant, J. (2022). Learning to retrieve prompts for in-context\n  learning. In Proceedings of the 2022 Conference of the North American Chapter of the\n  Association for Computational Linguistics: Human Language Technologies, pages 2655–\n  2671.\n\n\n                                       19\n\nShahriari, B., Swersky, K., Wang, Z., Adams, R. P., and De Freitas, N. (2015). Taking\n  the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE,\n  104(1):148–175.\n\nShen, C., Wang, Z., Villar, S., and Van Der Schaar, M. (2020). Learning for dose allocation\n  in adaptive clinical trials with safety constraints. In International Conference on Machine\n  Learning, pages 8730–8740. PMLR.\n\nShi, W., Han, X., Gonen, H., Holtzman, A., Tsvetkov, Y., and Zettlemoyer, L. (2022). Toward\n  human readable prompt tuning: Kubrick’s the shining is a good movie, and a good prompt\n  too? arXiv preprint arXiv:2212.10539.\n\nShin, T., Razeghi, Y., Logan IV, R. L., Wallace, E., and Singh, S. (2020). Autoprompt:\n  Eliciting knowledge from language models with automatically generated prompts. arXiv\n  preprint arXiv:2010.15980.\n\nSoare, M., Lazaric, A., and Munos, R. (2014). Best-arm identification in linear bandits.\n  Advances in Neural Information Processing Systems, 27.\n\nSu, H., Kasai, J., Wu, C. H., Shi, W., Wang, T., Xin, J., Zhang, R., Ostendorf, M.,\n  Zettlemoyer, L., Smith, N. A., et al. (2022). Selective annotation makes language models\n  better few-shot learners. arXiv preprint arXiv:2209.01975.\n\nSun, H., Hüyük, A., and van der Schaar, M. (2023). Query-dependent prompt evaluation\n  and optimization with offline inverse rl. arXiv e-prints, pages arXiv–2309.\n\nSuzgun, M., Scales, N., Schärli, N., Gehrmann, S., Tay, Y., Chung, H. W., Chowdhery, A.,\n  Le, Q. V., Chi, E. H., Zhou, D., et al. (2022). Challenging big-bench tasks and whether\n  chain-of-thought can solve them. arXiv preprint arXiv:2210.09261.\n\nTeam, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L.,\n  Rivière, M., Kale, M. S., Love, J., et al. (2024). Gemma: Open models based on gemini\n  research and technology. arXiv preprint arXiv:2403.08295.\n\nThompson, W. R. (1933). On the likelihood that one unknown probability exceeds another\n  in view of the evidence of two samples. Biometrika, 25(3/4):285–294.\n\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B.,\n  Goyal, N., Hambro, E., Azhar, F., et al. (2023a). Llama: Open and efficient foundation\n  language models. arXiv preprint arXiv:2302.13971.\n\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N.,\n  Batra, S., Bhargava, P., Bhosale, S., et al. (2023b). Llama 2: Open foundation and\n  fine-tuned chat models. arXiv preprint arXiv:2307.09288.\n\nWang, P.-A., Tzeng, R.-C., and Proutiere, A. (2023). Best arm identification with fixed\n  budget: A large deviation perspective. arXiv preprint arXiv:2312.12137.\n\n\n                                       20\n\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al.\n  (2022). Chain-of-thought prompting elicits reasoning in large language models. Advances\n  in neural information processing systems, 35:24824–24837.\n\nWen, Y., Jain, N., Kirchenbauer, J., Goldblum, M., Geiping, J., and Goldstein, T. (2023).\n  Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and\n  discovery. arXiv preprint arXiv:2302.03668.\n\nWu, Z., Wang, S., Gu, J., Hou, R., Dong, Y., Vydiswaran, V., and Ma, H. (2022). Idpg: An\n  instance-dependent prompt generation method. arXiv preprint arXiv:2204.04497.\n\nXu, H., Chen, Y., Du, Y., Shao, N., Wang, Y., Li, H., and Yang, Z. (2022). Gps: Genetic\n  prompt search for efficient few-shot learning. arXiv preprint arXiv:2210.17041.\n\nXu, S. and Zhang, C. (2024). Misconfidence-based demonstration selection for llm in-context\n  learning. arXiv preprint arXiv:2401.06301.\n\nYang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and Chen, X. (2023). Large\n  language models as optimizers. arXiv preprint arXiv:2309.03409.\n\nYang, J. and Tan, V. (2022). Minimax optimal fixed-budget best arm identification in linear\n  bandits. Advances in Neural Information Processing Systems, 35:12253–12266.\n\nYavas, R. C. and Tan, V. Y. (2023). Fixed-budget best-arm identification in sparse linear\n  bandits. arXiv preprint arXiv:2311.00481.\n\nZhang, T., Wang, X., Zhou, D., Schuurmans, D., and Gonzalez, J. E. (2023a). Tempera: Test-\n  time prompt editing via reinforcement learning. In The Eleventh International Conference\n  on Learning Representations.\n\nZhang, Z., Wang, S., Yu, W., Xu, Y., Iter, D., Zeng, Q., Liu, Y., Zhu, C., and Jiang,\n  M. (2023b). Auto-instruct: Automatic instruction generation and ranking for black-box\n  language models. arXiv preprint arXiv:2310.13127.\n\nZhang, Z., Zhang, A., Li, M., and Smola, A. (2022). Automatic chain of thought prompting\n  in large language models. arXiv preprint arXiv:2210.03493.\n\nZhao, Z., Wallace, E., Feng, S., Klein, D., and Singh, S. (2021).  Calibrate before use:\n  Improving few-shot performance of language models.  In International Conference on\n  Machine Learning, pages 12697–12706. PMLR.\n\nZhong, Z., Friedman, D., and Chen, D. (2021). Factual probing is [mask]: Learning vs.\n  learning to recall. arXiv preprint arXiv:2104.05240.\n\nZhou, D., Li, L., and Gu, Q. (2020). Neural contextual bandits with ucb-based exploration.\n  In International Conference on Machine Learning, pages 11492–11502. PMLR.\n\n\n\n                                       21\n\nZhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., and Ba, J. (2022). Large\n  language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910.\n\nZhu, Y., Zhou, D., Jiang, R., Gu, Q., Willett, R., and Nowak, R. (2021). Pure exploration in\n  kernel and neural bandits. Advances in neural information processing systems, 34:11618–\n  11630.\n\n\n\n\n\n                                       22\n\nA  Related Works\n\nPrompt Optimization. The study of prompt optimization (also known as instruction\nlearning) focuses on automatically learning suitable prompts, which is more scalable compared\nwith manual prompt engineering. Many efforts have been devoted to this direction (Gao et al.,\n2020; Wen et al., 2023; Sun et al., 2023; Zhang et al., 2022, 2023b), which is summarized in a\nrecent survey of Liu et al. (2023). The early studies mostly consider optimizing soft prompts\n(i.e., continuous vectors) (Lester et al., 2021; Li and Liang, 2021; Zhong et al., 2021; Liu\net al., 2021b; Wu et al., 2022) or discrete but not interpretable prompts (Shin et al., 2020;\nShi et al., 2022) for white-box LLMs, where different gradient-guided optimization techniques\nare leveraged. The recent research efforts, instead, are more focused on considering the more\npractical setting of learning interpretable prompts for black-box LLMs (Prasad et al., 2022;\nZhou et al., 2022; Pryzant et al., 2023; Xu et al., 2022; Guo et al., 2023; Pan et al., 2023;\nChen et al., 2023), where the generating-then-selecting pipeline in Fig. 1 is often adopted.\n   Compared with previous investigations, this work additionally considers a limited budget\nin an explicit fashion, which we believe is a practical but under-investigated concern. Most of\nthe previous methods perform selection based on evaluating prompts on all development data\n(Jiang et al., 2020; Xu et al., 2022; Guo et al., 2023; Prasad et al., 2022), which is unavoidably\ncostly. APE (Zhou et al., 2022) briefly touched on the cost issue by proposing a naive iterative\ntop filtering strategy (which however is suggested to have only marginal benefits). APO\n(Pryzant et al., 2023) tested a few MAB methods, including two classical BAI-FB designs, i.e.,\nSH (Karnin et al., 2013) and SR (Audibert et al., 2009), and reported that the performance\nof UCB is the more favorable. However, it neither formally introduces the budget constraint\nnor provides a systematical connection to BAI-FB as in this work. Also, this work goes\nmuch deeper in incorporating the state-of-the-art BAI-FB designs (i.e., CR (Wang et al.,\n2023) and GSE (Azizi et al., 2023)) and proposing embedding-based enhancements. It is\nworth noting that INSTINCT (Lin et al., 2023) also incorporates one MAB method, i.e.,\nNeuralUCB (Zhou et al., 2020), to prompt optimization. However, as mentioned in Sec. 1,\nNeuralUCB is designed for regret minimization (instead of best arm identification), which is\nnot suitable for learning the optimal prompt.\n   Multi-armed Bandits. Here we briefly discuss the representative studies of MAB, with\ncomprehensive surveys available in Bubeck et al. (2012); Lattimore and Szepesvári (2020).\nAs mentioned in Sec. 3.1, the target of learning in a MAB system can be roughly categorized\nas regret minimization and best arm identification. The regret minimization designs target\nachieving a desired balance between exploration and exploitation so that the cumulative\nrewards are maximized, e.g., UCB (Auer et al., 2002) and Thompson sampling (Thompson,\n1933). The best arm identification (BAI) designs are fully focused on exploration and can be\nfurther divided into two classes: fixed-budget (BAI-FB) and fixed-confidence (BAI-FC). The\nBAI-FB setting maximizes the probability of finding the best arm with a limited number\nof pulls (Audibert et al., 2010; Karnin et al., 2013; Wang et al., 2023; Azizi et al., 2023;\nAtsidakou et al., 2022; Yang and Tan, 2022). The BAI-FC setting is a dual one which focuses\non minimizing the overall number of pulls while guaranteeing that the probability of finding\nthe best arm is higher than a threshold (Garivier and Kaufmann, 2016; Jamieson and Nowak,\n\n\n                                       23\n\n2014; Soare et al., 2014; Jedra and Proutiere, 2020). Besides leveraging BAI-FB as in this\nwork, it is imaginable that BAI-FC designs can also find applications in prompt optimization,\nespecially when valuing identification accuracy over incurred costs. While MAB has found\nwide success in different applications, this work marks the first time that a systematical\nconnection between MAB and prompt optimization has been established to the best of our\nknowledge.\n\nB  Discussions\n\nB.1  Broader Impacts\n\nThis work introduces TRIPLE, a framework that can perform efficient prompt optimization\nfor large language models (LLMs) under limited budgets. By optimizing resource usage in\nprompt optimization for LLMs, we believe the proposed approach could make advanced\nAI tools and research more accessible to institutions and individuals with limited budgets,\npromoting a more equitable and democratized field of study. While acknowledging the need\nfor responsible usage of the proposed method, we do not foresee major negative societal\nimpacts.\n\nB.2  Limitations and Future Works\n\nThis work opens an interesting direction on the connection between MAB and prompt\noptimization. In the following, we discuss a few aspects that are currently lacking in this\nwork and particularly worth future explorations.\n   • Prompt-specific costs. This work considers an abstract model where the cost during\nlearning is measured by the number of LLM accesses. This model provides an important\nstarting point to initialize the investigation. To make the study more practical, more refined\nconsiderations on costs can be incorporated. For example, the OpenAI API charge the\ninteractions based on the number of input tokens, which means longer prompts incur higher\ncosts. The cost-aware BAI studied in Kanarios et al. (2024) can provide some insights to\nfurther considering prompt-specific costs.\n   • Other BAI designs. Based on the connection between prompt optimization and BAI,\nthis work has incorporated several BAI designs. However, the research on MAB has a long\nand rich history, where many other BAI designs can also be leveraged. For example, the\nBayesian perspective provided in Komiyama et al. (2023); Atsidakou et al. (2022) and the\nfunction approximation scheme adopted in Yavas and Tan (2023); Yang and Tan (2022) are\nall worth investigations. This work is important in delivering the message that (both existing\nand forthcoming) BAI methods can benefit prompt optimization, which may inspire future\nexplorations.\n   • Structured prompts. In Sec. 6, we discuss how to extend TRIPLE to select examples for\nfew-shot prompts. Based on the insights obtained in this work, we believe this direction is\nwork further exploration. Moreover, other forms of structured prompting methods, such as\n\n\n                                       24\n\nChain-of-Thoughts (Wei et al., 2022), are also interesting topics, which may further require\nmulti-step techniques such as reinforcement learning.\n\nC  Details of TRIPLE Designs\n\nThe details of TRIPLE-SH (inspired by Karnin et al. (2013)), TRIPLE-CR (inspired by Wang\net al. (2023)), and TRIPLE-GSE (inspired by Azizi et al. (2023)) can be found in Algs. 2, 3,\nand 4, respectively.\n\nAlgorithm 2 TRIPLE-SH\n  1: Input: the pool of candidate prompts P, budget N\n  2: Initialization: set ˆµ(p) ←0 for all p ∈P; set the active prompt set A ←P\n  3: for phase p = 1, · · · , ⌈log2(|P|)⌉do\n  4:    Interact with the targeted LLM using each prompt in A for ⌈N/(|A|⌈log2(|P|)⌉)⌉times\n\n  5:   Update the sample means {ˆµ(p) : p ∈A} using the collected samples\n  6:   Update the active prompt set A as the set of ⌈A/2⌉prompts in the original A with\n      the highest ˆµ(p)\n  7: end for\n  8: Output: the remaining active prompt ˆp∗\n\n\n\nAlgorithm 3 TRIPLE-CR\n  1: Input: the pool of candidate prompts P, budget N\n  2: Initialization: set n(p) ←0, ˆµ(p) ←0 for all p ∈P; set the active prompt set A ←P\n  3: for time τ = 1, · · · , N do\n  4:   Receive input xτ\n  5:    Select prompt pτ ←arg minp∈A n(p)\n  6:   Sample output ˆyτ ∼f([pτ, xτ]) from the targeted LLM\n  7:   Obtain score sτ ←s(xτ, ˆyτ)\n  8:   Update ˆµ(pτ) ←ˆµ(pτ)n(pτ)+sτn(pτ)+1   and n(pτ) ←n(pτ) + 1\n  9:   Compute p′ ←arg minp∈A ˆµ(p) and δτ ←minp∈A\\{p′}{ˆµ(p) −ˆµ(p′)}\n    r N−Pp/∈A n(p)\n10:    if  Pp∈A n(p) log(|A|) −1 ≤δτ then\n11:     Eliminate prompt p′, i.e., A ←A\\{p′}\n12:  end if\n13: end for\n14: Output: prompt ˆp∗←arg maxp∈A ˆµ(p)\n\n\n\n\n\n                                       25\n\nAlgorithm 4 TRIPLE-GSE\n  1: Input: the pool of candidate prompts P and their embeddings E, budget N\n  2: Initialization: set ˆµ(p) ←0 for all p ∈P; set the active prompt set A ←P\n  3: for phase p = 1, · · · , ⌈log2(|P|)⌉do\n  4:    Interact with the targeted LLM using each prompt in A for ⌈N/(|A|⌈log2(|P|)⌉)⌉times\n\n  5:   Use the collected samples to train a function gθ(·) parameterized by θ, e.g., a linear\n      function or an MLP\n  6:   Compute {ˆµ(p) = gθ(e(p)) : p ∈A}\n  7:   Update the active prompt set A as the set of ⌈A/2⌉prompts in the original A with\n      the highest ˆµ(p)\n  8: end for\n  9: Output: the remaining active prompt ˆp∗\n\nD  Details of TRIPLE’s Extensions to Example Selection\n\nIn this section, we provide additional discussions on the extension to example selection\nmentioned in Sec. 6. It is first noted that the properties of good combinations of examples for\nfew-shot prompts is a complicated topic and an active research problem (Lu et al., 2021; Liu\net al., 2021a; Min et al., 2022; Xu and Zhang, 2024), which still lacks conclusive answers. The\nproposed designs are based on heuristics that are well recognized and widely evidenced. With\ndeeper understanding of few-shot prompt developed in later research, the perspective provided\nby TRIPLE and these designs would still be beneficial to guide corresponding modifications\nand extensions.\n  CSAR. First, we incorporate the intuitive heuristic that if one example leads to better\nperformance as a one-shot prompt, it contributes positively to the overall few-shot perfor-\nmance (Rubin et al., 2022; Li et al., 2023). Based on this heuristic, we adapt the CSAR\ndesign (Chen et al., 2014; Bubeck et al., 2013) to perform example selection, which can\nidentify M prompts from G with the highest individual performances, i.e., µ(gm). The details\nare provided in Alg. 5.\n  SAR. It is also noticed in previous studies that selecting a diverse set of examples is\nvital in achieving good few-shot performances (Su et al., 2022; Levy et al., 2023). Leveraging\nthis heuristic, we propose to first divide the example set G into M clusters, denoted as\n{G1, · · · , GM}, based on the embeddings of the examples. Then, for each cluster Gm, we find\none example gm in it with the highest one-shot performance µ(gm). To perform such selection\nprocess efficiently, the SAR design (Bubeck et al., 2013) is leveraged. In this way, the diversity\nand quality of the selected examples are both guaranteed. The details are provided in Alg. 6.\n\n\n\n\n\n                                       26\n\nAlgorithm 5 TRIPLE-CSAR\n  1: Input: the set of available examples G, the size of the combination M, budget N\n  2: Initialization: set ˆµ(g) ←0 for all g ∈G; set the active example set A ←G; ˜T0 ←0;\n    Gacc ←∅; Grej ←∅; log(|G|)˜  ←Pi∈[|G|] 1/i\n  3: for phase p = 1, · · · , |G| do\n  4:     ˜Tp ←⌈(N −|G|)/(log(n)(|G|˜     −p + 1))⌉\n  5:   Interact with the targeted LLM using each example g ∈A as a one-shot prompt for\n         ˜Tp −˜Tp−1 times\n  6:   Update the sample means {ˆµ(g) : g ∈A} using the collected samples\n  7:   Obtain order σ such that ˆµ(gσ(1)) ≥ˆµ(gσ(2)) ≥· · · ≥ˆµ(gσ(|A|))\n  8:   Compute gaps\n\n            (                             ˆµ(gσ(r)) −ˆµ(gσ(M−|Gacc|+1))   if r ≤M −|Gacc|\n              ∆σ(r) ←                                             ∀r ∈[|A|]\n                            ˆµ(gσ(M−|Gacc|)) −ˆµ(gσ(r))       if r ≥M −|Gacc| + 1,\n\n  9:   Compute g′ ←arg maxg∈A ∆g\n10:   Update Gacc ←Gacc ∪{g′} if ˆµ(g′) ≥ˆµ(gσ(M−|Gacc|+1)); Grej ←Gacc ∪{g′} otherwise\n11:   Update A ←G/(Gacc ∪Grej)\n12: end for\n13: Output: the set Gacc\n\nE  Full Experimental Details\n\nIn this section, we include full details of our experiments, while the complete codes are also\nuploaded in the supplementary materials.\n\nE.1 LLM Models and System Instructions\n\nBefore further details, we first list the LLM models that we adopted for experiments:\n\n   • GPT-3.5: gpt-3.5-turbo-1106 (OpenAI, 2023a),\n\n   • Llama2: Llama2-7b Touvron et al. (2023b),\n\n   • Gemma: Gemma-7b (Team et al., 2024)\n\n   • Mistral: Mistral-7B-v0.2 (Jiang et al., 2023)\n\n   As we use chat-based LLMs, initial system instructions are needed, where the officially\nrecommended system instructions are adopted in experiments, as shown in Fig 4.\n\n\n\n\n\n                                       27\n\nAlgorithm 6 TRIPLE-SAR\n  1: Input: the set of available examples G and their embedding E, the size of the combination\n   M, budget N\n  2: Cluster G into clusters {G1, · · · , GM} based on embeddings E (e.g., via k-means)\n  3: Initialization: set ˆµ(g) ←0 for all g ∈G; set the active example set for cluster m as\n  Am ←Gm; set the overall active example set as A ←G; set the active cluster M ←[M];\n      ˜T0 ←0; log(|G|)˜  ←Pi∈[|G|] 1/i\n  4: for phase p = 1, · · · , |G| do\n  5:     ˜Tp ←⌈(N −|G|)/(log(n)(|G|˜     −p + 1))⌉\n  6:   Interact with the targeted LLM using each example g ∈A as a one-shot prompt for\n         ˜Tp −˜Tp−1 times\n  7:   Update the sample means {ˆµ(g) : g ∈A} using the collected samples\n  8:    if ∃m ∈M such that |Am| = 1 then\n  9:     Update M ←M/{m}\n10:     Update g∗m ←the remaining example in Am\n11:   else\n12:   ∀m ∈M, compute ∆m ←maxgm∈Am{max¯gm∈Am ˆµ(¯gm) −ˆµ(gm)} and  g′m ←\n        arg maxgm∈Am{max¯gm∈Am ˆµ(¯gm) −ˆµ(gm)}\n13:    Compute m′ ←arg maxm∈M ∆m\n14:     Update Am′ ←Am′/{g′m′}\n15:  end if\n16: end for\n17: Output: the set {g∗1, · · · , g∗M}\n\n\nE.2  Score Functions\n\nDifferent score functions s(·, ·), i.e., metrics for evaluation, are used for diverse tasks in the\nInstruction-Induction and BigBench-ii datasets, namely “Exact match”, “F1-score”, “Multiple\nchoice within”, and “Multiple choice f1-score”. These score functions are adopted according\nto the specific output requirements of different tasks:\n\n   • Exact match: Used for most tasks unless otherwise specified, this metric scores 1 for\n     outputs exactly matching the label, and 0 otherwise.\n\n   • f1-score: Applied to tasks with complex targets like long sentences (e.g., “informal\n      to formal”, “negation”, “sentence similarity”), this metric (defined in Definition E.1),\n      evaluates the overlap between the LLM response and the label.\n\n   • Multiple choice within: Suitable for tasks with several correct answers, it scores 1\n         if the LLM’s response matches any correct answer and 0 otherwise. We utilized this\n     metric for tasks “rhymes”, “translation-en-de”, “translation-en-es”, “translation-en-fr”\n     and “word in context”.\n\n\n\n                                       28\n\nFigure 4: The adopted system instructions: GPT-3.5 (left) and Llama2/Gemma/Mistral\n(right)\n\n\n   • Multiple choice f1-score: Employed for tasks with multiple, lengthy correct answers\n     (“common concept” task), it calculates the highest f1-score across all potential correct\n      answers.\n\nDefinition E.1 (f1-score). Suppose the question has a labeled answer T and the response of\nthe LLM is A, then the f1-score for this answer is defined as:\n\n                                      2 × P × R\n                                   Sf1 =                  ,\n                               P + R\n\nwhere P = lm/lA stands for the precision of the response and R = lm/lT the recall of the\nresponse. Here we use lA and lT to denote the length of the response and label while lm is\nadopted to represent the number of matching words between A and T.\n\n   For the specific score function adopted for the BigBench-ii dataset, we advise referring to\nthe “metric” label for each task therein. This label indicates the appropriate metric (“Exact\nmatch” or “Multiple choice within”) for the optimal evaluation.\n\nE.3  Experiments with Fixed Prompt Pools and APE\n\nThe prompt generation process to obtain the fixed prompt pools largely follows the one\nin APE Zhou et al. (2022), i.e., demonstrating LLMs with examples. In particular, in the\ngeneration of each prompt, we sample 10 examples from the training set to demonstrate\nLLMs with two types of generation templates: ‘forward’ and ‘backward’, which are illustrated\nin Fig. 5. The same setups are also adopted in the end-to-end experiments with APE in\nSec. 5.2.\n  A side observation is that we find that in general, GPT-3.5 can handle both templates,\nresulting in reasonable prompts. However, LLMs with fewer parameter numbers, like Llama2-\n7b, Gemma-7b, or Mistral-7b-v0.2 we use, exhibit difficulties in generating useful prompts\nfrom the ‘backward’ template, possibly due to its more simplified structure.\n\n\n                                       29\n\nFigure 5: The adopted prompt generation templates for experiments with APE: forward\n(left) and backward (right)\n\n\nE.4  Experiments with APO\n\nThe APO framework (Pryzant et al., 2023) iteratively refines prompts based on feedback gener-\nated by LLMs. In particular, for each iteration, the system is set to identify {num_feedback}\nfault reasons (i.e., gradients) for the selected prompts from previously incorrectly answered\nexamples. Then, with the selected prompts and the identified fault reasons, the LLM is\ninstructed to create {num_prompts} new prompts for further selection. The adopted tem-\nplates in our experiments are shown in Fig. 6, where we set {num_feedback} to 2 and\n{num_prompts} to 5. We believe this configuration ensures that each iteration effectively\nidentifies key areas of improvement and sufficiently expands the pool of potential prompts.\n\n\n\n\n\nFigure 6: The adopted templates for experiments with APO (Pryzant et al., 2023): fault\nidentification (i.e., “gradient”) (left) and new prompt generation (right).\n\n\n\n\n\n                                       30\n\nE.5  Implementions of TRIPLE-CLST and TRIPLE-GSE\n\nObtaining Embedding. A critical component of both TRIPLE-CLST and TRIPLE-GSE is\nthe extraction of sentence embeddings for the candidate prompts. In our experiments, the\nprompts are first tokenized using the cl100k_base tokenizer. Then, the tokenized prompts\nare input into the text-embedding-ada-002 model (OpenAI, 2023b), converting them into\ncontinuous vectors.\n   TRIPLE-CLST. In experiments with TRIPLE-CLST, the number of clusters is set as L =\n⌈ p |P|⌉and a third of our total budget is allocated for the initial phase, i.e., N1 = N/3. The\nk-means algorithm is employed as the clustering method. For more stable performance, Phase\nI is configured to find the top L/2 clusters, instead of the optimal one, which safeguards\nagainst the situation that the optimal prompt is not located in the optimal cluster. Also, for\nthe BAI-FB designs in both phases, the CR algorithm (Wang et al., 2023) is adopted due to\nits flexibility.\n   TRIPLE-GSE. The OpenAI embedding API returns embeddings of 1536 dimensions, which\ncan be challenging for learning with limited samples. To overcome this issue, in the imple-\nmentation of TRIPLE-GSE, we first employ a projection to 64 dimensions using a matrix with\nrandom elements from the standard normal distribution. This technique is also incorporated\nin Chen et al. (2023) and is particularly beneficial given our limited budget constraints.\nFurthermore, to avoid overfitting and convergence issues, we adopt the standard approach\nby dividing our interaction data into training (80%) and validation (20%) sets. The prompt\nelimination process on line 7 in Alg. 4 is performed only if the mean squared error on the\nvalidation set is sufficiently low, and we set this error threshold at 0.1 in our experiments.\n\nE.6  Experiments of Example Selection\n\nIn the results reported in Table 4, the task is to select 4 examples from a set of overall 50\ncandidate examples within 100 interactions with the targeted LLM. For tasks with a training\ndataset larger than 50 examples, 50 examples are first sampled to construct the candidate\nset, which is used consistently across experiments. There are also a few tasks with a training\ndataset smaller than 50 examples, which are thus entirely used as the candidate set. The\nsame prompt template, as illustrated in Fig. 7, is used for all tasks to maintain consistency.\n   Further details regarding the adopted baselines are provided in the following.\n• Random. To validate the benefits of interactions with the targeted LLM during the\n   selection, one commonly adopted baseline is to randomly select the required number of\n  examples from the candidate pool.\n• Uniform.  Similar to the uniform baseline adopted in Sec. 5, the overall budget can\n  be uniformly divided to evaluate the one-shot performance of each prompt. Then, the\n  examples with the highest estimated one-shot performances are selected.\n   Also, for TRIPLE-SAR, the same process of obtaining embeddings as described in Ap-\npendix E.5 with also k-means as the algorithm to perform clustering.\n\n\n\n\n                                       31\n\nFew-shot template\n\n                                             Instruction: Complete the problem.\n\n                                     Examples:\n                                            Input: [𝑄1] Output: [𝐴1]\n                                            Input: [𝑄2] Output: [𝐴2]\n                                            Input: [𝑄3] Output: [𝐴3]\n                                            Input: [𝑄4] Output: [𝐴4]\n                                          Task: Input: [𝑄] Output: {output}\n\n                                           Provide only one answer and NOTHING else.\n\n\n      Figure 7: The adopted few-shot templates for experiments of example selection.\n\n\nE.7  Computing Resources and Costs\n\nWe use a workstation with two Nvidia-A6000 Ada GPUs for all experiments using white-box\nLLMs (i.e., Llama2, Mistral, and Gemma). To reproduce our result, any GPU with over 30\nGB of memory should be sufficient. With our equipment, each interaction with the white-box\nLLMs typically takes around 1.3 −2.0 seconds. For experiments using GPT-3.5, the whole\nexecution is light regarding local computational resources, while accesses to the OpenAI API\nis needed to perform learning. Under our network condition, one API call typically takes\naround 1 second.\n\nF  Additional Experimental Results\n\nAdditional experimental results are provided to supplement observations in the main paper.\n\nF.1  Additional Details of Clustering\n\nIn Sec. 4, clustering is adopted to enhance the efficiency of prompt selection in TRIPLE-CLST.\nFig. 8 is provided to demonstrate the effectiveness of clustering, i.e., prompts with similar\nperformances are often clustered together. To supplement the two examples provided in\nFig. 8, Tables 5 and 6 provide the full details of the prompts to be clustered and showcase\nprompts that have been grouped into the same clusters. These examples reveal that clustered\nprompts often share thematic elements or keywords, such as the use of ‘choice/choose’ and\n‘movie’ in the movie selection task, Cluster 0, or a focus on ‘rhyming words’ in the rhymes\ntask, Cluster 3.\n\nF.2  Selection of Budgets\n\nTo further guide practical implementation, we additionally investigate how to select a\nreasonable budget.  In particular, we focus on the efficiency of various prompt selection\nalgorithms in identifying a “good” prompt – either the optimal prompt in the pool or\nachieving 95% or better of the optimal prompt’s performance. Fig. 9 illustrates that initial\n\n                                       32\n\nFigure 8: Clusters for 30 prompts for “movie_recommendation” (left) from BigBench (Suzgun\net al., 2022) and “rhymes” (right) from Instruction Induction (Honovich et al., 2022). Prompts\nin the same cluster are labeled by the same color and shape. The performance of each\nprompt is represented by the size of its shape (the larger the better). It can be observed that\nthe prompts in the same cluster (i.e., the same color and shape) share similar performance\n(i.e., similar sizes).  Especiall, the optimal prompt (marked by the red star) is clustered\ntogether with a few prompts with comparably near-optimal performances. The embeddings\nare projected to 2 dimensions using T-SNE (Hinton and Roweis, 2002).\n\n\nincreases in budgets significantly improve the probability of identifying a good prompt, but\nthis benefit tapers off with further budget expansion. This finding suggests that starting with\na modest budget and incrementally increasing it is the more effective approach, stopping\nwhen additional investment no longer translates into significant returns.\n\nF.3  Performances on Gemma and Mistral\n\nFor the experiments on the selected tasks with |P| = 30 prompts and budget N = 150,\nadditional results with Gemma and Mistral are reported in Fig. 10(a) and 10(b). The\nsuperiority of TRIPLE can still be observed, demonstrating its flexibility over different LLMs.\n\nF.4  Complete Evaluations on 47 Tasks\n\nIn the main paper, we provide experimental results of 12 representative tasks from the overall\n47 available tasks in Sec. 5. In the following, the complete results are discussed.\n\n   • |P| = 30, N = 150: results on the 24 available tasks in the Instruction-Induction dataset\n     (Honovich et al., 2022) are illustrated in Fig. 11(a) (GPT-3.5), and 11(b) (Llama2);\n\n   • |P| = 30, N = 150: results on the 23 available tasks in the BigBench-ii dataset (Suzgun\n      et al., 2022) are illustrated in Fig. 12(a) (GPT-3.5), and 12(b) (Llama2).\n\n\n\n\n                                       33\n\nFind Good Prompt Rate/Budget for Different Prompt Selection Algorithms\n                                                                                  1.0       Uniform\n                                                                      UCB\n                                                                       SH\n                                                                      CR\n                                                                                  0.9       FuncApprox\n                                                                                                 Cluster\n\n                                                                                  0.8\n                                                                                                                                                                                                                                                                              Rate/Budget 0.7\n                                                                                                                                                   Prompt 0.6\n                                                                                                  Good\n                                                                                                  Find 0.5\n\n\n                                                                                  0.4\n\n\n                                                                                  0.3\n\n                                                                          5          10         15         20         25         30\n                                                                                                          Budget\n\nFigure 9: Probability for different algorithms to select a good prompt under different budgets\n(right), collected with GPT-3.5 and averaged over 5 runs.\n\n\n   • |P| = 150, N = 100: results on the 24 available tasks in the Instruction-Induction\n      dataset (Honovich et al., 2022) are illustrated in Fig. 13(a) (GPT-3.5), and 13(b)\n     (Llama2);\n\n   • |P| = 150, N = 100:  results on the 23 available tasks in the BigBench-ii dataset\n     (Suzgun et al., 2022) are illustrated in Fig. 14(a) (GPT-3.5), and 14(b) (Llama2).\n\n    Also, the complete performances of example selection for few-shot prompts discussed in\nSec. 6 are presented in Fig. 15 (Instruction-Induction) and 16 (BigBench-ii).\n   Besides the average return, another key aspect of prompt selection is the frequency of\nselecting a good prompt. In Table 7, we further demonstrate the best prompt identification\nfrequency of different algorithms across 20 selected tasks from 5 independent runs.\n\n\n\n\n\n                                       34\n\nTable 5: Clusters for “movie selection”: the best prompt overall is marked in red, and the best\nprompt in each cluster in yellow.\n\n\n\n              Cluster   Prompts\n                    The instruction was to select the movie title that appeared the most frequently among the given choices.\n                    The instruction was to choose the correct movie from the given choices based on the input movie titles.\n                      Based on the given inputs and choices, the task was to select the option that matched the given genre film.\n                    The instruction was to choose the movie title from the given choices that corresponds to the movie titles in\n                        the input.\n               0     The instruction was to select the movie from the given choices.\n                   The instruction was to determine which movie from a list of choices the user should watch based on the\n                        inputted movies.\n                    The instruction was to select the movie title that received the most number of votes from the given choices.\n                    The instruction was to choose the correct movie based on the given choices.\n                    The instruction was to provide the output movie based on the given choices.\n                    The instruction was to choose one movie from the given choices.\n                    The instruction was to select the correct movie from the given list of choices.\n                   The instruction was to provide the output movie choice for each given input movie titles and their\n                        corresponding choices.\n                    The instruction was to recommend one movie out of the given choices.\n                    The instruction given was to determine the best choice from a given list of movies, based on a set of choices\n                     and their corresponding scores.\n                   The instruction was to choose the most suitable movie choice based on given input movies. There were\n                         multiple choices for each input, and the selected choice was the one with a value of 1. The chosen movie is\n                        the output.\n                      Choose the correct answer based on the given choices.\n               1\n                      Choose the correct answer from the given choices.\n               2       In each case, provide output responding the relative place of these Nos among Fraser beat shape singers\n                         then,the relative here is taken negatively ( greater– worser place’s id it falls in franchise with counselling\n                           distribution) Crush Orders Miscellaneous similarly ) depending continuity concentration tactical confirmed\n                      kidnook campaign Hudson stapuffer reinforcements Paris Concentraro’s theater!  stimket made water\n                         excavation blokers Estate Vector Vancouver British infantry company merchant banker subsidiary amended\n                LNG Ferdinand mates uber Schaap m Royalty fracture PSA Conv drafts navigate Parse Site-name CrossRef\n                    SC_K1-apemiller_MP Ref lightweight winds Hurricane winds login Joint GetString Parameters disparities\n                      Orth Rocket Venting MPI resemble are Met Lev arc-str sand erosion culernels Hophobic Inbox ashes Cosmos\n                       shaping Open whitespace subsidizing Urprot Monthly-Stagg NZ archivetiles coastline-connected Stretch\n                        Tribunal Recent Signing exposing Directors rose reveal FA corp Sew pro Last ranks banned Tokibi FusionRib\n                       bath storageSettings metaValidateFallback macros Un subtitle Rut Mexican commentary Ribad uploading\n                     grow encryption reading Util classes Teaching Alternative indent workflowsJSON filepath Strings testBy\n                        Samplefree textile Parser elem pract OakWhen nodes Up representatives Knoxville ODEM repositories BP\n                           fixed role Renighbours EIF Recall Copy Destruction gears\n                    The instruction was to determine the correct output based on a given input and its corresponding choices.\n                    The instruction was to determine the output choice based on the given inputs and options.\n               3     The instruction was to select the choice with the highest point value.\n                    The instruction was to select one choice from each list and provide the selected choice as the output.\n                    The instruction was to select the correct choice from each input sequence.\n                        RSelect the correct output film title from the given list of input films.\n               4\n                      Choose the correct title from a list of options.\n                          Select one movie from the given choices based on the input movies.\n                      Determine the correct movie choice based on the given options for each input.\n               5      Given a list of movie titles, you need to choose the correct movie from the given choices that matches closely\n                       with the given titles.\n                      Find the correct output movie from the provided choices.\n                          Select the movie from the given choices.\n\n\n\n\n\n                                       35\n\nTable 6: Clusters for “rhymes”: the best prompt overall is marked in red, and the best prompt in\neach cluster in yellow.\n\n\n\n              Cluster   Prompts\n                    The instruction was to identify any homophones in the given inputs.\n               0\n                          Identify the words from the given inputs.\n                    The instruction was to find the nearest rhyming word for each given word.\n                      Find the rhyming word for the given word.\n                       Replace the provided word with a similar word that rhymes with it and has a different meaning.\n               1\n                      Find the words that rhyme with the given word.\n                    The instruction was to provide the output word that rhymes with the given input word.\n                    The instruction was to identify any words that are still the same after removing the letters \"in\", \"re\", \"pro\",\n                         \"ex\", and \"anti\" from the beginning or middle of the word.\n               2       Identify the words that are pronounced the same but have different meanings (homophones).\n                          Identify the incorrect word within each pair.\n                          Identify any words that are one letter away from a real word that makes sense.\n                          Identify the word that can be created by changing a single letter at a time from the given word.\n                      Find the rhyming word for each input word.\n                    The instruction was to find the rhyming word for each input word.\n                      Find the rhyming word for each input Identify the rhyming word for each given input word.\n                      Find rhyming words for the given inputs.\n               3\n                      Find the rhyming word for each input word.\n                       Generate rhyming words with the given input words.\n                      Find the rhyming word for each input word.\n                       Replace the word ’phone’ with a similar word.\n                          Identify the words that rhyme with \"phone\".\n               4       Identify the words that rhyme with \"phone\".\n                          Identify words that rhyme with ’phone’ and suggest the alternative word that rhymes with each inputted\n                       word.\n                    The instruction was to list the words that rhyme with \"phone\".\n                        Provide the correct spelling for the given words.\n                        Correct the spelling of the word if it is misspelled, otherwise, keep the word as it is.\n               5       Identify the correct spelling of the word.\n                       Replace the letter \"o\" with the letter \"a\" in each word.\n                    The instruction was to correct any misspelled words in the given inputs.\n\n\n\n\n\n                                       36\n\nUCB        TRIPLE-SH        TRIPLE-CR          EI        NeuralUCB        TRIPLE-GSE        TRIPLE-CLST\n\n                                        2.61.9          2.1                                       2.4 2.42.3                                                                         1.9\nScore1.8\nEval1.2\nNorm.0.6\n   0.0                Cause     Common   Disambiguation Gender inc. DE  Hyperbaton      Larger        Movie        Object       Starts with     Question     Rhymes       Snarks\n                and        concept        qa                                     animal   recommendation  counting                      selection\n                    effect\n\n                                                 (a) Gemma\n\n\n                                        2.1\nScore1.8\nEval1.2\nNorm.0.6\n   0.0                Cause     Common   Disambiguation Gender inc. DE  Hyperbaton      Larger        Movie        Object       Starts with     Question     Rhymes       Snarks\n                and        concept        qa                                     animal   recommendation  counting                      selection\n                    effect\n\n                                               (b) Mistral\n\nFigure 10: Performances using Gemma and Mistral on selected tasks with |P| = 30 prompts\n                             and budget N = 150.\n\n\n\n\n\n                                       37\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0             Antonyms         Cause        Common               Diff                   First             Informal           Larger             Letters\n                                and            concept                           word                to              animal                    list\n                                        effect                                                           letter             formal\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0             Taxonomy         Negation        Number            Active            Singular         Rhymes          Second          Sentence\n                animal                                   to                  to                  to                             word              similarity\n                                                        verbal            passive              plural                                      letter\n\n                                                                                                                                 UCB\nScore1.5                                                                                                                                                          TRIPLE-SH                                                                                                                                                               TRIPLE-CR\nEval1.0                                                                                                                                                                                             EI\n                                                                                                                                                       NeuralUCB\nNorm.0.5                                                                                                                                                      TRIPLE-GSE\n   0.0                                                                                                                                                          TRIPLE-CLST               Sentiment         Starts with        Sum         Synonyms         Translation         Translation         Translation         Word\n                                                                                      en-de             en-es               en-fr                  in\n                                                                                                                                                 context\n\n                                                 (a) GPT-3.5\n\n                                                                                                                                                                 2.23   3.083.27\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0             Antonyms         Cause        Common               Diff                   First             Informal           Larger             Letters\n                                and            concept                           word                to              animal                    list\n                                        effect                                                           letter             formal\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0             Taxonomy         Negation        Number            Active            Singular         Rhymes          Second          Sentence\n                animal                                   to                  to                  to                             word              similarity\n                                                        verbal            passive              plural                                      letter\n\n                                                                                                                                 UCB\nScore1.5                                                                                                                                                          TRIPLE-SH                                                                                                                                                               TRIPLE-CR\nEval1.0                                                                                                                                                                                             EI\n                                                                                                                                                       NeuralUCB\nNorm.0.5                                                                                                                                                      TRIPLE-GSE\n   0.0                                                                                                                                                          TRIPLE-CLST               Sentiment         Starts with        Sum         Synonyms         Translation         Translation         Translation         Word\n                                                                                      en-de             en-es               en-fr                  in\n                                                                                                                                                 context\n\n                                               (b) Llama2\n\nFigure 11: Complete results on the Instruction-Induction dataset with |P| = 30 prompts and\n                                 budget N = 150.\n\n\n\n\n\n                                       38\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0               Implicatures          Ruin            Navigate           Causal            Sports            Object           Epistemic        Winowhy\n                             names                          judgment       understanding       counting         reasoning\n\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0                 Timedial           Snarks           Word          Hyperbaton         Linguistics         Question          Word              Logical\n                                                          sorting                              puzzles           selection       unscrambling          fallacy\n                                                                                                                                                    detection\n\n                                                                                                                                 UCB\nScore1.5                                                                                                                                                          TRIPLE-SH                                                                                                                                                               TRIPLE-CR\nEval1.0                                                                                                                                                                                             EI\n                                                                                                                                                       NeuralUCB\nNorm.0.5                                                                                                                                                      TRIPLE-GSE\n   0.0                                                                                                                                                          TRIPLE-CLST                Dyck           Disambiguation          Movie               Tense           Presuppositions      Gender inc. DE         Operators\n                languages             qa           recommendation                               as\n                                                                                                                                              nli\n\n                                                 (a) GPT-3.5\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0               Implicatures          Ruin            Navigate           Causal            Sports            Object           Epistemic        Winowhy\n                             names                          judgment       understanding       counting         reasoning\n\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0                 Timedial           Snarks           Word          Hyperbaton         Linguistics         Question          Word              Logical\n                                                          sorting                              puzzles           selection       unscrambling          fallacy\n                                                                                                                                                    detection\n                                                            1.90\n                                                                                                                                 UCB\nScore1.5                                                                                                                                                          TRIPLE-SH                                                                                                                                                               TRIPLE-CR\nEval1.0                                                                                                                                                                                             EI\n                                                                                                                                                       NeuralUCB\nNorm.0.5                                                                                                                                                      TRIPLE-GSE\n   0.0                                                                                                                                                          TRIPLE-CLST                Dyck           Disambiguation          Movie               Tense           Presuppositions      Gender inc. DE         Operators\n                languages             qa           recommendation                               as\n                                                                                                                                              nli\n\n                                               (b) Llama2\n\nFigure 12: Complete results on the BigBench-ii dataset with |P| = 30 prompts and budget\n                       N = 150.\n\n\n\n\n\n                                       39\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0            Antonyms    Cause    Common        Diff           First      Informal     Larger      Letters   Taxonomy   Negation   Number      Active\n                         and      concept                word         to       animal           list       animal                     to           to\n                               effect                                     letter      formal                                                       verbal      passive\n\n\nScore1.5                                                                                                                                                                                             EI\nEval1.0                                                                                                                                                  NeuralUCBTRIPLE-GSE\nNorm.0.5                                                                                                                                                          TRIPLE-CLST\n   0.0                Singular    Rhymes    Second    Sentence   Sentiment  Starts with   Sum    Synonyms  Translation  Translation  Translation    Word\n                   to                  word      similarity                                                  en-de       en-es        en-fr           in\n                  plural                      letter                                                                                                     context\n\n                                                 (a) GPT-3.5\n\n                                                                                                                     1.91\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0            Antonyms    Cause    Common        Diff           First      Informal     Larger      Letters   Taxonomy   Negation   Number      Active\n                         and      concept                word         to       animal           list       animal                     to           to\n                               effect                                     letter      formal                                                       verbal      passive\n\n\nScore1.5                                                                                                                                                                                             EI\nEval1.0                                                                                                                                                  NeuralUCBTRIPLE-GSE\nNorm.0.5                                                                                                                                                          TRIPLE-CLST\n   0.0                Singular    Rhymes    Second    Sentence   Sentiment  Starts with   Sum    Synonyms  Translation  Translation  Translation    Word\n                   to                  word      similarity                                                  en-de       en-es        en-fr           in\n                  plural                      letter                                                                                                     context\n\n                                               (b) Llama2\n\n Figure 13: Complete results on the Instruction-Induction dataset with |P| = 150 prompts\n                             and budget N = 100.\n\n\n\n\n\n                                       40\n\n2.14                                                         2.62\n   2.0\nScore1.5\nEval1.0\nNorm.0.5\n   0.0              Implicatures    Ruin      Navigate    Causal      Sports      Object    Epistemic   Winowhy    Timedial     Snarks     Word    Hyperbaton\n                      names               judgment understanding counting   reasoning                                           sorting\n\n                                                                                                                                                                      2.32      2.03\n   2.0\nScore1.5                                                                                                                                                                                             EI\nEval1.0                                                                                                                                                  NeuralUCBTRIPLE-GSE\nNorm.0.5                                                                                                                                                          TRIPLE-CLST\n   0.0                Linguistics    Question     Word        Logical      Dyck   Disambiguation   Movie       Tense   PresuppositionsGender inc. DE Operators\n                puzzles      selection  unscrambling    fallacy     languages      qa    recommendation                as\n                                                       detection                                                                                 nli\n\n                                                 (a) GPT-3.5\n\nScore1.5\nEval1.0\nNorm.0.5\n   0.0              Implicatures    Ruin      Navigate    Causal      Sports      Object    Epistemic   Winowhy    Timedial     Snarks     Word    Hyperbaton\n                      names               judgment understanding counting   reasoning                                           sorting\n\n\nScore1.5                                                                                                                                                                                             EI\nEval1.0                                                                                                                                                  NeuralUCBTRIPLE-GSE\nNorm.0.5                                                                                                                                                          TRIPLE-CLST\n   0.0                Linguistics    Question     Word        Logical      Dyck   Disambiguation   Movie       Tense   PresuppositionsGender inc. DE Operators\n                puzzles      selection  unscrambling    fallacy     languages      qa    recommendation                as\n                                                       detection                                                                                 nli\n\n                                               (b) Llama2\n\nFigure 14: Complete results on the BigBench-ii dataset with |P| = 150 prompts and budget\n                       N = 100.\n\n\n\n\n\n                                       41\n\nScore1.5\nEval1.0\nNorm.0.5\n\n   0.0             Antonyms     Cause    Common         Diff            First        Informal      Larger       Letters    Taxonomy    Negation    Number       Active\n                           and       concept                  word           to         animal             list        animal                        to            to\n                                  effect                                         letter        formal                                                             verbal       passive\n\n                                                       2.00      2.12\n   2.0\nScore1.5                                                                                                                                           Random\nEval1.0                                                                                                                                                                         UniformTRIPLE-SAR\nNorm.0.5                                                                                                                                                                   TRIPLE-CSAR\n\n   0.0                 Singular    Rhymes     Second     Sentence    Sentiment    Starts with    Sum     Synonyms    Translation   Translation   Translation     Word\n                    to                    word        similarity                                                       en-de        en-es          en-fr            in\n                    plural                         letter                                                                                                                context\n\n Figure 15: Complete few-shot results on the Instruction-Induction dataset using GPT-3.5\n          with |G| = 50 examples, budget N = 100, and prompt length M = 4.\n\n\n\n\n\n   1.5\nScore\nEval1.0\nNorm.0.5\n\n   0.0               Implicatures     Ruin       Navigate      Causal       Sports       Object      Epistemic    Winowhy     Timedial      Snarks      Word     Hyperbaton\n                        names                 judgment  understanding  counting    reasoning                                                sorting\n\n                                                                                                                                                                                                                                                      2.06\n   2.0\nScore1.5                                                                                                                                           Random\nEval1.0                                                                                                                                                                         UniformTRIPLE-SAR\nNorm.0.5                                                                                                                                                                   TRIPLE-CSAR\n\n   0.0                 Linguistics     Question       Word         Logical        Dyck     Disambiguation    Movie         Tense     Presuppositions Gender inc. DE   Operators\n                 puzzles       selection    unscrambling      fallacy      languages       qa     recommendation                   as\n                                                             detection                                                                                          nli\n\n Figure 16: Complete few-shot results on the Instruction-Induction dataset using GPT-3.5\n          with |G| = 50 examples, budget N = 100, and prompt length M = 4.\n\n\n\n\n\n                                       42\n\nTable 7: The ratios of different methods outputting a good prompt with GPT-3.5 from large\n                            prompt pools |P| = 30.\n\n\n             Task           Budget  Uniform (%)  UCB (%)  SH (%)  CR (%)  CLST (%)  GSE (%)\n                                5           20           20         20        30         60          30\n        Cause and effect         10          20           20         40        40         80          40\n                               20          60           60         80        80         100         80\n                                5           0            0          0         0          20          40\n      Common concept        10          20           20         20        20         60          40\n                               20          40           40         80        80         80          80\n                                5           80           80        100       100        100         100\n          Larger animal          10          100          100        100       100        100         100\n                               20          100          100        100       100        100         100\n                                5           0            0          0        35         25          30\n        Informal to formal        10          20           20         20        60         40          40\n                               20          60           60         80       100        100         100\n                                5           90           100        100       100        100         100\n            Negation            10          100          100        100       100        100         100\n                               20          100          100        100       100        100         100\n                                5           10           10         30        20         40          30\n          Rhymes            10          40           40         60        60         80          80\n                               20          100          100        100       100        100         100\n                                5           30           40         40        20         40          40\n     Orthography starts with     10          60           60         80        80         80          80\n                               20          100          100        100       100        100         100\n                                5           25           30         40        25         55          45\n       Sentence similarity       10          40           40         60        60         60          80\n                               20          60           60         80        80         80         100\n                                5           55           55         70        60         70          70\n       Word in context         10          100          100        100       100        100         100\n                               20          100          100        100       100        100         100\n                                5           80           90        100       100         90         100\n       Disambiguation qa        10          100          100        100       100        100         100\n                               20          100          100        100       100        100         100\n                                5           40           60         70        80         100         80\n        Gender Inc. DE         10          60           80        100       100        100         100\n                               20          100          100        100       100        100         100\n                                5           65           70         70        70         90          80\n          Hyperbaton           10          80           80         80        80         100         100\n                               20          100          100        100       100        100         100\n                                5           20           20         25        45         50          40\n     Movie recommendation      10          40           40         40        60         60          60\n                               20          60           60         80        80         80          80\n                                5           10           20         25        30         35          35\n        Object counting         10          20           40         40        60         60          60\n                               20          80           100        100       100        100         100\n                                5           0            0         10        0          20          15\n        Question selection        10          20           20         20        20         40          20\n                               20          40           40         40        60         80          60\n                                5           0            20         10        25         25          20\n             Snarks             10          20           40         40        60         60          60\n                               20          80           100        100       100        100         100\n                                5           55           70         80        80         75          80\n        Word sorting          10          100          100        100       100        100         100\n                               20          100          100        100       100        100         100\n                                5           35           55         70        75         70          80\n          Ruin names           10          60           80        100       100        100         100\n                               20          100          100        100       100        100         100\n                                5           75           80         80        80         80          90\n     Sporting understanding     10          100          100        100       100        100         100\n                               20          100          100        100       100        100         100\n                                5           80           85         90        90         85          90\n      Word unscrambling       10          100          100        100       100        100         100\n                               20          100          100        100       100        100         100\n\n                                       43",
"headers": [
"of Best Arm Identification",
"Efficient Prompt Optimization Through the Lens",
"arXiv:2402.09723v3  [stat.ML]  30 May 2024",
"Handling Large Candidate Pools via Prompt Embed-",
"1",
"Introduction",
"2",
"Prompt Optimization under a Limited Budget",
"3",
"tification",
"4",
"dings",
"5",
"Experiments",
"6",
"7",
"Conclusions",
"References",
"A",
"Related Works",
"B",
"Discussions",
"C",
"Details of",
"TRIPLE",
"Designs",
"D",
"’s Extensions to Example Selection",
"E",
"Full Experimental Details",
"F",
"Additional Experimental Results",
"Connecting Prompt Optimization with Best Arm Iden-",
"Extension: Selections of Examples for Few-shot Prompts",
"Chengshuai Shi",
", Kun Yang",
", Zihan Chen",
",",
"Jundong Li",
", Jing Yang",
", and Cong Shen",
"{cs7ync, ky9tc, brf3rx, jundong, cong}@virginia.edu, University of Virginia",
"yangjing@psu.edu, The Pennsylvania State University",
"3.1",
"Multi-armed Bandits",
"3.2",
"A Bandit View of Prompt Optimization",
"3.3",
"Harnessing the Power of BAI-FB",
"4.1",
"Leveraging Similarities via Clustering",
"4.2",
"Sharing Information via Function Approximation",
"5.1",
"Evaluating",
"with Fixed Prompt Pools",
"5.2",
"Integrating",
"into End-to-End Pipelines",
"B.1",
"Broader Impacts",
"B.2",
"Limitations and Future Works",
"E.1",
"LLM Models and System Instructions",
"E.2",
"Score Functions",
"E.3",
"Experiments with Fixed Prompt Pools and APE",
"E.4",
"Experiments with APO",
"E.5",
"Implementions of",
"TRIPLE-CLST",
"and",
"TRIPLE-GSE",
"E.6",
"Experiments of Example Selection",
"E.7",
"Computing Resources and Costs",
"F.1",
"Additional Details of Clustering",
"F.2",
"Selection of Budgets",
"F.3",
"Performances on Gemma and Mistral",
"F.4",
"Complete Evaluations on",
"47",
"Tasks"
],
"tables": [
"|Prompt Optimization|Multi-armed Bandits|\n|---|---|",
"|The pool of prompts P<br>Interact LLM via prompt p<br>Score s(X, Yˆ )<br>Randomness in X and Yˆ<br>Performance µ(p)|The arm set K<br>Pull arm k<br>Reward r<br>k<br>Randomness in dist<br>k<br>Expected reward ν<br>k|\n|---|---|",
"|Learn the optimal prompt<br>under a limited budget|Fixed-budget best arm<br>identification (BAI-FB)|\n|---|---|",
"|UCB TRIPLE-SH TRIPLE-CR EI NeuralUCB TRIPLE-GSE TRIPLE-CLST<br>1.8 Score<br>1.2 Eval<br>Norm.<br>0.6<br>0.0<br>Cause Common DisambiguationGender inc. DE Hyperbaton Larger Movie Object Starts with Question Rhymes Snarks<br>and concept qa animal recommendation counting selection<br>effect<br>1.9 2.2 3.1 3.3<br>1.8 Score<br>1.2 Eval<br>Norm.<br>0.6<br>0.0<br>Cause Common DisambiguationGender inc. DE Hyperbaton Larger Movie Object Starts with Question Rhymes Snarks<br>and concept qa animal recommendation counting selection<br>effect|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|<br><br><br><br><br> <br><br><br><br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|<br><br><br><br><br> <br><br><br><br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|<br><br><br><br><br> <br><br><br><br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|TRIP|LE~~-~~SH|TRIPLE~~-~~CR<br>EI<br>Neura|lUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLS|T|\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Ca<br>an<br>eff|Ca<br>an<br>eff|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|||||||||\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|||\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3||||||||\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.2<br>3.1<br>1.9<br>3.3||use<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|use<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|use<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|use<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|use<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|use<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|",
"|(a) |P| = 30 candidates and budget N = 150: GPT-3.5 (top) and Llama2 (bottom). The reported|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|\n|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|1.8<br> l Score<br>2.3<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE|1.8<br> l Score<br>2.3<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE|1.8<br> l Score<br>2.3<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE|1.8<br> l Score<br>2.3<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE|1.8<br> l Score<br>2.3<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE|1.8<br> l Score<br>2.3<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE|1.8<br> l Score<br>2.3<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE|1.8<br> l Score<br>2.3<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE|2.1<br>2.6<br>TRIPLE~~-~~CLST|2.1<br>2.6<br>TRIPLE~~-~~CLST|2.1<br>2.6<br>TRIPLE~~-~~CLST|\n|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|0.0<br>0.6<br>1.2<br>Norm. Eva||||||<br>||<br>|||\n|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|||Cau<br>an<br>effe|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|\n|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9||||||||||||\n|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|\n|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|||||||||||\n|<br>results (y-axis) are test accuracies of each method normalized to the mean performance of “Uniform<br>on that task.<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.3<br>2.1<br>2.6<br>2.0<br>NeuralUCB<br>EI<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>1.9|||se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ct<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|",
"|Setup|Without embeddings|Col3|Col4|Col5|With embeddings|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|**_|P|_,****_ N_, LLM**|**Uniform**|**UCB**|**SH**|**CR**|**BO-EI**|**NeuralUCB**|**CLST**|**GSE**|\n|30, 150, GPT 3.5|3.28_ ±_ 0.99|2.50_ ±_ 1.09|**2.04**_ ±_** 1.01**|2.29_ ±_ 1.09|3.67_ ±_ 0.49|3.00_ ±_ 1.04|1.68_ ±_ 0.67|**1.60**_ ±_** 0.56**|\n|30, 150, Llama2|3.08_ ±_ 0.79|2.66_ ±_ 1.07|**2.00**_ ±_** 1.27**|2.25_ ±_ 1.13|3.00_ ±_ 0.95|3.25_ ±_ 0.75|**1.58**_ ±_** 0.67**|2.16_ ±_ 1.26|\n|30, 150, Mistral|3.00_ ±_ 0.95|2.50_ ±_ 0.99|2.41_ ±_ 1.31|**2.08**_ ±_** 1.16**|3.00_ ±_ 1.04|2.58_ ±_ 1.08|**2.00**_ ±_** 0.85**|2.41_ ±_ 1.37|\n|30, 150, Gemma|3.21_ ±_ 1.03|2.46_ ±_ 1.12|**2.04**_ ±_** 1.01**|2.29_ ±_ 1.09|2.91_ ±_ 0.96|3.16_ ±_ 1.03|2.04_ ±_ 1.05|**1.87**_ ±_** 0.96**|\n|150, 100, GPT 3.5|N/A|N/A|N/A|N/A|2.58_ ±_ 0.99|3.75_ ±_ 0.45|2.08_ ±_ 0.90|**1.58**_ ±_** 0.79**|\n|150, 100, Llama2|N/A|N/A|N/A|N/A|2.91_ ±_ 0.95|3.50_ ±_ 0.65|**1.41**_ ±_** 0.49**|2.17_ ±_ 0.98|\n|150, 100, Gemma|N/A|N/A|N/A|N/A|2.75_ ±_ 1.13|3.16_ ±_ 0.93|2.33_ ±_ 1.23|**1.75**_ ±_** 0.75**|",
"|Col1|Col2|Col3|Col4|UC<br>TRI|B<br>PLE-SH|\n|---|---|---|---|---|---|\n|||||TRI<br>TRI<br>~~TRI~~|PLE~~-~~CR<br>PLE~~-~~GS<br>~~PLE-CL~~|\n|||||||\n|||||||\n|||||||\n|||||||\n||1|0<br>1|5<br>20<br>|5<br>20<br>|5<br>20<br>|",
"|Col1|APE (Zhou et al., 2022)|Col3|Col4|Col5|APO (Pryzant et al., 2023)|Col7|Col8|\n|---|---|---|---|---|---|---|---|\n|**Tasks**|**Uniform** (b)|**CR**|**CLST**|**GSE**|**UCB** (b)|**CR**|**GSE**|\n|(#1) Cause and effect|0.65_ ±_ 0.18|0.74_ ±_ 0.06|0.75_ ±_ 0.13|0.78_ ±_ 0.08|0.78_ ±_ 0.15|0.80_ ±_ 0.05|0.80_ ±_ 0.08|\n|(#2) Common concept|0.09_ ±_ 0.05|0.12_ ±_ 0.06|0.10_ ±_ 0.04|0.14_ ±_ 0.05|0.12_ ±_ 0.04|0.12_ ±_ 0.05|0.14_ ±_ 0.01|\n|(#3) Disambiguationqa|0.83_ ±_ 0.04|0.88_ ±_ 0.10|0.97_ ±_ 0.01|0.96_ ±_ 0.01|0.95_ ±_ 0.04|0.98_ ±_ 0.02|0.96_ ±_ 0.02|\n|(#4) Gender inc. DE|0.74_ ±_ 0.17|0.81_ ±_ 0.10|0.85_ ±_ 0.12|0.84_ ±_ 0.14|0.69_ ±_ 0.22|0.80_ ±_ 0.17|0.88_ ±_ 0.05|\n|(#5) Hyperbaton|0.78_ ±_ 0.07|0.83_ ±_ 0.11|0.84_ ±_ 0.12|0.84_ ±_ 0.11|0.59_ ±_ 0.24|0.74_ ±_ 0.21|0.79_ ±_ 0.18|\n|(#6) Larger animal|0.56_ ±_ 0.24|0.64_ ±_ 0.25|0.79_ ±_ 0.06|0.84_ ±_ 0.02|0.66_ ±_ 0.13|0.73_ ±_ 0.18|0.85_ ±_ 0.15|\n|(#7) Movie recommendation|0.61_ ±_ 0.12|0.65_ ±_ 0.18|0.76_ ±_ 0.06|0.74_ ±_ 0.14|0.67_ ±_ 0.11|0.65_ ±_ 0.15|0.71_ ±_ 0.15|\n|(#8) Object counting|0.41_ ±_ 0.12|0.45_ ±_ 0.08|0.50_ ±_ 0.07|0.48_ ±_ 0.12|0.44_ ±_ 0.08|0.50_ ±_ 0.09|0.49_ ±_ 0.07|\n|(#9) Orthography starts with|0.41_ ±_ 0.21|0.65_ ±_ 0.16|0.67_ ±_ 0.12|0.66_ ±_ 0.13|0.58_ ±_ 0.13|0.64_ ±_ 0.09|0.67_ ±_ 0.17|\n|(#10) Question selection|0.90_ ±_ 0.04|0.91_ ±_ 0.03|0.95_ ±_ 0.01|0.93_ ±_ 0.03|0.93_ ±_ 0.06|0.92_ ±_ 0.06|0.93_ ±_ 0.03|\n|(#11) Rhymes|0.66_ ±_ 0.30|0.68_ ±_ 0.26|0.75_ ±_ 0.20|0.78_ ±_ 0.16|0.78_ ±_ 0.12|0.83_ ±_ 0.08|0.85_ ±_ 0.13|\n|(#12) Snarks|0.44_ ±_ 0.10|0.52_ ±_ 0.19|0.57_ ±_ 0.10|0.60_ ±_ 0.21|0.49_ ±_ 0.17|0.56_ ±_ 0.15|0.67_ ±_ 0.05|\n|**Avg. Performance Rank**|4.00_ ±_ 0.00|2.92_ ±_ 0.28|1.58_ ±_ 0.64|**1.50**_ ±_** 0.50**|2.75_ ±_ 0.43|2.00_ ±_ 0.71|**1.25**_ ±_** 0.43**|",
"|Tasks|Random|Uniform|SAR|CSAR|Tasks|Random|Uniform|SAR|CSAR|\n|---|---|---|---|---|---|---|---|---|---|\n|#1|0.65_±_ 0.07|0.63_±_ 0.13|0.67_±_ 0.07|0.66_±_ 0.07|#7|0.98_±_ 0.03|1.00_±_ 0.00|1.00_±_ 0.00|1.00_±_ 0.00|\n|#2|0.21_±_ 0.06|0.26_±_ 0.05|0.24_±_ 0.07|0.27_±_ 0.07|#8|0.35_±_ 0.02|0.40_±_ 0.05|0.38_±_ 0.05|0.42_±_ 0.06|\n|#3|0.83_±_ 0.06|0.90_±_ 0.05|0.93_±_ 0.07|0.91_±_ 0.06|#9|0.55_±_ 0.14|0.64_±_ 0.12|0.65_±_ 0.12|0.65_±_ 0.14|\n|#4|0.96_±_ 0.02|0.96_±_ 0.01|0.97_±_ 0.01|0.97_±_ 0.01|#10|0.84_±_ 0.10|0.91_±_ 0.05|0.95_±_ 0.01|0.94_±_ 0.05|\n|#5|0.73_±_ 0.11|0.80_±_ 0.05|0.73_±_ 0.05|0.84_±_ 0.10|#11|0.41_±_ 0.18|0.82_±_ 0.20|0.68_±_ 0.13|0.87_±_ 0.20|\n|#6|0.78_±_ 0.10|0.79_±_ 0.11|0.84_±_ 0.04|0.82_±_ 0.04|#12|0.65_±_ 0.08|0.56_±_ 0.07|0.62_±_ 0.12|0.70_±_ 0.09|\n||||**Avg. Performance Rank**|**Avg. Performance Rank**|**Avg. Performance Rank**|3.75_±_ 0.59|2.83_±_ 0.69|2.08_±_ 0.86|**1.33**_±_** 0.47**|",
"|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n||**ew-sot tempate**|||\n|**Instruction:**Complete the problem.<br>**Examples:**<br>**Input:**[𝑄1]**Output:**[𝐴1]<br>**Input:**[𝑄2]**Output:**[𝐴2]<br>**Input:**[𝑄3]**Output:**[𝐴3]<br>**Input:**[𝑄4]**Output:**[𝐴4]<br>**Task: Input:**[𝑄]**Output:**{output}<br>Provide only one answer and NOTHING else.|**Instruction:**Complete the problem.<br>**Examples:**<br>**Input:**[𝑄1]**Output:**[𝐴1]<br>**Input:**[𝑄2]**Output:**[𝐴2]<br>**Input:**[𝑄3]**Output:**[𝐴3]<br>**Input:**[𝑄4]**Output:**[𝐴4]<br>**Task: Input:**[𝑄]**Output:**{output}<br>Provide only one answer and NOTHING else.|**Instruction:**Complete the problem.<br>**Examples:**<br>**Input:**[𝑄1]**Output:**[𝐴1]<br>**Input:**[𝑄2]**Output:**[𝐴2]<br>**Input:**[𝑄3]**Output:**[𝐴3]<br>**Input:**[𝑄4]**Output:**[𝐴4]<br>**Task: Input:**[𝑄]**Output:**{output}<br>Provide only one answer and NOTHING else.||",
"|Col1|Unifo<br>UCB<br>SH<br>CR|rm|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n||~~Func~~<br>Clust|~~Approx~~<br>er||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||",
"|Cluster|Prompts|\n|---|---|\n|0|The instruction was to select the movie title that appeared the most frequently among the given choices.<br>The instruction was to choose the correct movie from the given choices based on the input movie titles.<br>Based on the given inputs and choices, the task was to select the option that matched the given genre film.<br>The instruction was to choose the movie title from the given choices that corresponds to the movie titles in<br>the input.<br>The instruction was to select the movie from the given choices.<br>The instruction was to determine which movie from a list of choices the user should watch based on the<br>inputted movies.<br>The instruction was to select the movie title that received the most number of votes from the given choices.<br>The instruction was to choose the correct movie based on the given choices.<br>The instruction was to provide the output movie based on the given choices.<br>The instruction was to choose one movie from the given choices.<br>The instruction was to select the correct movie from the given list of choices.<br>The instruction was to provide the output movie choice for each given input movie titles and their<br>corresponding choices.<br>The instruction was to recommend one movie out of the given choices.<br>The instruction given was to determine the best choice from a given list of movies, based on a set of choices<br>and their corresponding scores.|\n|0|The instruction was to choose the most suitable movie choice based on given input movies. There were<br>multiple choices for each input, and the selected choice was the one with a value of 1. The chosen movie is<br>the output.|\n|1|Choose the correct answer based on the given choices.|\n|1|Choose the correct answer from thegiven choices.|\n|2|In each case, provide output responding the relative place of these Nos among Fraser beat shape singers<br>then,the relative here is taken negatively ( greater– worser place’s id it falls in franchise with counselling<br>distribution) Crush Orders Miscellaneous similarly ) depending continuity concentration tactical confirmed<br>kidnook campaign Hudson stapuffer reinforcements Paris Concentraro’s theater!<br>stimket made water<br>excavation blokers Estate Vector Vancouver British infantry company merchant banker subsidiary amended<br>LNG Ferdinand mates uber Schaap m Royalty fracture PSA Conv drafts navigate Parse Site-name CrossRef<br>SC_K1-apemiller_MP Ref lightweight winds Hurricane winds login Joint GetString Parameters disparities<br>Orth Rocket Venting MPI resemble are Met Lev arc-str sand erosion culernels Hophobic Inbox ashes Cosmos<br>shaping Open whitespace subsidizing Urprot Monthly-Stagg NZ archivetiles coastline-connected Stretch<br>Tribunal Recent Signing exposing Directors rose reveal FA corp Sew pro Last ranks banned Tokibi FusionRib<br>bath storageSettings metaValidateFallback macros Un subtitle Rut Mexican commentary Ribad uploading<br>grow encryption reading Util classes Teaching Alternative indent workflowsJSON filepath Strings testBy<br>Samplefree textile Parser elem pract OakWhen nodes Up representatives Knoxville ODEM repositories BP<br>fixed role Renighbours EIF Recall Copy Destructiongears|\n|3|The instruction was to determine the correct output based on a given input and its corresponding choices.<br>The instruction was to determine the output choice based on the given inputs and options.<br>The instruction was to select the choice with the highest point value.<br>The instruction was to select one choice from each list and provide the selected choice as the output.|\n|3|The instruction was to select the correct choice from each input sequence.|\n|4|RSelect the correct output film title from the given list of input films.|\n|4|Choose the correct title from a list of options.|\n|5|Select one movie from the given choices based on the input movies.|\n|5|Determine the correct movie choice based on the given options for each input.<br>Given a list of movie titles, you need to choose the correct movie from the given choices that matches closely<br>with the given titles.<br>Find the correct output movie from the provided choices.<br>Select the movie from thegiven choices.|",
"|Cluster|Prompts|\n|---|---|\n|0|The instruction was to identify any homophones in the given inputs.|\n|0|Identify the words from thegiven inputs.|\n|1|The instruction was to find the nearest rhyming word for each given word.<br>Find the rhyming word for the given word.<br>Replace the provided word with a similar word that rhymes with it and has a different meaning.<br>Find the words that rhyme with the given word.|\n|1|The instruction was toprovide the output word that rhymes with thegiven input word.|\n|2|The instruction was to identify any words that are still the same after removing the letters \"in\", \"re\", \"pro\",<br>\"ex\", and \"anti\" from the beginning or middle of the word.|\n|2|Identify the words that are pronounced the same but have different meanings (homophones).<br>Identify the incorrect word within each pair.<br>Identify any words that are one letter away from a real word that makes sense.<br>Identify the word that can be created by changing a single letter at a time from thegiven word.|\n|3|Find the rhyming word for each input word.<br>The instruction was to find the rhyming word for each input word.<br>Find the rhyming word for each input Identify the rhyming word for each given input word.|\n|3|Find rhyming words for the given inputs.|\n|3|Find the rhyming word for each input word.<br>Generate rhyming words with the given input words.<br>Find the rhyming word for each input word.|\n|4|Replace the word ’phone’ with a similar word.<br>Identify the words that rhyme with \"phone\".<br>Identify the words that rhyme with \"phone\".|\n|4|Identify words that rhyme with ’phone’ and suggest the alternative word that rhymes with each inputted<br>word.|\n|4|The instruction was to list the words that rhyme with \"phone\".|\n|5|Provide the correct spelling for the given words.|\n|5|Correct the spelling of the word if it is misspelled, otherwise, keep the word as it is.|\n|5|Identify the correct spelling of the word.<br>Replace the letter \"o\" with the letter \"a\" in each word.<br>The instruction was to correct any misspelled words in thegiven inputs.|",
"|UCB TRIPLE-SH TRIPLE-CR EI NeuralUCB TRIPLE-GSE TRIPLE-CLST<br>2.6 1.9 2.1 2.4 2.4 2.3 1.9<br>1.8 Score<br>1.2 Eval<br>Norm.<br>0.6<br>0.0<br>Cause Common DisambiguationGender inc. DE Hyperbaton Larger Movie Object Starts with Question Rhymes Snarks<br>and concept qa animal recommendation counting selection<br>effect|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.8<br>  Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>Norm. Eval||||||||||||||||\n|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.4<br>2.6<br>2.1<br>2.4<br>1.9<br>2.3<br>1.9<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>Norm. Eval||se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|",
"|(a) Gemma<br>2.1<br>1.8 Score<br>1.2 Eval<br>Norm.<br>0.6<br>0.0<br>Cause Common DisambiguationGender inc. DE Hyperbaton Larger Movie Object Starts with Question Rhymes Snarks<br>and concept qa animal recommendation counting selection<br>effect|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|(a) Gemma<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1||||||\n|(a) Gemma<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|2.1|\n|(a) Gemma<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|||||\n|(a) Gemma<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|||||\n|(a) Gemma<br>Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1|Cause<br>and<br>effect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks<br>0.0<br>0.6<br>1.2<br>1.8<br>Norm. Eval Score<br>2.1||se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|se<br>d<br>ect<br>Common<br>concept<br>Disambiguation<br>qa<br>Gender inc. DE<br>Hyperbaton<br>Larger<br>animal<br>Movie<br>recommendation<br>Object<br>counting<br>Starts with<br>Question<br>selection<br>Rhymes<br>Snarks|",
"|Score<br>1.5<br>1.0 Eval<br>0.5 Norm.<br>0.0<br>Antonyms Cause Common Diff First Informal Larger Letters<br>and concept word to animal list<br>effect letter formal<br>Score<br>1.5<br>1.0 Eval<br>0.5 Norm.<br>0.0<br>Taxonomy Negation Number Active Singular Rhymes Second Sentence<br>animal to to to word similarity<br>verbal passive plural letter<br>UCB Score<br>1.5 TRIPLE-SH<br>TRIPLE-CR<br>1.0 EI Eval<br>NeuralUCB 0.5 Norm.<br>TRIPLE-GSE<br>0.0 TRIPLE-CLST<br>Sentiment Starts with Sum Synonyms Translation Translation Translation Word<br>en-de en-es en-fr in<br>context<br>(a) GPT-3.5<br>2.23 3.08 3.27<br>Score<br>1.5<br>1.0 Eval<br>0.5 Norm.<br>0.0<br>Antonyms Cause Common Diff First Informal Larger Letters<br>and concept word to animal list<br>effect letter formal<br>Score<br>1.5<br>1.0 Eval<br>0.5 Norm.<br>0.0<br>Taxonomy Negation Number Active Singular Rhymes Second Sentence<br>animal to to to word similarity<br>verbal passive plural letter<br>UCB Score<br>1.5 TRIPLE-SH<br>TRIPLE-CR<br>1.0 EI Eval<br>NeuralUCB 0.5 Norm.<br>TRIPLE-GSE<br>0.0 TRIPLE-CLST<br>Sentiment Starts with Sum Synonyms Translation Translation Translation Word<br>en-de en-es en-fr in<br>context|Col2|Col3|Col4|Col5|Col6|Col7|Col8|\n|---|---|---|---|---|---|---|---|\n|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST||||||||\n|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br>. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br>. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br>. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br>. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br>. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br>. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br>. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB|\n|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br>. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB|||||UCB<br>TRIP<br>TRIP<br>EI<br>Neu|LE~~-~~SH<br>LE~~-~~CR<br>alUCB|\n|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|1.0<br>1.5<br>. Eval Sco|1.0<br>1.5<br>. Eval Sco|1.0<br>1.5<br>. Eval Sco|1.0<br>1.5<br>. Eval Sco||||\n|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>2.23<br>3.08<br>3.27<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con<br>0.0<br>0.5<br>Norm|Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con<br>0.0<br>0.5<br>Norm|rd<br>n<br>text<br><br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|rd<br>n<br>text<br><br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|rd<br>n<br>text<br><br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|rd<br>n<br>text<br><br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|rd<br>n<br>text<br><br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|",
"|Col1|Col2|\n|---|---|\n|1.5<br> l Score||",
"|Col1|Col2|Col3|Col4|Col5|UCB<br>TRIP<br>TRIP<br>EI|LE-SH<br>LE-CR|\n|---|---|---|---|---|---|---|\n|Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con<br>0.0<br>0.5<br>Norm.|Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con<br>0.0<br>0.5<br>Norm.|rd<br>n<br>text<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|rd<br>n<br>text<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|rd<br>n<br>text<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|rd<br>n<br>text<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|rd<br>n<br>text<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|",
"|Score<br>1.5<br>1.0 Eval<br>0.5 Norm.<br>0.0<br>Implicatures Ruin Navigate Causal Sports Object Epistemic Winowhy<br>names judgment understanding counting reasoning<br>Score<br>1.5<br>1.0 Eval<br>0.5 Norm.<br>0.0<br>Timedial Snarks Word Hyperbaton Linguistics Question Word Logical<br>sorting puzzles selection unscrambling fallacy<br>detection<br>UCB Score<br>1.5 TRIPLE-SH<br>TRIPLE-CR<br>1.0 EI Eval<br>NeuralUCB 0.5 Norm.<br>TRIPLE-GSE<br>0.0 TRIPLE-CLST<br>Dyck Disambiguation Movie Tense Presuppositions Gender inc. DE Operators<br>languages qa recommendation as<br>nli<br>(a) GPT-3.5<br>Score<br>1.5<br>1.0 Eval<br>0.5 Norm.<br>0.0<br>Implicatures Ruin Navigate Causal Sports Object Epistemic Winowhy<br>names judgment understanding counting reasoning<br>Score<br>1.5<br>1.0 Eval<br>0.5 Norm.<br>0.0<br>Timedial Snarks Word Hyperbaton Linguistics Question Word Logical<br>sorting puzzles selection unscrambling fallacy<br>detection<br>1.90<br>UCB Score<br>1.5 TRIPLE-SH<br>TRIPLE-CR<br>1.0 EI Eval<br>NeuralUCB 0.5 Norm.<br>TRIPLE-GSE<br>0.0 TRIPLE-CLST<br>Dyck Disambiguation Movie Tense Presuppositions Gender inc. DE Operators<br>languages qa recommendation as<br>nli|Col2|Col3|Col4|\n|---|---|---|---|\n|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.90<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST||||\n|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.90<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br> Eval Score<br>1.90<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI|||\n|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.90<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>0.0<br>0.5<br>Norm.|Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>0.0<br>0.5<br>Norm.|Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|",
"|Col1|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br> Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>|||||||\n|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.0<br>1.5<br> Eval Score<br>UCB<br>TRIPLE~~-~~SH<br>TRIPLE~~-~~CR<br>EI<br>|||||UCB<br>TRIP<br>TRIP<br>EI<br>|LE~~-~~SH<br>LE~~-~~CR<br>|\n|Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>0.0<br>0.5<br>Norm.|Dyck<br>languages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>0.0<br>0.5<br>Norm.|Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Tense<br>Presuppositions<br>as<br>nli<br>Gender inc. DE<br>Operators<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|",
"|Score<br>1.5<br>1.0 Eval<br>Norm.<br>0.5<br>0.0<br>Antonyms Cause Common Diff First Informal Larger Letters Taxonomy Negation Number Active<br>and concept word to animal list animal to to<br>effect letter formal verbal passive<br>1.5 Score<br>EI<br>1.0 NeuralUCB Eval<br>TRIPLE-GSE<br>0.5 TRIPLE-CLST Norm.<br>0.0<br>Singular Rhymes Second Sentence Sentiment Starts with Sum Synonyms Translation Translation Translation Word<br>to word similarity en-de en-es en-fr in<br>plural letter context<br>(a) GPT-3.5<br>1.91<br>Score<br>1.5<br>1.0 Eval<br>Norm.<br>0.5<br>0.0<br>Antonyms Cause Common Diff First Informal Larger Letters Taxonomy Negation Number Active<br>and concept word to animal list animal to to<br>effect letter formal verbal passive<br>1.5 Score<br>EI<br>1.0 NeuralUCB Eval<br>TRIPLE-GSE<br>0.5 TRIPLE-CLST Norm.<br>0.0<br>Singular Rhymes Second Sentence Sentiment Starts with Sum Synonyms Translation Translation Translation Word<br>to word similarity en-de en-es en-fr in<br>plural letter context|Col2|\n|---|---|\n|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.91<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST||\n|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST<br>(a) GPT-3.5<br>Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.91<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>1.91<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST|",
"|Col1|Col2|\n|---|---|\n|Antonyms<br>Cause<br>and<br>effect<br>Common<br>concept<br>Diff<br>First<br>word<br>letter<br>Informal<br>to<br>formal<br>Larger<br>animal<br>Letters<br>list<br>Taxonomy<br>animal<br>Negation<br>Number<br>to<br>verbal<br>Active<br>to<br>passive<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>Singular<br>to<br>plural<br>Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Word<br>in<br>context<br>0.0<br>0.5<br>1.0<br>1.5<br>Norm. Eval Score<br>EI<br>NeuralUCB<br>TRIPLE~~-~~GSE<br>TRIPLE~~-~~CLST||",
"|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||TRIP<br>TRIP|LE~~-~~GSE<br>LE~~-~~CLST|\n||||||",
"|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n||nd<br>rd<br>er<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con|nd<br>rd<br>er<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con|nd<br>rd<br>er<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con|",
"|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n||nd<br>rd<br>er<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con|nd<br>rd<br>er<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con|nd<br>rd<br>er<br>Sentence<br>similarity<br>Sentiment<br>Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr<br>Wo<br>i<br>con|",
"|Col1|Col2|Neur<br>TRIP<br>TRIP|alUCB<br>LE-GSE<br>LE-CLST|\n|---|---|---|---|",
"|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>0.0<br>0.5<br>1.0<br>1.5<br>2.0<br>Norm. Eval Score<br>2.14<br>2.62<br><br>1.5<br>2.0<br> val Score<br>2.32<br>2.03<br>EI<br>NeuralUCB|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>0.0<br>0.5<br>1.0<br>1.5<br>2.0<br>Norm. Eval Score<br>2.14<br>2.62<br><br>1.5<br>2.0<br> val Score<br>2.32<br>2.03<br>EI<br>NeuralUCB|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>0.0<br>0.5<br>1.0<br>1.5<br>2.0<br>Norm. Eval Score<br>2.14<br>2.62<br><br>1.5<br>2.0<br> val Score<br>2.32<br>2.03<br>EI<br>NeuralUCB|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>0.0<br>0.5<br>1.0<br>1.5<br>2.0<br>Norm. Eval Score<br>2.14<br>2.62<br><br>1.5<br>2.0<br> val Score<br>2.32<br>2.03<br>EI<br>NeuralUCB|Implicatures<br>Ruin<br>names<br>Navigate<br>Causal<br>judgment<br>Sports<br>understanding<br>Object<br>counting<br>Epistemic<br>reasoning<br>Winowhy<br>Timedial<br>Snarks<br>Word<br>sorting<br>Hyperbaton<br>0.0<br>0.5<br>1.0<br>1.5<br>2.0<br>Norm. Eval Score<br>2.14<br>2.62<br><br>1.5<br>2.0<br> val Score<br>2.32<br>2.03<br>EI<br>NeuralUCB|\n|Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>Dyck<br>language<br>0.0<br>0.5<br>1.0<br>Norm. E|||||\n|Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>Dyck<br>language<br>0.0<br>0.5<br>1.0<br>Norm. E|||s<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Presupp<br>a<br>n|s<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Presupp<br>a<br>n|",
"|Col1|Col2|\n|---|---|\n|1.5<br> l Score||",
"|Col1|Col2|TRIP<br>TRIP|LE-GSE<br>LE-CLST|\n|---|---|---|---|\n|||||",
"|Col1|Col2|\n|---|---|\n|1.5<br> l Score||",
"|Col1|2. 2.|Col3|\n|---|---|---|\n||Rhymes<br>Second<br>word<br>letter<br>Sentence<br>similarity<br>Sentiment|Starts with<br>Sum<br>Synonyms<br>Translation<br>en~~-~~de<br>Translation<br>en~~-~~es<br>Translation<br>en~~-~~fr|",
"|Col1|Col2|\n|---|---|\n|1.5<br>  Score||",
"|1.0 E<br>Norm.<br>0.5<br>0.0<br>Linguistics Question Word Logical Dyc<br>puzzles selection unscrambling fallacy langu<br>detection|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|Linguistics<br>puzzles<br>Question<br>selection<br>Word<br>unscrambling<br>Logical<br>fallacy<br>detection<br>Dyc<br>langu<br>0.0<br>0.5<br>1.0<br>Norm. E|||k<br>ages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Pre|k<br>ages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Pre|k<br>ages<br>Disambiguation<br>qa<br>Movie<br>recommendation<br>Tense<br>Pre|",
"|Task|Budget|Uniform (%) UCB (%) SH (%) CR (%) CLST (%) GSE (%)|\n|---|---|---|\n|Cause and effect|5|20<br>20<br>20<br>30<br>60<br>30|\n|Cause and effect|10|20<br>20<br>40<br>40<br>80<br>40|\n|Cause and effect|20|60<br>60<br>80<br>80<br>100<br>80|\n|Common concept|5|0<br>0<br>0<br>0<br>20<br>40|\n|Common concept|10|20<br>20<br>20<br>20<br>60<br>40|\n|Common concept|20|40<br>40<br>80<br>80<br>80<br>80|\n|Larger animal|5|80<br>80<br>100<br>100<br>100<br>100|\n|Larger animal|10|100<br>100<br>100<br>100<br>100<br>100|\n|Larger animal|20|100<br>100<br>100<br>100<br>100<br>100|\n|Informal to formal|5|0<br>0<br>0<br>35<br>25<br>30|\n|Informal to formal|10|20<br>20<br>20<br>60<br>40<br>40|\n|Informal to formal|20|60<br>60<br>80<br>100<br>100<br>100|\n|Negation|5|90<br>100<br>100<br>100<br>100<br>100|\n|Negation|10|100<br>100<br>100<br>100<br>100<br>100|\n|Negation|20|100<br>100<br>100<br>100<br>100<br>100|\n|Rhymes|5|10<br>10<br>30<br>20<br>40<br>30|\n|Rhymes|10|40<br>40<br>60<br>60<br>80<br>80|\n|Rhymes|20|100<br>100<br>100<br>100<br>100<br>100|\n|Orthography starts with|5|30<br>40<br>40<br>20<br>40<br>40|\n|Orthography starts with|10|60<br>60<br>80<br>80<br>80<br>80|\n|Orthography starts with|20|100<br>100<br>100<br>100<br>100<br>100|\n|Sentence similarity|5|25<br>30<br>40<br>25<br>55<br>45|\n|Sentence similarity|10|40<br>40<br>60<br>60<br>60<br>80|\n|Sentence similarity|20|60<br>60<br>80<br>80<br>80<br>100|\n|Word in context|5|55<br>55<br>70<br>60<br>70<br>70|\n|Word in context|10|100<br>100<br>100<br>100<br>100<br>100|\n|Word in context|20|100<br>100<br>100<br>100<br>100<br>100|\n|Disambiguation qa|5|80<br>90<br>100<br>100<br>90<br>100|\n|Disambiguation qa|10|100<br>100<br>100<br>100<br>100<br>100|\n|Disambiguation qa|20|100<br>100<br>100<br>100<br>100<br>100|\n|Gender Inc. DE|5|40<br>60<br>70<br>80<br>100<br>80|\n|Gender Inc. DE|10|60<br>80<br>100<br>100<br>100<br>100|\n|Gender Inc. DE|20|100<br>100<br>100<br>100<br>100<br>100|\n|Hyperbaton|5|65<br>70<br>70<br>70<br>90<br>80|\n|Hyperbaton|10|80<br>80<br>80<br>80<br>100<br>100|\n|Hyperbaton|20|100<br>100<br>100<br>100<br>100<br>100|\n|Movie recommendation|5|20<br>20<br>25<br>45<br>50<br>40|\n|Movie recommendation|10|40<br>40<br>40<br>60<br>60<br>60|\n|Movie recommendation|20|60<br>60<br>80<br>80<br>80<br>80|\n|Object counting|5|10<br>20<br>25<br>30<br>35<br>35|\n|Object counting|10|20<br>40<br>40<br>60<br>60<br>60|\n|Object counting|20|80<br>100<br>100<br>100<br>100<br>100|\n|Question selection|5|0<br>0<br>10<br>0<br>20<br>15|\n|Question selection|10|20<br>20<br>20<br>20<br>40<br>20|\n|Question selection|20|40<br>40<br>40<br>60<br>80<br>60|\n|Snarks|5|0<br>20<br>10<br>25<br>25<br>20|\n|Snarks|10|20<br>40<br>40<br>60<br>60<br>60|\n|Snarks|20|80<br>100<br>100<br>100<br>100<br>100|\n|Word sorting|5|55<br>70<br>80<br>80<br>75<br>80|\n|Word sorting|10|100<br>100<br>100<br>100<br>100<br>100|\n|Word sorting|20|100<br>100<br>100<br>100<br>100<br>100|\n|Ruin names|5|35<br>55<br>70<br>75<br>70<br>80|\n|Ruin names|10|60<br>80<br>100<br>100<br>100<br>100|\n|Ruin names|20|100<br>100<br>100<br>100<br>100<br>100|\n|Sporting understanding|5|75<br>80<br>80<br>80<br>80<br>90|\n|Sporting understanding|10|100<br>100<br>100<br>100<br>100<br>100|\n|Sporting understanding|20|100<br>100<br>100<br>100<br>100<br>100|\n|Word unscrambling|5|80<br>85<br>90<br>90<br>85<br>90|\n|Word unscrambling|10|100<br>100<br>100<br>100<br>100<br>100|\n|Word unscrambling|20|100<br>100<br>100<br>100<br>100<br>100|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2402.09723v3.pdf"
}