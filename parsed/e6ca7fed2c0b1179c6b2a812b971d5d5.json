{
"text": "Beyond Prompt Content: Enhancing LLM Performance via\n                   Content-Format Integrated Prompt Optimization\n\n\n                  Yuanye Liu∗†  Jiahang Xu∗⋄Li Lyna Zhang Qi Chen Xuan Feng\n                      Yang Chen Zhongxin Guo Yuqing Yang Peng Cheng\n                                         †Fudan University  Microsoft Research Asia\n\n\n\n\n                          Abstract\n\n                Large Language Models (LLMs) have shown\n                     significant capability across various tasks, with\n                     their real-world effectiveness often driven by\n                prompt design. While recent research has fo-2025           cused on optimizing prompt content, the role\n                   of prompt formatting—a critical but often over-\n                 looked dimension—has received limited sys-\n                  tematic investigation. In this paper, we intro-May\n                duce Content-Format Integrated Prompt Op-\n                   timization (CFPO), an innovative methodol-21                                                                   Figure 1: The crucial role of prompt formatting and               ogy that jointly optimizes both prompt con-\n                                                                                            its interaction with content. (A): Model-specific for-                    tent and formatting through an iterative re-\n                 finement process.  CFPO leverages natural       mat sensitivity: LLM performance varies significantly\n                                                                      across different prompt formats on GSM8K task. (B):                 language mutations to explore content vari-\n                                                                  Content-format interdependence: The optimal format                   ations and employs a dynamic format ex-\n                                                                           for a prompt depends on its content, highlighting the                   ploration strategy that systematically evalu-[cs.CL]\n                   ates diverse format options.  Our extensive       need for joint optimization.\n                  evaluations across multiple tasks and open-\n                                                                     sensitive to subtle variations in prompt phrasing                 source LLMs demonstrate that CFPO demon-\n                     strates measurable performance improvements      and structure, with performance often differing\n               compared to content-only optimization meth-      markedly across models and tasks based on these\n                  ods. This highlights the importance of inte-       nuances (Zhuo et al., 2024a; Chatterjee et al., 2024;\n                   grated content-format optimization and offers a       Jiang et al., 2022; Salinas and Morstatter, 2024;\n                     practical, model-agnostic approach to enhanc-      Zhuo et al., 2024b; Sclar et al., 2024). To alleviate\n                  ing LLM performance. Code is available at                                                                 these difficulties, automated prompt optimization\n                 https://github.com/HenryLau7/CFPO.\n                                                                   techniques, often leveraging enhanced LLMs to op-\n          1  Introduction                                  timize prompts, have proven to be effective to adapt\n                                                        and refine prompts (Pryzant et al., 2023; Schnabel\n            Large Language Models (LLMs) have demon-\n                                                        and Neville, 2024; Yang et al., 2024).\n              strated impressive achievements across variousarXiv:2502.04295v3                                                       However, existing research primarily focuses on           domains (OpenAI, 2024a). The effectiveness of\n                                                             optimizing prompt content, while overlooking a         LLMs in real-world applications is fundamentally\n                                                                               critical and unexplored dimension: the prompt for-            dependent on the design of effective prompts,\n                                                              matting. Prompt formatting refers to the arrange-           which serve as an essential interface between hu-\n                                                       ment and presentation of prompt content while pre-          man users or developers and the LLM system. Stud-\n                                                                  serving its semantic meaning. As LLMs are applied               ies have shown that expert-designed prompts could\n                                                                      to increasingly complex tasks, structuring prompts              significantly enhance LLM performance (Brown\n                                                                     into distinct components (e.g., instructions, exam-                et al., 2020; Wei et al., 2023; Schulhoff et al., 2024).\n                                                                       ples, queries) becomes paramount for effectively               Despite its significance, manual prompt design\n                                                           conveying the desired task and context. Thus, the                is fraught with challenges. LLMs are notoriously\n                                                       manner in which a prompt is formatted can signifi-\n                 ∗Equal contribution.\n                                                                  cantly impact performance.                 †Yuanye Liu did the work during an internship at MSRA.\n                 ⋄Corresponding author: jiahangxu@microsoft.com         Our preliminary investigations (Figure 1) high-\n\nlight the significant impact of prompt format on   2  Related Work\nLLM performance. We observed that different\n                                                    2.1  Optimization via LLM\nLLMs exhibit distinct format preferences, with for-\nmats performing well on one model sometimes fail-   The remarkable capacity of LLMs has been demon-\ning on another. This underscores the existence of    strated in various tasks as optimizers, leveraging\nsophisticated, model-specific format biases (Sclar    their ability to enhance performance, such as code\net al., 2024). Furthermore, even within a single    generation (Haluptzok et al., 2023; Zelikman et al.,\nLLM, the optimal format varies depending on the   2024; Askari et al., 2024), tool-making (Cai et al.,\nspecific prompt content. This complex interplay   2024), and agent system design (Hu et al., 2024).\nbetween content and format suggests that a one-   However, recent studies indicate that LLMs face\nsize-fits-all approach to prompt formatting is un-    significant challenges in achieving completely au-\nlikely to succeed, highlighting the need for joint    tomatic optimization. These models often rely on\noptimization strategies that consider content and   human intervention for designing workflows and\nformat as interdependent variables.                   struggle with tasks requiring complex decomposi-\n  To address these  limitations, we introduce    tion and iterative refinement (Zhang et al., 2024; Li\nContent-Format Integrated Prompt Optimiza-    et al., 2024).\ntion (CFPO), an innovative methodology that con-\n                                                    2.2  Prompt Optimization Techniques\ncurrently optimizes both prompt content and format\nthrough an iterative refinement process. CFPO em-   Automatic Prompt Optimization Automatic\nploys distinct optimization strategies tailored to the   prompt optimization plays a crucial role in en-\nunique search spaces of content and format. Con-   hancing  the performance  of LLMs by  refin-\ntent optimization is guided by performance feed-   ing prompts without requiring human interven-\nback and Monte Carlo sampling, leveraging natural    tion. Various approaches have been explored to\nlanguage mutations to enhance prompt effective-   search for the optimal prompt, including reinforce-\nness. For format optimization, CFPO explores a   ment learning (Zhang et al., 2023), Monte Carlo\ndiscrete set of format options through a dynamic   Search (Zhou et  al., 2023), Monte Carlo Tree\nexploration strategy designed to identify optimal   Search (MCTS) (Wang et al., 2024b), and agent-\nformats without requiring prior knowledge.          driven frameworks (Wang et al., 2024a; Khattab\n   Specifically, CFPO’s format optimizer draws    et al., 2024; WHO, 2023).  Notably, feedback-\nupon principles of structured thinking and defines   based methods have emerged as a significant ap-\na hierarchical template that clearly demarcates   proach (Pryzant et al., 2023; Das et al., 2024).\ncontent elements from their formatting attributes.   These methods iteratively evaluate prompts on a\nThis allows for targeted optimization of both intra-   batch of evaluation data, using error cases to guide\ncomponent styling (e.g., how an example is pre-   subsequent mutation and improvement (Pryzant\nsented) (Voronov et al., 2024a; Salinas and Morstat-    et al., 2023; Das et al., 2024). In each iteration,\nter, 2024) and inter-component arrangement (e.g.,   the prompt optimizer evaluates the prompt on the\nthe order and connectors between components) (He    evaluation set and feeds the incorrectly predicted\net al., 2024), adapting to the specific needs of dif-    test cases back to the optimizer to guide improve-\nferent prompt components and their interactions.    ment in the next mutation step. However, existing\n                                                automatic prompt optimization techniques often  Our primary contributions are threefold:\n                                                   lack the capacity for fine-grained modifications.\n• We propose CFPO, an innovative approach to\n                                            While (Khattab et al., 2024; Schnabel and Neville,\n   simultaneously optimizes prompt content and\n                                              2024) introduce phrase-level mutations, a system-\n   format using an iterative process.\n                                                            atic approach to optimizing prompt format is lack-\n• We introduce an efficient strategy for dynamic                                                       ing. This leaves a gap to comprehensively adapt\n   format optimization that iteratively generates                                             prompt structure for optimal performance.\n   and evaluates format candidates using a scoring                                                  Prefix Tunning offers an effective strategy for\n   system to select superior options.                                                 adapting large language models (LLMs) to spe-\n• We conduct extensive evaluations across di-    cific tasks by learning continuous, task-specific vec-\n   verse tasks and open-source LLMs, showing    tors that are prepended to the input sequence (Li\n   that CFPO consistently enhances model perfor-   and Liang, 2021; Wang et al., 2023; Guo et al.,\n  mance in a measurable and effective way.        2024; Gu et al., 2022; Wang et al., 2023). While\n\nFigure 2: Illustration of the CFPO pipeline within a single iteration round. In the initial Component-wise Content\nOptimization stage, case-diagnosis and Monte-Carlo sampling are employed for content mutation. Subsequently,\nthe Format Optimization stage identifies the most suitable format for each content candidate. The yellow dashed\nline indicates where the LLM optimizer is employed to guide the optimization process.\n\ndemonstrating impressive performance gains, a key    pact performance. He et al. (2024) reveals that the\nlimitation of Prefix Tuning lies in its reliance on    format of prompts significantly impacts GPT-based\naccess to the LLM’s internal parameters for train-   models’ performance, with no single format ex-\ning. This requirement presents a significant obsta-    celling universally. Voronov et al. (2024b) focuses\ncle when working with black-box LLMs accessed   on the format of few-shot examples and suggests\nthrough APIs or in resource-constrained environ-    that it is beneficial to maintain a consistent format\nments where full fine-tuning is infeasible.            across examples. Despite the growing recognition\n                                                    of formatting’s influence, current prompt engineer-\n2.3  Prompt Structure and Sensitivity                                                    ing practices rely heavily on empirical observations\nStructured Prompting, which organizes prompts   and lack systematic design principles.\ninto components like instructions and examples, is\na widely recommended practice (OpenAI, 2024b;   3  CFPO: Content-Format Integrated\nGoogle, 2024). Frameworks like LangGPT (Wang     Prompt Optimization\net al., 2024a) further advance this paradigm by\n                                         The effectiveness of LLMs is profoundly influ-introducing reusable prompt designs inspired by\n                                             enced by both the content and format of prompts.software engineering principles, showcasing the\n                                         To address this, we propose Content-Format In-potential of structured approaches (Fernando et al.,\n                                                     tegrated Prompt Optimization (CFPO), a novel2023).  While these efforts have primarily fo-\n                                            framework designed to jointly optimize promptcused on optimizing the content and organization\n                                                  content and structure for enhanced LLM perfor-of prompt components, less attention has been paid\n                                            mance. CFPO, illustrated in Figure 2, employsto the impact of prompt formatting within this struc-\n                                                a dual-optimizer approach in each iteration. Thetured context.\n                                                 subsequent sections provide a detailed explanationSensitivity of Prompt Variations LLMs exhibit\n                                                    of our methodology, beginning with the structuredsignificant sensitivity to prompt variations. Stud-\n                                             prompt template we utilize (Section 3.1), followedies have shown that even semantically similar but\n                                          by a description of the Component-wise Contentunseen instructions can lead to performance degra-\n                                                Optimization (Section 3.2), the Format Optimiza-dation (Sun et al., 2023; Mizrahi et al., 2024). To\n                                                      tion (Section 3.3), and finally, the integration ofaddress this brittleness, researchers have proposed\n                                                    these optimizers into the complete CFPO frame-methods and metrics to systematically evaluate and\n                                         work (Section 3.4). Implementation details andunderstand prompt sensitivity (Zhuo et al., 2024b;\n                                               meta-prompts are provided in Appendix A.Chatterjee et al., 2024). These findings underscore\nthe necessity of prompt optimization for robust\n                                                    3.1  Structured Prompt Template\nLLM performance.\nFormat Sensitivity of Prompt Studies have high-   To facilitate fine-grained and targeted optimization,\nlighted the impact of formatting on prompt perfor-   our framework adopts a structured prompt template\nmance (Salinas and Morstatter, 2024). Sclar et al.   inspired by prompt engineering guidelines from\n(2024) revealed that modifications to separators   OpenAI (2024b) and Google (2024). Our template\nand spacing within a query could substantially im-   decomposes prompts into distinct functional com-\n\nFigure 3: An illustrative example of our Structured Prompt Template. This template systematically organizes the\nprompt into distinct components, each serving a specific functional role. When formulating a prompt, the template\nfirst employs a Query format to present examples and queries, and then integrates all content components via the\nPrompt Renderer to construct the comprehensive prompt string.\n\nponents, allowing for both detailed analysis and    3.2  Component-wise Content Optimization\nselective modification. The template distinguishes                                                  Building upon existing prompt optimization strate-\nbetween content-based and format-based compo-                                                         gies, which often rely on either feedback-driven\nnents, providing flexibility and adaptability to di-                                                   refinement or Monte-Carlo sampling (Section 2.2),\nverse user needs. A set of common and generally                                  CFPO introduces a more targeted and efficient ap-\napplicable elements is illustrated in Figure 3.                                               proach to content optimization. While feedback-\n  The Content-based Components define the in-                                                   driven methods diagnose weaknesses through fail-\nformation provided to the LLM, including:                                                    ure analysis, and Monte-Carlo sampling diversifies\n• Task Instruction defines the primary goal, guid-   perspectives with semantic variations, CFPO inno-\n   ing the model’s overall behavior.                  vates along two key dimensions.\n• Task Detail offers supplementary task-specific       First, CFPO expands the diagnostic phase be-\n   information, including resolution steps.         yond traditional failure analysis by incorporating\n                                                      correct cases. This allows the LLM to identify and• Output Format specifies the desired output\n                                                       reinforce successful aspects of the prompt, comple-   structure (e.g., JSON, bullet points, etc.).\n                                              menting error correction. Second, CFPO adopts a\n• Few-shot Examples provide specific instances\n                                              component-wise optimization strategy. Instead of\n   for contextual learning patterns.\n                                                       treating the prompt as a monolithic block, CFPO\n• Query shows the question or request to be an-                                                          targets specific content-based components for indi-\n   swered by the LLM.                                                     vidual refinement, enabling more precise and effec-\n  The Format-based Components dictate how    tive optimization.\nthe prompt is assembled and presented, including:\n• Prompt Renderer defines how to aggregate all    3.3  Format Optimization Design\n   components into a structured prompt.                                         To efficiently navigate the prompt format space,\n• Query Format: defines how to structure the ren-  CFPO incorporates a format optimizer based on a\n   dering of examples and queries.               dynamic format pool and an LLM-assisted gener-\n  Note that this template is highly adaptable. Users    ation module. The optimizer iteratively explores,\ncan readily adjust the template by adding or delet-    evaluates, and refines formatting choices.\ning components, or incorporating additional format-\n                                                      3.3.1  Format Pool with Scoring Systemting elements (e.g., tables, structured documents)\nwithin existing components to suit their specific   The format pool maintains a diverse collection\nrequirements. By decoupling format from content,   of prompt format configurations, organized hier-\nthis structured template empowers users to perform    archically to represent variations at both macro\ntargeted and precise optimizations, leading to im-    (e.g., overall prompt structure) and micro (e.g.,\nproved prompt effectiveness.                       component-internal rendering) levels. In this work,\n\nFigure 4: Built-in formats and rendering effects in our initial format pool. The final format configuration is achieved\nby selecting and combining elements from both the Prompt Renderer and the Query Format categories.\n\nwe prototype this structure with two distinct render-   cape local optima and discover potentially superior\ners: a Prompt Renderer defining the global struc-   formatting strategies.\nture, and a Query Format governing the rendering      In each optimization round, the format generator\nof individual components, such as examples and     is provided with the existing formats and their nor-\nqueries, as shown in Figure 4.                      malized performance scores, Q(f) and tasked with                                                                               N(f),\n  Each format f in the pool is associated with    creating new formats or variations that might im-\na performance score, Q(f), which cumulatively   prove performance. This iterative process not only\nreflects its effectiveness across different prompt    diversifies the format pool but also ensures that our\ncontents. When a format f is evaluated on a new   system can adapt to and incorporate a wide range of\ncontent c, its score is updated as follows: Q(f) ←    formats, thereby enhancing its utility and effective-\nQ(f) + m(c, f), where m(c, f) is a task-specific    ness. Additional details and generated examples\nmetric function. For example, in reasoning tasks,   about the format generation process are available\nm(·) represents the average accuracy (0 or 1) on an    in Appendix A.3 and Appendix D.1.\nevaluation dataset. The number of evaluations for\n                                                      3.3.3  Search Format via Format Optimizer\neach format, N(f), is also tracked to enable score\n                                                  For each content candidate generated by the con-normalization and fair comparison.\n                                                           tent optimizer, the format optimizer aims to identify  To initiate the format exploration process, we\n                                                     the most appropriate format from format pool. Todefine an initial format search space, F, consisting\n                                                  navigate the balance between exploring new for-of a set of predefined and commonly used formats\n                                             mats and exploiting known effective ones, we im-(Figure 4), along with diverse variations that in-\n                                              plemented the Upper Confidence Bounds appliedtroduce subtle changes (e.g., spacing, punctuation,\n                                                       to Trees (UCT) algorithm (Kocsis and Szepesvári,special symbols). This initial format pool serves as\n                                                 2006). The UCT algorithm employs a selectionthe foundation for subsequent exploration.\n                                                         criterion given by:\n3.3.2  LLM-assisted Format Generation\n                                                      Q(f)  sPf N(f)\nTo overcome the limitations of a static format pool       UCT(f) =    + α                  (1)\n                                                   N(f)       N(f)\nand promote continuous adaptation, we introduce\nan LLM-based format generator, LLMf_gen. This   where α serves as a balancing hyper-parameter,\nmodule autonomously generates novel formats by    adjusting the trade-off between exploration and\nleveraging information about the existing formats    exploitation.\nin the pool and their performance characteristics.     The overall process, outlined in Algorithm 1,\nBy dynamically creating new formats, we aim to es-    selects 2k formats for evaluation in each optimiza-\n\nAlgorithm 1 Searching Optimal Format Given a   work in tandem, leveraging the LLM to enable\nPrompt Candidate                                   rapid adaptation and customization. This iterative\nInput: p0 = (c0, f0): initial prompt, p = (c, ·):   and collaborative process optimizes both the con-\n    current prompt candidate(with content c), F:    tent and the format of prompts, leading to signifi-\n   dynamic format pool, k: number of formats,   cant improvements in prompt quality.\n    m(·): evaluation metric, D: evaluation data.\n  1: Initialize: Q(f) ←m(c0, f), N(f) ←1 for   4  Experiments\n     all f ∈F\n                                                    4.1  Experimental Setups\n  2: Format Selection: Fselect ←{f ∈F  : f is\n    in the top k w.r.t. UCT(f)}                  Models. We selected four open-source Large Lan-\n  3: Format Generation:                       guage Models (LLMs) as our primary evaluation\n  4: for each i = 0, 1, ..., k do                           targets, including two foundational models, Mistral-\n  5:   Generate format: fnew ←LLMf_gen(F)     7B-v0.1 (Jiang et  al., 2023) and LLaMA-3.1-\n  6:    Collect fnew to Fgen, and add fnew to F     8B (Meta, 2024b), as well as two instruction-tuned\n  7: end for                                     models, LLaMA-3-8B-Instruct (Meta, 2024a) and\n  8: Format Evaluation:                            Phi-3-Mini-Instruct (Microsoft, 2024). For content\n  9: for each f ∈Fselect ∪Fgen do                mutation and format generation during the opti-\n 10:   Evaluate m(c, f) with dataset D             mization process, we employed GPT-4 (2024-05-\n 11:   Q(f) ←Q(f) + m(c, f)                    01-preview) (OpenAI, 2024a).\n 12:   N(f) ←N(f) + 1                         Datasets.  Our evaluation benchmark was de-\n 13:   Update UCT(f) by Eq. 1                   signed to comprehensively assess model perfor-\n 14: end for                                mance across a range of task types and difficulty\n 15: ˆf ←arg maxf∈Fselect∪Fgen m(c, f)               levels, emphasizing diverse query formats. Specifi-\nOutput: The optimal format ˆf for content c          cally, we employed the following tasks:\n                                                              • Classification: The Implicatures task from the\n                                               Big-Bench benchmark (bench authors, 2023).\ntion round: k existing formats from the pool (based                                                              • Multiple-choice: ARC-Challenge (Clark et al.,\non UCT score), and k new formats generated by                                                 2018) task.\nthe LLMf_gen. The selected formats from both\n                                                              • Reasoning: GSM8K (Cobbe et al., 2021) and\nthe existing pool (Fselect) and the newly generated\n                                    MATH500 (Hendrycks et al., 2021; Lightman\npool (Fgen) are then evaluated using a predefined\n                                                               et al., 2023) requiring complex reasoning abili-\nmetric function m(·), and the best-performing for-\n                                                                      ties.\nmat among the tested candidates will be identified.\n                                                   Baselines. We compared CFPO with several com-The result is then incorporated into the pool for\n                                          monly used and popular baselines. GrIPS (Prasadfuture iterations. By iteratively evaluating formats,\n                                                           et al., 2023) performs syntactic phrase-level ed-the format optimizer ensures a balance between\n                                                                   its in instruction, representing a non-LLM-basedexploring new formats and refining current ones,\n                                                  optimization approach. APE (Zhou et al., 2023)converging to the best format configuration.\n                                            and ProTeGi (Pryzant et al., 2023) both employ\n                               LLM to optimize prompt content, but differ in mu-3.4  Integrated Optimizer Design\n                                                        tation strategy. APE adopts an instruction induc-\nCFPO integrates content and format optimization    tion approach, while ProTeGi leverages test cases\nwithin an iterative loop, as illustrated in Figure 2.   feedback with LLM to guide the mutation process.\nIn each iteration, the content optimizer proposes  SAMMO (Schnabel and Neville, 2024) introduces\ncandidate prompts, and the format optimizer iden-   a structured framework that incorporates a prelimi-\ntifies the most effective format for each candidate.   nary format mutation strategy, which relies on ran-\nThis ensures that each prompt benefits from the   dom selection from a predefined format pool. All\nmost effective formatting. Furthermore, effective   methods were evaluated using consistent experi-\nformats can improve the diversity and performance   mental configurations to ensure a fair comparison.\nof content candidates, thereby helping content opti-  We also report common baseline prompts for rea-\nmizer for beam search in the next iteration.          soning tasks, including 8-shot for GSM8K and 4-\n  In summary, the content and format optimizers    shot for MATH500.\n\nMethod              Mistral-7B-v0.1  LLaMA-3.1-8B   LLaMA-3-8B-Instruct   Phi-3-Mini-Instruct\n\n                                        Big-Bench Classification\n      Baseline                   56.00             64.00                70.00                  54.00\n    GRIPS                    86.00             67.00                84.00                  69.00\n    APE                      73.00             65.00                60.00                  63.00\n     ProTeGi                   83.00             81.00                82.00                  76.00\n   SAMMO                  86.00             80.00                86.00                  78.00\n    CFPO (Ours)              94.00             90.00                91.00                  87.00\n                                           ARC-Challenge\n      Baseline                   67.15             73.81                75.94                  84.39\n    GRIPS                    77.05             77.90                79.61                  87.46\n    APE                      75.85             77.05                78.67                  87.63\n     ProTeGi                   76.54             77.22                79.86                  87.54\n   SAMMO                  77.22             77.13                79.86                  87.03\n    CFPO (Ours)              79.35             78.50                80.63                  88.23\n                                   GSM8K\n      Baseline (1-shot cot)        36.85             50.03                74.00                  83.45\n      Baseline (8-shot cot)        38.21             51.02                73.46                  85.75\n    GRIPS                    39.04             50.27                74.53                  83.47\n    APE                      40.33             52.39                75.13                  83.85\n     ProTeGi                   45.72             54.74                75.36                  84.84\n   SAMMO                  43.82             54.74                75.89                  84.76\n    CFPO (Ours)              53.22             63.38                80.74                  89.16\n                                      MATH-500\n      Baseline (1-shot cot)         4.60             10.58                12.20                  12.60\n      Baseline (4-shot cot)        10.20             23.40                14.00                  40.40\n    GRIPS                    13.40             15.80                23.60                  10.80\n    APE                      11.60             12.80                22.80                  30.60\n     ProTeGi                   10.80             17.00                18.40                  28.80\n   SAMMO                  12.20             15.40                25.80                  42.40\n    CFPO (Ours)              14.80             26.99                33.33                  44.20\n\n                 Table 1: Main results of CFPO and state-of-the-art methods on four datasets.\n\nImplementation Details. To evaluate the gener-   ing only marginal improvements. This highlights\nated prompts, we sample subsets from the training    the importance of iterative feedback for effective\nsplit for each benchmark (sizes: 50, 500, 500, and   prompt refinement, a feature shared by ProTeGi,\n300 examples respectively). Beam search (bud-  SAMMO, and CFPO. Furthermore, CFPO incor-\nget of 8) is used during prompt mutations. Each    porates integrated format optimization that con-\nexperiment was capped at 20 iterations. Early stop-    tributes significantly to the performance gains, par-\nping was implemented, halting the process if per-    ticularly for previously challenging tasks.\nformance plateaus. The number of prompt com-     The benefits of CFPO are particularly pro-\nponents the LLM could modify decreased linearly   nounced in reasoning tasks, such as GSM8K and\nfrom 4 to 1 over the iterations (see Appendix B.1).  MATH, known for their sensitivity to prompt struc-\nWe start with a single in-context example without    ture. While improvements are observed on both\nany further instruction as the initial prompt for each    datasets, the impact is more noticeable on GSM8K\nmodel and task, except for GrIPS which requires   compared to the more complex MATH dataset, sug-\nan initial instruction. Detailed parameter settings    gesting that task difficulty can moderate the attain-\nand procedure are in the Appendix B.                able performance gains from prompt optimization.\n                                           Beyond performance metrics, we further eval-\n4.2  Main Results                                uate the stability of CFPO and the computational\n                                                          cost, as detailed in Appendix C. Examples of opti-Table 1 summarizes the performance of CFPO com-\n                                           mal prompts are detailed in Appendix E.pared with several state-of-the-art methods across\nfour datasets. The results highlight the superior\n                                                    4.3  Ablation Studyperformance of CFPO, significantly outperforming\nthe baseline prompt and competing methods.       Impact of the CFPO Pipeline Components. To\n  The effectiveness of CFPO is particularly ev-   understand the contribution of each component\nident when compared to methods like GRIPS,    in CFPO, we compared the full CFPO approach\nwhich relies solely on phrase-level mutations, yield-   against the following ablated variants: (1) CFPOf\n\nTask    Method   Llama3.1   Llama3-Ins            Optimizer       Mistral   Llama3.1   Llama3-Ins   Phi-3\n             ProTeGi      81.00        82.00              Qwen2.5-14B     50.49      58.76        80.14      88.48\n                                                            GPT-4 (CFPO)    53.22      63.38        80.74      89.16\n           CFPOf        83.00        86.00\n   BBC    CFPOc        85.00        85.00                                                       Table 4: Performance of CFPO using different optimizer\n           CFPOc+f     88.00        89.00\n                                                     models.         CFPO        90.00        91.00\n\n             ProTeGi      54.74        75.36            for generation. As shown in Table 3, the version\n           CFPOf        52.46        76.65\n                                                with format generation consistently outperforms  GSM8K  CFPOc        58.07        77.71\n           CFPOc+f     61.94        79.30           the variant using only the initial pool. This high-\n         CFPO        63.38        80.74            lights the benefit of our format exploration mech-\nTable 2: Performance comparison of the full CFPO   anism in expanding the prompt space. (See Ap-\npipeline against ablated variants with format-only   pendix D.2 for the ablation study with different\n(CFPOf),  content-only  (CFPOc),  and  sequential    format generation models.)\ncontent-then-format (CFPOc+f) optimization. CFPOc   Analysis of Format Selection Strategies. We fur-\nalso compared to ProTeGi (Pryzant et al., 2023).                                                        ther examined the effectiveness of our UCT-based\n   Task       Method      Llama3.1   Llama3-Ins      format selection strategy. We compared it against\n                                           two baselines: random selection from the format               Impact of Format Generation\n                                                  pool and a greedy selection approach (equivalent to\n            w/o Format Gen      88.00        87.00\n   BBC             with Format Gen     90.00        91.00          setting α = 0 in Eq. (1), disabling exploration). Ta-\n            w/o Format Gen      62.70        78.85         ble 3 shows that CFPO with UCT-based selection  GSM8K\n             with Format Gen     63.38        80.74\n                                                      consistently achieves the best performance across\n             Different Format Selection Strategies\n                                                                  all settings, demonstrating the efficacy of balancing\n          Random             85.00        87.00         exploration and exploitation in format searching.\n   BBC   UCT(α = 0)         86.00        88.00\n            UCT(ours)          90.00        91.00       Exploring Different Optimizer Models. While\n          Random             62.40        78.82       GPT-4 was used as the primary optimizer model for\n  GSM8K  UCT(α = 0)         63.23        79.08\n            UCT(ours)          63.38        80.74       CFPO, we also investigated the feasibility of using\n                                                a more accessible model , Qwen2.5-14B-Instruct.\nTable 3: Ablation of format generation and comparison                                                Table 4 presents the performance of CFPO with\nof format selection strategies.\n                                                 Qwen2.5-14B-Instruct as the optimizer. The results\n                                                     are encouraging, demonstrating that CFPO can be\n                                                        effectively adapted to smaller-sized open-sourced(format-only): optimizes the prompt format while\n                                               models, albeit with some performance trade-offs,\nholding content constant, (2) CFPOc (content-\n                                                     increasing its potential for broader applicability.only): optimizes the prompt content while hold-\ning format constant, and (3) CFPOc+f (sequential):                                       5  Conclusion\nperforms iterative content optimization followed\nby a separate, single-step format optimization. We   This paper introduces Content-Format Integrated\nalso include ProTeGi (Pryzant et al., 2023) as a   Prompt  Optimization (CFPO),  an  innovative\nbaseline. While CFPOc shares the goal of content   methodology that concurrently optimizes both\noptimization with ProTeGi, CFPOc incorporates   prompt content and format. By leveraging a struc-\ncorrect cases in diagnosis and component-wise mu-   tured prompt template, CFPO decouples these el-\ntation as key inovations. Table 2 presents the re-   ements, enabling integrated optimization and ad-\nsults of this analysis. CFPOc significantly outper-   dressing a significant gap in current research that\nforms ProTeGi, demonstrating the effectiveness of    largely overlooks the critical influence of format.\nour content optimization strategy.  Furthermore,   Our results demonstrate the substantial significant\nthe ablated variants all underperform compared to    influence of format on LLM performance, under-\nthe complete CFPO pipeline. These results under-   scoring the necessity of a joint optimization ap-\nscore the interdependence of content and format in    proach. These findings emphasize the importance\nprompt optimization, highlighting the importance    of integrating content and format considerations in\nof joint optimization for best performance.          prompt engineering. CFPO represents a significant\nAnalysis of Format Generation. We compared   advancement, empowering developers to design ef-\nthe full CFPO approach against variant that uses    fective and robust prompts and unlocking the full\nformat from initial format pool without using LLM    potential of LLMs across diverse applications.\n\nLimitations While the proposed method demon-      Tafjord. 2018.  Think you have solved question\nstrates promising results, there are several limita-      answering?  try arc, the ai2 reasoning challenge.\n                                                                Preprint, arXiv:1803.05457.tions worth noting. First, the effectiveness of the\napproach is task- and model-dependent. While                                                    Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\nthe method generates promising prompts for spe-     Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\ncific tasks and models, it may not generalize as       Plappert, Jerry Tworek, Jacob Hilton, Reiichiro\n                                                    Nakano, et al. 2021. Training verifiers to solve matheffectively to others—particularly tasks that are\n                                                word problems. arXiv preprint arXiv:2110.14168.\nless sensitive to prompt structure or models that al-\nready possess strong reasoning capabilities, thereby    Sarkar Snigdha Sarathi Das, Ryo Kamoi, Bo Pang,\nlimiting its broader applicability. Moreover, the it-     Yusen Zhang, Caiming Xiong, and Rui Zhang. 2024.\nerative nature of the optimization process, with       Greater: Gradients over reasoning makes smaller lan-\n                                                    guage models strong prompt optimizers.\nmultiple mutation strategies, introduces computa-\ntional complexity, which could hinder scalability    Chrisantha  Fernando,  Dylan  Banarse,  Henryk\nin resource-constrained environments. Finally, we      Michalewski, Simon Osindero, and Tim Rock-\nacknowledge the inherent difficulty in definitively       täschel. 2023.   Promptbreeder:  Self-referential\n                                                       self-improvement via prompt evolution.  Preprint,\nseparating content and format, especially in real-                                                        arXiv:2309.16797.\nworld scenarios where structured data can be em-\nbedded within content. Future work will focus on    Google. 2024.   Prompting guide 101.   https:\naddressing these limitations, including exploring      //workspace.google.com/resources/ai/\n                                                  writing-effective-prompts/.the application of CFPO to complex agentic tasks\nand improving the stability and scalability of the                                                 Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang.\noptimization process.                                 2022. PPT: Pre-trained prompt tuning for few-shot\n                                                                learning. In Proceedings of the 60th Annual Meeting\n                                                           of the Association for Computational Linguistics\nReferences                                       (Volume 1: Long Papers), pages 8410–8423, Dublin,\n                                                                Ireland. Association for Computational Linguistics.\nArian Askari, Christian Poelitz, and Xinye Tang. 2024.\n  Magic: Generating self-correction guideline for in-   Yanhui Guo, Shaoyuan Xu, Jinmiao Fu,  Jia Liu,\n   context text-to-sql.                                 Chaosheng Dong, and Bryan Wang. 2024. Q-tuning:\n                                                     Queue-based prompt tuning for lifelong few-shot lan-\nBIG bench authors. 2023. Beyond the imitation game:                                                    guage learning. Preprint, arXiv:2404.14607.\n   Quantifying and extrapolating the capabilities of lan-\n  guage models.  Transactions on Machine Learning                                                            Patrick Haluptzok, Matthew Bowers, and Adam Tauman\n   Research.                                                              Kalai. 2023. Language models can teach themselves\n                                                                to program better.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\n   Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\n                                                               Jia He, Mukund Rungta, David Koleczek, Arshdeep\n   Neelakantan, Pranav Shyam, Girish Sastry, Amanda\n                                                    Sekhon, Franklin X Wang, and Sadid Hasan. 2024.\n   Askell,  Sandhini Agarwal,  Ariel  Herbert-Voss,\n                                                Does prompt formatting have any impact on llm per-\n  Gretchen Krueger, Tom Henighan, Rewon Child,\n                                                     formance? Preprint, arXiv:2411.10541.\n  Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\n  Clemens Winter, Christopher Hesse, Mark Chen, Eric\n                                          Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul\n   Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\n                                                          Arora, Steven Basart, Eric Tang, Dawn Song, and Ja-\n  Jack Clark, Christopher Berner, Sam McCandlish,\n                                                    cob Steinhardt. 2021. Measuring mathematical prob-\n  Alec Radford, Ilya Sutskever, and Dario Amodei.\n                                                 lem solving with the math dataset. arXiv preprint\n  2020. Language models are few-shot learners. In\n                                                        arXiv:2103.03874.\n   Proceedings of the Annual Conference on Neural\n   Information Processing Systems (NeurIPS).\n                                                 Shengran Hu, Cong Lu, and Jeff Clune. 2024.  Au-\n                                                     tomated design  of  agentic systems.    Preprint,Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen,\n                                                        arXiv:2408.08435.  and Denny Zhou. 2024. Large language models as\n   tool makers.\n                                                      Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-\nAnwoy Chatterjee, H S V N S Kowndinya Renduchin-       sch, Chris Bamford, Devendra Singh Chaplot, Diego\n   tala, Sumit Bhatia, and Tanmoy Chakraborty. 2024.      de las Casas, Florian Bressand, Gianna Lengyel, Guil-\n   Posix: A prompt sensitivity index for large language      laume Lample, Lucile Saulnier, Lélio Renard Lavaud,\n   models. Preprint, arXiv:2410.02185.                  Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,\n                                                       Thibaut Lavril, Thomas Wang, Timothée Lacroix,\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,     and William El Sayed. 2023. Mistral 7b. Preprint,\n  Ashish Sabharwal, Carissa Schoenick, and Oyvind      arXiv:2310.06825.\n\nEllen Jiang, Kristen Olson, Edwin Toh, Alejandra    Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit\n  Molina, Aaron Donsbach, Michael Terry, and Carrie J      Bansal. 2023. Grips: Gradient-free, edit-based in-\n   Cai. 2022. Promptmaker: Prompt-based prototyping       struction search for prompting large language models.\n  with large language models. In Extended Abstracts       Preprint, arXiv:2203.07281.\n   of the 2022 CHI Conference on Human Factors in\n  Computing Systems, CHI EA ’22, New York, NY,   Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chen-\n  USA. Association for Computing Machinery.           guang Zhu, and Michael Zeng. 2023.  Automatic\n                                                  prompt optimization with \"gradient descent\" and\nOmar Khattab, Arnav Singhvi, Paridhi Maheshwari,     beam search. In Proceedings of the Conference on\n  Zhiyuan Zhang, Keshav Santhanam,  Sri Vard-      Empirical Methods in Natural Language Processing\n  hamanan, Saiful Haq, Ashutosh Sharma, Thomas T.     (EMNLP), page 7957–7968.\n   Joshi, Hanna Moazam, Heather Miller, Matei Za-\n                                                Abel Salinas and Fred Morstatter. 2024. The butterfly   haria, and Christopher Potts. 2024. Dspy: Compiling\n                                                                 effect of altering prompts: How small changes and   declarative language model calls into self-improving\n                                                               jailbreaks affect large language model performance.   pipelines.    In Proceedings of  the  International\n                                                                Preprint, arXiv:2401.03729.  Conference on Learning Representations (ICLR).\n                                                     Tobias Schnabel and Jennifer Neville. 2024.  Sym-\nLevente Kocsis and Csaba Szepesvári. 2006. Bandit                                                             bolic prompt program search: A structure-aware ap-\n  based monte-carlo planning. In European conference                                                     proach to efficient compile-time prompt optimiza-\n  on machine learning, pages 282–293. Springer.                                                                      tion. In Proceedings of the Conference on Empirical\n                                                 Methods in Natural Language Processing (EMNLP),\nWoosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying                                                      pages 670–686.\n  Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gon-\n   zalez, Hao Zhang, and Ion Stoica. 2023. Efficient    Sander Schulhoff, Michael Ilie, Nishant Balepur, Kon-\n  memory management for large language model serv-       stantine Kahadze, Amanda Liu, Chenglei Si, Yin-\n   ing with pagedattention. In Proceedings of the ACM      heng Li, Aayush Gupta, HyoJung Han, Sevien Schul-\n  SIGOPS 29th Symposium on Operating Systems       hoff, Pranav Sandeep Dulepet, Saurav Vidyadhara,\n   Principles.                                     Dayeon Ki, Sweta Agrawal, Chau Pham, Gerson\n                                                          Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava,\nJunyou Li, Qin Zhang, Yangbin Yu, Qiang Fu, and      Hevander Da Costa, Saloni Gupta, Megan L. Rogers,\n  Deheng Ye. 2024.  More agents is all you need.      Inna Goncearenco, Giuseppe Sarli, Igor Galynker,\n   Transactions on Machine Learning Research.            Denis Peskoff, Marine Carpuat, Jules White, Shya-\n                                                mal Anadkat, Alexander Hoyle, and Philip Resnik.\nXiang Lisa Li and Percy Liang. 2021.    Prefix-      2024. The prompt report: A systematic survey of\n   tuning: Optimizing continuous prompts for gener-      prompting techniques.\n   ation. arXiv preprint arXiv:2101.00190.\n                                                 Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane\nHunter Lightman, Vineet Kosaraju, Yura Burda, Harri       Suhr. 2024. Quantifying Language Models’ Sensitiv-\n  Edwards, Bowen Baker, Teddy Lee, Jan Leike,       ity to Spurious Features in Prompt Design or: How\n  John Schulman, Ilya Sutskever, and Karl Cobbe.        I learned to start worrying about prompt formatting.\n  2023.  Let’s verify step by step.  arXiv preprint       In Proceedings of the International Conference on\n  arXiv:2305.20050.                                    Learning Representations (ICLR).\n\n                                                         Jiuding Sun, Chantal Shaib, and Byron C. Wallace. 2023.Meta. 2024a. Introducing meta llama3: The most capa-\n                                                        Evaluating the zero-shot robustness of instruction-   ble openly available llm to date.\n                                                        tuned language models. Preprint, arXiv:2306.11270.\nMeta. 2024b. The llama 3 herd of models.  Preprint,                                               Anton Voronov, Lena Wolf, and Max Ryabinin. 2024a.\n  arXiv:2407.21783.                                             Mind your format: Towards consistent evaluation\n                                                          of in-context learning improvements.    Preprint,\nMicrosoft. 2024. Phi-3 technical report: A highly capa-                                                        arXiv:2401.06766.\n   ble language model locally on your phone. Preprint,\n  arXiv:2404.14219.                              Anton Voronov, Lena Wolf, and Max Ryabinin. 2024b.\n                                             Mind your format: Towards consistent evaluation\nMoran Mizrahi, Guy Kaplan, Dan Malkin, Rotem Dror,      of in-context learning improvements. In Findings of\n  Dafna Shahaf, and Gabriel Stanovsky. 2024. State       the Association for Computational Linguistics: ACL\n   of what art? a call for multi-prompt llm evaluation.      2024, pages 6287–6310, Bangkok, Thailand. Associ-\n   Preprint, arXiv:2401.00595.                               ation for Computational Linguistics.\n\nOpenAI. 2024a.  Gpt-4 technical report.   Preprint,   Ming Wang, Yuanzhong Liu, Xiaoyu Liang, Songlian Li,\n  arXiv:2303.08774.                                          Yijie Huang, Xiaoming Zhang, Sijia Shen, Chaofeng\n                                                    Guan, Daling Wang, Shi Feng, Huaiwen Zhang, Yifei\nOpenAI.  2024b.    Prompt  generation.    https:      Zhang, Minghui Zheng, and Chi Zhang. 2024a. Lang-\n  //platform.openai.com/docs/guides/                 gpt: Rethinking structured reusable prompt design\n  prompt-generation/.                              framework for llms from the programming language.\n\nXinyuan  Wang,  Chenxi  Li,  Zhen  Wang,  Fan  A  Appendix: Detailed Optimization\n   Bai, Haotian Luo, Jiayou Zhang, Nebojsa Jojic,       Process and Meta-Prompts\n   Eric P Xing, and Zhiting Hu. 2024b.   Promp-\n   tagent:  Strategic planning with language mod-   A.1  Meta-Prompt Header Setup\n   els enables expert-level prompt optimization.  In\n  Proceedings  of  the  International Conference on   At the beginning of the prompt, we introduce the\n  Learning Representations (ICLR).                    task and provide a detailed explanation of the\n                                                 prompt’s components, followed by the current ver-\nZhen Wang, Rameswar Panda, Leonid Karlinsky, Roge-\n   rio Feris, Huan Sun, and Yoon Kim. 2023. Multitask    sion of the prompt. Below is the structure of the\n  prompt tuning enables parameter-efficient transfer   meta-prompt header, where placeholders are de-\n   learning. Preprint, arXiv:2303.02861.               noted in [ALL CAPS]:\n\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten    I'm trying to write a prompt to [TASK INTENTION].\n  Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\n                                                    The current prompt consists of several key  Denny Zhou. 2023. Chain-of-thought prompting elic-\n                                                    components, including:\n   its reasoning in large language models.  Preprint,\n                                                    [DESCRIPTION OF COMPONENTS]\n  arXiv:2201.11903.\n\n                                                    The complete prompt is as follows:\nWHO. 2023.   Auto-gpt.   https://github.com/                                                    \"\"\"[CURRENT PROMPT]\"\"\"\n  Significant-Gravitas/AutoGPT.\n\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanx-   A.2  Content Optimization\n   iao Liu, Quoc V. Le, Denny Zhou, and Xinyun\n  Chen. 2024. Large Language Models as Optimiz-   A.2.1  Case-diagnosis and Revision\n   ers. In Proceedings of the International Conference                                      As described in Section 3.4, content optimization\n  on Learning Representations (ICLR).\n                                                               is achieved through an iterative process of case-\nEric Zelikman, Eliana Lorch, Lester Mackey, and    diagnosis and feedback guided mutation. To fa-\n  Adam Tauman Kalai. 2024. Self-Taught Optimizer     cilitate this process, we utilize three distinct meta-\n  (STOP): Recursively Self-Improving Code Genera-\n                                                prompts, each tailored to a specific task within\n   tion. In Conference On Language Model (COLM).\n                                                   content optimization.\nJiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng,   Case Diagnosis Meta-Prompt. This meta-prompt\n  Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin                                                   analyzes the current prompt’s performance against\n  Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng,\n                                                a set of test cases. It identifies areas for improve-  Bang Liu, Yuyu Luo, and Chenglin Wu. 2024. Aflow:\n  Automating agentic workflow generation.           ment and suggests specific modifications for the\n                                                   next iteration.\nTianjun Zhang, Xuezhi Wang, Denny Zhou, Dale\n  Schuurmans, and Joseph E. Gonzalez. 2023. Tem-   [META PROMPT HEADER]\n   pera: Test-time prompting via reinforcement learn-\n                                                    Upon evaluating the current prompt, this prompt   ing. In Proceedings of the International Conference\n                                                    gets the following examples wrong:\n  on Learning Representations (ICLR).                                                    [INCORRECT CASES]\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,                                                    Meanwhile, this prompt gets the following\n  Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy    examples correct:\n  Ba. 2023. Large language models are human-level    [CORRECT CASES]\n  prompt engineers. Preprint, arXiv:2211.01910.\n                                                    Please review the provided examples of correct\nJingming  Zhuo,  Songyang  Zhang,  Xinyu  Fang,    and incorrect answers, and identify [NUM OF\n  Haodong Duan, Dahua Lin, and Kai Chen. 2024a.   DIAGNOSED COMPONENTS] specific area for\n  ProSA: Assessing and understanding the prompt sen-   improvement in the prompts. Each suggestion\n   sitivity of LLMs.  In Findings of the Association    should focus on A SPECIFIC segment of the prompt\n   for Computational Linguistics: EMNLP 2024, pages     that needs optimization. For each suggestion,\n  1950–1976, Miami, Florida, USA. Association for    provide a comprehensive explanation that\n                                                    encapsulates all the evaluation results. If you\n  Computational Linguistics.\n                                                    believe the EXAMPLES segment needs improvement,\n                                                    you may suggest one example that can be added,Jingming  Zhuo,  Songyang  Zhang,  Xinyu  Fang,\n                                                    removed, or altered to enhance the EXAMPLES\n  Haodong Duan, Dahua Lin, and Kai Chen. 2024b.                                                    segment based on the examples given. If you\n   Prosa: Assessing and understanding the prompt sen-   think there is no need for improvement, do not\n   sitivity of llms. Preprint, arXiv:2410.12405.           return any prompt segment.\n                                                    Please encapsulate each suggestion using the\n                                                    following format:\n\n                                                    <START>\n\n<Prompt segment: [Segment name]>                   A.2.2  Monte-Carlo Sampling\n[Suggestion goes here]\n                                           Monte-Carlo Sampling Meta-Prompt explores a<END>\n                                               wider range of semantically equivalent yet syntac-\n                                                           tically varied instructions, enhancing the chancesFeedback Application Meta-Prompt. Based on\n                                                    of discovering more effective prompts.the diagnosis, this meta-prompt generates targeted\ntextual changes to enhance the prompt’s perfor-   [META PROMPT HEADER]\nmance. It directly modifies the identified compo-                                                    Please create a different version of [COMPONENT\nnents of the prompt based on the feedback.           NAME] segment without changing its semantic\n                                                    meaning. In case this segment is an empty string,\n[META PROMPT HEADER]                                 generate a suitable one. The existing [\n                                                    COMPONENT NAME] segment contains:\nThe existing [COMPONENT NAME] segment contains:     [CURRENT CONTENT FOR THE COMPONENT]\n[CURRENT CONTENT FOR THE COMPONENT]\n                                                    The varied [COMPONENT NAME] segment is as\nHere are some suggestions for improving the [       follows:\nCOMPONENT NAME] segments:\n[GENERATED DIAGNOSES]                         Monte-Carlo Sampling Meta-Prompt (for Ex-\n                                              amples) refines few-shot examples by strategically\nBased on the above information, I wrote [NUMBER\nOF GENERATED CONTENT] distinct and improved         adding, deleting, or modifying single instances to\nversions of the [COMPONENT NAME] segment within     ensure their effectiveness.\nthe prompt.\n                                                    [META PROMPT HEADER]Each revised segment is encapsulated between <\nSTART> and <END>. In case this segment is an\n                                                    The existing EXAMPLE set contains:empty string, generate a suitable one referring\n                                                    [CURRENT IN-CONTEXT EXAMPELS IN PROMPT]to the suggestion.\nThe [NUMBER OF GENERATED CONTENT] revised [\n                                                    Please generate a variation of the EXAMPLES setCOMPONENT NAME] segments are:\n                                                    within the prompt while keeping the semantic\n                                                    meaning. The revision shoud represent ONLY ONE\nFeedback Application Meta-Prompt (for Exam-   of the following specific actions:\nples). This meta-prompt specifically handles the    1. Addition: Incorporating one new example into\n                                                    the existing set.\noptimization of few-shot examples. It revises exam-   2. Deletion: Eliminating one single example from\nples by adding, deleting, or modifying one single     the current set.\n                                                    3. Modification: Changing the content of an\ninstances, ensuring that the in-context learning pro-                                                    example while maintaining its contextual\ncess is effective.                                     relevance.\n                                                    Please present the results without indicating\n[META PROMPT HEADER]                                which action was taken. The varied EXAMPLES\n                                                    segment is as follows:\nThe existing EXAMPLES segment contains:\n[CURRENT IN-CONTEXT EXAMPELS IN PROMPT]\n                                            A.3  Format Generation\nHere are some suggestions for enhancing the\nEXAMPLES segment:                            Our format generation process is a two-step pro-\n[GENERATED DIAGNOSES]                             cedure designed to create diverse and effective\n                                            prompt formats. We focus on generating two key\nBased on the above information, I have crafted [\nNUMBER OF GENERATED EXAMPLES] improved version     components of a prompt’s format:  the Prompt\nof the EXAMPLES segment within the prompt. Each     Renderer and the Query Format. The appendix\nrevision represents ONLY ONE of the following                                                    presents examples of the format generated using\nspecific actions:\n1. Addition: Incorporating one new example into      this pipeline.\nthe existing set.                              Step 1: Format Description Generation. For\n2. Deletion: Eliminating one single example from\n                                              each component (i.e., Prompt Renderer and the the current set.\n3. Modification: Changing the content of an        Query Format), we first generate a natural language\nexample while maintaining its contextual             description of the format, alongside an example of\nrelevance.\nPlease present the results without indicating      how this format would render a sample input. This\nwhich action was taken. Each refined EXAMPLES       description acts as a blueprint, guiding the subse-\nsegment is marked by <START> and <END>.            quent code generation. We utilize a meta-prompt\nThe [NUMBER OF GENERATED EXAMPLES] revised           to instruct an LLM to perform this task. The meta-\nEXAMPLES are:                                 prompt takes existing format examples as context\n                                            and generates new format descriptions along with\n\nrendered results. As an illustrative example, here is   Step 2: Format Code Generation. Based on the\na conceptual outline of the meta-prompt employed    natural language description and rendered exam-\nfor generating new Query Format descriptions:       ple produced in Step 1, we subsequently generate\n[META PROMPT HEADER]                                 the corresponding code implementation of the new\n                                                     format. This code will be used by the system to ren-\nWe have some preset QUERY_FORMAT candidates,        der prompts according to the defined format. We\nhere are our whole search pool:\n[ALL EXISTING QUERY FORMATS DESCRIPTION]            again leverage a meta-prompt to instruct the LLM,\n                                                           this time to generate the executable code. As an\nHere are two examples from our QUERY_FORMAT\n                                                              illustrative example, here is a conceptual outline ofcandidates as for your reference:\n<Format name: Question-Answer>                       the meta-prompt employed for generating the code\n[RENDERED EXAMPLE 1]                                 representation of a new Query Format:\n\n<Format name: Instruction-Response>\n[RENDERED EXAMPLE 2]                                                    [META PROMPT HEADER]\n\nPlease generate ONE new format for the                                                    We have some preset QUERY_FORMAT candidates,\nQUERY_FORMAT segment, its description and render                                                    here are our whole search pool:\n the provided example using this new format. The                                                    [ALL EXISTING QUERY FORMATS DESCRIPTION]\n new format could either be a completely new\nformat or a variation of an existing format.                                                    Here are two code implementations from our\n                                                    QUERY_FORMAT candidates as for your reference:\nIf you choose to generate a completely new                                                    <Format name: Question-Answer>\nformat, please ensure that the new format is                                                    <Renderer code>\nconventional, structured, and aligned with                                                    [Question-Answer RENDERER CODE]\ncommonly used query formats. Avoid overly                                                    <Extractor code>\ncreative or unconventional formats that deviate                                                    [Question-Answer EXTRACTOR CODE]\nsignificantly from standard practices. The new\nformat should be distinct from the existing                                                    <Format name: Instruction-Response>\nformats.                                                    <Renderer code>\n                                                    [Instruction-Response RENDERER CODE]\nThe variation can focus on two parts, CASING and                                                    <Extractor code>\n SEPARATOR:                                                    [Instruction-Response EXTRACTOR CODE]\n\nCASING refers to both the capitalization of the                                                    Here is the example rendered by the new format:\ntext (e.g., f(x) = x.title(), f(x) = x.upper(),                                                    [RENDERED RESULTS]\nf(x) = x.lower()) and the specific wording or\nphrasing used (e.g., changing \"question\" to \"                                                    Please generate the code for this provided\ninstruction\" or \"input\").                                                    example based on the new QUERY_FORMAT. Ensure\n                                                    that both the renderer and extractor functions\nSEPARATOR: the punctuation or symbols used to                                                    are included. The generated code should be plain\nseparate the question and answer, there are some                                                     Python code without any Markdown syntax or\n candidates as for your reference {{'', ' ', '\\\\                                                    language identifiers such as ```python or '''\nn', '--', ';\\\\n', ' ||', '<sep>', ' \\\\n', ':',                                                    python. Please output the code directly without\n'.'}}.                                                    any additional formatting. If you need to use\n                                                    any additional and specific packages, please\nNote that focus solely on the format itself                                                    import them in the code. Note that the generated\nwithout altering the content of the question and                                                     functions should include properly indented\n answer. The format should remain focused on the                                                    blocks, so they can execute without errors. Note\n existing structure (e.g., Question/Answer or                                                     that the renderer function name should be\nInstruction/Response) without modifying the                                                    query_renderer_{format_name} and the extractor\ncontent or introducing any new sections. Avoid                                                    function name should be query_extractor_{\nthe use of underlines or any unconventional                                                    format_name}.\nformatting styles among words. The format name\nshould only include alphanumeric characters and                                                    Please encapsulate the code using the following\nunderscores. Special characters such as `|`,                                                    format:\n`!`, `#`, `@`, and spaces should be avoided.\n\n                                                    <START>\nPlease encapsulate the new query format using                                                    <Format name: {format_name}>\nthe following format:                                                    <Description: {format_description}>\n                                                    <Renderer code>\n<START>                                                    [Renderer code]\n<Format name: [format name]>                                                    <Extractor code>\n<Description: [format description]>                                                    [Extractor code]\n[The example rendered by the newly generated                                                    <END>\nformat]\n<END>\n\nB  Appendix: Experimental Setup             string match with the ground truth. For Chain-of-\n                                             Thought reasoning tasks (GSM8K and MATH500),\nB.1  Hyperparameter in Optimization                                                     the final numerical answer was extracted from the\n     Procedure                                                 generated explanation and compared to the cor-\nDuring content optimization, case-diagnosis and    rect solution for an exact match. Finally, the best-\nMonte Carlo sampling each generate 4 prompts   performing prompt identified on the evaluation set\nper round. A set of 40 test cases is used, with    for each optimization method is reported on the\n5 correct and incorrect cases leveraged for case-   corresponding test set.\ndiagnosis.  During optimization, the number of\n                                              B.4   Initial Prompt\nprompt components (e.g., Task Instruction, Task\nDetail, Output Format, Few-shot Examples) the    B.4.1  Big-Bench Classification\nLLM could modify simultaneously was dynami-   Prompt Renderer: Directly Joint\ncally adjusted across all the iterations. The number   Query Format: Input-Output\nof components that could be modified decreases    Examples:\nlinearly from 4 to 1 over the iterations, promoting    Input: Speaker 1: 'You do this often?' Speaker 2:\n                                                      'It's my first time.'broad exploration of the prompt space initially and\n                                                     Output: no\nfine-grained refinement in later stages.\n  For format optimization, 4 UCT-selected formats    {{Query placeholder}}\nand 4 newly generated formats are used to generate\n                                                  B.4.2  ARC-Challengenew prompts. The coefficient in the UCT selection\nprocess α is set to 1e −3.                       Prompt Renderer: Directly Joint\n  Each experiment was capped at a maximum of   Query Format: MultiChoice_QA\n20 optimization iterations. An early stopping cri-   You are a commonsense helper. I will provide\nterion was implemented, halting the process if the    several examples and a presented question. Your\n                                                     goal is to pick the most reasonable answer among\nperformance did not improve for a specified num-    the given options for the current question.\nber of consecutive iterations.                        Please respond with the corresponding label (A/B\n                                                     /C/D) for the correct answer.\nB.2  Model Generation Parameters                                                     Here are some examples:\nKey generation parameters for both the LLM opti-\n                                                     Question: Forests have been cut and burned so\nmizer (GPT-4) and the target evaluation models are    that the land can be used to raise crops. Which\ndetailed below.                                      consequence does this activity have on the\n                                                     atmosphere of Earth?\n• LLM Optimizer (GPT-4): We utilized the fol-   Choices:\n   lowing settings to generate and refine prompts:   A: It reduces the amount of carbon dioxide\n   top_p=1.0, max_tokens=4096, seed=42, and    production\n                                                     B: It reduces the production of oxygen\n   temperature=1.0.                               C: It decreases the greenhouse effect\n• Evaluation  Models:   The   target  evalu-   D: It decreases pollutants in the air\n                                                     Answer: B\n   ation  model,   evaluated  on  the  gener-\n   ated   prompts,   was   configured   with:   {{Query placeholder}}\n   top_p=0.1,   max_tokens=256,   seed=42,\n   temperature=0.0,   repetition_penalty=    B.4.3 GSM8K\n   1.0, and stop=’\\n’.  The stop parameter   Prompt Renderer: Directly Joint\n   ensured the model ceased generation upon en-   Query Format: QA\n   countering a newline character. All generation    Q: There are 15 trees in the grove. Grove\n   processes were implemented using the vLLM    workers will plant trees in the grove today.\n   library (Kwon et al., 2023).                       After they are done, there will be 21 trees. How\n                                                      many trees did the grove workers plant today?\n\nB.3  Evaluation Metric                            A: There are 15 trees originally. Then there\n                                                     were 21 trees after some more were planted. So\nPerformance across all tasks was evaluated using    there must have been 21 - 15 = 6. The answer is\nthe exact match metric. For direct answer tasks    6.\n(BigBench-Classification and ARC-Challenge), the                                                     {{Query placeholder}}\nmodel’s direct prediction was assessed for an exact\n\nTask    Method   Llama3.1   Llama3-Ins\n\n             Baseline     78.84        82.03\n MMLU\n         CFPO       81.74        83.77\n\nTable 5: Ablation of format generation and comparison\nof format selection strategies.\n\n\nB.4.4  MATH500\n\nPrompt Renderer: Directly Joint\nQuery Format: Question-Answer\n\nA chat between a curious user and an AI\nassistant. The assistant gives step-by-step\nsolutions to the user's questions. In the end of\n assistant's response, a final answer is given\nin the format of \"The answer is: <ANSWER>.\".\n\nHere are some examples:\nQuestion: Let \\[f(x) = \\left\\{\n\\begin{array}{cl} ax+3, &\\text{ if }x>2, \\\\\nx-5 &\\text{ if } -2 \\le x \\le 2, \\\\                  Figure 5: Overview of in-context examples and text\n2x-b &\\text{ if } x <-2.                                                           lengths for optimized prompts on various tasks and mod-\n\\end{array}\n                                                                      els.\\right.\\]Find $a+b$ if the piecewise function is\n continuous (which means that its graph can be\ndrawn without lifting your pencil from the paper                                                  Model          CFPO   Reproduced CFPO\n).\nAnswer: Let's think step by step. For the                Mistral-7B-v0.1       53.22       51.87 ± 0.22\npiecewise function to be continuous, the cases         Llama-3.1-8B         63.38       62.70 ± 0.59\nmust \"meet\" at $2$ and $-2$. For example, $ax+3$        Llama-3-8B-Instruct   80.74       80.67 ± 0.17\n and $x-5$ must be equal when $x=2$. This                 Phi-3-Mini-Instruct    89.16       88.89 ± 0.31\nimplies $a(2)+3=2-5$, which we solve to get $2a\n=-6 \\Rightarrow a=-3$. Similarly, $x-5$ and $2x-    Table 6: Stability Analysis: Comparison of reported\nb$ must be equal when $x=-2$. Substituting, we     CFPO scores with reproduced results (4 runs each).\nget $-2-5=2(-2)-b$, which implies $b=3$. The\nanswer is: $a+b=-3+3=\\boxed{0}$.\n                                            C.2  Impact of In-context Examples and\n{{Query placeholder}}\n                                            Prompt Length\n\n                                                  Figure 5 presents an overview of the number of in-\nC  Appendix: CFPO Performance,                                                   context examples and the text length of optimized\n     Stability, and Cost Analysis                                             prompts across various tasks and models. An in-\n                                                        teresting pattern emerges: pre-trained models con-\nC.1 CFPO Performance on MMLU\n                                                           sistently prefer prompts with longer text and more\nTo further evaluate the Content-Format Integrated    in-context examples compared to instruction-tuned\nPrompt Optimization (CFPO) approach, we as-   models. This observation suggests that pre-trained\nsessed its performance on the MMLU benchmark.   models benefit more from explicit context and de-\nSpecifically, we focused on high school history cat-    tailed reasoning steps, which align with their less\negories (including high_school_european_history,    task-specialized nature. In contrast, the relative\nhigh_school_us_history and high_school_world    insensitivity of instruction-tuned models to prompt\n_history) to evaluate CFPO’s effectiveness on    length and in-context examples supports the notion\nknowledge-based tasks.                                that these models have already trained with task-\n  Table 5 summarizes the MMLU performance,    specific knowledge during fine-tuning, reducing\nshowcasing improvements achieved with CFPO,    their dependence on highly detailed prompts.\nwhich reinforce the generalizability of CFPO, ex-\n                                            C.3  Stability and Convergence Analysistending its demonstrated benefits from reasoning\ntasks (as presented in the main paper) to knowledge-  A crucial aspect of our framework is its stability.\nbased tasks. This expanded validation will be inte-   To quantify this, we performed multiple indepen-\ngrated into the revised manuscript.                  dent runs of CFPO and analyzed the variance in\n\nOperation         Tokens (I/O)  API Calls   Est. Cost\n\n                                                                   Case-diagnose          2k/0.2k        32       $ 0.83\n                                                            Apply Feedback        0.5k/0.1k       110       $ 0.93\n                                                      Gen Variation          0.5k/0.2k       81        $0.89\n                                                      Gen Format            0.5k/0.1k        2        $0.016\n                                                      Gen Format Code      0.6k/0.2k        2        $0.024\n\n                                                                    Total (per Round)   159.6k/36.6k     237        $2.69\n\n                                                      Table 7: Average token usage, API calls, and estimated\n                                                          cost per round of CFPO optimization. Tokens (I/O):\n                                                             typical input/output tokens per round, API Calls: aver-\n                                                    age API calls per round, Est. Cost: estimated cost in $.\n\n\n                                                   Task        Avg. Cost to Tar.   Avg. Time to Tar.\nFigure 6: Convergence behavior of format and content    BBC             $14.10              5.24 h\noptimization (Mistral-7B-v0.1 on GSM8K). Values in-    ARC-C          $16.81              6.25 h\ndicate performance scores, with improvements from the    GSM8K          $28.25             10.50 h\nprevious sub-round in parentheses.                  MATH500        $19.85              7.38 h\n\n                                                     Table 8: Average cost and time required for CFPO to\nperformance. Table 6 presents a comparison of                                                        reach the reported target state-of-the-art performance on\nthe originally reported CFPO scores with the mean    each benchmark.\nand standard deviation of scores obtained from four\nindependent runs. The consistently low standard\n                                                   Furthermore, CFPO incorporates an early stop-deviations across all models demonstrate the ro-\n                                                ping mechanism that terminates the optimizationbustness and stability of our CFPO framework.\n                                                  process when performance improvement plateaus.  Furthermore, we examined the convergence be-\n                                                This prevents unnecessary iterations and reduceshavior of content and format optimization. Prelim-\n                                                      overall cost. Table 8 details the average cost andinary analysis using Mistral-7B-v0.1 on GSM8K\n                                                  time required to reach the reported performance on(Figure 6) indicates that format optimization may\n                                               each benchmark task. As demonstrated in Table 8,converge faster than content optimization. The per-\n                                                    the average computational cost per task remainsformance gains in each sub-round (content or for-\n                                               manageable.mat optimization) are shown in parentheses. This\nsuggests that the optimization schedule could be\n                           D  Appendix: Format Generation\nrefined.\n                                         Examples and Ablation Study\n  This difference in convergence speed could stem\nfrom the distinct optimization strategies: during   D.1  Examples of Generated Format\ncontent optimization, a diverse set of correct and                                             Here we select several format generated by GPT-4\nincorrect examples is resampled from the training                                                        in CFPO process.\nset in each round. In contrast, format optimization\nrelies on generating variations of existing formats,   D.1.1  Query Format\nleading to reduced diversity as the UCT score con-   Highlight_Separator_Case\nverges. We hypothesize that allocating more re-   QUESTION > Statement 1 | Every element of a\nsources to format optimization in early rounds, and    group generates a cyclic subgroup of the group.\n                                                     Statement 2 | The symmetric group S_10 has 10\nsubsequently shifting focus to content optimization,                                                     elements.\ncould improve overall efficiency. This is an area    OPTIONS > (A) True, True (B) False, False (C)\nfor further investigation in future work.              True, False (D) False, True\n                                                     ANSWER > C\n\nC.4  Cost Analysis                            Cascading_Statements\n\nAn important consideration is the computational    Question: Statement 1 | Every element of a group\n                                                      generates a cyclic subgroup of the group.\ncost associated with CFPO. Table 7 breaks down                                                     Statement 2 | The symmetric group S_10 has 10\nthe average token usage, API calls, and estimated    elements.\ncost per round of optimization for each operation    Options:\n                                                      -A True, True\nwithin CFPO. These costs are calculated using cur-     -B False, False\nrent API pricing for the utilized LLMs.                -C True, False\n\n-D False, True                                          Format Generation Model   Accuracy\n   Answer: C\n                                                                     Claude-3.5-haiku              58.91\nQA_Titlecase_Separator                                         Llama-3.3-70B-Instruct         61.71\n                                                                  Gemini-2.0                    62.09\nQuestion || In 3 years, Jayden will be half of              DeepSeek-R1                  62.24\nErnesto's age. If Ernesto is 11 years old, how             GPT-4 (CFPO)                 63.38\nmany years old is Jayden now?\nAnswer || Let's think step by step. Ernesto = 11\n                                                     Table 9: GSM8K Accuracy with Different LLMs for + 3 = <<11+3=14>>14 Jayden = 14/2 = <<14/2=7>>7\n in 3 years Now = 7 - 3 = <<7-3=4>>4 Jayden is 4    Format Generation (Using GPT-4 as content optimizer\n years old.                                       and LLaMA-3.1-8B as the target model).\n\nQA_Brackets_Colon_Newline\n\n[Question]:\n                                                     The function should take two numbers as inputIn 3 years, Jayden will be half of Ernesto's age.\n                                                     and return their sum. If Ernesto is 11 years old, how many years old\nis Jayden now?\n                                                     - [ ] **Examples**\n                                                     Input: 1, 2[Answer]:\n                                                     Output: 3Let's think step by step.\nErnesto = 11 + 3 = <<11+3=14>>14 Jayden = 14/2 =\n                                                     - [ ] **Query** <<14/2=7>>7 in 3 years Now = 7 - 3 = <<7-3=4>>4\n                                                     Input: 1, 2 Jayden is 4 years old.\n                                                     Output:\nQA_CapsBold_ColonNewline\n\n**QUESTION**:\nIn 3 years, Jayden will be half of Ernesto's age.\n If Ernesto is 11 years old, how many years old     D.2  Ablation Study of Format Generation\nis Jayden now?                                   Models\n\n**ANSWER**:\nLet's think step by step.                     To investigate the potential reliance on a specific\nErnesto = 11 + 3 = <<11+3=14>>14 Jayden = 14/2 =   LLM for format generation within our framework,\n <<14/2=7>>7 in 3 years Now = 7 - 3 = <<7-3=4>>4\n                                     we conducted an ablation study. This study evalu- Jayden is 4 years old.\n                                                   ated the performance of several alternative LLMs\n                                                        in generating the formats used by CFPO, as shownD.1.2  Prompt Renderer\n                                                       in Table 9. We systematically replaced the orig-\nConcise_Bullet_Points_Renderer\n                                                         inal format generation LLM (GPT-4) with alter-\n- Task Instruction: Write a function that                                                      native models: Gemini-2.0, DeepSeekR1, Claude-\nreturns the sum of two numbers.\n                                                  3.5-Haiku, and Llama-3.3-70B-Instruct. In these\n- Task Detail: The function should take two         experiments, GPT-4 was consistently used for con-\nnumbers as input and return their sum.\n                                                         tent optimization, and LLaMA-3.1-8B remained\n- Examples: Input: 1, 2                              the target model for evaluating performance on the\nOutput: 3                          GSM8K benchmark.\n\n- Query: Input: 1, 2                            The results demonstrate that the choice of LLM\nOutput:                                               for format generation has a relatively minor im-\nTabular_Sections_Renderer                        pact on overall accuracy. While variations in the\n                                                         specific generated formats are observed across dif-| Task Instruction | Write a function that\nreturns the sum of two numbers. |                     ferent LLMs, the consistent performance suggests\n| Task Detail | The function should take two         that CFPO’s effectiveness is not critically depen-\nnumbers as input and return their sum. |\n| Examples | Input: 1, 2                           dent on a single LLM. Specifically, as long as the\nOutput: 3 |                        LLM demonstrates the capability to generate vari-\n| Query | Input: 1, 2                                ations and code based on the provided schema,\nOutput: |\n                                                     the downstream performance on GSM8K remains\nChecklist_Format_Renderer                           stable. This robustness suggests that the core prin-\n- [ ] **Task Instruction**                            ciples of CFPO are transferable and not tied to the\nWrite a function that returns the sum of two         idiosyncrasies of a particular LLM. This suggests\nnumbers.\n                                   CFPO is not overly sensitive to the choice of format\n- [ ] **Task Detail**                               generation model.\n\nE  Appendix: Examples of CFPO Optimal    </div>\n   Prompt                                       <div class='Examples'>\n                                                      <h2>Examples</h2>\n                                                      <p>Here are some examples:\nHere we selected several optimal prompts searched\nby CFPO.                                           Question: Forests have been cut and burned so\n                                                     that the land can be used to raise crops. Which\nLLaMA-3.1-8B on ARC-C                          consequence does this activity have on the\n                                                     atmosphere of Earth?<div class='TaskInstruction'>\n                                                     A: It reduces the amount of carbon dioxide in  <h2>TaskInstruction</h2>\n                                                     the atmosphere  <p>Your mission is to meticulously assess each\n                                                     B: It reduces the availability of oxygen   situation presented alongside a specific\n                                                     C: It lessens the greenhouse effect  question, employing your critical thinking and\n                                                     D: It lowers the levels of pollutants in the air   analytical skills. Your task comprises not\n                                                     Answer: B  only identifying the most logical and coherent\n   choice (A/B/C/D) but also thoroughly\n                                                     Question: What is the most critical practice to  evaluating how each option connects or\n                                                     ensure electrical safety while operating devices  diverges from the question's essence. This\n                                                     ?  requires a deep engagement with both the query\n                                                     A: Ensure the device does not come into contact   and the choices, ensuring your reasoning is\n                                                     with water.  firmly anchored in the specifics of the\n                                                     B: Use the device with hands covered in oil.  options provided. It is essential to weave\n                                                     C: Operate the device with wet hands.  direct elements from the choices into your\n                                                     D: Leave the device plugged in when not in use.  analysis, demonstrating a detailed\n                                                     Answer: A  understanding of how each option relates to\n  the core question, and articulating why\n                                                     Question: Placing a plant cell in a hypertonic  alternatives may be less fitting given the\n                                                     solution typically results in which of the  scenario. This approach ensures a nuanced and\n                                                     following?  well-justified selection process, grounded in\n                                                     A: The cell expanding as it absorbs water.  the interplay between the question context and\n                                                     B: No significant change due to the rigid cell   the specific details of the available choices\n                                                     wall.  .</p>\n                                                     C: The cell shrinking as water exits the cell.</div>\n                                                     D: Rapid division of the cell.<div class='TaskDetail'>\n                                                     Answer: C  <h2>TaskDetail</h2>\n  <p>In addressing the questions set before you,\n                                                     Question: What is the primary effect of using   it is imperative to delve deeper than mere\n                                                     fossil fuels on global climate change?  superficial observations or initial judgments.\n                                                     A: It leads to a significant reduction in   Each scenario or question must be examined\n                                                     greenhouse gases.  not just in its immediate context but within a\n                                                     B: It decreases the Earth's surface temperature.   broader spectrum, looking into the\n                                                     C: It increases the amount of greenhouse gases  underpinning mechanisms or far-reaching\n                                                     in the atmosphere.  effects of each option presented. This\n                                                     D: It contributes to a decrease in carbon  necessitates a thorough exploration of the\n                                                     dioxide levels.  larger implications and the scientific or\n                                                     Answer: C  logical foundations that dictate the outcomes.\n   For instance, in environmental matters, it is\n                                                     Question: The process of photosynthesis in   vital to assess not just the immediate\n                                                     plants primarily involves which of the following  effects but the sustained impact on the\n                                                      transformations?  ecosystem. In the realm of science, such as\n                                                     A: Converting oxygen and glucose into carbon  when discerning chemical processes, it is\n                                                     dioxide and water  crucial to understand the molecular or atomic\n                                                     B: Transforming water and carbon dioxide into  level changes that classify a reaction as a\n                                                     oxygen and glucose  chemical change. This enhanced level of\n                                                     C: Changing sunlight into chemical energy  scrutiny and deeper analysis will lead to more\n                                                     without producing oxygen   accurate and well-founded choices, ensuring\n                                                     D: Producing carbon dioxide and glucose from  your responses are not just correct, but are\n                                                     oxygen and water  also backed by a solid understanding of the\n                                                     Answer: B  underlying principles or long-term\n  consequences.</p>\n                                                     {{ query }}</div>\n<div class='OutputFormat'>\n                                         LLaMA-3.1-8B on GSM8K  <h2>OutputFormat</h2>\n  <p>For every query presented, your task is to      **Understanding the Task: A Foundation for\n  identify the right choice from the options (A/     Mathematical Problem-Solving**\n  B/C/D) accompanied by a concise rationale for      Your task is to methodically analyze the\n  your selection. This format is vital as it         information provided and logically deduce the\n  showcases the thought process leading to your      correct answer to the mathematical problem.\n  decision, facilitating a comprehensive grasp       Delve into each relevant detail, ensuring no\n  and interaction with the task.</p>                 critical step or aspect is overlooked. Approach\n\nthe solution with a detailed-oriented mindset,      provides a robust framework for identifying and\nensuring every part of the process is considered    rectifying any potential inaccuracies throughout\n to arrive at an accurate conclusion. Reflect on     the problem-solving process.\n all the elements that might influence your\nreasoning or calculation, striving for              **Examples to Illuminate the Path**\nthoroughness in your analysis.                      To better grasp the concepts, consider the\n                                                    following illustrative examples:\n**Decoding Mathematical Language in Real-World      Question: There are 15 trees in the grove. Grove\nScenarios**                                          workers will plant trees in the grove today.\nFor the most effective problem-solving in           After they are done, there will be 21 trees. How\nmathematics, particularly when faced with            many trees did the grove workers plant today? /\nintricate calculations over periods or under         ANSWER: Think through the problem step by step,\nspecific scenarios affecting results, an             diving into each segment for a thorough\nattentive and systematic method is key. Start by    exploration to piece together the final answer.\n accurately determining the base numerical value.   There are 15 trees originally. Then there were\n Then proceed by methodically listing every         21 trees after some more were planted. So there\nsignificant change whether it be increases,         must have been 21 - 15 = 6. The answer is 6.\ndecreases, or modifications that impacts this\nbase figure as the scenario unfolds, making sure    Question: A book club starts with a membership\n to include each change in your overall             of 120. If the club increases its membership by\ncomputations. It's essential to focus on the        10% in the first year and then loses 5% of its\nconcept of compounded operations, whether they'     members in the second year, what is the total\nre applied annually, monthly, or daily, and to      membership at the end of the second year? /\nthoughtfully evaluate the consequences of           ANSWER: Think through the problem step by step,\nextraordinary events or circumstances (like an      diving into each segment for a thorough\nunexpected inheritance, a yearly loss, or a         exploration to piece together the final answer.\nsingular occurrence with a major impact) that       The club starts with 120 members. In the first\nmight significantly shift the end calculations.     year, it increases by 10%, which is 0.10 * 120 =\nSharpen your attention on the dynamics of            12, so there are 120 + 12 = 132 members after\nnumerical relationships, particularly in cases      the first year. In the second year, the club\ninvolving ratios, proportions, and the impact of    loses 5% of its members, which is 0.05 * 132 =\n percentage changes over durations, to avoid        6.6, but since the number of members must be an\ncommon mistakes. Misunderstandings or               integer, we consider a loss of 7 members (\nmisapplications of these numerical relationships    assuming the figure is rounded up for practical\n can frequently cause inaccuracies. Thus, it is     reasons). Therefore, there are 132 - 7 = 125\ncritical to scrutinize these mathematical           members at the end of the second year.\nrelationships, whether they are of direct or\ninverse proportions, as well as the aggregate       Question: Martin saves $10 every week. In\neffects of consecutive percentage changes, as       addition, every third week, he earns an extra\noutlined in the problem description. This           $15 from helping his neighbor. How much has\nintensified attention is pivotal for an accurate    Martin saved after 9 weeks? / ANSWER: Think\n and detailed resolution of complex issues,         through the problem step by step, diving into\nmarked by multiplicative elements and               each segment for a thorough exploration to piece\ninterconnected circumstances. Reflect deeply on      together the final answer. Martin saves $10\nthe significance of every step in the               each week, so over 9 weeks, he saves 9 * $10 =\ncalculation process, absorbing the nuances of       $90. Additionally, every third week, he earns an\nthese changes, to systematically arrive at the       extra $15, which occurs three times within 9\nmost precise solution.                              weeks (in the 3rd, 6th, and 9th weeks). So, he\n                                                    earns an extra 3 * $15 = $45 from helping his\n**Ensuring Your Solution Fits the Scenario          neighbor. Therefore, the total amount Martin has\nPerfectly**                                          saved after 9 weeks is $90 + $45 = $135.\nIn presenting your solution, ensure it comprises\n both a numerical answer and a meticulously         Question: A teacher divides a class into groups\ndetailed explanation of the process leading to      for a project. If the ratio of boys to girls in\nit. Begin with outlining the initial conditions     the class is 3 to 2, and there are 30 students\nand sequentially narrate the calculations you       in the class, how many boys are in the class? /\nmake at each step, highlighting any compounded      ANSWER: Think through the problem step by step,\noperations or adjustments made to account for       diving into each segment for a thorough\nunique scenarios or conditions. This progression    exploration to piece together the final answer.\n should clearly show how each step contributes      The total ratio units for boys to girls in the\nto arriving at the final answer. For instance,      class is 3 + 2 = 5. With 30 students in the\nif the task involves calculating the total costs    class, each ratio unit represents 30 / 5 = 6\n saved over time with additional periodic           students. Therefore, the number of boys,\nbenefits, your response should methodically         represented by 3 parts of the ratio, is 3 * 6 =\nexplain: \"Starting with an initial savings of X,    18. The answer is 18.\n plus Y every Z period, and considering an\nadditional benefit of A every B period, leads to    Question: Grandma wants to order 5 personalized\n a total of...\". This comprehensive breakdown       backpacks for each of her grandchildren's first\nnot only bolsters the understanding of the          days of school. The backpacks are 20% off of $20\nmathematical principles applied but also            .00, and having their names monogrammed on the\n\nbackpack will cost $12.00 each. How much will       for conveying the most precise value possible.\nthe backpacks cost in total? / ANSWER: Think        3. Present solutions involving square roots in\nthrough the problem step by step, diving into       their reduced radical form, ensuring the\neach segment for a thorough exploration to piece    simplification process enhances comprehension\n together the final answer. The backpacks are       without diluting mathematical integrity.\n20% off of $20.00, so the price after the           4. In scenarios involving complex numbers,\ndiscount is $20.00 - ($20.00 * 20%) = $20.00 -      represent answers in their standard form (a + bi\n$4.00 = $16.00 each. The monogramming costs an      ), ensuring both 'a' and 'b' are presented in\nadditional $12.00 per backpack. Therefore, the      their simplest, most refined state. This\ntotal cost for each backpack is $16.00 + $12.00     emphasizes the need for a clear, coherent\n= $28.00. For 5 backpacks, the total cost will      representation of solutions encompassing complex\nbe 5 * $28.00 = $140.00. The correct answer is       numbers.\n$140.00.                                            5. Conclude your explanation with the statement:\n                                                      \"The answer is: \\[<ANSWER>\\].\", reinforcing\n**Query**                                           consistency and clarity across various\n{{query}}                                           mathematical challenges. This concluding\n                                                     statement should encapsulate the solution in its\nLLaMA-3-8B-Instruct on MATH-500                simplest and most direct form, reflecting a\n                                                     thorough simplification and rationalization- Task Instruction: A chat between a curious\n                                                     process.user and an AI assistant focused on solving\nmathematical and reasoning tasks. The assistant\n                                                     Your explanation must delineate a detailed, step-is expected to deliver step-by-step solutions to\n                                                     by-step progression leading to the final the user's questions, emphasizing mathematical\n                                                     solution. This approach is not merely aboutaccuracy and rigor throughout the process. It\n                                                     arriving at the correct answer but aboutmust ensure that each mathematical operation and\n                                                     illuminating the path taken to get there, logical deduction is carefully examined and\n                                                     ensuring a deep understanding and clearvalidated to derive the correct solution. At the\n                                                     demonstration of the reasoning behind each step. conclusion of the response, the final answer\nshould be presented in the format of \"The answer\n                                                     - Examples: Here are some examples: is: <ANSWER>.\", thereby confirming the solution\n                                                     ### Instruction:'s validity and demonstrating a thorough\n                                                     A rectangle ABCD has sides AB = 8 units and BC =understanding of the problem-solving approach.\n                                                      6 units. A circle with a radius r units is\n                                                     inscribed within this rectangle. Calculate the- Task Detail: In addressing equation-based\n                                                     radius r of the inscribed circle, ensuring theinquiries, precision in algebra, geometry,\n                                                     answer is in its simplest form.piecewise functions, complex numbers, and\nfinancial mathematics is paramount. This\n                                                     ### Response:involves a detailed analysis of each equation,\n                                                     We'll approach this problem by breaking it downassessing every element and specific condition.\n                                                     into manageable steps. We start by understandingFor piecewise functions, it's critical to ensure\n                                                      that the radius of the inscribed circle is continuity by solving for variables that\n                                                     equal to the distance from the center of themaintain consistency across sections. In\n                                                     rectangle to any of its sides because the circlegeometry, integrating measurements such as\n                                                      is perfectly inscribed. In a rectangle, thisangles, lengths, and areas is fundamental.\n                                                     distance is half the length of the rectangle'sAlgebraic queries require a consideration of all\n                                                     shorter side. Therefore, the radius r of the potential solutions and constraints, ensuring a\n                                                     inscribed circle is half the length of BC, which comprehensive resolution. The addition of\n                                                      is $6 \\div 2 = 3$ units. The answer is: $r=3$.complex numbers into this mix necessitates a\nthorough understanding of their properties and\n                                                     ### Instruction:operations to accurately determine both real and\n                                                     Given a triangle where two sides are represented imaginary solutions. Similarly, tackling\n                                                      by complex numbers (3 + 4i) units and (1 - 2i)financial mathematics problems demands a deep\n                                                     units, and the angle between them is 90 degrees,comprehension of concepts such as compound\n                                                      calculate the length of the hypotenuse. Ensureinterest, present value, and future value to\n                                                     your answer includes a comprehensive breakdownmake precise financial forecasts and comparisons.\n                                                     of complex number operations and geometric This holistic approach confirms that all\n                                                     principles applied.aspects of the problem are considered and that\nthe solution accounts for every requirement,\n                                                     ### Response:assuring mathematical integrity in the\n                                                     We'll approach this problem by breaking it downresolution process.\n                                                     into manageable steps. We start by acknowledging\n                                                      that the length of a side represented by a- Output Format: 1. Solutions that involve\n                                                     complex number can be found using the modulus offractions, square roots, or crucial mathematical\n                                                      that number. The modulus of the first side is $ figures (e.g., pi) must be simplified to their\n                                                     \\sqrt{3^2 + 4^2} = 5$ units, and the modulus ofmost fundamental form. This includes reducing\n                                                     the second side is $\\sqrt{1^2 + (-2)^2} = \\sqrtfractions to their lowest terms and expressing\n                                                     {5}$ units. Since these sides form a rightsquare roots in their least complex radical form.\n                                                     triangle and we are given that the angle between\n                                                      them is 90 degrees, we can apply the2. Avoid the use of decimals unless the question\n                                                     Pythagorean theorem to find the length of the explicitly requires it or they are necessary\n\nhypotenuse. The hypotenuse's length squared will\n be the sum of the squares of the lengths of the\n other two sides, which is $5^2 + (\\sqrt{5})^2 =\n 25 + 5 = 30$. Thus, the length of the\nhypotenuse is $\\sqrt{30}$ units. The answer is:\n$\\sqrt{30}$.\n\n- Query:\n{{query}}",
"headers": [
"arXiv:2502.04295v3  [cs.CL]  21 May 2025",
"Beyond Prompt Content: Enhancing LLM Performance via",
"Content-Format Integrated Prompt Optimization",
"Yuanye Liu",
"Jiahang Xu",
"Li Lyna Zhang Qi Chen Xuan Feng",
"Yang Chen Zhongxin Guo Yuqing Yang Peng Cheng",
"Abstract",
"1",
"Introduction",
"2",
"Related Work",
"3",
"CFPO: Content-Format Integrated",
"Prompt Optimization",
"4",
"Experiments",
"5",
"Conclusion",
"References",
"A",
"Appendix: Detailed Optimization",
"Process and Meta-Prompts",
"B",
"Appendix: Experimental Setup",
"C",
"Appendix: CFPO Performance,",
"Stability, and Cost Analysis",
"D",
"Appendix: Format Generation",
"Examples and Ablation Study",
"E",
"Prompt",
"Appendix: Examples of CFPO Optimal"
],
"tables": [
"|Task|Method|Llama3.1|Llama3-Ins|\n|---|---|---|---|",
"|Optimizer Mistral Llama3.1 Llama3-Ins Phi-3|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|Qwen2.5-14B<br>GPT-4 (CFPO)|50.49<br>53.22|58.76<br>63.38|80.14<br>80.74|88.48<br>89.16|",
"|BBC|ProTeGi<br>CFPO<br>f<br>CFPO<br>c<br>CFPO<br>c+f<br>CFPO|81.00<br>83.00<br>85.00<br>88.00<br>90.00|82.00<br>86.00<br>85.00<br>89.00<br>91.00|\n|---|---|---|---|",
"|GSM8K|ProTeGi<br>CFPO<br>f<br>CFPO<br>c<br>CFPO<br>c+f<br>CFPO|54.74<br>52.46<br>58.07<br>61.94<br>63.38|75.36<br>76.65<br>77.71<br>79.30<br>80.74|\n|---|---|---|---|",
"|Task|Method|Llama3.1|Llama3-Ins|\n|---|---|---|---|",
"|BBC|w/o Format Gen<br>with Format Gen|88.00<br>90.00|87.00<br>91.00|\n|---|---|---|---|\n|GSM8K|w/o Format Gen<br>with Format Gen|62.70<br>**63.38**|78.85<br>**80.74**|",
"|BBC|Random<br>UCT(α = 0)<br>UCT(ours)|85.00<br>86.00<br>90.00|87.00<br>88.00<br>91.00|\n|---|---|---|---|\n|GSM8K|Random<br>UCT(_α_ = 0)<br>UCT(ours)|62.40<br>63.23<br>**63.38**|78.82<br>79.08<br>**80.74**|",
"|Task|Method|Llama3.1|Llama3-Ins|\n|---|---|---|---|",
"|MMLU|Baseline<br>CFPO|78.84<br>81.74|82.03<br>83.77|\n|---|---|---|---|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2502.04295v3.pdf"
}