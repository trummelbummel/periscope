{
"text": "Linear Feedback Control Systems for Iterative\n     Prompt Optimization in Large Language Models\n                                               Rupesh Raj Karn\n                              Center for Cyber Security, New York University, Abu Dhabi, UAE.\n                                                 Email: rupesh.k@nyu.edu\n\n\n\n\n           Abstract—Large Language Models (LLMs) have revolutionized   the state-of-the-art in automated prompt refinement. The follow-\n          various applications by generating outputs based on given prompts.  up publication will detail the practical implementation and\n         However, achieving the desired output requires iterative prompt                                                                         evaluation of this theory across diverse computing applications\n         refinement. This paper presents a novel approach that draws\n                                                            and release the source code for AI community.          parallels between the iterative prompt optimization process in\n      LLMs and feedback control systems. We iteratively refine the     This paper makes the following key contributions:2025  prompt by treating the deviation between the LLM output and    1) Introduces a novel framework that applies linear feed-\n          the desired result as an error term until the output criteria are                                                                   back control system principles to the iterative prompt\n         met. This process is akin to a feedback control system, where\n                                                                            optimization process in LLMs.Jan   the LLM, despite being non-linear and non-deterministic,  is\n        managed using principles from linear feedback control systems.    2) Provides a detailed mathematical foundation for integrat-\n      We explore the application of different types of controllers        ing PID feedback controller mechanisms with LLMs and21\n         within this framework, providing a mathematical foundation        displays its functionality with an FPGA design example.\n          for integrating linear feedback control mechanisms with LLMs.\n           Index Terms—LLM, Feedback Control System, PID Controller,        II. PRELIMINARIES: FEEDBACK CONTROL SYSTEM\n         Transformer, Tokenization, Embedding                A feedback control system shown in Fig. 1 is a dynamic\n                                                                system that automatically adjusts  its operation to meet a\n                                        I. INTRODUCTION                        reference point [10]. The controller processes the error signal[cs.LG]\n                                                               and generates a control action to minimize this error, thereby\n          Large Language Models (LLMs) have become influential\n                                                                          driving the system towards the desired performance.\n          tools across various fields, such as natural language processing,\n                                          A Proportional-Integral-Derivative (PID) controller  is a\n        automated code generation, and others [1]. These models\n                                                                    widely used feedback control mechanism in industrial automa-\n        produce outputs based on provided prompts, but achieving\n                                                                            tion and control systems [11]. It aims to regulate a process\n         the desired outcomes necessitates iterative prompt refinement\n                                                                             variable by adjusting a manipulated variable based on the error\n           [2]. This iterative process resembles a feedback control system,\n                                                               between the setpoint and the actual process variable.\n        where the difference between the generated output and the\n                                                            The PID controller combines three control actions: propor-\n         desired result is considered an error term. By continuously\n                                                                                     tional, integral, and derivative. The control output u(t) is given\n          refining the prompt, we strive to minimize this error and achieve\n                                                                       by:\n         the desired result [3].                                                                                                      t                                                                            Z               de(t)\n         The concept of feedback control systems is well-established           u(t) = Kpe(t) + Ki    e(τ)dτ + Kd             (1)\n                                                                                                            0               dt\n          in control theory, where it is used to manage the behavior of\n                                                                   where:        dynamic systems [4]. In a typical feedback control system, the\n         system’s output is continuously monitored and compared to    ▷e(t) is the error signal, y(t): e(t) = r(t) −ˆy(t).arXiv:2501.11979v1\n         the desired output [5]. Any deviation (error) is fed back into   ▷Kp, Ki, Kd are the proportional, integral, and derivative\n          the system to adjust the inputs, thereby reducing the error over        gains, respectively.\n         time. This paper proposes a novel approach to apply these  The proportional term provides an output that is proportional\n          principles to optimize LLM outputs.                              to the current error value e(t). The integral term accounts for\n           Despite the non-linear and non-deterministic nature of   the accumulation of past errors. It integrates the error over\n      LLMs [6], we explain that principles from linear feedback   time to eliminate the steady-state error. The derivative term\n          control systems [7] can be effectively applied to optimize their   predicts the error’s future trend by considering its change rate. It\n         outputs. By integrating different types of controllers, such as   provides a damping effect, reducing overshoot and oscillations.\n          Proportional-Integral-Derivative (PID) controllers [8], we pro-  Combining the three control actions, the overall PID control\n         vide a structured methodology for enhancing the performance   law is expressed as in equ (1).\n        and reliability of LLM-driven applications. Traditional methods    The error signal e(t) is fed into the PID controller, which\n         of prompt optimization often rely on heuristic or trial-and-error   computes the control output u(t) to adjust the process variable\n         approaches, which can be time-consuming and inefficient [9].   ˆy(t) to match the setpoint r(t). The term β is feedback gain\n      By leveraging the systematic approach of feedback control  and ˆy(t) = βy(t).\n         systems, we aim to provide a more robust and theoretically    The performance of a PID controller depends on the proper\n        grounded method for prompt optimization, thereby advancing   tuning of  its parameters Kp, Ki, and Kd. Various tuning\n\n2) Non-Linearity in LLM Architecture: The architecture\n                                                                                 Output     Setpoint +                     Controller                    System                                                              of LLMs is highly non-linear, which affects the relationship\n                                        (PID)\n             -                                            between the input prompt p(t) and the output σ(t). To capture\n                 Feedback                                                    this non-linearity, we modify the function f to include a non-\n                                         Feeback Gain                           linear transformation g:\n                                                                       σ(t + 1) = g (f (p(t + 1))) + η(t)            (6)\n              Fig. 1: General feedback control system.            The function g could be activation functions or attention\n                                                                                                Output   mechanisms that are applied in LLM architecture.     Setpoint +            Controller         Prompt            LLM            System\n                              (PID)            Update           (OpenAI GPT)\n             -                                              C. Refined System Output\n                 Feedback\n                                                     The system output y(t) is influenced by the non-linear and\n                                         Feeback Gain                                stochastic nature of the LLM. We modify the output equation\n                                                                    to include these effects:    Fig. 2: LLM feedback control system for prompt refinement.\n                                                                             y(t + 1) = ϕ (σ(t + 1)) + ν(t)             (7)\nmethods, such as the Ziegler-Nichols method [12], Cohen-  Here, ν(t) represents additional noise introduced during the out-\nCoon method [10], are used to determine these parameters to   put processing stage, capturing any uncertainties or variations\nachieve the desired system performance.                         in the final output.\n             III. FEEDBACK CONTROL FOR LLMS            By incorporating the stochastic, non-deterministic, and non-\nA. Overall Architecture                                           linear properties of LLMs into the feedback loop equations,\n                                              we enhance the robustness and accuracy of the iterative prompt\n  The feedback loop mechanism employed in our approach\n                                                               optimization process.\nfor iterative prompt optimization using LLMs is illustrated in\nFig. 2. We integrate principles from linear feedback control                                                                 IV. LLM OUTPUT GENERATION WITH PID CONTROL\nsystems with modern machine learning techniques employed\n                                                                 In this section, we describe the mechanism by which anin LLMs in this setup.\n                                     LLM processes the input prompt p(t) to generate the output  Like Fig. 1, the control signal u(t) is calculated through\n                                                                  σ(t), incorporating the effects of a PID controller.equ (1). In this case, the u(t) is used to update the prompt\np(t) through the ’Prompt Update (OpenAI GPT [13])’ block.                                                             A. Tokenization and Embedding\n                   p(t + 1) = p(t) + u(t)                  (2)\n                                                    The first step in processing the updated prompt p(t + 1)The updated prompt p(t + 1) is subsequently processed by the\n                                                                 involves tokenization [18], where the input text is divided intoLLM block (e.g., OpenAI’s GPT) to generate the output σ(t),\n                                                              smaller units called tokens. Each token is converted into awhich is then integrated into the system use case. The LLM’s\n                                                              high-dimensional vector through an embedding layer [19]. Letoutput is modeled as:\n                                                               p(t + 1) be tokenized into {p1, p2, . . . , pn}. The embedding                 σ(t + 1) = f (p(t + 1))                 (3)\n                                                              process can be represented as:Here, the function f represents the LLM. Similarly, the system\n                                                                           ei = Embed(pi + u(t)),   i = 1, 2, . . . , n        (8)function is denoted by ϕ, whose output is given as:\n                                                       where ei is the embedding vector corresponding to the token pi,                  y(t + 1) = ϕ (σ(t + 1))                 (4)\n                                                        and the PID controller output u(t) influences the tokenizationThe output y(t) is fed back into the system through a feedback\n                                                              process by adjusting the prompt due to equ (2).gain β, completing the loop.\n  This feedback loop allows for continuous refinement of the                                                             B. Positional Encoding\nprompt p(t), ensuring that the output y(t) converges towards\n                                                    To incorporate the order of tokens, positional encoding isthe desired setpoint r(t). Integrating traditional control theory\n                                                        added to the embedding vectors [19]. This can be mathemati-with advanced machine learning techniques applied in LLMs\n                                                                    cally expressed as:provides a structured methodology for optimizing LLM outputs.\n                                                                                          e′i = ei + PE(i + u(t))                 (9)\nB. Incorporating LLM Properties into Feedback Control                                                          where, PE(i) is the positional encoding vector for the i-th\n  LLMs exhibit several key properties, including stochasticity   position, and u(t) affects the positional encoding by modifying\n[14], non-determinism [15], and inherent non-linearity [16],   the position indices.\n[17]. These properties significantly influence the behavior of the\n                                                          C. Transformer Layersfeedback control loop used for iterative prompt optimization.\n   1) Stochastic and Non-Deterministic Outputs: LLMs gener-    The core of the LLM consists of multiple transformer layers\nate outputs that are inherently stochastic and non-deterministic.   [20], each comprising self-attention [21] and feed-forward sub-\nFor a given prompt p(t), the output σ(t) can vary across   layers [20]. The self-attention mechanism computes a weighted\ndifferent iterations. To model this behavior, we introduce a  sum of the input embeddings, allowing the model to focus\nstochastic noise term η(t) into the LLM output equation:      on different parts of the input sequence. The self-attention\n              σ(t + 1) = f (p(t + 1)) + η(t)             (5)   operation is given by:\nHere, η(t) represents the stochastic variations in the LLM          Attention(Q(u(t)), K(u(t)), V(u(t))) =\noutput, which can be modeled as a random variable with a                    Q(u(t))K(u(t))T\n                                                                  softmax                    V(u(t))         (10)specific probability distribution.                                                               √dk\n\nwhere Q(u(t)), K(u(t)), and V(u(t)) are the query, key, and     2) Positional Encoding: In positional encoding, the propor-\nvalue matrices derived from the input embeddings influenced   tional component directly adjusts the position indices, ensuring\nby the PID controller output u(t).                          immediate alignment with the current  error. The integral\n  Each transformer layer also includes a feed-forward network  component corrects long-term deviations in positional encoding,\n(FFN) applied to each position separately and identically:      enhancing the model’s ability to maintain context over time. The\n   FFN(x(u(t))) = ReLU(x(u(t))W1 + b1)W2 + b2   (11)   derivative component smooths positional adjustments, reducing\nwhere W1, W2, b1, and b2 are learnable parameters, and u(t)   oscillations and ensuring stable positional encoding.\naffects the input x.                                                3) Transformer Layers: The transformer layers, comprising\nD. Output Generation                                             self-attention and feed-forward networks, are significantly\n   After passing through several transformer layers, the final hid-  impacted by the control signal u(t). The proportional com-\nden states are used to generate the output tokens. This involves   ponent adjusts the query, key, and value matrices in the self-\n                                                                     attention mechanism, ensuring the attention weights reflect thea linear transformation [22] followed by a softmax function to\n                                                                 current error. The integral component influences the attentionproduce a probability distribution over the vocabulary:\n              oi = softmax(hi(u(t))Wo + bo)          (12)  mechanism by incorporating past errors, refining the model’s\n                                                              focus over time. The derivative component helps predict futurewhere hi(u(t)) is the hidden state of the i-th token influenced\n                                                            changes, smoothing the attention weights to prevent abruptby u(t), and Wo and bo are the output layer parameters.\n  The output σ(t + 1) is then generated by sampling from the   shifts.\nprobability distribution oi.                                       In the feed-forward network (FFN), the proportional com-\n                                                         ponent immediately affects the input x, ensuring that theE. Incorporating PID Control into LLM Output Generation\n                                                          network responds to the current error. The integral component\n  The PID controller adjusts the prompt p(t) iteratively to\n                                                            ensures long-term stability by incorporating the history of\nminimize the error e(t). This updated prompt p(t + 1) is then\n                                                                      errors, while the derivative component smooths the input to\nprocessed by the LLM to generate the output σ(t + 1). The\n                                                                 the FFN, reducing oscillations.\nfunction f that represents the LLM’s processing can be broken\n                                                                 4) Impact Analysis Summary:  Overall, the proportional\ndown as follows:\n                                                    component Kpe(t) has the most immediate and significant\nf(p(t + 1)) = softmax (FFN (Attention (Q(p(t) + u(t)),\n                                                         impact on  all stages of the LLM processing pipeline. In\n                    K(p(t) + u(t)), V(p(t) + u(t))))) (13)                                                                     contrast, the integral and derivative components ensure long-\nHere, Q(p(t) + u(t)), K(p(t) + u(t)), and V(p(t) + u(t)) are                                                         term stability and smoothness. The combined effect of the\nthe query, key, and value matrices derived from the tokenized   control signal u(t) and the previous prompt p(t) results in the\nand embedded prompt p(t + 1).                                                           optimized generation of the output σ(t + 1) (equ (6)).\n  The control signal u(t) directly affects the embeddings and\npositional encodings, thereby influencing the self-attention  G. Session-Based Impact of PID Control\nmechanism and the subsequent feed-forward network. This     In cases where the LLM remembers the current session, typ-\nresults in the generation of the output σ(t+1) that is optimized   ically through a GUI interface (e.g., Chat GPT [23], Google’s\nbased on the PID controller’s adjustments.                  Gemini [24], Microsoft Co-pilot [25]), the PID controller\n  This detailed breakdown illustrates the complex yet struc-   significantly enhances performance by leveraging the history\ntured process by which LLMs transform input prompts into   of prompts and responses. The integral component accumulates\ncoherent outputs, leveraging advanced deep learning and   past errors, and the derivative component anticipates future\nmathematical operations while incorporating the adjustments   trends, both contributing to a more refined and stable output.\nmade by the PID controller to optimize the output.            For example, in a customer support chatbot integrated into a\nF. Impact Analysis                                  web application, the LLM can maintain context across multiple\n  We analyze the impact of the control signal u(t) on the   interactions within the same session, allowing for more coherent\nvarious stages of the LLM processing pipeline. The control  and contextually relevant responses [26].\nsignal u(t) is composed of three components: proportional     In contrast, LLMs accessed via APIs, such as OpenAI’s GPT\nerror, integral error, and derivative error, with corresponding   models, do not retain history between sessions, as each call\ngains Kp, Ki, and Kd. We will examine how each component   creates a new session [27]. For instance, an LLM used in a\naffects the Tokenization and Embedding, Positional Encoding,   serverless architecture where each API call is stateless will not\nTransformer Layers, and Output Generation stages.           remember previous interactions, leading to each request being\n  1) Tokenization and Embedding: The control signal u(t)  processed independently [28]. In such scenarios, the integral\naffects the tokenization and embedding process by adjusting  and derivative components are effectively zero, as there is no\nthe prompt p(t). The proportional component Kpe(t) provides   historical data to accumulate or trends to predict. Consequently,\nimmediate adjustments to the token embeddings (equ (8)),   the LLM output is directly influenced by the proportional term\nensuring that the prompt reflects the current error state. The   Kpe(t), which provides immediate adjustments based solely\nintegral component Ki R 0t e(τ)dτ influences the embeddings by  on the current error.\nincorporating the history of errors, thereby refining the prompt\n                                                             V. COMPARE: PID VS OTHER CONTROLLERS FOR LLMbased on accumulated deviations. The derivative component\nKd de(t)dt  helps in anticipating future trends and smoothing the   We compare the effectiveness of different controllers—PID,\nembeddings to prevent abrupt changes.                     Lead-Lag [29], Linear-Quadratic Regulator (LQR) [30], and\n\nFuzzy Logic Controller [31]—in the context of LLM prompt    3) Resource Utilization Calculation: The generated design is\noptimization.                                                        synthesized using tools like Vivado [37], Quartus [38], to\n                                                                      obtain the utilization values of LUTs, FFs, DSPs, BRAMs,\nA. Lead-Lag Controller                                                          and timing slack. This is represented through equ (7).\n  The Lead-Lag controller [29] improves system stability and      The utilization y(0) is calculated for each resource. Also,\ntransient response by adding lead and lag compensations:          assume the feedback gain β = 1.\n                        T1s + 1                            4) Error Calculation: The error e(0) =  r(t) −y(0)  is                 u(t) = K             e(t)\n                        T2s + 1                            computed.\nWhere T1 and T2  are  the lead and  lag time  constants,                                                                 5) Control Signal Computation: The control signal u(0) is\nrespectively. The Lead-Lag controller can enhance the phase                                                                       calculated using the PID control law as given in equ (1).\nmargin and improve the transient response but may not handle                                                                 6) Prompt Update: The prompt is updated to p(1) based on\nsteady-state errors as effectively as the PID controller due to                                                                      the control signal u(0) through equ (2).\nthe lack of integral action.                                                                 7) Iteration: Steps 2-6 are repeated until the average utiliza-\nB. Linear-Quadratic Regulator (LQR)                                 tion y(t) meets the desired setpoint r(t).\n  The LQR [30] controller minimizes a cost function to achieve   B. Example for FPGA Design\noptimal control:            ∞                                 The system function ϕ(t), equ (7), represents the relationship\n                Z\n            J =    (xT Qx + uT Ru) dt                between the LLM output σ(t) and the system output y(t),\n                       0                                  which includes various FPGA resources. The system output\n                      u(t) = −Kx(t)                                                                y(t) can be expressed as a vector of resource utilizations:\nWhere Q and R are weighting matrices, and K is the gain   y(t) =  λLUTs(t)  λFFs(t)  λDSPs(t)  λBRAMs(t)   λSlack(t)\nmatrix. The LQR  controller provides optimal control by  The setpoint value r(t) = 60%. Next, we provide an example of\nbalancing state and control efforts. However, unlike PID, it   the computations based on our proposed feedback mechanism:\nrequires a precise model of the system dynamics, which is     p(0) = ”Generate HLS C code for a neural network with 1 layer, 64 neurons\nhard to compute for LLMs.                                                    each, using Vivado HLS.”\n                                                            Consider a scenario where the initial prompt p(0) leads to\nC. Fuzzy Logic Controller                                 an FPGA design with the following resource utilizations and\n  The Fuzzy Logic Controller [31] uses fuzzy logic to handle   timing:\nuncertainties and non-linearities:                                       y(0) = 70%  65%  80%  75%  −2\n                                    de(t)                                                 Assume the PID gains are Kp = 0.6, Ki = 0.1, Kd = 0.05.                 u(t) = Fuzzy(e(t),       )\n                                    dt                      e(0) = r(0)−y(0) = −10% −5%  −20%  −15%  +3ns\nThe Fuzzy Logic  Controller can  effectively handle non-                                0\n                                                                   Z               de(0)\nlinearities and uncertainties in LLMs but requires the design      u(0) = Kpe(0) + Ki    e(τ)dτ + Kd    =\n                                                                                                      dtof fuzzy rules and membership functions. These can be more                               0\ncomplex and time-consuming than PID, making them less        −6% −3%  −12% −9%  +0.15 ns\nefficient for iterative prompt optimization.                       p(1) = p(0) + u(0) = ”Generate optimized HLS C code for a neural\n  The PID controller’s proportional, integral, and derivative    network with 1 layer, 64 neurons each, using Vivado HLS. Reduce resource usage by\nterms ensure immediate, long-term, and predictive adjustments   6% LUTs, 3% FFs, 12% DSPs, 9% BRAMs, and improve timing by 0.15 ns.” After\nto the prompt, resulting in a stable and coherent LLM output.  processing by the LLM, the new output y(1) might be:\n                                                                    y(1) = 65%  62%  70%  68%  0 ns\n             VI. USE CASE: FPGA DESIGN\n                                                             e(1) = r(1)−y(1) = −5% −2%  −10% −8%  +1 ns\n  To illustrate the application of our feedback control approach\n                                                                   Z 1             de(1)\nto LLMs, we consider a use case in the domain of neural      u(1) = Kpe(1) + Ki    e(τ)dτ + Kd    =\nnetwork implementation on FPGA [32], [33]. The objective is                               0                dt\nto iteratively refine the prompt (p(t)) to generate an optimal      −3%  −1.2% −6%  −4.8%  +0.05 ns\ndesign (y(t)) that closely matches the desired setpoint (r(t)).     p(2) = p(1)+u(1) = ”Generate optimized HLS C code for a neural network\nSpecifically, we aim to ensure that the utilization of FPGA    with 1 layer, 64 neurons each, using Vivado HLS. Further reduce resource usage by 3%\nresources λi, i ∈{LUTs, FFs, DSPs, BRAMs} [34] for the   LUTs, 1.2% FFs, 6% DSPs, 4.8% BRAMs, and improve timing by 0.05 ns.”\nneural network design is less than setpoint r(t) while meeting     This iterative process continues until the resource utilization\ntiming constraints (positive setup/hold slack time [35], [36]).   y(t) meets the desired setpoint r(t).\n                                                                              VII. CONCLUSION\nA. Iterative Prompt Refinement Process\n                                         We have presented a novel approach to optimizing LLM\n  The iterative prompt refinement process involves the follow-\n                                                                outputs by applying linear feedback control systems principles.\ning steps:\n                                                          This methodology bridges the gap between control theory\n  1) Initial Prompt: Start with a prompt p(0) to generate the  and natural language processing, offering a structured and\n   HLS C code for the neural network implementation.       theoretically grounded method for prompt optimization. Our\n  2) LLM Output: The LLM processes the prompt and gen-   findings explain that despite LLMs’ non-linear and stochastic\n     erates the initial design specification σ(0) as the HLS C   nature, integrating feedback PID controllers can enhance the\n     code, represented by equ (6).                           performance of LLM-driven applications.\n\nREFERENCES                                 [26] D. Chin, Y. Wang, and G. Xia, “Human-centered llm-agent user interface:\n                                                 A position paper,” arXiv preprint arXiv:2405.13050, 2024.\n [1] M. U. Hadi, Q. Al Tashi, A. Shah, R. Qureshi, A. Muneer, M. Irfan,   [27] X. Liu, Y. Zheng, Z. Du, M. Ding, Y. Qian, Z. Yang, and J. Tang, “Gpt\n     A. Zafar, M. B. Shaikh, N. Akhtar, J. Wu et al., “Large language models:         understands, too,” AI Open, 2023.\n     a comprehensive survey of its applications, challenges, limitations, and    [28] W. Ma, C. Yang, and C. K¨astner, “(why) is my prompt getting worse?\n      future prospects,” Authorea Preprints, 2024.                                    rethinking regression testing for evolving llm apis,” in Proceedings of\n [2] W. Dai, Y.-S. Tsai, J. Lin, A. Aldino, H. Jin, T. Li, D. Gaˇsevi´c, and         the IEEE/ACM 3rd International Conference on AI Engineering-Software\n     G. Chen, “Assessing the proficiency of large language models in automatic        Engineering for AI, 2024, pp. 166–171.\n     feedback generation: An evaluation study,” Computers and Education:   [29] Z. K. Jadoon, S. Shakeel, A. Saleem, A. Khaqan, S. Shuja, Q. Ul-Hasan,\n      Artificial Intelligence, p. 100299, 2024.                                         S. A. Malik, and R. Ali Riaz, “A comparative analysis of pid, lead,\n [3] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,          lag, lead-lag, and cascaded lead controllers for a drug infusion system,”\n     C. Zhang, S. Agarwal, K. Slama, A. Ray et al., “Training language        Journal of healthcare engineering, vol. 2017, no. 1, p. 3153252, 2017.\n     models to follow instructions with human feedback,” Advances in neural    [30] M. A. Abdullah, A. Q. Al-Shetwi, M. Mansor, M. Hannan, C. W. Tan, and\n     information processing systems, vol. 35, pp. 27 730–27 744, 2022.            A. Yatim, “Linear quadratic regulator controllers for regulation of the dc-\n [4] H. Ozbay, Introduction to feedback control theory.  CrC Press, 2019.         bus voltage in a hybrid energy system: Modeling, design and experimental\n [5] K. J. ˚Astr¨om and R. Murray, Feedback systems: an introduction for          validation,” Sustainable Energy Technologies and Assessments, vol. 50,\n      scientists and engineers.  Princeton university press, 2021.                       p. 101880, 2022.\n [6]  S. Ouyang, J. M. Zhang, M. Harman, and M. Wang, “Llm is like a box    [31]  S. Sharma and A. J. Obaid, “Mathematical modelling, analysis and design\n      of chocolates: the non-determinism of chatgpt in code generation,” arXiv         of fuzzy logic controller for the control of ventilation systems using\n      preprint arXiv:2308.02828, 2023.                                          matlab fuzzy logic toolbox,” Journal of Interdisciplinary Mathematics,\n [7]  Y. Zhou and Z. Wang, “Optimal feedback control for linear systems with          vol. 23, no. 4, pp. 843–849, 2020.\n      input delays revisited,” Journal of Optimization Theory and Applications,   [32] K. Bjerge, J. H. Schougaard, and D. E. Larsen, “A scalable and efficient\n      vol. 163, pp. 989–1017, 2014.                                                  convolutional neural network accelerator using hls for a system-on-chip\n [8] M. A. Johnson and M. H. Moradi, PID control.  Springer, 2005.               design,” Microprocessors and microsystems, vol. 87, p. 104363, 2021.\n [9] L. Beurer-Kellner, M. Fischer, and M. Vechev, “Prompting is program-   [33] M. Shahshahani, B. Khabbazan, M. Sabri, and D. Bhatia, “A framework\n     ming: A query language for large language models,” Proceedings of the          for modeling, optimizing, and implementing dnns on fpga using hls,”\n   ACM on Programming Languages, vol. 7, no. PLDI, pp. 1946–1969,         in 2020 IEEE 14th Dallas Circuits and Systems Conference (DCAS).\n     2023.                                                                IEEE, 2020, pp. 1–6.\n[10] R. P. Borase, D. Maghade, S. Sondkar, and S. Pawar, “A review of    [34] E. B. Kavun, N. Mentens, J. Vliegen, and T. Yalc¸ın, “Efficient utilization\n     pid control, tuning methods and applications,” International Journal of         of dsps and brams revisited: New aes-gcm recipes on fpgas,” in 2019\n     Dynamics and Control, vol. 9, pp. 818–827, 2021.                              International Conference on ReConFigurable Computing and FPGAs\n[11] A. R. Kumar and P. J. Ramadge, “Diffloop: Tuning pid controllers        (ReConFig).  IEEE, 2019, pp. 1–2.\n    by differentiating through the feedback loop,” in 2021 55th Annual    [35] R. R. Karn, K. Nawaz, and  I. A. M. Elfadel, “Securing decision\n     Conference on Information Sciences and Systems (CISS).  IEEE, 2021,          tree inference using order-preserving cryptography,” in 2023 IEEE 5th\n     pp. 1–6.                                                                          International Conference on Artificial Intelligence Circuits and Systems\n[12] V. V. Patel, “Ziegler-nichols tuning method: Understanding the pid        (AICAS).  IEEE, 2023, pp. 1–5.\n      controller,” Resonance, vol. 25, no. 10, pp. 1385–1397, 2020.             [36] R. R. Karn, J. Knechtel, and O. Sinanoglu, “Code-based cryptography\n[13] K. I. Roumeliotis and N. D. Tselikas, “Chatgpt and open-ai models: A          for confidential inference on fpgas: An end-to-end methodology,” in 2024\n     preliminary review,” Future Internet, vol. 15, no. 6, p. 192, 2023.             25th International Symposium on Quality Electronic Design (ISQED).\n[14] W. S. Saba, “Stochastic llms do not understand language: towards        IEEE, 2024, pp. 1–8.\n     symbolic, explainable and ontologically based llms,” in International    [37] D. O’Loughlin, A. Coffey, F. Callaly, D. Lyons, and F. Morgan, “Xilinx\n     Conference on Conceptual Modeling.  Springer, 2023, pp. 3–19.              vivado high level synthesis: Case studies,” 2014.\n[15] H. Naveed, A. U. Khan, S. Qiu, M. Saqib, S. Anwar, M. Usman,   [38] R. Snider, “Chapter 6: Introduction to intel quartus prime,” in Advanced\n     N. Akhtar, N. Barnes, and A. Mian, “A comprehensive overview of         Digital System Design using SoC FPGAs: An Integrated Hardware/Soft-\n      large language models,” arXiv preprint arXiv:2307.06435, 2023.             ware Approach.  Springer, 2022, pp. 55–86.\n[16] M. A. K. Raiaan, M. S. H. Mukta, K. Fatema, N. M. Fahad, S. Sakib,\n    M. M. J. Mim, J. Ahmad, M. E. Ali, and S. Azam, “A review on large\n     language models: Architectures, applications, taxonomies, open issues\n     and challenges,” IEEE Access, 2024.\n[17] Z. Lin, S. Guan, W. Zhang, H. Zhang, Y. Li, and H. Zhang, “Towards\n     trustworthy llms: a review on debiasing and dehallucinating in large\n     language models,” Artificial Intelligence Review, vol. 57, no. 9, pp. 1–50,\n     2024.\n[18]  J. D. M.-W. C. Kenton and L. K. Toutanova, “Bert: Pre-training of deep\n      bidirectional transformers for language understanding,” in Proceedings\n      of naacL-HLT, vol. 1.  Minneapolis, Minnesota, 2019, p. 2.\n[19] A. Vaswani, “Attention is all you need,” Advances in Neural Information\n     Processing Systems, 2017.\n[20] R. Patil and V. Gudivada, “A review of current trends, techniques, and\n     challenges in large language models (llms),” Applied Sciences, vol. 14,\n     no. 5, p. 2074, 2024.\n[21] L. Song, Y. Chen, S. Yang, X. Ding, Y. Ge, Y.-C. Chen, and Y. Shan,\n    “Low-rank approximation for sparse attention in multi-modal llms,” in\n     Proceedings of the IEEE/CVF Conference on Computer Vision and\n     Pattern Recognition, 2024, pp. 13 763–13 773.\n[22] A. Y. Din, T. Karidi, L. Choshen, and M. Geva, “Jump to conclusions:\n      Short-cutting transformers with linear transformations,” arXiv preprint\n     arXiv:2303.09435, 2023.\n[23]  S. Sharma and R. Yadav, “Chat gpt–a technological remedy or challenge\n      for education system,” Global Journal of Enterprise Information System,\n      vol. 14, no. 4, pp. 46–51, 2022.\n[24]  S. K. Singh, S. Kumar, and P. S. Mehra, “Chat gpt & google bard ai: A\n      review,” in 2023 International Conference on IoT, Communication and\n     Automation Technology (ICICAT).  IEEE, 2023, pp. 1–6.\n[25]  J. Stratton, “An introduction to microsoft copilot,” in Copilot for Microsoft\n     365: Harness the Power of Generative AI in the Microsoft Apps You Use\n     Every Day.  Springer, 2024, pp. 19–35.",
"headers": [
"Linear Feedback Control Systems for Iterative",
"Prompt Optimization in Large Language Models",
"arXiv:2501.11979v1  [cs.LG]  21 Jan 2025",
"+",
"-"
],
"tables": [],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2501.11979v1.pdf"
}