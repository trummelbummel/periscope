{
"text": "SIPDO: CLOSED-LOOP PROMPT OPTIMIZATION VIA\n          SYNTHETIC DATA FEEDBACK\n\n\n                     Yaoning Yu1∗Ye Yu1∗Peiyan Zhang2  Kai Wei3  Haojing Luo4 Haohan Wang1\n                         1University of Illinois at Urbana-Champaign 2Hong Kong University of Science and Technology\n                         3University of South Florida 4Starc.Institute\n\n\n                                       ABSTRACT\n\n                           Prompt quality plays a critical role in the performance of large language mod-\n                                    els (LLMs), motivating a growing body of work on prompt optimization. Most\n                                  existing methods optimize prompts over a fixed dataset, assuming static input2026                                   distributions and offering limited support for iterative improvement. We intro-\n                            duce SIPDO (Self-Improving Prompts through Data-Augmented Optimization),\n                              a closed-loop framework for prompt learning that integrates synthetic data gen-Jan                                  eration into the optimization process. SIPDO couples a synthetic data generator\n27                        withcurrenta promptpromptoptimizer,weaknesseswhereand thethe optimizergenerator incrementallyproduces new refinesexamplesthe thatpromptrevealin\n                                response. This feedback-driven loop enables systematic improvement of prompt\n                             performance without assuming access to external supervision or new tasks. Ex-\n                              periments across question answering and reasoning benchmarks show that SIPDO\n                              outperforms standard prompt tuning methods, highlighting the value of integrating\n                                data synthesis into prompt learning workflows.[cs.CL]\n\n                1  INTRODUCTION\n\n                     Large language models (LLMs) have demonstrated strong performance across a wide range of nat-\n                         ural language tasks, including classification, question answering, and reasoning. However, their\n                       output quality is highly sensitive to prompt design—small changes in phrasing, structure, or for-\n                      matting can lead to significant variations in performance (He et al., 2024; Spiess et al., 2025). This\n                          sensitivity has made prompt optimization a core challenge in adapting LLMs to downstream appli-\n                         cations, where consistency and reliability are crucial. In domains such as healthcare and finance, the\n                          inability to ensure stable, predictable performance makes prompt optimization more than a desirable\n                     enhancement, but a critical necessity for reliable system deployment.\n\n                   The core challenge of prompt optimization is multifaceted. Unlike traditional hyperparameter tun-\n                          ing, the search space of prompts is discrete, non-differentiable, and vast. Small modifications to\n                     prompts can have unpredictable effects on LLMs’ behavior, and the gradient-based methods that\n                         typically power optimization in machine learning are not directly applicable. Furthermore, LLMsarXiv:2505.19514v4                        often perform well on a fixed, curated test set, but their performance can deteriorate when faced\n                      with novel linguistic variations, edge cases, or adversarial queries. This makes prompt optimization\n                         particularly challenging, as a prompt that performs well in one scenario may fail when the input\n                         distribution shifts, leading to issues such as catastrophic forgetting or fragile performance across\n                          different contexts.\n\n                        Prior work in prompt optimization has explored manual tuning, discrete search, and gradient-based\n                    methods to improve model responses (Wang et al., 2023; Shin et al., 2020; Cui et al., 2024; Kwon\n                           et al., 2024; Zhang et al., 2024). While effective in some settings, these approaches do not address\n                        the dynamic nature of real-world inputs, where the input space evolves over time. As a result, they\n                     can produce prompts that perform well on average but lack robustness when the input distribution\n                      changes.\n\n                       In contrast, data augmentation has long been used in supervised learning to improve model robust-\n                       ness by exposing models to diverse training conditions (Mikołajczyk & Grochowski, 2018). In the\n\n                         ∗These authors contributed equally.\n\n\n                                                           1\n\ncontext of prompt learning, the ability of LLMs to generate high-quality synthetic data presents an\nexciting opportunity to improve prompt optimization. However, existing prompt optimization meth-\nods do not leverage synthetic data in a dynamic, feedback-driven manner (Singh et al., 2023; Gilardi\net al., 2023; Tang et al., 2023; Gao et al., 2023). Moreover, it is not sufficient to simply produce\nmore data; the challenge is to generate data that is purposeful and stressful that targets the current\nfailure modes of the prompt and provides a progressive challenge that helps guide its evolution.\nThe synthetic data must also be carefully crafted to ensure that it does not overwhelm the model\nwith trivially easy or overly difficult cases, but instead exposes latent weaknesses that need to be\naddressed.\n\nTo  address  these  challenges, we propose SIPDO (Self-Improving Prompts through Data-\nAugmented Optimization), a closed-loop framework for prompt optimization that integrates syn-\nthetic data generation directly into the learning process. SIPDO consists of two components: a Syn-\nthetic Data Generator that produces inputs specifically designed to challenge the current prompt,\nand a Prompt Optimizer that uses these examples to iteratively refine the prompt. This feedback\nloop enables the prompt to evolve continuously over time, adapting to new, previously unseen in-\nputs without requiring external supervision or the need to tune for each new scenario individually.\nParticularly, SIPDO addresses the unique challenges of prompt optimization by transforming the\noptimization process from a static, one-time procedure to a dynamic, self-adaptive learning loop.\nThis shift is critical for ensuring prompt robustness in the face of evolving input distributions.\n\nContributions. This paper makes the following contributions:\n\n• We introduce a feedback-driven framework SIPDO that integrates synthetic data generation into\n  prompt optimization, providing a novel pathway for improving prompt robustness.\n• We develop a method to construct synthetic examples that dynamically stress-test prompts, reveal-\n  ing failure modes and guiding refinement.\n• We empirically demonstrate that augmenting prompt optimization with synthetic data improves\n  performance across multiple reasoning benchmarks, surpassing existing prompt tuning methods.\n\n\n2  RELATED WORK\n\n2.1  AUTOMATIC PROMPT ENGINEERING\n\nAutomatically discovering optimal prompts has become a key challenge in the era of large language\nmodels (LLMs). Automatic Prompt Engineering (APE) employs optimization-based, generative,\nand template-driven approaches. Optimization techniques include gradient-based search (Shin et al.,\n2020), reinforcement learning (Ouyang et al., 2022; Kwon et al., 2024), and evolutionary algorithms\n(Cui et al., 2024).  Generative methods use models like GPT and Gemini to generate candidate\nprompts, with StablePrompt (Kwon et al., 2024) optimizing prompts via reinforcement learning.\nAdditionally, PromptAgent (Wang et al., 2023) breaks down prompt creation into sub-goals, while\ntemplate-driven approaches, like fill-in-the-blank formats, ensure clarity (Chen et al., 2024). Recent\nwork has expanded on automatic prompt optimization techniques. AutoPDL (Spiess et al., 2025)\nautomates the discovery of optimal configurations for agents which successive halving to explore\nthe space of agentic and non-agentic prompting patterns. The sequential optimal learning approach\nfor automated prompt engineering (Wang et al., 2025) uses Bayesian regression and Knowledge-\nGradient policies to efficiently identify effective prompt features. Progressively Automatic Prompt\nOptimization (Qu et al., 2025) introduces an evolution-based algorithm to optimize prompts for\nvisual classification tasks.\n\nAdopting LLM as a feedback loop to refine prompts has recently emerged. Self-Refine (Madaan\net al., 2023) improves the model by generating feedback based on the previously generated outputs\nand using that feedback to refine the next output. In Promptbreeder (Fernando et al., 2023), it uses\nan iterative feedback loop to select better prompts from the original prompts and mutation prompts,\nwhile Recursive In-Context Learning for Autonomous Prompt Generation in Large Language Mod-\nels: A Self-Instructed Approach (Yilar et al., 2024) introduces a framework that refines prompts\nthrough iterative loops based on generated outputs. More recently, SPO(Self-Supervised Prompt\nOptimization) (Xiang et al., 2025) uses iterative feedback to refine prompts by comparing the out-\nputs of the current prompt and its revised version without relying on ground truth, and DLPO (Peng\net al., 2025) optimizes prompts within loops by mimicking a deep learning style where it uses textual\n\n\n                                       2\n\nloss, gradients, and a feedback process to update prompts. CriSPO (He et al., 2025) also extends\niterative feedback loop optimization using critique guides to update prompts with multi-metric.\n\nWe propose a hybrid framework integrating LLM-driven rewriting with natural language feedback\n(Pryzant et al., 2023), alongside self-reflection (Shinn et al., 2024) and planning (Wang et al., 2023),\nenhancing prompt adaptability and precision.\n\n\n2.2  DATA SYNTHESIS\n\nUsing large language models (LLMs) for data synthesis is a relatively new and rapidly evolving\napproach. Recent advancements have shown that LLMs possess the capability to generate text with\nfluency and quality comparable to human output (Li et al., 2023; Mukherjee et al., 2023; Eldan &\nLi, 2023). For instance, prior work (Gao et al., 2023) has explored leveraging pre-trained language\nmodels (PLMs) to generate task-specific text data that can be used to train and evaluate. Recent\nwork Magpie (Xu et al., 2024) leverages the auto-regressive nature of aligned LLMs to generate\nhigh-quality instruction data. Additionally, Synthetic Text Generation for Training Large Language\nModels via Gradient Matching (Nguyen et al., 2025) proposes a novel approach to generate synthetic\ntext that matches the gradients of human data. However, these studies have not fully incorporated\nadvanced methodologies such as chain-of-thought (CoT) reasoning, in-context learning, or data\nsynthesis driven by prompts that integrate task descriptions and label information.\n\nIn this study, we systematically experimented with a range of techniques, including in-context learn-\ning and prompt-driven data synthesis, combining task descriptions and label information. Our results\nshow that these approaches generate high-quality synthetic data. By introducing a difficulty tier, we\nfurther enhanced the data’s robustness and applicability. These findings demonstrate the potential of\ncombining advanced LLM capabilities with tailored prompting strategies to improve data synthesis\nfor prompt optimization.\n\n\n3  METHOD\n\n\nIn this work, we introduce SIPDO, a two-agent system for optimizing prompts using data augmenta-\ntion techniques. The workflow has two cooperating agents: (i) Data Generator creates synthetic data\nwith increasing difficulty levels to expose weaknesses in the prompt, and (ii) Auto Prompt Optimizer\niteratively analyzes errors and rewrites the prompt to maximize task performance. An overview of\nSIPDO is shown in Fig 1.\n\nNotation. We define the true data distribution as S, which governs input-label pairs (x, y) ∈X ×\nY. Let N denote the size of an i.i.d. dataset drawn from S, denoted as {(xi, yi)}Ni=1 ∼S. We\nconsider LLMs equipped with a prompt p ∈P, and define its output function as f(p, x) ∈Y.\nPrediction accuracy is measured using a bounded surrogate loss L f(p, x), y  , where L ∈[0, 1].\nWe introduce a synthetic data generator defined by a distribution qψ(˜x, ˜y), parameterized by ψ ∈Ψ,\nwhich produces synthetic samples forming a dataset D = {(˜xi, ˜yi)}Mi=1, where M is the number of\ngenerated examples. To ensure that the synthetic labels remain realistic, we estimate the population\nlabel prior with p∗(y) and use this to regularize the generator.\n\n\n3.1  DATA GENERATOR\n\nThe Data Generator supplies fresh, well-targeted examples that expose the weakness by creating a\nnew synthetic-pair whose difficulty is designed beyond prompt’s current reach.\nSampling rule. The data generator first draws a target label ˜y ∼p∗(y). By sampling a latent variable\nz ∼gϕ(z|S) that captures the structure of few-shot S, the decoder qψ produces ˜x = qψ(z, ˜y, c)\nwhere c is a controlled difficulty tier.\n\nLearning objective. The parameters ψ are learned by minimizing a hybrid objective that balances\nthe KL penalty and the bounded surrogate loss:\n\n                    min R(ψ) + λ E(˜x,˜y)∼qψ L f(p, ˜x), y   ,                          (1)\n                      ψ\n\n\n                                       3\n\nFigure 1:  Starting from true data distribution S, the Data Generator(left) produces a synthetic\nquestion-answer pair at difficulty level c. The Auto Prompt Optimizer(right) evaluates the cur-\nrent prompt on this synthetic data via three sub-modules-error analysis, recommendation, and\nrefinement-and outputs a revised prompt. The revised prompt is tested on present failures and all\npreviously solved examples. If the prompt still makes errors, then return to the Auto Prompt Opti-\nmizer for further refinement; if passes, move on to the next sample(with higher c). The cycle repeats\nuntil no error remains or the budget is reached, yielding a self-improved prompt.\n\n\nNote that, we penalize deviations from the true label distribution using the Kullback–Leibler diver-\ngence term R(ψ) = KL qψ(y) ∥p∗(y)  , scaled by a factor λ−1R(ψ) during training.\n\nProgressive difficulty. To address tasks of varying difficulty, we introduces a progressive difficulty\nparameter c where c ∈{1, ..., n} so that prompts could be tested on gradually more challenging\nexamples. This allows the prompts to progressively improve and generalize effectively across task\nof increasing difficulty. Since qψ is conditioned on c, a single latent template (z, y) can therefore\nyield n difficulty-aligned variants\n                            {˜x(1), · · · , ˜x(n)} = {qψ(z, y, 1), · · · , qψ(z, y, n)}\n\nFor curriculum generation, an ordered sequence c1 < · · · < cn is sampled and feeds the output of\nthe previous level back into the generator,\n        ˜x(1) = qψ z, y, c1  , ˜x(2) = qψ hϕ x(1)  , y, c2  , . . . , ˜x(n) = qψ hϕ x(n−1)  , y, cn  ,\nwhere hϕ is a summarizer that distills the previous sample into a new latent cue, allowing semantic\ndepth to accumulate across levels. The sequence c1 < c2 < · · · < cn guarantees monotone growth\nof problem difficulty, providing a rich gradient of difficulty for the prompt to learn from.\n\n3.2  AUTO PROMPT OPTIMIZER\n\nAfter each new synthetic instance is calibrated, the Auto Prompt Optimizer probes the current\nprompt, identifies the weaknesses, and repairs them before the next instance is drawn. This stage\nbuilds a prompt that is both robust, suitable, and generalizable for specific tasks.\n\nAccuracy score. At iteration t ∈{1, . . . , M}, the optimizer improves the current prompt p(t) using\nthe feedback collected from synthetic log Dt = {(˜xj, ˜yj)}tj=1 ⊆X × Y. For any prompt p and set\nA ⊆X × Y, we define\n\n                                  1\n                         sA(p) =  X  I f(p, ˜x) = ˜y ,                            (2)\n                                     |A|\n                                                        (˜x,˜y)∈A\nI[·] is the indicator function that evaluates to 1 if the prompt’s output matches the target label, and 0\notherwise.\nStep 1: Error analysis. We first evaluate p(t) on the whole set and collect the current error slice\n                               E(t) =    (˜x, ˜y)∈D  f(p(t), ˜x) ̸= ˜y  .                            (3)\nIf E(t) = ∅, the prompt already “covers” all unseen cases, therefore, we terminate and return\np∗= p(t); otherwise, we proceed to the next step.\n\nStep 2:   Recommendation.  A  reflection module Rφ  inspects  E(t),   (˜x, ˜y),  p(t),  and\nf(p(t), ˜x) and produces a  textual-patch  suggesting how  to modify  the prompt:  ∆(t) =\n\n\n                                       4\n\nRφ p(t), E(t), (˜x, ˜y), f(p(t), ˜x)  . This summarizes why the prompt failed and how  it can be\namended(e.g., clarify/revise instructions, drop distracting details).\n\nStep 3: Targeted refinement. A prompt editor Uθ applies the patch ∆(t) to a revised prompt ˜p(t) in\norder to fix the current error: ˜p(t) = Uθ ∆(t), p(t), E(t)  .\n\nLocal confirmation. We then test revised prompt ˜p(t) only on the current errors: if sE(t)(˜p(t)) < 1,\nsome errors still remain. In this case, we make the revised prompt as new baseline prompt by setting\np(t) ←˜p(t), updating E(t), and repeating Step 2 to generate more sufficient patch ∆(t); otherwise,\nproceed to global confirmation.\n\nGlobal confirmation. Solving the local error slice is not enough-we must ensure that revised prompt\n“covers” all seen cases. Therefore, we evaluate ˜p(t) on the entire synthetic history collected seen so\nfar by sDt ˜p(t)  . During evaluation, if E(t) ̸= ∅at any previous data, we treat them as new error\nset and sent them back to step 2 with new E(t) to fix the current error. If E(t) = ∅, we accept the\nrevision, set p(t+1) = ˜p(t), draw the next synthetic example, and restart from Step 1 until t = M.\n\nConvergence guarantee. Because sD(p(t)) is non-decreasing and bounded above by 1, the pro-\ncess stops at most M successful corrections or the user-chosen cap Tmax.  The final output\np∗ =  arg max0≤t≤T sD p(t)  achieves perfect coverage (sDT (p∗) = 1) whenever it is attain-\nable within the budget.\n\nBy iteratively applying this feedback-driven process, it systematically refines prompts to improve\nclarity, adaptability, and overall performance, making the framework highly generalizable across\ntasks and domains.\n\n\n3.3  THEORETICAL GUARANTEE\n\nSince one of our goals in SIPDO is to demonstrate that, data augmentation, a popular branch of\nperformance improvement in deep learning, can also be used in prompt optimization context, we\naim to offer similiar performance guarantees as done in previous data augmentation literature (Wang\net al., 2022; Chen et al., 2020; Dao et al., 2019).\n\nAssumptions. We first offer the assumptions that we need for the theoretical guarantees.\n\nA1 (Label-preservation) For all ψ ∈Ψ and for any (x, y), the generator’s conditional satisfies\nPrqψ[˜y = y | ˜x g←(x, y)] = 1.\nWe require the generator never flips the ground-truth label of the base example it is derived from\n(it may, however, hallucinate novel inputs as long as their labels match the intended classes). In\npractice, because LLMs sometimes assign unexpected labels, we first generate the label ˜y and then\nsample ˜x conditioned on that label. For tasks and domains where producing valid synthetic data is\ndifficult, we apply a three-voter check: three expert agents independently verify each generated item\nfor label–input consistency and basic factual correctness.\nA2 (Approximate maximizer). Let ψ⋆ =  arg maxψ∈Ψ EqψL(f(p, ˜x), ˜y) −λ−1R(ψ), The\ninner-loop training of the generator attains a value at most ε below this supremum.\nA perfect maximizer would be ideal but is infeasible; we only need the learned generator to be good\nenough—within ε of optimal. The residual ε directly appears in the bound.\n\nA3 (Uniform convergence). (Wang et al., 2022) For every prompt p, the empirical loss deviates\nfrom its population counterpart by at most q(|P|, n, δ) with probability 1 −δ., where a standard\n           q log |P|+log(1/δ)\nform of q(|P|, n, δ) is ˜O       N             .\nPAC(probably approximately correct) guarantee: empirical performance generalizes provided n is\nlarge enough.\n\nA4 (Alignment of risks). For any prompt p and generator ψ,\n\n                   EqψL(f(p, ˜x), ˜y) ≤ESL(f(p, x), y) + λ−1R(ψ).\n\nThe KL penalty controls how far the generator may wander: if it manufactures rare-label outliers,\nR(ψ) increases and the bound tightens. We can verify that qψ(y) is always absolutely-continuous\n\n\n                                       5\n\n1st       2nd       3rd         Final Result\n MMLU Subject           Method\n                                                   iteration    iteration    iteration   (Comparative Acc.)\n\n                           TextGrad       85       88       86          89(↓4.0)\n                          M-TextGrad     85       87       87          89(↓4.0)\n  College Computer Science\n                    REVOLVE      85       88       89          90(↓3.0)\n                     SIPDO         –        –        –            93\n\n                           TextGrad        84.8       87.5       82.1        88.4(↓5.4)\n                          M-TextGrad     85.5       85.4       85.3        85.0(↓8.8)\n Machine Learning       REVOLVE      85.7       86.6       85.7        88.4(↓5.4)\n                  ANN           –        –        –          90.1(↓3.7)\n                     SIPDO         –        –        –             93.8\n\n                           TextGrad        95.1       97.2       95.1        96.5(↓0.0)\n  College Biology        REVOLVE      96.5       96.1       97.2        96.5(↓0.0)\n                     SIPDO         –        –        –             96.5\n\n\nTable 1: Results on MMLU Machine Learning, College Computer Science, and College Biology\nsubject by GPT-4o, demonstrating SIPDO’s effectiveness on different subjects\n\n\nw.r.t.  p∗(y); KL is then finite and the inequality follows from the classical Donsker–Varadhan\nvariational formula.\nA5 (Surrogate link). The 0–1 loss is upper-bounded by the surrogate loss: 1{f(p, x) ̸= y} ≤\nL(f(p, x), y).\nThis is needed in order to translate guarantees on the differentiable training loss to the classification\nerror(e.g. cross-entropy, hinge, logistic).\n\nTheorem 3.1 Regularised Worst-case Data Generation.  Under Assumptions A1-A5, for any\nfixed prompt p ∈P, with probability at least 1 −δ over the draw of the training set, we have\n\n                            n\n  sup Eqψ1{f(p, ˜x) ̸= ˜y} ≤ n1 X L f(p, xi), yi  + λ−1R(ψ⋆)  + ε + q |P|, n, δ  .  (2)\n ψ∈Ψ\n                               i=1                    |KL penalty{z   of}\n  |          population{z         }    |       empirical{z  risk    }        hardest generator\n           worst-case error\n\nPractical implication. The inequality states that if the empirical loss of the prompt is low, and no\ngenerator can inflate that loss without paying a high KL tax, then even a hypothetically all-powerful\nadversary (generator) cannot cause the prompt to misclassify more than the RHS. Selecting a larger λ\ntightens the KL tax, thus lowering the worst-case error but potentially harming accuracy—precisely\nthe robustness–performance trade-off observed empirically in Experiments Section 4. In addition,\ndetailed proof of theorem can be found in Appendix F.\n\n4  EXPERIMENTS\n\n4.1  EXPERIMENTAL SETUP\n\nWe use following baseline methods are for comparison across the different datasets and benchmarks:\nChain of Thought (CoT) (Suzgun et al., 2022) guides models through explicit step-by-step reason-\ning; Automatic Prompt Engineer (APE) (Wang et al., 2023) refines prompts via Monte Carlo search\nand model feedback; PromptAgent (Zhou et al., 2022) also uses Monte Carlo Tree Search to iter-\natively improve prompts; Neuro-Symbolic (Pan et al., 2023) converts LLM outputs into structured\nforms for rule-based inference; TextGrad (Yuksekgonul et al., 2024) treats textual feedback as a\nfirst-order gradient for prompt updates; Momentum-Enhanced TextGrad (Yuksekgonul et al., 2024)\nadds momentum, enlarging updates when feedback aligns; REVOLVE (Zhang et al., 2024) adjusts\nprompts using the trajectory of model responses as a second-order-style signal; and ANN (Ma et al.,\n2025) models agent collaboration as a layered neural network.\n\nWe test SIPDO on five main datasets across reasoning tasks:\n\n\n                                       6\n\nBIG-Bench. We include all 4689 instances from six BIG-Bench tasks: Penguins In a Table, Geo-\nmetric Shapes, Epistemic Reasoning, Object Counting, Temporal Sequences, and Causal Judgment\n(Srivastava et al., 2022). For these tasks, SIPDO is compared to Chain of Thought (CoT) (Suzgun\net al., 2022), Automatic Prompt Engineer (APE) (Wang et al., 2023), and PromptAgent (Zhou et al.,\n2022).\n\nLogical Reasoning Tasks. To assess logical reasoning, we sample 600 examples from the depth-5\nsubset of ProofWriter with a balanced label distribution (Tafjord et al., 2021), use 204 test examples\nfrom FOLIO that require first-order inference over short passages (Han et al., 2024), and select the\n500 most challenging 5-hop scenarios from the fictional-character version of PrOntoQA (Saparov\n& He, 2022). For these tasks, SIPDO is compared to Chain of Thought (CoT) (Suzgun et al., 2022),\nNeuro-Symbolic (Pan et al., 2023), and REVOLVE (Zhang et al., 2024).\n\nMMLU (Massive Multitask Language Understanding). To test expert-level factual knowledge\nand problem solving in LLMs, we evaluate on MMLU (Hendrycks et al., 2020), focusing on college-\nlevel subject areas: Biology (114 instances), Computer Science (100 instances), and Machine Learn-\ning (112 instances). For this benchmark, SIPDO is compared with TextGrad (Yuksekgonul et al.,\n2024), REVOLVE (Zhang et al., 2024), and ANN (Ma et al., 2025).\n\n\n4.2  IMPLEMENTATION\n\nData Generation and Prompt Improvements. We specify a maximum level c and data generated\nwith level of difficulties in prior iterations so that model is aware of the difficulty level of each\nprevious example. To illustrate this, we provide a detailed example of generating a Causal Judgment\nQA pair from BIG-Bench below.\n\n  Causal Judgment Prompt Template\n\n  [System Input]:\n\n  You are an expert in generating logical causal-attribute questions and answers. Your task is to generate\n  one pair of causal attributions or causation. One is a causation statement, and another is a non-causation\n  statement.\n\n  [User Input]:\n\n  Guidelines:\n   1. Make sure that the data generated is different.\n   2. Use clear and direct words in the question, avoiding overly complex phrasing, trickiness, or ambiguity.\n   3. Do not make the logic in the statement overly complicated; the statement and question should be\n      understood at a fair level.\n   4. Be creative and diverse. Only follow the logic and flow of the given examples, but be creative and\n      diverse with the content and not limited to the given example.\n   5. Only one data instance needs to be generated each time.\n   6. Generate only one output: the generated content should strictly follow the output format from the\n     examples below.\n   7. Difficulty should increase with each iteration with total difficulty level: {max difficulty level} (current\n       difficulty level: {c}).\n   8. Make sure the generated data is sufficient and robust without any errors, especially logic.\n   9. The generated samples are suppose to challenge the model’s ability to reason and answer the question\n       correctly.\n\n  Past generated samples: {Generated data with difficulty}\n\n  Below are the Examples with expected data format:\n  {True Data 1}\n  {True Data 2}\n\n\nWe set the difficulty budget at c = 10 for all benchmarks except Penguins In a Table and Geomet-\nric Shapes from BIG-Bench, where c = 25 accommodates their complex reasoning. The number\nof training iterations is tied to the difficulty level, with t = c to ensure progressively harder sam-\nples. The model temperature is set to 0.5 for data generation to maintain coherence. We fix the\n\n\n                                       7\n\nAccuracy (%)                              Avg. Acc. (%)\n     Model         Method                                                                   (Comparative Acc.)\n                                    Penguins   Geome.   Epistemic   Obj. Count   Temporal   Causal\n\n                   CoT           79.8       79.1       79.3         85.2        98.0       67.8        81.5(↓7.6)\n                 APE           84.8       65.3       84.8         86.0        99.2       74.0        82.4(↓6.7)\n     GPT-4o\n                   PromptAgent       96.1       83.0       91.6         88.2        98.4       77.8        89.2(↑0.1)\n                 SIPDO         96.4       82.2       86.3         91.1        99.3       79.0           89.1\n\n                   CoT           75.8       68.6       85.2         81.5        94.9       63.6        78.3(↓9.0)\n                 APE           83.7       44.5       81.6         86.3        97.2       75.6        78.2(↓9.1)\n   GPT-4o-mini\n                   PromptAgent       89.8       72.0       86.0         84.3        94.6       84.6        85.2(↓2.1)\n                 SIPDO         92.1       73.2       85.1         87.5        98.0       88.0           87.3\n\n                   CoT           70.4       68.3       85.5         90.1        94.0       66.8        79.2(↓3.7)\n                 APE           37.6       49.4       88.8         84.7        99.4       69.4       71.6(↓11.3)\n  Gemini-1.5-flash\n                   PromptAgent       67.4       70.3       81.6         86.3        94.2       67.9        78.0(↓4.9)\n                 SIPDO         77.3       68.9       87.0         92.3        98.4       73.2           82.9\n\n                   CoT           81.8       59.1       82.6         92.8        98.9       61.5        79.5(↓3.9)\n                 APE           40.2       56.6       88.7         78.6        86.0       65.7       69.3(↓14.1)\n  Gemini-1.5-pro\n                   PromptAgent       73.6       58.3       83.8         72.6        98.4       74.2        76.8(↓6.6)\n                 SIPDO         79.3       64.3       89.3         91.3        98.0       78.3           83.4\n\n\nTable 2: Results on BIG-Bench tasks across multiple LLMs. SIPDO consistently outperforms stan-\ndard prompting baselines (CoT, APE, PromptAgent) across most tasks and models, demonstrating\ngeneralization and effectiveness of the prompt optimization by synthetic data feedback.\n\n\ntarget label ˜y and prompt the model to generate a matching question for data validity. For chal-\nlenging MMLU benchmarks, three expert agents review each generated item, and only those with\nunanimous approval are passed to the auto-prompter. This minimizes hallucinations and ensures ac-\ncurate question–answer pairs. Examples of synthetic BIG-Bench Causal Judgment data at different\ndifficulty levels are shown in Appendix E.\n\nFor further prompt optimization, we set the model temperature to 0.0 during error analysis and im-\nprovement steps to ensure deterministic, high-quality outputs. However, we use a higher temperature\nof 0.7 for generating recommendations, which encourages the model to produce more diverse and\ncreative suggestions. This combination stabilizes the error analysis and prompt improvement phases\nwhile simultaneously enhancing the breadth and quality of recommendations. The full prompt-\nimprovement process for BIG-Bench Penguins In a Table is in Appendix D.\n\nGeometric Data Generation. Constructing complex or irregular shapes exceeds the limits of few-\nshot methods, so we introduce three safeguards for SVG path generation in the geometry task: (1)\nprecision normalization—each coordinate is rounded to two decimal places, preventing floating-\npoint drift that makes downstream parsers miscount line (L) and arc (A) commands; (2) template-\nguided retrieval—a retriever selects an SVG path template whose instruction pattern matches the\ntarget shape (e.g., “4 L” for a rectangle, “1 A” for a sector), and the generator perturbs only\nthe vertex coordinates, ensuring syntactic correctness while adding variety; (3) reverse-generation\ncheck—because the shape label is known in advance, a rule-based decoder parses the generated path,\ntallies L/A commands, and rejects any sample whose inferred label disagrees. Examples appear in\nAppendix E.\n\n\n4.3  RESULTS AND ANALYSIS\n\nWe tested SIPDO across various LLMs with temperature of 0.0 on all benchmarks, including BIG-\nBench, FOLIO, PrOntoQA, ProofWriter, and three subjects from MMLU. Specifically, we ran\nSIPDO on GPT-4o, GPT-4o-mini, Gemini-1.5-flash, and Gemini-1.5-pro, so that all synthetic-data\ncalls and prompt refinements in result were driven by the same model.\n\nMMLU. We first evaluate SIPDO on three subjects from the MMLU benchmark: Machine Learning,\nCollege Biology, and College Computer Science. As shown in Table 1, SIPDO achieves the highest\nresults in all three subjects, while TextGrad and REVOLVE tie in the Biology subject. Specifically,\nwe set up the SIPDO pipeline using the GPT-4o model, except for the GPT-4o-mini during the\ntesting phase, in order to provide greater insight into the reasoning weaknesses of LLMs.\n\nBIG-Bench. We then evaluate SIPDO on six BIG-Bench tasks As shown in Table 2, GPT-4o, GPT-\n4o-mini, and Gemini-1.5-flash demonstrate particularly strong performance in Temporal Reason-\n\n\n                                       8\n\nGPT-4o                                       GPT-4o-mini\n Tasks         Vanilla   Neuro-S  CoT  REVOLVE   SIPDO     Baseline   Neuro-S  CoT  REVOLVE   SIPDO\n\n  ProofWriter    58.5      81.6     72.3      54.0         79.6        52.6       79.7     61.8      48.6         79.3\n FOLIO         71.2      79.2     72.6      65.7      83.2(↑4.0)     51.2       73.2     69.3      62.8      81.1(↑7.9)\n PrOntoQA      80.4      85.2     95.6      85.4      96.3(↑0.7)     74.6       79.3     89.3      83.4      91.3(↑2.0)\n\n Average        70.0      82.0     80.2      68.4      86.4(↑4.2)     59.5       77.4     73.5      64.9      83.9(↑6.5)\n\n\nTable 3: Performance(%) on ProofWriter, FOLIO, and PrOntoQA by Neuro-Symbolic, CoT, RE-\nVOLVE, SIPDO, and Baseline Prompting methods across GPT-4o and GPT-4o-mini.\n\n\n  Model    PENGUINS   GEOME.   EPISTEMIC  OBJ.CNT.  TEMPORAL  CAUSAL       Avg.\n\n                 73.2         68.1         81.9         53.8         97.0         68.4         73.7\n  GPT-4o\n            (↓24.1%)   (↓17.2%)   (↓5.1%)   (↓40.9%)   (↓2.3%)   (↓13.4%)   (↓17.3%)\n GPT-4o-       69.6         47.5         80.0         39.9         92.1         67.4         66.1\n   mini      (↓24.4%)   (↓35.1%)   (↓6.0%)   (↓54.4%)   (↓6.0%)   (↓23.4%)   (↓24.3%)\n\n\nTable 4: Accuracy (%) after removing the difficulty gradient. Numbers in parentheses show the\nabsolute drop (↓) relative to the performance with difficulty gradient placed.\n\n\ning, Object Counting, Penguins In a Table, and Causal Judgment. While Geometric Shapes exhibits\ncomparable accuracy across GPT-4o and GPT-4o-mini, SIPDO achieves the highest overall accuracy\nacross all LLMs except for GPT-4o, trailing PromptAgent by only 0.1%, yet still demonstrating that\nLLMs benefit from synthetic data generation for reasoning improvements, whereas other methods\nprimarily rely on existing datasets. To further illustrate the generated different difficulty data in\nCausal Judgment tasks as iteration and difficulty increase, the actual logical turns display a mono-\ntonic trend in figure 2.\n\nFOLIO, PrOntoQA, and ProofWriter. We further test\nSIPDO on FOLIO, PrOntoQA, and ProofWriter, assess-\ning the methods’ ability to perform structured logical\nreasoning.  As shown in Table 3, SIPDO outperforms\nall approaches on FOLIO and PrOntoQA and achieves\nthe highest average accuracy.   In PrOntoQA, SIPDO\nsurpasses all methods, demonstrating  its capability to\ngenerate structured logical proofs.  Similarly, for FO-\nLIO, SIPDO outperforms Neuro-Symbolic, CoT, and RE-\nVOLVE, further validating  its effectiveness in formal\nlogic inference.\n\nWhile neuro-symbolic reasoning remains the best per-\nformer on ProofWriter, SIPDO achieves highly compet-\n                                                       Figure 2: Generated BIG-Bench Causalitive results on ProofWriter, trailing by only 0.4% on\n                                                 Judgment task in different difficultiesGPT-4o-mini and 2% on GPT-4o, underscoring its strong\nadaptability to structured reasoning tasks. Crucially, un-\nlike neuro-symbolic approaches that rely on predefined\nrule-based datasets, SIPDO is trained entirely on generated synthetic data, demonstrating the effec-\ntiveness of LLM-driven data augmentation for enhancing logical inference across diverse reasoning\nbenchmarks. SIPDO outputs a revised prompt that surpasses baselines, validating its effectiveness\nfor prompt design and performance gains. All generated prompts appear in Appendix B.\n\n\n4.4  ABLATION STUDY\n\nDifficulty Gradient. To assess the contribution of the difficulty gradient, we conduct an ablation\nstudy by comparing without difficulty level. As Table 4 shows, every BIG-Bench sub-task suffers\nwhen the difficulty gradient is absent. On average, GPT-4o loses 17.3% accuracy, while the weaker\nGPT-4o-mini drops 24.3%, confirming that smaller models depends even more on the difficulty\ngradient. The steepest declines appear on tasks Object Counting (40.9 % and 54.4 %) and Geometric\nShapes (17.2 % and 35.1 %). Even comparatively simple tasks—Temporal Sequences and Epistemic\n\n\n                                       9\n\nReasoning—still lose up to 6 %. These results indicate that within the OpenAI model family, the\nweaker model is more sensitive to the absence of a difficulty gradient and the benefit of a progressive\ndifficulty schedule becomes more pronounced. Without this gradient, generated prompts tend to be\nshorter and easier, often failing to capture complex reasoning patterns (details in Appendix C).\n\nOne-Shot Extremes. We experimented with replacing the step-wise difficulty gradient by a one-\nshot extremes sampler that tells the generator to create the most unusual examples. On our synthetic\nsuites this shortcut delivered no measurable gain. The “extreme” samples were either solved in-\nstantly or only slight perturbations of original cases, leaving the optimizer with no fresh errors to\nexploit. We suspect the idea will pay off in real-world corpora (e.g.  financial statements) where\ngenuine edge cases abound and can expose blind spots that our synthetic tasks do not capture.\n\n5  CONCLUSION\n\nWe presented SIPDO, a data-centric framework that converts augmentation into a live feedback sig-\nnal for prompt optimization. A generator creates progressively harder examples, and an auto-prompt\noptimizer uses them to expose and correct prompt weaknesses. This coupling produces consistent\naccuracy gains across diverse reasoning benchmarks, outperforming several leading baselines. Be-\nyond these empirical results, SIPDO shows how data-generation strategies and prompt optimization\ncan reinforce one another, linking ideas from curriculum learning and adaptive optimization with\nLLM practice. Further investigation on domain specific corpora such as financial filings and clini-\ncal notes and exploration of fully automated variants that refine prompts through continuous model\nfeedback will clarify SIPDO’s broader value and extend its principles to new settings.\n\nREFERENCES\n\nShuxiao Chen, Edgar Dobriban, and Jane H Lee. A group-theoretic framework for data augmenta-\n   tion, 2020. URL https://arxiv.org/abs/1907.10905.\n\nYongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang, Nicholas Roy, and Chuchu Fan. Prompt opti-\n  mization in multi-step tasks (promst): Integrating human feedback and heuristic-based sampling,\n  2024. URL https://arxiv.org/abs/2402.08702.\n\nWendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun, Damien Lopez, Kamalika Das, Bradley Malin, and\n  Sricharan Kumar. Phaseevo: Towards unified in-context prompt optimization for large language\n  models. arXiv preprint arXiv:2402.11347, 2024.\n\nTri Dao, Albert Gu, Alexander J. Ratner, Virginia Smith, Christopher De Sa, and Christopher R´e. A\n  kernel theory of modern data augmentation, 2019. URL https://arxiv.org/abs/1803.\n  06084.\n\nRonen Eldan and Yuanzhi Li.  Tinystories: How small can language models be and still speak\n  coherent english?, 2023. URL https://arxiv.org/abs/2305.07759.\n\nChrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt¨aschel.\n  Promptbreeder:   Self-referential self-improvement  via prompt  evolution.    arXiv  preprint\n  arXiv:2309.16797, 2023.\n\nJiahui Gao, Renjie Pi, Yong Lin, Hang Xu, Jiacheng Ye, Zhiyong Wu, Weizhong Zhang, Xiaodan\n  Liang, Zhenguo Li, and Lingpeng Kong. Self-guided noise-free data generation for efficient zero-\n  shot learning, 2023. URL https://arxiv.org/abs/2205.12679.\n\nFabrizio Gilardi, Meysam Alizadeh, and Ma¨el Kubli. Chatgpt outperforms crowd workers for text-\n  annotation tasks. Proceedings of the National Academy of Sciences, 120(30):e2305016120, 2023.\n\nSimeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Wenfei Zhou, James\n  Coady, David Peng, Yujie Qiao, Luke Benson, Lucy Sun, Alex Wardle-Solano, Hannah Szabo,\n  Ekaterina Zubova, Matthew Burtell, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, An-\n  song Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Alexander R. Fabbri, Wojciech Kryscin-\n   ski, Semih Yavuz, Ye Liu, Xi Victoria Lin, Shafiq Joty, Yingbo Zhou, Caiming Xiong, Rex Ying,\n  Arman Cohan, and Dragomir Radev.  Folio: Natural language reasoning with first-order logic,\n  2024. URL https://arxiv.org/abs/2209.00840.\n\n\n                                       10\n\nHan He, Qianchu Liu, Lei Xu, Chaitanya Shivade, Yi Zhang, Sundararajan Srinivasan, and Katrin\n  Kirchhoff.  Crispo: Multi-aspect critique-suggestion-guided automatic prompt optimization for\n   text generation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pp.\n  24014–24022, 2025.\n\nJia He, Mukund Rungta, David Koleczek, Arshdeep Sekhon, Franklin X Wang, and Sadid Hasan.\n  Does prompt formatting have any impact on llm performance?, 2024. URL https://arxiv.\n  org/abs/2411.10541.\n\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and\n  Jacob Steinhardt.   Measuring massive multitask language understanding.   arXiv preprint\n  arXiv:2009.03300, 2020.\n\nMinchan Kwon, Gaeun Kim, Jongsuk Kim, Haeil Lee, and Junmo Kim.  Stableprompt: Auto-\n  matic prompt tuning using reinforcement learning for large language models.  arXiv preprint\n  arXiv:2410.07652, 2024.\n\nYifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. Making\n  language models better reasoners with step-aware verifier.  In Proceedings of the 61st Annual\n  Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 5315–\n  5333, 2023.\n\nXiaowen Ma, Chenyang Lin, Yao Zhang, Volker Tresp, and Yunpu Ma. Agentic neural networks:\n  Self-evolving multi-agent systems via textual backpropagation. arXiv preprint arXiv:2506.09046,\n  2025.\n\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri\n  Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al.  Self-refine: Iterative refinement\n  with self-feedback. Advances in Neural Information Processing Systems, 36:46534–46594, 2023.\n\nAgnieszka Mikołajczyk and Michał Grochowski. Data augmentation for improving deep learning in\n  image classification problem. In 2018 international interdisciplinary PhD workshop (IIPhDW),\n  pp. 117–122. IEEE, 2018.\n\nSubhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and\n  Ahmed Awadallah. Orca: Progressive learning from complex explanation traces of gpt-4. arXiv\n  preprint arXiv:2306.02707, 2023.\n\nDang Nguyen, Zeman Li, Mohammadhossein Bateni, Vahab Mirrokni, Meisam Razaviyayn, and\n  Baharan Mirzasoleiman. Synthetic text generation for training large language models via gradient\n  matching, 2025. URL https://arxiv.org/abs/2502.17607.\n\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\n  Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.  Training language models to fol-\n  low instructions with human feedback. Advances in neural information processing systems, 35:\n  27730–27744, 2022.\n\nLiangming Pan, Alon Albalak, Xinyi Wang, and William Yang Wang.  Logic-lm: Empower-\n  ing large language models with symbolic solvers for faithful logical reasoning. arXiv preprint\n  arXiv:2305.12295, 2023.\n\nDengyun Peng, Yuhang Zhou, Qiguang Chen, Jinhao Liu, Jingjing Chen, Libo Qin, and Wanxiang\n  Che. Dlpo: Towards a robust, efficient, and generalizable prompt optimization framework from a\n  deep-learning perspective. arXiv preprint arXiv:2503.13413, 2025.\n\nReid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng.  Automatic\n  prompt optimization with ”gradient descent” and beam search, 2023. URL https://arxiv.\n  org/abs/2305.03495.\n\nXiangyan Qu, Gaopeng Gou, Jiamin Zhuang, Jing Yu, Kun Song, Qihao Wang, Yili Li, and Gang\n  Xiong. Proapo: Progressively automatic prompt optimization for visual classification, 2025. URL\n  https://arxiv.org/abs/2502.19844.\n\n\n                                       11\n\nAbulhair Saparov and He He. Language models are greedy reasoners: A systematic formal analysis\n  of chain-of-thought. arXiv preprint arXiv:2210.01240, 2022.\n\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. Autoprompt:\n   Eliciting knowledge from language models with automatically generated prompts, 2020. URL\n  https://arxiv.org/abs/2010.15980.\n\nNoah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion:\n  Language agents with verbal reinforcement learning. Advances in Neural Information Processing\n  Systems, 36, 2024.\n\nAvi Singh, John D Co-Reyes, Rishabh Agarwal, Ankesh Anand, Piyush Patil, Xavier Garcia, Peter J\n  Liu, James Harrison, Jaehoon Lee, Kelvin Xu, et al. Beyond human data: Scaling self-training\n   for problem-solving with language models. arXiv preprint arXiv:2312.06585, 2023.\n\nClaudio Spiess, Mandana Vaziri, Louis Mandel, and Martin Hirzel. Autopdl: Automatic prompt\n  optimization for llm agents, 2025. URL https://arxiv.org/abs/2504.04365.\n\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam\n  Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri`a Garriga-Alonso, et al. Beyond the\n  imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint\n  arXiv:2206.04615, 2022.\n\nMirac Suzgun, Nathan Scales, Nathanael Sch¨arli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung,\n  Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-bench tasks\n  and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261, 2022.\n\nOyvind Tafjord, Bhavana Dalvi Mishra, and Peter Clark.  Proofwriter: Generating implications,\n  proofs, and abductive statements over natural language, 2021. URL https://arxiv.org/\n  abs/2012.13048.\n\nChangli Tang, Wenyi Yu, Guangzhi Sun, Xianzhao Chen, Tian Tan, Wei Li, Lu Lu, Zejun Ma,\n  and Chao Zhang. Salmonn: Towards generic hearing abilities for large language models. arXiv\n  preprint arXiv:2310.13289, 2023.\n\nHaohan Wang, Zeyi Huang, Xindi Wu, and Eric Xing. Toward learning robust and invariant repre-\n   sentations with alignment regularization and data augmentation. In Proceedings of the 28th ACM\n  SIGKDD Conference on Knowledge Discovery and Data Mining, pp. 1846–1856, 2022.\n\nShuyang Wang, Somayeh Moazeni, and Diego Klabjan. A sequential optimal learning approach to\n  automated prompt engineering in large language models, 2025. URL https://arxiv.org/\n  abs/2501.03508.\n\nXinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P\n  Xing, and Zhiting Hu. Promptagent: Strategic planning with language models enables expert-\n   level prompt optimization. arXiv preprint arXiv:2310.16427, 2023.\n\nJinyu Xiang,  Jiayi Zhang, Zhaoyang Yu, Fengwei Teng,  Jinhao Tu, Xinbing Liang,  Sirui\n  Hong, Chenglin Wu, and Yuyu Luo.  Self-supervised prompt optimization.  arXiv preprint\n  arXiv:2502.06855, 2025.\n\nZhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, and\n   Bill Yuchen Lin. Magpie: Alignment data synthesis from scratch by prompting aligned llms with\n  nothing, 2024. URL https://arxiv.org/abs/2406.08464.\n\nJonathan Yilar, Olivia Foster, and Benjamin Woods. Recursive in-context learning for autonomous\n  prompt generation in large language models: A self-instructed approach.  Authorea Preprints,\n  2024.\n\nMert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos Guestrin, and\n  James Zou.  Textgrad: Automatic” differentiation” via text. arXiv preprint arXiv:2406.07496,\n  2024.\n\n\n                                       12\n\nPeiyan Zhang, Haibo Jin, Leyang Hu, Xinnuo Li, Liying Kang, Man Luo, Yangqiu Song, and Hao-\n  han Wang. Revolve: Optimizing ai systems by tracking response evolution in textual optimization.\n  arXiv preprint arXiv:2412.03092, 2024.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan,\n  and Jimmy Ba.  Large language models are human-level prompt engineers.  arXiv preprint\n  arXiv:2211.01910, 2022.\n\n\n\n\n\n                                       13\n\nA  DETAILED ABLATION TABLE STUDIES\n\nIn this section, we provide more comprehensive and detailed ablation studies that demonstrate our\nstudies and findings.\n\n\n                                             GPT-4o-mini                               GPT-4o\n Task                 Difficulty\n                            Time (s)  Money ($)     Tokens   Acc. (%)   Time (s)  Money ($)    Tokens   Acc. (%)\n\n                  5            217.43      0.0130      67269       83.7     58.55      0.1089     35426       91.3\n                  10          1078.47      0.0929     527358      92.59    561.05      1.2100    410807      93.33\n Penguins\n                  15          2226.68      0.2174    1250646      92.59   2392.23      6.4528   2275582       96.0\n                  20         19753.99      2.6698   16695611      93.33   3452.01      7.8194   2759306      96.67\n\n                  5              49.07      0.0027      14297      75.33    119.28      0.1401     42985       78.0\n                  10           686.18      0.0420     227607       76.0    555.86      0.6814    224480       79.0\n  Epistemic\n                  15          1471.69      0.1149     640713      80.33   1440.52      2.0357    695678      83.67\n                  20          3279.38      0.2583    1483605       80.0   2885.80      4.0457   1418053       84.0\n\n                  5              51.70     0.00369      19079      35.33    106.06      0.0955     27548       50.0\n                  10           690.22     0.03237     144212      49.17    560.95      0.4726    133780      67.67\n Geometric\n                  15          1326.86     0.06710     296540      72.22    964.28      0.9158    268912       80.0\n                  20          2503.59     0.20610     571178      78.06   1334.71      1.4882    450575      87.78\n\n                  5            103.80      0.0064      35013      58.42    149.56      0.1611     52383      67.95\n                  10           899.33      0.0699     385346      66.66    156.22      0.2761    101715       81.6\n  causal judgement\n                  15          2066.64      0.2017    1152961      79.67    534.45      0.6921    237519      82.42\n                  20           443.71      0.0388     236561      67.89   3033.81      4.8447   1738332      79.49\n\n                  5              35.40      0.0016       7650       94.0     39.27      0.0283      7813      99.67\n                  10           147.00      0.0066      26538       97.5    647.34      0.8005    267894      99.33\n  temporal\n                  15          2166.98      0.1876    1039249      99.67   1432.08      2.1206    736935      99.33\n                  20          1518.23      0.1187     630972      99.64   2235.50      3.5084   1255135      99.66\n\n                  5            190.52      0.0122      60765       91.0    115.30      0.1660     49776       97.0\n                  10          1094.08      0.0684     363795       92.0    512.40      0.7296    232588       98.0\n  object counting\n                  15          2592.44      0.2069    1148406       96.0   1396.33      1.8831    624918      99.33\n                  20          5078.75      0.3968    2260081       96.0   2848.81      4.3167   1459739      99.33\n\n\nTable 5: SIPDO’s cost (time, money, tokens) and accuracy across tasks and difficulty levels for\nGPT-4o-mini and GPT-4o.\n\n\n\n Model        Method               Penguins                  Epistemic                Geometric                Temporal              Causal Judgment           Object Counting\n                         Run Time (s)   Acc. (%)  Run Time (s)   Acc. (%)  Run Time (s)   Acc. (%)  Run Time (s)   Acc. (%)  Run Time (s)   Acc. (%)  Run Time (s)   Acc. (%)\n GPT-4o       PromptAgentSIPDO             183002392       96.196.4        23675556       91.686.3        306391335       83.082.2        40399647       99.398.4        18232156       79.077.8        374531094       91.188.2\n GPT-4o-mini   PromptAgentSIPDO              93982227       89.892.1        24150686       86.085.1        460122504       72.073.2        48561147       98.094.6        15097899       88.084.6        41977512       87.584.3\n\n\n            Table 6: Run time and accuracy across tasks for SIPDO and PromptAgent\n\n\n\n\n                                  Cost in time (s)              Cost in money ($)             Performance (%)\n\n Task                  Remove voters   With voters  Remove voters   With voters  Remove voters   With voters\n\n  College Biology                    763         912          0.0167       0.0221           95.14          96.5\n Machine Learning                  375         680          0.0096       0.7974           76.79          93.8\n  College Computer Science            432        1311          0.0104       1.8080           88.00          93.0\n\n\n            Table 7: Impact of SIPDO’s voters on cost and performance across tasks.\n\n\n\n\n                                          Accuracy (%)                                 Cost in time (s)\n\n Task                    w/o generator   w/o error analysis   w/o revisor   w/o generator   w/o error analysis   w/o revisor\n\n  College Biology                   95.83              95.83        95.14           331              677         314\n Machine Learning                  90.18              84.82        77.68           767             1622         353\n  College Computer Science          94.00              90.00        89.00          2405             2852        2861\n\n\n  Table 8: Ablation results on accuracy and time cost when removing each component of SIPDO.\n\n\n\n                                       14\n\nB  OPTIMZED PROMPTS FOR DIFFERENT TASKS\n\nIn this section, we demonstrate optimized prompts by Chain-of-Thought (CoT), Automatic Prompt\nEngineering (APE), PromptAgent, and SIPDO with Accuracys respectively.\n\n                 Table 9: Comparison of Optimized Prompts for Object Counting task, including\n               CoT, APE, PromptAgent, and SIPDO\n\nApproach     Optimized Prompt                                                       Accuracy\n\nCoT          Your task is to count the total number of objects mentioned in the question. Follow     0.928\n                these simple steps to ensure accurate counting:\n               **Steps to Follow:** 1. **Identify Items**: Read the question carefully and list all\n                 objects mentioned.  2. **Count Quantities**: For each item, check if a quantity is\n                provided.  If no quantity is mentioned, assume it is one. 3. **Add Totals**: Add up\n                 the quantities of all items to calculate the total count. 4. **Verify the Total**: Double-\n              check to ensure no item is missed or counted twice.\n              **Example:** - Question: ”Count the apples, oranges, and bananas. There are 2 apples,\n             1 orange, and 3 bananas.” - Step 1: Identify items: apples, oranges, bananas. - Step 2:\n              Count quantities: 2 apples, 1 orange, 3 bananas. - Step 3: Add totals: 2 + 1 + 3 = 6. -\n               Step 4: Verify: All items are accounted for, total is 6. - **Output**: ”The total count is\n                  6.”\n             Use this step-by-step method for every question to ensure accurate and clear results.\nAPE            Calculate the overall total of all items even those spoken in groups.                       0.863\nPromptAgent   Carefully examine the provided information. Identify and catalog each mentioned item,     0.882\n                ensuring that explicitly stated quantities are accurately recorded. If no quantity is spec-\n                   ified for an item, assume it as a single unit. However, for items with defined quantities,\n               count each unit separately and include it in the total. If collective terms or categories\n                 are mentioned, break them down into their individual components and associate each\n               with its stated count. When computing the total for such categories, ensure that the sum\n                   reflects all individual units rather than just the number of groups or types. Each item\n               should be counted independently, but related items belonging to a common category\n               should be grouped together, with their specific quantities contributing precisely to the\n                   final total. Avoid assumptions regarding the classification or nature of items—adhere to\n                 standard, widely accepted definitions. Finally, summarize the count by explicitly listing\n                 the quantity of each identified item or category, and provide a comprehensive total of\n                 individual units rather than just category counts, unless otherwise specified.\nSPIDO        Task Requirements:                                                                 0.923\n             The task involves counting the total number of objects listed in a question. Each distinct\n                 object should be considered as part of the total count, regardless of its type or variation.\n             The output should be formatted correctly as specified. Problem Rule Application:\n                 Identify all items listed in the question. Count each item exactly once, regardless of\n                 type, to determine the total number of objects. Ensure accuracy by verifying that all\n                   listed items have been included in the final count. Provide the final result in the re-\n                quired format: The number should be presented in both word form and numerical form,\n                separated by a comma (e.g., ”nine, 9”). No extra symbols, characters, or explanations\n               should be included. Judgment Criteria: (Strictly follow these rules)\n              Complete Identification:\n                Extract and recognize all objects in the given list. Do not overlook any item mentioned\n                 in the question. Accurate Counting:\n             Each item must be counted exactly once.  Ensure no items are omitted or double-\n                counted. Verification Process:\n              Double-check the list to confirm that all objects are included.  Cross-verify the final\n               count to avoid errors.\n\n\n\n\n\n                                       15\n\nTable 10: Comparison of Optimized Prompts for Penguins In A Table task,\n                 including CoT, APE, PromptAgent, and SIPDO\n\nApproach     Optimized Prompt                                                       Accuracy\n\nCoT         You are tasked with answering questions about a table of penguins and their attributes.     0.818\n             Use step-by-step reasoning to ensure accuracy in calculations and comparisons.\n             The table is as follows:  “‘ Name, Age, Height (cm), Weight (kg) Louis, 7, 50, 11\n               Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15 “‘\n              **Reasoning Steps for Each Question:** 1. Identify the target attribute (age, height,\n                or weight) and the type of operation (comparison, ranking, filtering).  2. Extract the\n                 relevant rows or columns based on the question’s requirements. 3. Perform the required\n                operation step-by-step using the extracted data. 4. Clearly summarize the answer based\n             on the operation’s result.\n             Example Workflow: - Question: ”Who is the tallest penguin?” - Step 1: Identify the\n                  target attribute: Height. - Step 2: Extract the height values and corresponding names:\n                 [(Louis, 50), (Bernard, 80), (Vincent, 60), (Gwen, 70)]. - Step 3: Find the maximum\n                 height: Bernard (80 cm).  - Step 4: Output the result: ”Bernard is the tallest penguin\n               with a height of 80 cm.”\n              Follow this workflow for every question to ensure clarity and correctness.\nAPE            Carefully scrutinize the provided table or tables. Understand the query in relation to the     0.848\n                information given. Pinpoint the pertinent data and carry out the vital computations or\n               comparisons to determine the right answer from the given choices.\nPromptAgent   Answer questions about a table of penguins and their attributes, considering both the     0.961\n               penguin table and any additional relevant tables. Please provide step-by-step reasoning\n                 for your answers, and ensure to clarify any criteria used for filtering or sorting data.\n              Here is a table where the first line is a header and each subsequent line is a penguin:\n              name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60,\n             11 Gwen, 8, 70, 15\n               For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard\n                    is 80 cm. What is the name of the last penguin sorted by alphabetic order? Options: (A)\n               Louis (B) Bernard (C) Vincent (D) Gwen (E) James\n                **Instructions**: 1. List the names of the penguins. 2. Sort the names alphabetically\n              and present the sorted list clearly. 3. Identify the last name in the sorted list and indicate\n                 the corresponding option letter from the provided options. 4. If the last name does not\n              match any of the options, select the name that is closest to the last name in the original\n                      list of penguins.\n             At the end, show the answer option bracketed between ¡answer¿ and ¡/answer¿.\nSIPDO       Answer questions about a dynamic, comprehensive table of penguins and their attributes     0.964\n                  that allows penguins and other animals to be added and removed. Perform calculations\n              and comparisons based on the questions asked. Read the question carefully to determine\n              which attribute is being compared (age, height, weight). When comparing an attribute,\n                 extract the name and that attribute, and then compare, ignoring the other attributes.\n               Ensure the extracted value is from the correct column corresponding to the requested\n                   attribute. When using the table, align the data so that the first number is age, the second\n                    is height, and the third is weight. Understand the question correctly, find the key words\n              from it, and then perform calculations or comparisons based on the key words\n             The current table is as follows:\n             Name, Age, Height (cm), Weight (kg)\n                Louis, 7, 50, 11\n               Bernard, 5, 80, 13\n                Vincent, 9, 60, 11\n             Gwen, 8, 70, 15\n               **Question Rules to Apply:**\n                    - Identify the rows or columns that meet the specified conditions.\n                    - Retrieve the value of the required attribute from the identified rows or columns.\n           When we modify this table (by adding new penguins or removing existing penguins\n                or adding giraffes), we first confirm whether the information we added is a penguin\n                or a giraffe, and then solve the problem of comparing, ranking, and filtering based on\n                  attributes between penguins or giraffes, depending on the problem.\n\n\n\n\n\n                                       16\n\nTable 11: Comparison of Optimized Prompts for Geometric Shapes task, in-\n                 cluding CoT, APE, PromptAgent, and SIPDO\n\nApproach     Optimized Prompt                                                       Accuracy\n\nCoT          Your task is to identify the geometric shape represented by the given SVG path data.     0.791\n              Follow these steps to ensure accuracy:\n               **Steps to Identify the Shape:** 1. **Check for ‘A’ Instructions**: – If the path con-\n                  tains ‘A’, determine:  • **Circle**: 2 or more ‘A’ instructions.  • **Sector**: 1 ‘A’\n                  instruction.  2. **Count ‘L’ Instructions**: – If there are no ‘A’ instructions, count\n                 the ‘L’ instructions to determine the polygon’s shape:  • **Line**: 2 ‘L’. • **Trian-\n                gle**: 3 ‘L’. • **Rectangle**: 4 ‘L’. • **Pentagon**: 5 ‘L’. • **Hexagon**: 6 ‘L’. •\n              **Heptagon**: 7 ‘L’. • **Octagon**: 8 ‘L’. • **Kite**: 4 ‘L’. 3. **Provide the Shape\n             Name**: Output only the name of the shape (e.g., “circle”, “triangle”, “hexagon”).\n              **Example:** – Input: ‘”M 10 10 L 20 10 L 20 20 L 10 20 Z”‘ – Step 1: No ‘A’\n                  instructions. – Step 2: Count ‘L’ instructions: 4 ‘L’. – Step 3: Shape is a **Rectangle**.\n             – **Output**: “rectangle”.\n             Use this step-by-step process for all inputs to determine the correct shape.\nAPE          Determine the shape each SVG path element is drawing, then pair it with the corre-     0.650\n               sponding letter from the available choices. In this case, C symbolizes hexagon, G is for\n               pentagon, I signifies sector, and B stands for heptagon.\n\n                                                                               Continued on next page\n\n\n\n\n\n                                       17\n\nTable 11: Comparison of Optimized Prompts for Geometric Shapes task (con-\n                  tinued)\n\nApproach     Optimized Prompt                                                       Accuracy\n\nPromptAgent   Analyze the SVG path data to identify the geometric shape it represents. Follow these     0.830\n               comprehensive and refined steps to ensure accurate identification:\n                  1. **Holistic Path Closure**: Determine if the path forms a closed shape by check-\n                ing if the last point connects back to the starting point. If multiple ‘M‘ commands are\n                 present, analyze the segments collectively to identify any closed loops. Treat the entire\n                path as a single entity for thorough analysis. 2. **Segment and Side Analysis**: Iden-\n                   tify the types of segments used in the path: – **Line Segments**: Count the number\n                of distinct line segments to determine the number of sides. Ensure accurate counting\n             by considering all segments collectively. – **Arc Segments**: For paths using the ‘A‘\n             command, note that these represent elliptical arcs. Pay attention to the parameters to\n                 distinguish between circles and ellipses. 3. **In-depth Geometric Properties**: – For\n                  line segments, analyze the relative lengths of sides and angles between them. Consider\n                 properties such as parallel sides, equal side lengths, and right angles to distinguish be-\n              tween different types of polygons. Evaluate the overall shape formed by all segments.\n             – For arc segments, examine the parameters of the ‘A‘ command: • Check if the radii\n                 are equal, which indicates a circle.  • If the radii differ, consider the shape as an el-\n                   lipse. 4. **Shape Identification and Classification**: Use the geometric properties to\n                  classify the shape: – For polygons, identify specific types like rectangles, kites, and\n                trapezoids based on their properties. Pay special attention to the number of sides and\n                 the relationships between them. Consider the entire path as a single shape to ensure\n                accurate classification. – For arcs, determine if the shape is a circle or an ellipse based\n             on the radii. 5. **Options Selection and Interpretation**: Choose the most appropri-\n                 ate shape from the given options. Consider multiple interpretations of the path data,\n                 especially when multiple ‘M‘ commands are present, to ensure accurate classification.\n                    If the path represents multiple shapes, prioritize the most complex or relevant shape.\n                  6. **Ambiguity Resolution**: In cases where the path data could represent multiple\n                shapes, provide a rationale for selecting the most complex or relevant shape. Consider\n                 the context and any additional information that might influence the classification.  7.\n               **Visual Verification**: If possible, visualize the path to confirm the identified shape.\n               This step can help resolve any remaining ambiguities and ensure the accuracy of the\n                  classification. 8. **Iterative Refinement**: If the initial classification is uncertain, re-\n                    visit the analysis steps to refine the identification. Consider alternative interpretations\n              and re-evaluate the geometric properties. 9. **Contextual Considerations**: Take into\n               account any contextual information or additional data that might influence the shape\n                  classification, especially in ambiguous cases.\n               Provide your answer by selecting the correct option and enclosing it within ‘¡answer¿‘\n              and ‘¡/answer¿‘ tags.\n              **Example:** – SVG Path:  ‘path d=”M 8.10,55.86 L 1.74,25.57 L 12.08,23.40 L\n                18.44,53.69 L 8.10,55.86”‘ Analysis: The path forms a closed quadrilateral with op-\n                 posite sides parallel and equal, indicating a rectangle. Answer: ‘¡answer¿H¡/answer¿‘\n             – SVG Path: ‘path d=”M 16.33,5.98 A 8.87,8.87 275.02 1,0 14.78,23.64 A 8.87,8.87\n               275.02 1,0 16.33,5.98”/‘ Analysis: The path uses elliptical arcs with equal radii, form-\n                ing a closed loop, indicating a circle. Answer: ‘¡answer¿A¡/answer¿‘\n\n                                                                               Continued on next page\n\n\n\n\n\n                                       18\n\nTable 11: Comparison of Optimized Prompts for Geometric Shapes task (con-\n                  tinued)\n\nApproach     Optimized Prompt                                                       Accuracy\n\nSIPDO        Given the following SVG path data: “input” and options, identify the geometric shape     0.822\n                        it represents and provide **ONLY** the name of the shape as the ‘target’.\n              **Task Requirements:** 1. Count the instructions in the SVG path 2. Judge the shape\n                of the graphic according to the judgment criteria 3. Provide the exact name of the shape\n                as output.\n             You need to count how many instructions **L** are in the SVG path:\n              **Problem Rule Application:** 1.  Visualize the path data to understand the overall\n                  structure. 2. Find out whether there is instruction **A** in the instruction. If so, deter-\n             mine whether it is a circle or a sector according to the number of instructions **A**.\n                    If not, determine how many sides it is 3. For polygons, pay attention to the number of\n               edges to identify the shape. The following are the number of instructions correspond-\n                ing to different shapes: – **triangle**: 3 L – **rectangle**: 4 L – **hexagon**: 6\n           L – **pentagon**: 5 L – **octagon**: 8 L – **heptagon**: 7 L – **kite**: 4 L –\n                **line**: 2 L – **circle**: 2 or more A – **sector**: 1 A\n              **Judgment criteria:** (Please strictly abide by this rule) – No need to pay attention to\n           “M” instructions – !! First identify whether there is an instruction “A” in the SVG path.\n                    If so, first determine whether it is a circle or a sector. – !! If there is no instruction “A”,\n               determine the number of sides of the polygon based on the instruction “L”. A polygon\n               with *n* sides requires *n* “L” instructions. (Please strictly abide by this rule)\n\n\n\n                 Table 12: Comparison of Optimized Prompts for Causal Judgment tasks, in-\n                 cluding CoT, APE, PromptAgent, and SIPDO\n\nApproach     Optimized Prompt                                                       Accuracy\n\nCoT            Task: Respond to inquiries about causal attribution by identifying the key causes and     0.678\n                  their contributions to the outcome. Follow the steps below to ensure accurate and clear\n                reasoning:\n               **Steps to Analyze Causation:** 1. **Identify Key Entities**: Read the question care-\n                  fully and highlight the specific entities or factors being discussed.  2. **Determine\n               Relevant Causes**: Analyze the context to identify immediate and incidental causes\n                 contributing to the outcome. - Immediate causes: Directly lead to the outcome. - Inci-\n                 dental causes: Indirectly influence the outcome but may still contribute. 3. **Evaluate\n                 Interactions**: Consider how multiple causes might interact to produce the observed\n                  effect (e.g., synergy or independent contributions). 4. **Provide the Answer**: Clearly\n                  state the primary and secondary causes, as well as their roles in creating the outcome.\n              Avoid unsupported assumptions.\n             Use this structured reasoning approach to analyze each inquiry and provide a clear and\n                 logical explanation.\nAPE           For each situation, decide if the result was caused deliberately or not. If the individual     0.756\n                or party behind the event was aware of the potential result and chose to go ahead, select\n                 ’Yes’.  If they didn’t intend the result to happen, even if they knew it could possibly\n                 occur, select ’No’.\n\n                                                                                (Continued on next page)\n\n\n\n\n\n                                       19\n\n(Continued from previous page)\n\nApproach     Optimized Prompt                                                       Accuracy\n\nPromptAgent  When addressing questions about causal attribution, ensure a comprehensive analysis     0.846\n             by considering both individual and collective actions that contribute to an outcome.\n                Clearly differentiate between necessary and sufficient causes, and recognize that mul-\n                   tiple causes can simultaneously contribute to an outcome. Emphasize the importance\n                of understanding both general and specific intentions, especially when outcomes are\n                unintended. Define ”intentional” actions as those where the actor or group had control\n               over maintaining or altering the conditions necessary for the outcome, even if the spe-\n                    cific result was not desired. Address scenarios where unintended consequences arise\n              from intentional actions, and provide answers that reflect a nuanced understanding of\n            how different elements interact to produce a result. Use diverse examples to illustrate\n              key concepts like ”direct causation,” ”simultaneity,” and ”unintended consequences,”\n                ensuring a balanced consideration of necessary and sufficient causes. Simplify com-\n                plex scenarios by breaking them down into clear, manageable components, and provide\n                  definitions or examples of key terms to guide your analysis. Additionally, clarify def-\n                  initions of key terms such as ”necessary,” ”sufficient,” ”intentional,” and ”unintended\n               consequences” to ensure precise understanding. Highlight the importance of interac-\n                 tions between multiple causes, especially in complex scenarios, and offer strategies for\n                analyzing scenarios where simultaneity is crucial. Explore the nuances of intentional\n                 actions and unintended consequences more deeply, and encourage the use of diverse\n              examples to illustrate different aspects of causation. Pay special attention to the role of\n                 individual actions in maintaining necessary conditions and the distinction between col-\n                  lective and individual causation. Emphasize that in collective decision-making, the out-\n            come can be intentional if it aligns with the group’s goals, even if individual members\n                 disagree. Reinforce the distinction between necessary and sufficient causes, ensuring\n                 the model understands that necessary causes alone do not determine the outcome. Clar-\n                  ify that following a protocol does not remove intentionality if the outcome aligns with\n                 organizational priorities. Highlight that intentionality can be attributed if the outcome\n             was a foreseeable consequence of the action, regardless of individual opposition.\nSIPDO        Task Requirements Determine whether a given event (cause) directly leads to another     0.880\n                event (effect). Assess the causal relationship based on logical reasoning, ensuring a\n                 clear and definitive answer. The final output must be only ”Yes” or ”No”, strictly ad-\n                hering to the required format. Problem Rule Application Identify the cause and effect\n                within the question. Assess necessity: Determine if the cause is essential for the effect\n                 to occur. Evaluate causation: If the cause did not happen, would the effect still occur?\n                    If the effect only happens when the cause is present, then the cause directly leads to the\n                   effect. If the effect can still happen independently, then the relationship is not causal.\n              Judgment Criteria Direct Causation:  If the cause directly leads to the effect and is a\n                necessary condition, answer ”Yes”. If the effect would not have occurred without the\n                cause, answer ”Yes”. Example: ”Dropping a glass caused it to shatter.” →Yes. No\n                Direct Causation: If the effect can occur without the cause, answer ”No”. If the cause is\n               only correlated but not necessary, answer ”No”. Example: ”Wearing a red shirt caused\n                 the stock market to rise.” →No. Verification Process: Check whether the absence of\n                 the cause results in the absence of the effect. Ensure logical consistency in the causal\n                assessment.\n\n\n\n\n\n                                       20\n\nTable 13: Comparison of Optimized Prompts for Epistemic task, including CoT,\n              APE, PromptAgent, and SIPDO\n\nApproach     Optimized Prompt                                                       Accuracy\n\nCoT            Task: Analyze the logical relationship between a given premise and hypothesis. Your     0.855\n                goal is to determine if the premise guarantees the truth of the hypothesis. Choose one\n                of the following answers: ’entailment’ or ’non-entailment’.\n               **Steps to Follow:** 1. **Understand the Premise and Hypothesis**: Carefully read\n                 the premise and hypothesis to identify the key information in both statements. 2. **An-\n                alyze the Logical Relationship**: Determine whether the information in the premise\n               confirms the truth of the hypothesis. - If the premise logically supports and guarantees\n                 the hypothesis, choose ’entailment’. - If the premise does not confirm the hypothesis,\n                or if there is uncertainty, choose ’non-entailment’. 3. **Provide the Answer**: Based\n             on your analysis, output the correct answer (’entailment’ or ’non-entailment’).\n             Use this step-by-step approach for all premise and hypothesis pairs to ensure accurate\n                reasoning.\nAPE          Determine whether the hypothesis is directly implied by the premise or not.  If the     0.888\n                premise’s statement is a direct claim or conviction of the individual mentioned in the\n                hypothesis, choose ’entailment’. However, if the premise is formed on the belief or sup-\n                 position of someone other than the subject in the hypothesis, opt for ’non-entailment’.\nPromptAgent   Determine the relationship between two sentences by evaluating whether the first sen-     0.916\n                tence provides direct or logically implied evidence for the second. Choose from the\n                options ’entailment’ or ’non-entailment’.\n               Consider the following: - **Entailment**: The first sentence directly or through logical\n                implication confirms the truth of the second sentence, even if it involves a chain of\n                  beliefs or perceptions, as long as the chain logically supports the hypothesis. - **Non-\n                entailment**: The first sentence does not confirm the truth of the second sentence, often\n                involving unsupported assumptions, beliefs, or suspicions that do not logically lead to\n                 the hypothesis.\n                Guidelines for Analysis: 1. **Clarify Belief Chains and Logical Implications**: Un-\n                derstand how belief chains work and when they logically support the hypothesis. Pay\n                 attention to verbs indicating beliefs, assumptions, or suspicions (e.g., ”thinks,” ”as-\n               sumes,” ”suspects”) versus those indicating direct evidence (e.g., ”learns,” ”knows,”\n               ”remembers”). Consider how these verbs interact in belief chains and what they imply\n               about the subject’s own beliefs.  2. **Evaluate Direct and Implied Evidence**: De-\n               termine if the premise provides direct or logically implied evidence for the hypothesis,\n                considering how belief chains can logically support the hypothesis. Recognize that in-\n                  direct beliefs about another person’s recognition can imply one’s own belief about a\n                  situation, especially when the belief chain is logical and straightforward. 3. **Consider\n                Perspective and Source of Information**: Note any differences in perspective or source\n                of information (e.g., who remembers or assumes something) and how these perspectives\n                 contribute to the logical implication of the hypothesis. 4. **Conduct a Comprehensive\n               Analysis**: Use a step-by-step approach to ensure all relevant details and logical im-\n                 plications are considered in the analysis. Balance the emphasis on direct evidence with\n                 the recognition of logical implications from indirect beliefs.\n              Example: Premise: ”Charlotte thinks that Richard recognizes that a boy is standing in a\n               pool getting splashed with water.” Hypothesis: ”Charlotte thinks that a boy is standing\n                 in a pool getting splashed with water.” Options: (A) entailment (B) non-entailment\n                Analysis:  1.  **Understanding the Premise**: The premise indicates that Charlotte\n                thinks Richard recognizes a specific situation involving a boy in a pool. 2. **Under-\n                standing the Hypothesis**: The hypothesis states that Charlotte thinks a boy is in a\n               pool getting splashed with water.  3.  **Assessing the Relationship**: The premise\n                implies that Charlotte has a belief about the situation (through Richard’s recognition),\n              which logically supports the hypothesis. Charlotte’s belief about Richard’s recognition\n                suggests she also believes in the situation’s occurrence. 4. **Conclusion**: The re-\n                 lationship is one of entailment because Charlotte’s belief about Richard’s recognition\n                 logically implies her belief in the situation.\n                Therefore, the correct answer is:\n           <answer>A</answer>\n                 Identify the relation between the following premises and hypotheses, choosing from the\n                options ’entailment’ or ’non-entailment’. At the end, show the answer option bracketed\n              between <answer> and </answer>.\n\n                                                                                (Continued on next page)\n\n\n\n                                       21\n\n(Continued from previous page)\n\nApproach     Optimized Prompt                                                       Accuracy\n\nSIPDO        Task Requirements:                                                                 0.893\n              Analyze a given premise (primary sentence) and determine whether it fully supports the\n                  truth of a hypothesis (subsequent sentence). Classify the relationship as either ”Entail-\n              ment” or ”Non-Entailment” based on the logical and factual connections between the\n               two. Provide the classification only as the final output. Problem Rule Application:\n                Entailment:\n             The premise explicitly confirms the hypothesis with clear, direct evidence. No addi-\n                  tional information, assumptions, or interpretations are required to validate the hypothe-\n                     sis. Non-Entailment:\n             The premise does not fully or explicitly confirm the hypothesis. If there is ambiguity,\n                 uncertainty, or missing logical links, label it as Non-Entailment. Judgment Criteria:\n                  (Strictly follow these rules)\n              Language of Uncertainty:\n             Words like ”assumes,” ”believes,” ”thinks,” ”feels,” ”suspects” indicate subjectivity and\n               should not be considered definitive proof. These terms suggest a possibility rather than\n              an explicit factual connection. Specific vs. General Statements:\n         A specific premise (e.g., mentioning a “full face mask”) does not necessarily contradict\n               a general hypothesis (e.g., referencing a “mask” in general). However, if the premise is\n                too general to confirm the specific claim, classify as Non-Entailment. Objective Rea-\n                soning:\n             Only use the logical and factual ties within the given statements. Do not rely on external\n               knowledge, assumptions, or interpretations unless directly supported by the premise.\n               Decision Process:\n              Determine whether the premise fully supports the hypothesis without needing extra\n                inference →Entailment. If the premise only partially supports or fails to confirm the\n                hypothesis →Non-Entailment.\n\n\n\n                 Table 14: Comparison of Optimized Prompts for Temporal task including CoT,\n              APE, PromptAgent, and SIPDO.\n\nApproach     Optimized Prompt                                                       Accuracy\n\nCoT          Your task is to determine the available time slot for an event, based on a schedule of     0.989\n               occupied times. Follow these steps to ensure accuracy:\n               **Steps to Identify Free Time Slots:** 1.  **List Occupied Periods**: Organize all\n               occupied time slots in chronological order. 2. **Find Gaps**: Identify gaps between\n                 the occupied periods where no activities are scheduled.  3. **Check Constraints**:\n               Ensure that the free time slots fall within operational constraints (e.g., facility closing\n                 times). 4. **Select the Slot**: Choose the correct free time slot that satisfies all criteria.\n              **Output Result Format:** - Present the selected free time slot in a clear format, such\n                as ”Xpm to Ypm” or ”Xam to Yam”.\n             Use this step-by-step method to ensure that the identified time slot is accurate and does\n                not overlap with any occupied periods.\nAPE            Identify the period when the individual was unnoticed and had the possibility to visit     0.994\n                 the specified place before its closing time.\n\n                                                                                (Continued on next page)\n\n\n\n\n\n                                       22\n\n(Continued from previous page)\n\nApproach     Optimized Prompt                                                       Accuracy\n\nPromptAgent   Analyze the timeline of events to determine possible time frames during which certain     0.984\n                events could have occurred, even if they were not explicitly observed.  Start by con-\n                 structing a comprehensive timeline, clearly listing all observed and unobserved time\n                   slots. Identify gaps where the subject is unobserved, ensuring these gaps fit within any\n               given constraints, such as opening and closing times. Emphasize the importance of\n                 constraints by verifying them after identifying potential gaps. Use a step-by-step rea-\n               soning approach to systematically evaluate all available information, and include a final\n               review to check for potential errors or overlooked details before finalizing the answer.\n               Define key terms like ”unobserved” and ”constraints” to ensure clarity in the task re-\n                quirements. Provide examples to illustrate the reasoning process and expected output\n                format, guiding the model in analyzing timelines and identifying possible time frames\n                 for unobserved events. Additionally, incorporate a checklist to ensure all steps are fol-\n               lowed, and highlight common pitfalls to avoid during the analysis. Finally, include a\n             summary of the reasoning process to reinforce understanding and ensure the model’s\n                conclusions are well-supported.\n             To further enhance the model’s performance, include additional examples that cover\n               a wider range of scenarios and constraints, such as overlapping time slots or multiple\n                  constraints. Provide explicit guidance on handling complex constraints and ambiguous\n                information. Incorporate interactive feedback mechanisms to help the model learn from\n               mistakes and improve over time. Ensure the prompt is concise and focused, avoiding\n               unnecessary repetition while maintaining clarity and comprehensiveness. Additionally,\n                introduce a section for handling exceptions or unusual cases, offering strategies for\n                dealing with incomplete or conflicting data. This will help the model adapt to a broader\n               range of real-world scenarios and improve its robustness in timeline analysis tasks.\nSIPDO        **Task Requirements:** Determine the possible time period during which an event     0.993\n               could have occurred, based on a detailed schedule of occupied times. Your goal is to\n                 identify the correct time slot that fits all the provided criteria without any overlap.\n              **Problem Rule Explanation:** 1. Analyze the schedule to identify all time slots during\n              which the person is occupied. 2. Determine the available time slots by identifying gaps\n              between these occupied periods. 3. Consider any additional constraints, such as closing\n                 times, that may limit the available time slots.\n              **Problem Rule Application:** - List all the occupied time slots chronologically.  -\n                 Identify gaps between these occupied slots where the person is free. - Ensure that the\n                 free time slots do not conflict with constraints like closing times.\n               **Result Verification:** - Confirm that the identified time slot is completely free and\n               adheres to any constraints. - Double-check against all occupied periods to ensure there\n                    is no overlap.  - Avoid selecting time slots that are partially occupied or overlap with\n              any scheduled activities.\n              **Output Result Format:** - Present the correct time slot in a straightforward manner,\n                using the format ”Xpm to Ypm” or ”Xam to Yam” as appropriate. - Ensure the output\n                    is clear and free of any extraneous symbols or text.\n           **Common Mistakes to Avoid:** - Do not include time slots that extend beyond the\n                closing time of the facility. - Avoid selecting time slots that overlap with any scheduled\n                   activities. - Ensure the selected time slot is entirely free and does not partially overlap\n               with any occupied period.\n               **General Rules and Analysis:** - Identify all occupied periods and list them chrono-\n                  logically. - Look for gaps between these periods where the person is not scheduled for\n              any activity.  - Verify that these gaps fall within any operational constraints, such as\n                closing times. - Ensure the selected time slot is entirely free and does not overlap with\n              any occupied periods.\n            By following these guidelines, you can accurately determine the available time slot for\n                 the event in question. Avoid errors by ensuring that the selected time slot is entirely free\n              and does not overlap with any occupied periods.\n\n\n\n\n\n                                       23\n\nC  OPTIMIZED PROMPTS WITHOUT DIFFICULTY SCALING IN SYNTHETIC\n   DATA\n\n\n                     Table 15: Optimized Prompts Without Difficulty Scaling in Synthetic Data\n\nTasks            Optimized Prompt                                                       Accuracy\n\nPenguins        You are provided with two tables containing data about penguins and giraffes. Your task     0.732\n                         is to focus solely on the giraffe data to answer a specific question regarding the tallest\n                       giraffe.\n                 **Penguin Data:**\n        — Name — Age — Height (cm) — Weight (kg) — ————-——–—————–——\n         ———-— — Louis — 7 — 50 — 11 — — Bernard — 5 — 80 — 13 — — Vincent\n        — 9 — 60 — 11 — — Gwen — 8 — 70 — 15 — — James — 12 — 90 — 12 —\n                   **Giraffe Data:**\n        — Name — Age — Height (cm) — Weight (kg) — ———–——–—————–——\n         ———-— — Jody — 5 — 430 — 620 — — Gladys — 10 — 420 — 590 — — Marian\n        — 2 — 310 — 410 — — Donna — 9 — 440 — 650 —\n                 **Task Requirements:** 1. Identify the tallest giraffe based on the height provided in\n                    the Giraffe Data table. 2. Provide the weight of the tallest giraffe in kilograms.\n                 **Problem Rule Explanation:** - Review the height values for each giraffe listed in\n                    the Giraffe Data table. - Compare these height values to determine which giraffe is the\n                         tallest.\n                 **Problem Rule Application:** - Examine the height values for the giraffes: - Jody:\n                430 cm - Gladys: 420 cm - Marian: 310 cm - Donna: 440 cm - Identify that Donna is\n                    the tallest giraffe at 440 cm.  - Retrieve the corresponding weight of Donna, which is\n                650 kg.\n                  **Result Verification:** - Ensure that you have considered all entries in the Giraffe\n                 Data table. - Confirm that the weight you provide corresponds to the giraffe identified\n                    as the tallest.\n                 **Output Result Format:** - Provide your answer in the following format: - ”Weight\n                    of the tallest giraffe: [Weight in kg]”\n        —\n                **Example Output:** - ”Weight of the tallest giraffe: 650”\n        —\nGeometry         ” Given the following input: ””input””, you must provide ONLY the correct value for     0.681\n                    the ’target’.\n                  **Rules:** 1. Do NOT provide any explanations. 2. Do NOT provide any sentences,\n                        text, or words other than the ’target’ value.  3. The answer must be the exact value\n                   contained in the ””target”” and any unauthorized additions are prohibited.”\nObject Counting   ”**Task Requirements:** - Determine the total number of fruits by accurately identify-     0.538\n                   ing and counting each type listed in the question.\n                 **Problem Rule Explanation:** - The task involves listing and counting each fruit men-\n                     tioned. - Each fruit should be counted as one unless a specific quantity is provided.\n                 **Problem Rule Application:** - Carefully read through the list to identify all items that\n                    are fruits. - Count each fruit once unless otherwise specified with a different quantity. -\n                 Avoid including any non-fruit items or miscounting due to misinterpretation of the list.\n                  **Result Verification:** - Re-examine the list to ensure all fruits have been correctly\n                      identified and counted. - Verify that the total count reflects only the fruits listed, with\n                no errors in inclusion or exclusion.\n                 **Output Result Format:** - Provide the total number of fruits in both word and nu-\n                  meral forms, such as: [””ten””, ””10””].  - Ensure the output is clear and free from\n                     special symbols or formatting errors.”\n\n                                                                                   (Continued on next page)\n\n\n\n\n\n                                       24\n\n(Continued from previous page)\n\nTasks            Optimized Prompt                                                       Accuracy\n\nCausal Judgment   Analyze the scenario to determine if the described action directly caused the outcome.     0.684\n                   Provide a definitive ’Yes’ or ’No’ answer based on a logical assessment of the causal\n                     relationship as described in the scenario.\n                 **Problem Rule Explanation:** A causal relationship exists when an action directly\n                    leads to an outcome without other factors influencing the result. The outcome should\n                   not occur without the action. Avoid assumptions and base your analysis solely on the\n                   information provided.\n                 **Problem Rule Application:** - Identify the key action and the resulting outcome\n                   within the scenario. - Determine if the outcome is a direct result of the action, ensuring\n                no additional factors are at play.  - Evaluate whether the outcome would still occur\n                   without the initial action, focusing on the explicit roles, responsibilities, and conditions\n                  mentioned. - Avoid external assumptions and concentrate on the details provided in the\n                     scenario.\n                  **Result Verification:** - Confirm that the action directly causes the outcome, with no\n                     interference from other factors. - Ensure the outcome logically follows from the action,\n                   considering the context and rules provided. - Review the scenario for any overlooked\n                      details that could affect the causal link, ensuring a comprehensive analysis.\n                 **Output Result Format:** - Answer ’Yes’ if the action directly causes the outcome,\n                  with the outcome being a direct consequence of the action. - Answer ’No’ if there is no\n                      direct causal relationship or if other factors could have contributed to the outcome.\nTemporal         **Task Requirements:** Determine the available time slots for an unscheduled activity\n                   within a given daily schedule, ensuring these slots do not conflict with scheduled events\n                 and comply with any facility operating hours.\n                 **Problem Rule Explanation:** 1. Review the entire schedule to identify all events\n                 and their specific time frames. 2. Identify gaps between these events or after the last\n                  scheduled event to find potential time slots for the unscheduled activity. 3. Consider\n                 any additional constraints, such as facility operating hours, to ensure the proposed time\n                       slot is feasible.\n                 **Problem Rule Application:** - List all scheduled events with their respective time\n                   frames. - Identify gaps between these events or available time after the last scheduled\n                     event. - Ensure that the identified time slots comply with any additional constraints, like\n                       facility operating hours.\n                  **Result Verification:** - Confirm that the identified time slots do not overlap with any\n                  scheduled events. - Verify that the time slots fall within the facility’s operating hours.\n                 **Output Result Format:** Present the time range in a clear and concise format, such\n                    as ”Xpm to Ypm” or ”Xam to Yam”, ensuring clarity and precision.\n                **Example Application:** Given the schedule:  - Breakfast: 8am to 9am - Business\n                   meeting: 9am to 11am - Art gallery: 11am to 1pm - Lunch: 1pm to 2pm - Cinema: 3pm\n                     to 5pm - Dinner party: 6pm to 8pm - Gym closes at 10pm\n                 Determine the available time for the gym: - Identify the gaps: 5pm to 6pm and 8pm to\n                10pm. - Ensure these time slots do not overlap with scheduled events and are within the\n                 gym’s operating hours. - The correct answer is ”5pm to 6pm” and ”8pm to 10pm”, as\n                   they fit within the gym’s operating hours and do not overlap with any scheduled events.\n\n\n\n\n\n                                       25\n\nD  SELF-IMPROVEMENT PROMPT TEMPLATES\n\n\n\n\nWe provide an example of a self-improvement prompt template in the BIG-Bench Penguins In a Table task:\nError analysis, Improvement recommendations, and prompt refinement.\n\n\n\n\n\n  Error Analysis Prompt Template\n\n  You are an expert at analysing why LLM answer is wrong in Penguins in a table reasoning task.\n\n  Your task  is to give a concise and general description of the reasoning mistake from the current\n  prompt that caused the mistake with the provided question, generated answer, ground truth, and current\n  prompt below:\n  Question :{synthetic question}\n  Model generated answer: {LLM generated answer}\n  Ground truth: {true answer}\n  Current prompt: {current prompt}\n\n   1. Misinterpretation of the Question: The model may have misinterpreted the question, focusing on\n      the structure of the data rather than the specific request for the height of the tallest penguin. This could\n      lead to confusion and an irrelevant answer.\n\n   2. Inattention to Numerical Data: The model might have overlooked the numerical values provided in\n      the table, failing to recognize that it needed to compare the heights of the penguins to determine the\n       tallest one.\n\n   3. Irrelevant Output Generation:  The answer ”rectangle” does not relate to the context of the\n      question. This suggests that the model may have generated a response based on unrelated patterns or\n      associations rather than the specific data presented.\n\n   4. Lack of Contextual Understanding: The model may not have fully grasped the context of the data\n       table, leading to a failure in recognizing that the question was asking for a specific value derived from\n      the table.\n\n   5. Failure to Process Tabular Data: The model might struggle with processing tabular data effectively,\n     which can lead to incorrect conclusions or irrelevant outputs when asked to analyze such formats.\n\n\n\n\n\n  Improvement Recommendation Prompt Template\n\n  You are an expert in giving recommendations for optimizing current prompts. The goal is to output\n  reasonable and decent suggestions on how to revise the current prompt to solve the encountered issue.\n\n  Question :{synthetic question}\n  Model generated answer: {LLM generated answer}\n  Ground truth: {true answer}\n  Current prompt: {current prompt}\n  Generated error analysis: {error analysis from previous step}\n\n  Some recommendation examples in Penguins In A Table task(But don’t be limited to these):\n   - Clarify the question to emphasize the need for numerical comparison.\n   - Provide explicit instructions to focus on extracting specific values from the data.\n   - Ensure the model is trained to recognize and process tabular data more effectively.\n   - Avoid ambiguity in the question to prevent misinterpretation of the request.\n\n\n\n                                       26\n\nPrompt Refinement Template\n\nYou are an expert in revising prompt engineering and refinement in tables related to reasoning tasks.\n\nGoal: Create a revised prompt that fixes the failure without overfitting – keep it generic.\nQuestion :{synthetic question}\nModel generated answer: {LLM generated answer}\nGround truth: {true answer}\nCurrent prompt: {current prompt}\nRefinement recommendation: {recommendation from previous step}\n\nTasks:\n- Give a better prompt, which can avoid all the problems that have occurred.\n- Summarize the logic based on the question and correct answer, and summarize the mistakes that should\nbe avoided based on the question and generated wrong answer.\n- Do not modify the prompt based on the specific problem, but modify the prompt based on the cause of\nthe error. The modified prompt should be able to give some regular hints and logical revisions.\n- You should specify the output format according to the correct answer. The output should not contain\nany special symbols.\n- You can summarize the characteristics of each option and reverse the answer based on the characteristics.\n- It can analyze the general rules of the problem, which helps the model understand how the problem is\nsolved.\n- Prompts should be planned according to the following categories:  task requirements, problem rule\nexplanation, problem rule application, result verification, and output result format.\n\n\n\n\n\n                                     27\n\nE  EXAMPLES OF GENERATED DATA\n\n\n                      Table 16: Examples of Generated Data for BIG-Bench tasks\n\nTasks            Generated Data\n\n Causal Judgment   Question: In a small town, there is a bakery that makes the best pastries. Every morning,\n                     the bakery opens at 7:00 am, and a line of customers forms outside. The bakery owner\n                   has a rule that only one person can enter at a time to maintain order. One day, two\n                    customers, Alice and Bob, arrive at the same time. Alice follows the rule and waits\n                     outside, but Bob ignores the rule and enters the bakery while another customer is still\n                      inside. The bakery becomes overcrowded, and a shelf of pastries falls over, ruining the\n                    day’s batch. Did Bob cause the pastries to be ruined?\n                 Answer: Yes\nGeometry         Question:This SVG path element <path d=\"M 50.00,30.00 L\n              66.18,35.09 L 72.45,50.00 L 66.18,64.91 L 50.00,70.00 L\n              33.82,64.91 L 27.55,50.00 L 33.82,35.09 L 50.00,30.00\"/>\n                 Answer: Polygon\n Object Counting    Question: I have two violins, a drum, a piano, a flute, and a trumpet. Additionally, I\n                  have a cat, a rabbit, a dog, a chicken, and a goat. How many musical instruments do I\n                  have?\n                 Answer: 4\n Epistemic          Question: Premise: Olivia suspects that Ethan recognizes that a group of musicians\n                    gather in a park, tuning their instruments as the sun sets behind the city skyline. Hy-\n                     pothesis: Ethan recognizes that a group of musicians gather in a park, tuning their\n                    instruments as the sun sets behind the city skyline.\n                 Answer: non-entailment\nTemporal          Question:Today, Alex attended several events. Between what times could he have gone\n                      to the gym? We know that: Alex had breakfast at 8am. He attended a meeting from 9am\n                      to 11am. He was seen at the art gallery from 11am to 1pm. He had lunch with friends\n                 from 1pm to 2pm. He was at the cinema from 2pm to 4pm. He visited his grandmother\n                 from 4pm to 6pm. The gym closes at 10pm. Between what times could Alex have gone\n                      to the gym? 12pm to 1pm, 9am to 10am, 6pm to 10pm, 4pm to 5pm\n                 Answer: 6pm to 10pm\n Penguins          Question: Here is a table where the first line is a header and each subsequent line is a\n                   penguin: name, age, height (cm), weight (kg)\n                    Louis, 7, 50, 11\n                   Bernard, 5, 80, 13\n                    Vincent, 9, 60, 11\n                Gwen, 8, 70, 15. For example: the age of Louis is 7, the weight of Gwen is 15 kg, the\n                    height of Bernard is 80 cm. Which is the youngest penguin??\n                 Answer: Bernard\n\n\n\n\n\n                                       28\n\nTable 17: Examples of Generated Causal Judgement Data for BIG-Bench tasks\n\nDifficulty Level/Iteration   Generated Data\n\n1                           In a small town, there is a bakery known for its delicious pastries. The bakery owner,\n                         Mr. Thompson, has a strict policy that only his trained staff can bake the pastries.\n                         However, one day, a customer named Sarah, who has some baking experience, decides\n                               to sneak into the kitchen while the staff is busy. She bakes a batch of pastries without\n                            permission. The next morning, Mr. Thompson discovers that the pastries are not up to\n                               his usual standards. Did Sarah cause the pastries to be of poor quality?\n\n2                           In a bustling restaurant, the head chef, Chef Maria, has a rule that only she and her sous\n                            chefs are allowed to create new dishes. One evening, a waiter named Tom, who has a\n                            passion for cooking, decides to experiment and prepares a new dish during a slow shift.\n                       The next day, Chef Maria tastes the dish and finds it lacks flavor and presentation. Did\n                    Tom cause the dish to be of poor quality\n\n3                           In a high-tech company, the lead engineer, Ms. Johnson, has a strict protocol that only\n                                 certified technicians are allowed to perform software updates on the main server. One\n                             afternoon, a junior intern named Alex, eager to impress, decides to bypass the protocol\n                         and updates the software without authorization. The next day, the server experiences\n                                significant downtime due to compatibility issues. Did Alex cause the server downtime?\n\n4                           In a prestigious university, the dean, Dr.  Roberts, has a clear policy that only fac-\n                               ulty members are allowed to supervise student research projects. However, a graduate\n                             student named Emily, frustrated with the slow progress of her project, decides to take\n                            matters into her own hands and conducts an experiment without faculty approval. When\n                             the results are presented, they are deemed unreliable and flawed. Did Emily cause the\n                             research results to be unreliable?\n\n5                           In a renowned art gallery, the curator, Ms. Patel, has a strict guideline that only pro-\n                              fessional artists can submit their work for exhibition. One day, a passionate art student\n                      named Jake, feeling confident in his skills, sneaks in his painting and hangs it on the\n                            wall without permission. When the exhibition opens, visitors notice that Jake’s painting\n                             lacks the finesse and depth of the other artworks. Did Jake cause the negative reception\n                             of his painting?\n\n6                           In a large corporate office, the HR manager, Ms. Lee, has a strict policy that only trained\n                            personnel are allowed to conduct interviews for new hires. One day, a receptionist\n                      named Mark, eager to help, decides to conduct an interview for a candidate without\n                            permission. The next day, during the hiring meeting, it becomes clear that the candidate\n                                    is not a good fit for the company culture. Did Mark cause the poor hiring decision?\n\n7                           In a cutting-edge research lab, the lead scientist, Dr. Nguyen, has a strict rule that only\n                            authorized researchers can handle the sensitive equipment. One afternoon, a visiting\n                             scholar named Rachel, excited to contribute, decides to use the equipment without per-\n                            mission. The next day, Dr. Nguyen discovers that the data collected is corrupted and\n                            unusable. Did Rachel cause the data corruption?\n\n8                           In a competitive publishing house, the editor-in-chief, Ms. Carter, has a strict policy that\n                           only experienced editors can approve manuscripts for publication. One day, a new intern\n                      named David, eager to make a mark, decides to approve a manuscript without consulting\n                           anyone. When the book is published, it is filled with errors and inconsistencies. Did\n                         David cause the poor quality of the published book?\n\n9                           In a prestigious law firm, the managing partner, Mr. Stevens, has a strict rule that only\n                             licensed attorneys can represent clients in court. One day, a paralegal named Lisa,\n                          wanting to prove her capabilities, decides to represent a client during a hearing without\n                              authorization. The next day, the judge dismisses the case due to Lisa’s lack of legal\n                         knowledge and experience. Did Lisa cause the dismissal of the case?\n\n10                          In a leading aerospace company, the project director, Mr. Carter, has a strict rule that\n                           only certified engineers can work on the aircraft design.  However, his enthusiastic\n                             neighbor, Jake, who has no formal training, often offers unsolicited advice on the design\n                             process. One day, Jake manages to convince Mr. Carter to incorporate a design feature\n                         he believes will improve aerodynamics. Unfortunately, the feature is flawed and leads\n                               to a critical failure during a test flight, resulting in the loss of the prototype. Did Jake\n                           cause the failure of the prototype?\n\n\n\n\n                                       29\n\nF  DETAILED PROOF OF THEOREM 3.3\n\n1. Surrogate domination.  Because the surrogate loss upper-bounds the 0–1 loss point-wise,\n               sup Eqψ 1{f(p, ˜x) ̸= ˜y}  ≤  sup Eqψ L f(p, ˜x), ˜y  = sup J(ψ),\n             ψ∈Ψ                    ψ∈Ψ                 ψ∈Ψ\n\nwhere we abbreviated J(ψ):=EqψL f(p, ˜x), ˜y  .\n\n2. Reduce to the near-optimal generator.  Let ψ⋆be any generator that ε-maximises the regularised\nobjective,\n\n  ψ⋆= arg max n J(ψ) −λ−1R(ψ)o   s.t.  J(ψ⋆) −λ−1R(ψ⋆) ≥sup J(ψ) −λ−1R(ψ) −ε.\n           ψ∈Ψ                                      ψ∈Ψ\n\nRearranging, J(ψ) ≤J(ψ⋆) + λ−1 R(ψ) −R(ψ⋆) + ε for every ψ, hence\n\n                                sup J(ψ) ≤  J(ψ⋆) + ε.\n                            ψ∈Ψ\n\n3. Bound the hard generator via KL.  Applying the risk-alignment inequality to ψ⋆,\n\n                      J(ψ⋆) ≤  E(x,y)∼P L f(p, x), y + λ−1R(ψ⋆).\n\n4. Sample–population substitution.  With probability at least 1 −δ over the draw of the training set,\n\n                                          n\n                                        1\n                   E(x,y)∼P L f(p, x), y  ≤ X L f(p, xi), yi + q |P|, n, δ  .\n                                 n\n                                                i=1\n\nCombine.  Chaining 1-4 we obtain\n\n                                  n\n           X L f(p, xi), yi + λ−1R(ψ⋆) + ε + q |P|, n, δ  ,        sup Eqψ1{f(p, ˜x) ̸= ˜y} ≤1\n       ψ∈Ψ                 n i=1\nwhich is exactly the bound claimed in Theorem 3.3.                             □\n\n\n\n\n\n                                       30",
"headers": [
"arXiv:2505.19514v4  [cs.CL]  27 Jan 2026",
"SIPDO: C",
"-L",
"P",
"O",
"S",
"D",
"F",
"LOSED",
"OOP",
"ROMPT",
"PTIMIZATION VIA",
"YNTHETIC",
"ATA",
"EEDBACK",
"A",
"1",
"I",
"2",
"R",
"W",
"3",
"M",
"4",
"E",
"5",
"C",
"T",
"B",
"-",
"G",
"3.3"
],
"tables": [
"|Accuracy (%) Avg. Acc. (%)<br>Model Method (Comparative Acc.)<br>Penguins Geome. Epistemic Obj. Count Temporal Causal|Col2|Col3|\n|---|---|---|\n|GPT-4o<br>CoT<br>APE<br>PromptAgent<br>**SIPDO**|79.8<br>79.1<br>79.3<br>85.2<br>98.0<br>67.8<br>84.8<br>65.3<br>84.8<br>86.0<br>99.2<br>74.0<br>96.1<br>**83.0**<br>**91.6**<br>88.2<br>98.4<br>77.8<br>**96.4**<br>82.2<br>86.3<br>**91.1**<br>**99.3**<br>**79.0**|81.5(_↓_7_._6)<br>82.4(_↓_6_._7)<br>**89.2**(_↑_0_._1)<br>89.1|\n|GPT-4o-mini<br>CoT<br>APE<br>PromptAgent<br>**SIPDO**|75.8<br>68.6<br>**85.2**<br>81.5<br>94.9<br>63.6<br>83.7<br>44.5<br>81.6<br>86.3<br>97.2<br>75.6<br>89.8<br>72.0<br>86.0<br>84.3<br>94.6<br>84.6<br>**92.1**<br>**73.2**<br>85.1<br>**87.5**<br>**98.0**<br>**88.0**|78.3(_↓_9_._0)<br>78.2(_↓_9_._1)<br>85.2(_↓_2_._1)<br>**87.3**|\n|Gemini-1.5-flash<br>CoT<br>APE<br>PromptAgent<br>**SIPDO**|70.4<br>68.3<br>85.5<br>90.1<br>94.0<br>66.8<br>37.6<br>49.4<br>**88.8**<br>84.7<br>**99.4**<br>69.4<br>67.4<br>**70.3**<br>81.6<br>86.3<br>94.2<br>67.9<br>**77.3**<br>68.9<br>87.0<br>**92.3**<br>98.4<br>**73.2**|79.2(_↓_3_._7)<br>71.6(_↓_11_._3)<br>78.0(_↓_4_._9)<br>**82.9**|\n|Gemini-1.5-pro<br>CoT<br>APE<br>PromptAgent<br>**SIPDO**|**81.8**<br>59.1<br>82.6<br>**92.8**<br>**98.9**<br>61.5<br>40.2<br>56.6<br>88.7<br>78.6<br>86.0<br>65.7<br>73.6<br>58.3<br>83.8<br>72.6<br>98.4<br>74.2<br>79.3<br>**64.3**<br>**89.3**<br>91.3<br>98.0<br>**78.3**|79.5(_↓_3_._9)<br>69.3(_↓_14_._1)<br>76.8(_↓_6_._6)<br>**83.4**|",
"|Tasks|GPT-4o<br>Vanilla Neuro-S CoT REVOLVE SIPDO|GPT-4o-mini<br>Baseline Neuro-S CoT REVOLVE SIPDO|\n|---|---|---|\n|ProofWriter<br>FOLIO<br>PrOntoQA|58.5<br>**81.6**<br>72.3<br>54.0<br>79.6<br>71.2<br>79.2<br>72.6<br>65.7<br>**83.2**(_↑_4_._0)<br>80.4<br>85.2<br>95.6<br>85.4<br>**96.3**(_↑_0_._7)|52.6<br>**79.7**<br>61.8<br>48.6<br>79.3<br>51.2<br>73.2<br>69.3<br>62.8<br>**81.1**(_↑_7_._9)<br>74.6<br>79.3<br>89.3<br>83.4<br>**91.3**(_↑_2_._0)|\n|Average|70.0<br>82.0<br>80.2<br>68.4<br>**86.4**(_↑_4_._2)|59.5<br>77.4<br>73.5<br>64.9<br>**83.9**(_↑_6_._5)|",
"|Model|PENGUINS GEOME. EPISTEMIC OBJ.CNT. TEMPORAL CAUSAL|Avg.|\n|---|---|---|",
"|GPT-4o<br>GPT-4o-<br>mini|73.2 68.1 81.9 53.8 97.0 68.4<br>(↓24.1%) (↓17.2%) (↓5.1%) (↓40.9%) (↓2.3%) (↓13.4%)<br>69.6 47.5 80.0 39.9 92.1 67.4<br>(↓24.4%) (↓35.1%) (↓6.0%) (↓54.4%) (↓6.0%) (↓23.4%)|73.7<br>(↓17.3%)<br>66.1<br>(↓24.3%)|\n|---|---|---|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2505.19514v4.pdf"
}