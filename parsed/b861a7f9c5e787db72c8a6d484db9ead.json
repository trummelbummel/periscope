{
"text": "1\n\n    EMPOWER: Evolutionary Medical Prompt\n      Optimization With Reinforcement Learning\n\n         Yinda Chen, Yangfan He, Jing Yang, Dapeng Zhang, Zhenlong Yuan, Muhammad Attique Khan, Jamel\n                                                                Baili, Por Lip Yee\n\n\n\n\n\n         Abstract— Prompt engineering significantly influences                                 I. INTRODUCTION\n        the reliability and clinical utility of Large Language Mod-\n         els (LLMs) in medical applications. Current optimization     Large Language Models (LLMs) have substantial implica-\n        approaches inadequately address domain-specific medi-   tions for healthcare applications including clinical decision2025   cal knowledge and safety requirements. This paper in-                                                                          support, documentation, and education [1]. However, imple-\n        troduces EMPOWER, a novel evolutionary framework that\n                                                                    mentation in clinical environments presents unique challenges       enhances medical prompt quality through specialized rep-\n         resentation  learning, multi-dimensional  evaluation, and  due  to medical knowledge complexity, the importance ofAug         structure-preserving algorithms. Our methodology incor-   factual accuracy, and potential consequences of errors [2].\n25   porates:(2) a comprehensive(1) a medicalassessmentterminologyarchitectureattention mechanism,evaluating   guidingPromptLLMengineering—theoutputs—criticallymethodicaldeterminesdesign ofmodelinstructionsperfor-\n           clarity, specificity, clinical relevance, and factual accuracy,\n                                                          mance and reliability [3]. This process  is particularly con-          (3) a component-level evolutionary algorithm preserving\n          clinical reasoning integrity, and (4) a semantic verification   sequential in medical contexts, requiring precise terminology,\n       module ensuring adherence to medical knowledge. Evalu-   adherence to clinical reasoning frameworks, appropriate repre-\n         ation across diagnostic, therapeutic, and educational tasks   sentation of uncertainty, and clear acknowledgment of system\n        demonstrates significant improvements: 24.7% reduction                                                                              limitations [2], [4], [5].[cs.CL]   in factually incorrect content, 19.6% enhancement in do-\n       main specificity, and 15.3% higher clinician preference in     Current approaches to medical prompt optimization typ-\n        blinded evaluations. The framework addresses critical chal-   ically employ general-domain techniques without sufficient\n        lenges in developing clinically appropriate prompts, facili-   adaptation to healthcare’s unique requirements. Wang et al. [6]\n         tating more responsible integration of LLMs into healthcare   explored terminology adaptation techniques but insufficiently\n         settings.\n                                                                     addressed integration with clinical reasoning patterns. Zhang\n          Index Terms— Large language models, Medical artificial   et  al. [7] proposed Bayesian optimization methods lacking\n          intelligence, Prompt engineering, Evolutionary algorithms,   explicit mechanisms for validating medical accuracy. Li et al.\n          Clinical decision support                                        [2] introduced clinical guardrails primarily focused on post-\n                                                                        generation filtering rather than generating appropriate prompts.\n            Corresponding authors: Yinda Chen, Jing Yang                   Recent advances in chain-of-thought prompting [8] and few-\n              Y. Chen and Y. He contributed equally to this work.                  shot learning [9] have shown promise in medical reasoning\n          The authors extend their appreciation to the Deanship of Research\n         and Graduate Studies at King Khalid University for funding this work   tasks, but these approaches often lack systematic integration\n          through the Large Research Project under grant number RGP.2/275/46.   with clinical knowledge bases and guideline adherence verifi-\n           Yinda Chen is with MoE Key Laboratory of Brain-inspired  Intelli-   cation.\n          gent Perception and Cognition, University of Science and Technol-\n                                                                 These contributions address  isolated aspects of medicalarXiv:2508.17703v1   ogy of China, Hefei 230027, China (corresponding author, e-mail:\n          cyd0806@mail.ustc.edu.cn).                                   prompting without establishing a comprehensive methodology\n           Yangfan  He   is   with  Department   of  Computer   Science,   incorporating domain knowledge, structural requirements, and\n           University  of  Minnesota-Twin  Cities,  Minneapolis, USA  (e-mail:\n         he000577@umn.edu).                                              validation processes. Most approaches evaluate prompt quality\n             Jing Yang and Por Lip Yee are with Center of Research for Cyber   using general metrics rather than clinically relevant criteria.\n           Security and Network (CSNET), Faculty of Computer Science and In-\n                                                                      This  paper  introduces  a  novel  evolutionary framework          formation Technology, Universiti Malaya, 50603 Kuala Lumpur, Malaysia\n           (e-mail: e-mail: s2147529@siswa.um.edu.my; porlip@um.edu.my).       specifically designed for medical prompt optimization that\n          Dapeng  Zhang   is  with  DSLAB,  School  of  Information  Sci-   integrates computational intelligence with structured medical\n         ence &  Engineering, Lanzhou  University, 730000, China  (e-mail:\n                                                              knowledge representation. Our approach consists of four inte-         zhangdp22@lzu.edu.cn).\n           Zhenlong Yuan is with the Institute of Computing Technology, Chi-   grated components:\n         nese Academy of Sciences, Beijing 100190, China (e-mail: yuanzhen-      First, a medical domain representation model implements\n          long21b@ict.ac.cn).\n                                                                    terminology attention grounded in  clinical ontologies,  dif-         Muhammad  Attique  Khan  is  with  Department  of  AI,  Prince\n       Mohammad   bin  Fahd   University,   Al-Khobar,  KSA   (e-mail:   ferentially weighting medical concepts based on semantic\n         mkhan3@pmu.edu.sa).                                        importance and contextual relevance.\n           Jamel Baili is with Department of Computer Engineering, College of\n         Computer Science, King Khalid University, Abha 61413, Saudi Arabia     Second, a multi-dimensional assessment system evaluates\n          (Jabaili@kku.edu.sa).                                        prompts across four clinically significant dimensions: struc-\n\n2\n\n\n\ntural clarity, domain specificity, medical accuracy, and risk of   optimize for general metrics rather than domain-specific re-\nfactual errors.                                                 quirements.\n  Third, a structure-aware evolutionary algorithm operates at\nthe clinical reasoning component level, preserving established                                                         B. Large Language Models in Healthcare\nreasoning patterns while improving effectiveness through spe-\n                                            LLMs show promise in healthcare applications includingcialized crossover and mutation operations. The algorithm in-\n                                                               diagnosis [1], documentation [16], and education [17], butcorporates early stopping mechanisms and adaptive parameter\n                                                                face challenges due to specialized medical knowledge require-tuning to improve computational efficiency while maintaining\n                                                            ments. While domain-specific adaptation improves  perfor-optimization quality.\n                                                   mance on medical benchmarks [1], alignment between LLM   Finally, a medical semantic verification system validates ter-\n                                                               outputs and physician responses remains inconsistent [18].minology usage against standardized lexicons, assesses reason-\ning consistency, and evaluates boundary statements according\nto responsible AI principles. Enhanced verification processes  C. Medical-Specific Prompt Engineering\nspecifically address clinical guideline alignment through inte-                                                                 Specialized medical prompting techniques include adaptive\ngration with evidence-based practice databases.                                                         prompting [6], Bayesian optimization for knowledge elicita-\n  Through experiments across multiple specialties and clinical                                                                    tion [7], clinical guardrails [2], and uncertainty-aware prompt-\nscenarios, we demonstrate that our approach statistically out-                                                              ing [4].\nperforms existing methods across clinically relevant metrics                                                         Contemporary advances include chain-of-thought reason-\nand receives significantly higher ratings from clinicians in                                                              ing in medical contexts [19], demonstrating improved diag-\nblinded evaluations.                                                                  nostic accuracy through structured reasoning prompts. Few-\n  The primary contributions of this research include:                                                               shot learning approaches [20] have shown effectiveness in\n  • A  specialized  medical  prompt  representation  model   clinical prediction tasks, while retrieval-augmented generation\n     with ontology-grounded terminology attention and multi-  methods [21] offer promising directions for integrating current\n     dimensional evaluation framework calibrated to clinical   medical literature into prompt-based systems.\n    communication requirements                               Despite these advances, current approaches typically ad-\n  • A structure-preserving evolutionary algorithm that main-   dress isolated aspects without systematically integrating do-\n     tains clinical reasoning integrity while incorporating com-  main knowledge, reasoning structures, and validation mecha-\n     prehensive semantic verification to ensure medical knowl-   nisms.\n    edge alignment with computational efficiency improve-\n    ments through early stopping and adaptive parameter\n                                                         D. Multimodal Medical AI and Representation Learning\n     selection\n  • Rigorous experimental validation demonstrating signif-    The development of effective medical AI systems increas-\n     icant improvements in factual accuracy, domain speci-   ingly relies on sophisticated representation learning techniques\n      ficity, and  clinician  preference over  current methods   that can capture the complexity of medical knowledge across\n     including comprehensive sensitivity analysis and cross-   different modalities. Recent advances in vision-language pre-\n     institutional validation                                       training have demonstrated significant progress in medical\n                                                                    applications, with approaches ranging from text-guided 3D  The remainder of this paper is organized as follows: Sec-\n                                                          medical image segmentation [22] to comprehensive 3D med-tion II examines relevant literature. Section III presents our\n                                                                         ical image understanding [23].proposed framework. Section IV describes experimental de-\n                                                                 Scalable representation learning approaches, including au-sign and datasets. Section V reports results and comparative\n                                                                  toregressive visual pretraining with mixture token predictionanalyses. Section VI discusses implications and limitations,\n                                                               [24] and conditional latent coding techniques [25], providefollowed by conclusions in Section VII.\n                                                               foundational insights for developing domain-specific embed-\n                                                           ding methods. In medical imaging specifically, multiscale con-\n                           II. RELATED WORK\n                                                                  sistency learning [26] and self-supervised neural segmentation\nA. Prompt Engineering for Large Language Models                                                           approaches [27] have shown effectiveness in learning robust\n  Prompt engineering optimizes large language model perfor-   representations from limited labeled data, while unsupervised\nmance by designing effective text instructions without modi-  domain adaptation methods [28] address the challenge of\nfying underlying parameters [10]. This field has evolved from   cross-institutional generalization.\nsimple templating [9] to sophisticated techniques including    The creation of specialized medical datasets, exemplified\nchain-of-thought prompting [8] and few-shot exemplar selec-  by landmark datasets for 3D CT text-image retrieval [29],\ntion [11].                                                     enables systematic evaluation of multimodal medical AI sys-\n  Recent automated optimization methods include gradient-   tems. Recent investigations into synthetic data generation for\nbased prompt token selection [12] and reinforcement learning   medical applications [30], [31] address critical data scarcity\nfor prompt refinement [13]. Soft prompt tuning approaches   issues while maintaining clinical validity—a challenge directly\n[14]  have  demonstrated  effectiveness  through  parameter-   relevant to our prompt optimization framework, where diverse,\nefficient fine-tuning, while prefix tuning [15] offers alternative   high-quality training examples are essential for robust perfor-\nstrategies for prompt optimization. These approaches typically   mance.\n\n3\n\n\n\n  These advances in medical representation learning inform   levels  stratified as straightforward (30%), moderate (50%),\nour approach to developing specialized embeddings for medi-  and complex (20%). TreatmentSelect-1500: 1,500 therapeutic\ncal prompt optimization, particularly in capturing the semantic   decision-making scenarios balanced across pharmacological\nrelationships between medical concepts and clinical reasoning   (40%), procedural/surgical (30%), and multidisciplinary ap-\npatterns.                                                    proaches (30%). MedHistory-1200: 1,200 complex patient\n                                                                      histories featuring longitudinal data with multiple conditions.\nE. Evolutionary Algorithms for Optimization Problems      PatientEd-1800: 1,800 patient questions requiring explana-\n                                                                    tions at various health literacy levels.  Evolutionary algorithms provide robust optimization  for\n                                                     The specialty distribution was determined based on repre-complex  problems  with  large  search  spaces  and  non-\n                                                                    sentative clinical caseload analysis from major academic med-differentiable objectives [32], proving effective in neural archi-\n                                                                         ical centers. Internal Medicine (24.8%) and Family Medicinetecture search [33], feature selection [34], and hyperparameter\n                                                         (18.5%) represent the highest volumes in primary care settings,optimization [35].\n                                                           while Emergency Medicine (14.2%) reflects acute care presen-  Evolutionary approaches have demonstrated remarkable ver-\n                                                                      tation patterns. Specialty-specific distributions were validatedsatility across diverse AI applications. In computer vision,\n                                                                 against national healthcare utilization statistics and adjustedsuccessful implementations include joint-motion mutual learn-\n                                                                    for case complexity to ensure adequate representation of rareing for video pose estimation [36], causal-inspired multitask\n                                                               but critical conditions.learning frameworks [37], and pose-guided human motion\nanalysis  [38]. Advanced applications  in IoT environments     Dataset creation involved: (1) extracting relevant MIMIC-III\n[39] showcase the adaptability of evolutionary optimization   cases, (2) enhanced de-identification, (3) UMLS terminology\nto resource-constrained settings, providing insights relevant to   standardization, and (4) expert review for clinical validity.\nclinical deployment scenarios where computational efficiency   Table I shows the distribution across medical specialties.\nis critical.\n  In language processing, evolutionary methods have been  TABLE I: Distribution of cases across medical specialties in\napplied to summarization [40], sentiment analysis [41], and   the combined datasets\nprompt optimization [42]. Guo et al. [42] showed that genetic                     Specialty                 Percentage\nalgorithms can effectively optimize prompts for text genera-                       Internal Medicine           24.8%\ntion, sometimes outperforming gradient-based methods.                         Family Medicine            18.5%\n                                                                                 Emergency Medicine        14.2%\n  However,  evolutionary  algorithms remain  largely unex-                                                                                                       Pediatrics                 10.7%\nplored for medical prompt optimization. The structured nature                      Obstetrics & Gynecology     7.6%\nof medical knowledge presents unique opportunities for spe-                     Psychiatry                 6.8%\n                                                                                          Surgery                   6.3%\ncialized evolutionary operators that preserve critical domain                                                                                     Neurology                 4.5%\npatterns while optimizing performance.                                             Cardiology                 3.2%\n                                                                                  Oncology                  2.1%\n                                                                                    Dermatology               1.3%\n                              III. DATASETS\n\n  To evaluate our framework comprehensively, we compiled\nfour specialized clinical datasets spanning different medical\nscenarios.\n                                                         B. Expert Annotation and Prompt Library\n\nA. Clinical Datasets Overview                            Each dataset was annotated by board-certified physicians,\n  Our datasets were derived from the MIMIC-III database,   including gold-standard responses and critical medical con-\na large, freely-available database of de-identified critical care   cepts. Inter-annotator agreement was achieved through a three-\ndata [43]. The use of MIMIC-III was approved by the In-   phase process: initial independent annotation, structured dis-\nstitutional Review Boards of Beth Israel Deaconess Medical   agreement  resolution, and  final consensus building. When\nCenter (2001-P-001699/14) and MIT (0403000206). All data   annotators disagreed (occurring in 12.3% of cases), a formal\nprocessing adhered to the data use agreement.                  adjudication process involved senior clinicians from relevant\n  Dataset construction followed a systematic process to ensure   specialties. Disagreements were categorized as clinical judg-\nclinical  validity and  diversity. From MIMIC-III admission  ment variations (67%), terminology preferences (21%), or gen-\nnotes, discharge summaries, and clinical reports, we extracted   uine errors (12%). All cases with clinical judgment variations\nrelevant clinical presentations using automated text mining fol-  were retained with majority consensus, while terminology\nlowed by manual curation. The conversion process involved:   conflicts were resolved using standardized medical lexicons.\n(1) anonymization verification beyond MIMIC-III standards,   Inter-annotator agreement achieved a Cohen’s kappa of 0.87.\n(2)  clinical scenario standardization using established case   We developed a library of 340 medical prompt templates\npresentation formats, (3) complexity stratification by board-   designed by medical educators and AI specialists, categorized\ncertified physicians, and  (4) cross-validation with external  by scenario type, structure, complexity level, and directive\nclinical databases to ensure representativeness.                    style. Table  II provides representative examples of prompt\n  From  this foundation, we  created: MedDiagnosis-2000:   templates across different categories to illustrate the diversity\n2,000 clinical vignettes across 12 specialties, with complexity  and structure of our template library.\n\n4\n\n\n\nTABLE II: Representative examples from the medical prompt                                                                    1) Terminology-Enhanced Embeddings: Given a prompt P\ntemplate library                                                                 consisting of tokens [t1, t2, ..., tn], we first process it through\n                                                           a pre-trained clinical language model fθ (BioClinicalBERT       Category        Template Example\n                                                                  [46]) to obtain contextual token embeddings:\n  Diagnostic Reasoning   As a [specialty] consultant, analyze this\n                          case using differential diagnosis framework: [case].\n                         Consider pre-test probabilities                  H = fθ(P) ∈Rn×d                   (1)\n                       and provide confidence calibration.\n                                                        where H = [h1, h2, ..., hn] and d is the model’s hidden\n   Treatment Planning   You are managing a patient with [condition].\n                                                            dimension.\n                          Evaluate treatment options considering:\n                         evidence quality, contraindications, patient factors.   We then implement a medical concept identification module\n                    Recommend approach with rationale.              that maps tokens to concepts in the Unified Medical Language\n                                                      System (UMLS) ontology. For ambiguous UMLS mappings,    Patient Education     Explain [medical condition] to a patient\n                         with [literacy level]. Use appropriate analogies,   we employ a disambiguation algorithm that considers local\n                          address common concerns,                     context windows and semantic type consistency. Missing terms\n                          ensure comprehension checks.                   are handled through fuzzy matching against medical lexicons\n Clinical Documentation  Generate clinical note for [scenario]          (SNOMED-CT, ICD-10) with manual validation for terms\n                          following [documentation standard]. Include       with confidence scores below 0.8. For each identified medical\n                          assessment, plan, and follow-up requirements.     concept ci spanning tokens from position a to b, we compute\n                                                           a concept-level representation:\n\nC. Evaluation Methodology                                                     1       b\n                                                                mci =   X hj                 (2)\n                                                                                       b −a + 1  Datasets were divided into development (60%), validation                                  j=a\n(20%), and test (20%) splits, stratified by specialty, complexity,\n                                                               Next, we calculate concept importance weights using an at-\nand scenario type. Cross-institutional validation was conducted\n                                                                   tention mechanism incorporating both semantic and structural\nusing datasets from three additional medical centers to assess\n                                                                       factors:\ngeneralizability beyond MIMIC-III derived cases.\n                                                                  exp(ws · sci + wh · hci + wp · pci)\n                                                                αi =                                                (3)\n                         IV. METHOD                Pj exp(ws · scj + wh · hcj + wp · pcj)\n\n  Our approach implements a structured evolutionary frame-     where  sci  represents semantic importance derived from\nwork for optimizing medical prompts through medical-specific   the concept’s UMLS semantic type, hci captures hierarchi-\nrepresentation learning, multi-dimensional quality assessment,   cal importance based on the concept’s position in medical\nand component-level evolutionary optimization with  clini-   taxonomies, and pci  reflects positional relevance within the\ncal knowledge verification. Figure 1 illustrates the complete  prompt structure. The weights ws, wh, and wp are learned\nEMPOWER framework, showing how medical prompts are   during training.\nsystematically optimized through specialized representation    The terminology-enhanced prompt representation  is then\nlearning, component-level evolutionary operations, and multi-  computed as:\ndimensional quality assessment with clinical knowledge veri-\nfication.                                                        zP = Wg[hCLS; X αimci] + bg           (4)\n                                                                                                                                             i\n\n                                                        where hCLS is the [CLS] token representation, [·; ·] denotes\nA. Medical Prompt Representation Learning                                                                concatenation, and Wg ∈Rd′×2d and bg ∈Rd′ are learnable\n   Effective prompt optimization requires specialized represen-   parameters that project the concatenated vector to dimension\ntations that capture the nuances of medical language and rea-   d′.\nsoning. Recent advances in medical AI representation learning     2) Clinical Reasoning Structure Encoding: Medical prompts\nprovide valuable insights for this challenge. Success in vision-   typically contain specific reasoning structures that guide diag-\nlanguage pretraining for medical applications [22], [23], [44]   nosis, treatment selection, or patient explanation. We encode\nand scalable autoregressive approaches [24] demonstrates the   these structures through a specialized component that identifies\nimportance of domain-specific representation techniques that  and represents key reasoning elements:\ncan effectively encode complex medical knowledge.\n                                                          K\n  Building on insights from multiscale consistency learning\n                                                                         rP = X wjej                      (5)[26] and self-supervised medical image analysis [27], [45],\n                                                                                   j=1\nwe developed a domain-specific embedding model that empha-\nsizes clinically relevant concepts and their relationships. Our     where ej represents embeddings of K identified reasoning\napproach adapts proven representation learning principles from  components  (e.g., symptom  analysis,  differential consider-\nmedical imaging to the unique challenges of textual medical   ation, evidence  evaluation), and wj  are  attention weights\nprompting.                                             computed based on component presence and quality.\n\n5\n\n\n\n                                                                                                                                           Parent A                Parent B\n                                                                            Terminology           �1\n                                                                          Encoding                                     �   q(�1�) > q(�1�)     �                                                                                            �1              �1\n                                                                        �2\n\n                                                                                                                                �                                                                                        Structure   …             �2�   q(�2�) < q(�2�)   �2\n                                                                          Encoding\n                       Medical Prompt                                     ��\n                             Library                                                             �3�      SematicFusion     �3�\n                                                                                   Initial Generation                                              Child P\n                                                                                            �1�    �2�   �( �3�, �3�)\n                        Multi-Dimensional Quality Assessment Q(P)\n                                                             F(P)\n                                      Structural Clarity           Clinical Relevance                                                  Crossover\n                                Medical Specificity         Factual Accuracy             Selection\n\n                           Medical Semantic Verification   V(P)                                                                                  �1�   �2�          No Mutation\n                             Terminology        Reasoning       Boundary                          High q(C)\n                                   Verification        Coherence        Statement                                              Synonym\n                                                                                                                         Elaborate                                       Q(P) ,       if V(P) ≥ �                                  �( �3�, �3�)                                                                                                                      Simplify\n                                F(P) =   Q(P) ∙�(�)                                                                                                                       , otherwise  F(P)                       Low q(C)                          Replace                                                  �\n\n                                 Fitness Evaluation                                                    Controlled Mutation\nFig. 1: Overview of the EMPOWER framework: The complete evolutionary optimization pipeline for medical prompts, showing\ninitial generation with terminology and structure encoding, multi-dimensional quality assessment, fitness evaluation, selection,\ncrossover with semantic fusion, and controlled mutation components.\n\n\n\n  The final prompt representation combines terminology and     Clinical  Relevance: Evaluates alignment with  standard\nreasoning structure information:                                    clinical approaches and the prompt’s ability to elicit medically\n                                                                   relevant information for the specific case.\n                 zfinalP  = Wf[zP ; rP ] + bf               (6)     Factual Accuracy Risk: Estimates the likelihood that a\n                                                            response to this prompt would contain factual errors or un-\n  with Wf  ∈Rd′′×(d′+K) and bf ∈Rd′′  as learnable   supported assertions, with higher scores indicating lower risk.\nparameters.                                                         2) Integrated Quality Score: The overall prompt quality is\n                                                           determined through an adaptive weighting mechanism that\n                                                                   adjusts dimension importance based on the clinical scenario:\nB. Multi-Dimensional Quality Assessment\n\n  We developed a  specialized  evaluation framework  that              Q(P) = X wc(s) · sc(P)               (8)\nassesses prompt quality across four  clinically relevant  di-                                   c\nmensions through independent neural network heads, each\ncalibrated to specific aspects of medical communication.         where wc(s) represents the importance weight for dimen-\n  1) Dimension-Specific Evaluation: Each quality dimension   sion c in scenario s, with Pc wc(s) =  1. These weights\nis evaluated by a specialized network that maps the prompt  were determined through a combination of expert judgment\nrepresentation to a quality score:                           and empirical validation, with accuracy risk receiving higher\n                                                          weight in scenarios involving direct clinical recommendations.\n                                                                    3) Training the Quality Assessment Model: The quality as-\n      sc(P) = σ(W(2)c GeLU(LayerNorm(                   sessment model was trained on a dataset of 3,500 expert-                                                              (7)\n                  W(1)c  zfinalP  + b(1)c  )) + b(2)c  ))          annotated prompts using a multi-task learning approach. The\n                                                                    loss function combines dimension-specific losses with overall\n  where c ∈{clarity, specificity, relevance, accuracy} repre-   quality prediction:\nsents the evaluation dimension, σ is the sigmoid function, and\nGeLU is the Gaussian Error Linear Unit activation.\n                                                  L = X λcLc + λQLQ                 (9)\n  The four evaluation dimensions capture distinct aspects of\n                                                                                                       c\nprompt quality:\n  Structural Clarity: Assesses the organizational coherence     where Lc is the mean squared error for dimension c, LQ is\nand logical flow of the prompt, evaluating whether  it estab-   the overall quality prediction loss, and λc and λQ are balancing\nlishes clear roles, expectations, and reasoning frameworks.     hyperparameters.\n  Medical  Specificity: Measures the degree to which the    The model achieved a Pearson correlation of 0.87 with ex-\nprompt incorporates domain-specific terminology, concepts,   pert ratings on held-out validation data, demonstrating strong\nand reasoning patterns appropriate to the clinical scenario.     alignment with human quality assessments.\n\n6\n\n\n\nC. Structure-Aware Evolutionary Optimization                  5) Structure-Preserving Crossover: Our crossover operation\n                                                               preserves the structural integrity of medical reasoning while\n  Our evolutionary framework optimizes prompts through\n                                                        combining  high-quality components from  parent prompts.\nspecialized genetic operations that preserve clinical reasoning\n                                                       Given parent prompts Pa and Pb, we generate a child promptintegrity while improving overall effectiveness. The framework\n                                                           through component-level recombination:\nincorporates computational efficiency improvements through\nearly stopping criteria and adaptive parameter adjustment.\n  1) Prompt Component Representation: We represent each       Cai ,             if q(Cai ) > q(Cbi ) + δ or r < pa\n                                   prompt as a structured collection of distinct components:         Cchildi  =                                                        Cbi ,             if q(Cbi ) > q(Cai ) + δ or r < pb\n                                   ϕ(Cai , Cbi ),  otherwise\n             P = {C1, C2, ..., Cm}               (10)                                                           (14)\n                                                        where q(Ci)  is the component-specific quality score, δ\n  where each component Ci belongs to a specific category                                                                               is a threshold parameter, r  is a random value between 0\n(e.g., role definition, reasoning framework, information re-                                                       and 1, pa and pb are selection probabilities proportional to\nquest, uncertainty expression, or boundary statement). This                                                                   overall prompt quality, and ϕ(·, ·) is a semantic fusion function\nrepresentation allows for granular optimization while main-                                                                      that combines elements from both components when their\ntaining prompt coherence.                                                                 individual qualities are similar.\n  2) Initial Population Generation: The  initial population of                                                            For the semantic fusion function, we implement a structured\nprompts P = {P1, P2, ..., PN} is generated by sampling com-   contextual merging approach that preserves critical medical\nponents from a curated library of medical prompt elements.                                                            concepts while aligning with the reasoning scaffold of the\nEach prompt is assembled according to scenario-specific tem-                                                                     better-quality component:\nplates that ensure basic structural validity. Components are\nselected with  probabilities proportional  to  their individual\n                                                      ψ(Cai , Cbi ) = M(E(Cai ), E(Cbi ), S(C∗i ))      (15)quality scores from preliminary evaluation.\n  3) Selection Mechanism: We implement a tournament se-     Here, Cai and Cbi represent the i-th components from parent\nlection strategy that balances exploration and exploitation. For   prompts a and  b, respectively. C∗i  denotes the component\neach generation, k candidates are randomly sampled from the   with the higher  quality  score. The function E(·)  extracts\npopulation, and the highest-quality prompt according to the   essential medical concepts from a component, while S(·)\nquality assessment model  is selected with probability psel,   retrieves the structural template associated with the better-\nwhile a random selection occurs with probability 1 −psel:      quality component. Finally, M(·, ·, ·) merges the extracted\n                                                           concept sets from both parents into the selected structure in a\n                                                               semantically consistent manner.      (            arg maxP ∈Sk Q(P),  with probability psel\nPselected =                                                         6) Controlled Mutation: Mutation operations introduce con-\n            random(Sk),         with probability 1 −psel   trolled variations while preserving medical validity. For each\n                                                         (11)                                                     component Ci in a prompt, mutation occurs with probability\n  where Sk is the set of k prompts sampled for the tourna-                                            pm that adaptively decreases with generation number g and\nment.                                                                 increases with component quality distance from optimal:\n  4) Adaptive Parameter Tuning and Early Stopping: To ad-\ndress computational efficiency concerns, we implement adap-                                                                   pm(g, q) = pm0 · γg · (1 −q)β           (16)\ntive parameter adjustment based on population diversity and\nfitness convergence metrics:                                 where pm0 is the initial mutation probability, γ is a decay\n                                                                         factor, and β controls the effect of component quality q on\n                                      σ(g)fitness !               mutation probability.\n             p(g+1)m  = p(g)m  ·  1 + β ·                    (12)    When mutation occurs, we apply one of several medically                                      µ(g)fitness                                                          informed operations:\n  where p(g)m   is the mutation probability  at generation  g,\nσ(g)fitness and µ(g)fitness are the standard deviation and mean      Synonym(Ci),  with probability psyn\nof fitness values, respectively, and β  is an adaptation rate                                   Elaborate(Ci),  with probability pelabparameter.                                                C′i =                                               (17)\n                                                                         Simplify(Ci),   with probability psimp\n  Early stopping is triggered when fitness improvement over      Replace(Ci),    with probability prepthe last 5 generations falls below a threshold ϵ = 0.001:\n                          g                                   where Synonym replaces medical terms with appropriate\n                 1\n           Stop if       X (F best(i+1) −F best)(i) < ϵ        (13)   alternatives from the same semantic category, Elaborate ex-                 5                                      pands key reasoning elements, Simplify reduces verbosity\n                    i=g−4\n                                                           while preserving core content, and Replace substitutes the\n  This mechanism reduces average computational time by  component with a different one from the same functional\n34% while maintaining optimization quality.                    category.\n\n7\n\n\n\nD. Medical Semantic Verification                                5) Integrated Verification Score: The overall semantic veri-\n                                                                      fication score is computed as a weighted sum of term consis-  To  ensure  clinical  validity throughout  the  optimization\n                                                                    tency, reasoning coherence, guideline alignment, and boundaryprocess, we implement a comprehensive verification module\n                                                                appropriateness:that evaluates prompt adherence to medical knowledge and\nreasoning standards. Enhanced verification processes address\nclinical guideline alignment through integration with evidence-                                             V (P) = β1·Vt(P)+β2·Vr(P)+β3·Vguideline(P)+β4·Vb(P)\nbased practice databases and automated guideline consistency                                                                                                                        (22)\nchecking.                                                              Here, Vt(P), Vr(P), Vguideline(P), and Vb(P) denote the\n  1) Terminology Verification: We verify medical terminology                                                                      verification scores for terminology alignment, reasoning logic,\nusing a multi-stage process:                                                                guideline consistency, and boundary statements, respectively.\n                                                   The weights β1, β2, β3, and β4 reflect the relative importance\n             1                                              of each component in assessing the clinical validity of prompt\n Vterm(P) =  X [UMLS(t)·wu +Context(t)·wc] (18)\n             |TP |                                    P.\n                  t∈TP\n\n  where TP  is  the  set  of medical terms  in prompt P,\n                                                        E. Evolutionary Process Integration\nUMLS(t) indicates whether term t has a valid UMLS map-\nping, Context(t) evaluates contextual appropriateness, and wu    The complete evolutionary optimization process integrates\nand wc are weighting factors.                                    quality assessment and semantic verification through a con-\n  2) Reasoning Coherence Analysis: We evaluate the logical   strained fitness function:\nstructure  of  clinical reasoning using a  specialized model\n                                           (trained on expert-validated reasoning patterns:                               Q(P),             if V (P) ≥τ\n                                                     F(P) =         V (P )                       (23)\n                                                            Q(P) ·   τ   ,  otherwise\n\n     Vlogic(P) = flogic(ExtractReasoningChain(P))     (19)     where τ is the minimum acceptable verification score. This\n                                                             formulation ensures that prompts maintain medical validity\n  where ExtractReasoningChain  identifies the sequence of   while optimizing for quality, with a fitness penalty applied\nreasoning steps, and flogic evaluates adherence to valid clinical   to prompts that fail to meet verification standards.\nreasoning patterns.                                      The optimization process continues for a fixed number of\n  3) Enhanced Clinical Guideline Verification: We implement   generations or until convergence criteria are met. The resulting\nautomated guideline consistency checking by integrating with   optimized prompts maintain clinical validity while demonstrat-\nevidence-based practice databases. The verification process   ing improved effectiveness across the quality dimensions.\nevaluates recommendations against current clinical guidelines:\n\n                                                                                 V. EXPERIMENTS\n                    1\n     Vguideline(P) =  X max sim(r, g) · wg     (20)   We conducted comprehensive experiments to evaluate our\n                  |RP |     g∈G\n                       r∈RP                            proposed framework across various clinical scenarios, com-\n                                                              paring against state-of-the-art methods and analyzing the con-  where RP  represents  extracted  recommendations from\n                                                                     tribution of individual components. Our evaluation focused onprompt P, G is the set of guideline statements from medi-\n                                                           both computational metrics and expert assessment to providecal societies, sim(r, g) measures semantic similarity between\n                                                           a holistic view of performance.recommendation r and guideline g, and wg represents the\nevidence quality weight of guideline g.\n  4) Boundary Statement Assessment: We assess the bound-   A. Experimental Setup\nary validity of a prompt by evaluating the presence, complete-\n                                                                    1) Implementation Details: We implemented our framework\nness, and correctness of its safety disclaimers:\n                                                             using PyTorch 1.12.0. The medical representation model was\n                                                                         initialized with BioClinicalBERT [46] weights and fine-tuned\n                                                           with learning rate 2 × 10−5 using AdamW optimizer. Qual-     Vb(P) = α1 · P(B) + α2 · C(B) + α3 · A(B)      (21)\n                                                                           ity assessment modules used GeLU activations with hidden\n  Here, B denotes the set of boundary statements in prompt   dimensions of 512.\nP. The functions P(·), C(·), and A(·) measure the presence,    The evolutionary optimization ran for 50 generations with\ncompleteness, and accuracy of the boundary content, respec-   population size N = 100, tournament size k = 5, selection\ntively. Algorithmic implementation involves pattern match-   probability psel = 0.8, initial mutation probability pm0 = 0.3,\ning for standard medical disclaimers (e.g., ”consult health-   decay factor γ = 0.98, and verification threshold τ = 0.75.\ncare provider,” ”emergency situations”), completeness scoring   Early stopping criteria reduced average computational time\nbased on risk category coverage, and accuracy verification   to 34 generations while maintaining solution quality. Param-\nagainst medical liability guidelines. The weights α1, α2, and   eter sensitivity analysis revealed stable performance across\nα3 determine their relative importance in the overall score  k ∈[3, 7] and psel ∈[0.7, 0.9], indicating robust parameter\nVb(P).                                                              selection.\n\n8\n\n\n\n                                                                            Method Performance Comparison Across Clinical Scenarios  2) Baseline Methods: We compare against several repre-         95\nsentative baselines: EC (manually written prompts by board-\n                                                                               (%) 90\ncertified physicians), AMP [47] (retrieval-augmented method\nadapting prompts based on medical terminology), BPO [48]         85\n(Bayesian optimization for medical knowledge  elicitation),                                                                                                                                                                                                                    Coverage 80CNER [49] (safety-aware structures constraining harmful out-\nputs), and Prompt-eng [50] (general-purpose genetic algorithm         75without domain  adaptations). CoT-Med implements chain-         Concept\nof-thought prompting specifically adapted for medical rea-         70\nsoning tasks, following recent advances in structured clini-                                                                                                       65                   Expert Crafted       BPO         Prompt-eng                                                                                                                                                                                         Medical\ncal reasoning [8]. FSL-Med applies few-shot learning with                     AMP              CNER        Ours\nmedical exemplars selected through similarity matching [9].         60        Diagnosis            Treatment          Medical History          Education\nOur EMPOWER framework incorporates medical terminology\nattention, structure-aware evolutionary operators, and multi-   Fig. 2: Performance comparison across different clinical sce-\ndimensional evaluation.                                         narios using the Medical Concept Coverage metric. Our ap-\n  3) Evaluation Models: We evaluated prompts on three rep-   proach demonstrates consistent improvements across all sce-\nresentative models: GPT-4 (OpenAI), Med-PaLM 2 (Google)   narios, with the most substantial gains in complex diagnostic\n[1], and Llama 2-Med (modified Meta’s Llama 2 with medical   cases.\nfine-tuning).\n  4) Evaluation Metrics: We used automated metrics (Med-                       Reasoning Chain Accuracy Comparison Across Medical Specialties\nical Concept Coverage, Reasoning Chain Accuracy, Factual             Dermatology                                                                 ExpertAMP   Crafted\nConsistency Score, Uncertainty Calibration) and expert assess-                                                                    BPO\n                                                                                                                                        Psychiatry                                                   CNER\nment. A panel of 18 practicing physicians across 12 special-                                                                                 Prompt-eng\n                                                                                                                                                                    Our Method\nties (expanded from initial 12 to address reviewer concerns)                  Pediatrics\nrated responses on Clinical Reliability, Diagnostic/Therapeutic\nAccuracy, Information Completeness, and Patient Communi-                Oncology\ncation Appropriateness using 1-5 scales. Inter-rater reliability      Emergency Medicine\nachieved ICC = 0.82, with systematic bias correction applied\nfor specialty-specific rating patterns.                                                            Neurology\n\n                                                                                                                                     Cardiology\n\nB. Overall Performance                                                                                    Internal Medicine\n  Table III presents the overall performance across all clinical                         60             65             70             75             80             85             90\nscenarios using GPT-4 as the evaluation model. Our method                                              Reasoning Chain Accuracy (%)\ndemonstrates consistent and significant improvements over all                                                               Fig. 3: Reasoning Chain Accuracy (%) across different medi-\nbaselines across both automated metrics and expert evalua-                                                                    cal specialties. Our method shows consistent advantages across\ntions. Statistical significance was assessed using Bonferroni                                                                               all specialties, with particularly strong performance in special-\ncorrection for multiple comparisons, with effect sizes (Cohen’s                                                                            ties involving complex pathophysiological reasoning.\nd) ranging from 0.68 to 1.24, indicating medium to large\npractical significance. The most substantial gains are observed\nin Reasoning Chain Accuracy (79.8% vs. 74.8% for the best                                                                  scenarios, where clinical reasoning complexity is highest. For\nbaseline) and Factual Consistency Score (91.4% vs. 86.1%),                                                                    patient education scenarios,  all methods perform relatively\nwith expert evaluations showing notable improvements  in                                                                   well, but our approach still maintains a significant advantage\nClinical Reliability (4.37 vs. 4.08) and Diagnostic/Therapeutic                                                       (FCS: 93.6% vs. 89.2%).\nAccuracy (4.29  vs.  3.97). The strong performance across\npatient communication metrics (PCA: 4.31) alongside clinical\naccuracy demonstrates  effective balance between technical   D. Performance Across Medical Specialties\ncorrectness and communication clarity.\n                                                               Figure 3 illustrates performance variations across medical\n                                                                        specialties. Our method consistently outperforms baselines\nC. Performance Across Clinical Scenarios                                                               across all specialties, with particularly strong results in Internal\n  Figure 2 shows the performance comparison across different   Medicine, Cardiology, and Neurology—areas that typically\nclinical scenarios using the Medical Concept Coverage metric.   involve complex pathophysiological reasoning.\nOur approach demonstrates consistent improvements across    The performance differential is smaller in specialties with\nall scenarios, with the most  substantial gains  in complex  more standardized presentation and treatment patterns (e.g.,\ndiagnostic cases (87.3% vs. 79.1% for the best baseline).      Dermatology) but remains statistically significant (p < 0.05\n  This pattern is also evident in Table IV, which presents   for all pairwise comparisons).\ndetailed results for each clinical scenario. The improvement\nmargins are particularly pronounced in diagnosis and treatment\n\n9\n\n\n\nTABLE III: Overall performance comparison across all clinical scenarios using GPT-4 as the evaluation model. Values show\nmean ± standard deviation, with best results in bold and second best underlined. † indicates statistically significant improvement\nover the best baseline (p < 0.01, Bonferroni corrected).\n\n                               Automated Metrics                                 Expert Evaluation (1-5)\n Method\n           MCC (%)  RCA (%)   FCS (%)   UC (%)     CR       DTA         IC       PCA\n  Expert-Crafted     72.4 ± 5.3    68.7 ± 4.9    83.2 ± 3.8    71.5 ± 6.2    3.84 ± 0.31    3.79 ± 0.28    3.62 ± 0.35    3.91 ± 0.32\n AMP [47]         74.9 ± 4.8    67.3 ± 5.2    80.4 ± 4.3    69.3 ± 5.8    3.72 ± 0.27    3.68 ± 0.33    3.76 ± 0.29    3.65 ± 0.36\n BPO [48]          77.1 ± 3.9    70.5 ± 4.1    81.9 ± 3.5    73.8 ± 4.9    3.89 ± 0.24    3.82 ± 0.26    3.71 ± 0.30    3.78 ± 0.28\n CNER [49]        75.2 ± 4.2    73.6 ± 3.6    85.7 ± 3.1    74.9 ± 4.5    4.05 ± 0.22    3.86 ± 0.25    3.69 ± 0.28    4.03 ± 0.24\n Prompt-eng [50]    78.6 ± 3.7    71.9 ± 3.9    82.3 ± 3.3    76.2 ± 4.1    3.91 ± 0.26    3.94 ± 0.23    3.88 ± 0.25    3.82 ± 0.27\n CoT-Med [8]       76.3 ± 4.1    74.8 ± 3.7    86.1 ± 3.0    77.1 ± 4.3    4.08 ± 0.23    3.97 ± 0.24    3.82 ± 0.26    4.05 ± 0.25\n FSL-Med [9]       75.8 ± 4.4    72.5 ± 4.0    84.3 ± 3.4    75.6 ± 4.7    3.95 ± 0.25    3.89 ± 0.27    3.77 ± 0.28    3.88 ± 0.29\n Ours              84.3 ± 3.1†   79.8 ± 3.4†   91.4 ± 2.8†   82.7 ± 3.6†   4.37 ± 0.19†   4.29 ± 0.21†   4.18 ± 0.22†   4.31 ± 0.20†\n\n\nTABLE IV: Performance comparison across clinical scenarios  TABLE VI: Ablation study on diagnostic scenarios, showing\nusing Factual Consistency Score (%). Best results in bold.     performance impact of removing individual components. Val-\n                                                           ues are relative changes (%) from full model performance.  Method           Diagnosis   Treatment   History   Education\n   Expert-Crafted        79.7         84.1        81.3        87.4                Configuration        MCC  RCA  FCS  CR\n  AMP [47]            77.3         80.6        79.8        83.9                  Full Model                     0.0      0.0     0.0     0.0\n  BPO [48]            78.5         82.8        80.2        85.6                                                                        w/o Term Attention             -8.4      -7.1     -6.3    -7.8\n  CNER [49]           83.2         86.4        83.5        89.2                                                                        w/o Structure Encoding         -5.7      -9.6     -4.8    -6.5\n   Prompt-eng [50]      79.1         83.7        80.9        85.2                                                                        w/o Multi-Dim Assessment     -4.3      -5.2     -7.9    -8.7\n  CoT-Med [8]         84.6         87.1        84.8        88.9                                                                        w/o Component Crossover      -6.9      -6.7     -5.3    -6.2\n  FSL-Med             82.5         85.3        83.7        86.7                                                                        w/o Semantic Verification      -3.8      -4.5     -8.2    -9.4\n   Ours                 90.3         91.8        89.6        93.6              w/o Early Stopping             -1.2      -0.8     -1.5    -2.1\n                                                                        w/o Guideline Verification      -2.9      -3.4     -5.6    -6.8\nTABLE V: Cross-model generalization: Factual Consistency\nScore (%) of optimized prompts when applied to different  TABLE VII: Parameter sensitivity analysis showing Factual\nLLMs. Best results in bold.                                  Consistency Score (%) across different parameter settings.\n\n     Method         GPT-4  Med-PaLM 2   Llama 2-Med              Parameter           Low       Default      High\n       Expert-Crafted      83.2         80.4             76.7                   Tournament size (k)     88.7 (k=3)   91.4 (k=5)   90.1 (k=7)\n    AMP [47]          80.4         78.9             73.5                      Selection prob. (psel)    89.3 (0.7)    91.4 (0.8)    90.8 (0.9)\n    BPO [48]           81.9         79.6             75.2                    Mutation prob. (pm0)    90.2 (0.2)    91.4 (0.3)    89.6 (0.4)\n    CNER [49]         85.7         83.1             78.6                     Population size (N)      88.9 (50)    91.4 (100)    91.7 (150)\n      Prompt-eng [50]     82.3         80.7             75.8\n     CoT-Med [8]        86.1         83.5             79.2\n     FSL-Med [9]        84.3         81.8             77.9\n      Ours                91.4         88.3             84.1               Several key insights emerge from the ablation study: The\n                                                           terminology attention mechanism contributes substantially to\n                                                        Medical Concept Coverage (-8.4% without it), confirming the\nE. Cross-Model Generalization                            importance of focusing on key medical concepts. Structure\n                                                          encoding has the largest impact on Reasoning Chain Accuracy\n  To evaluate the generalization capabilities of our optimized                                                               (-9.6%), highlighting its role in maintaining clinical reasoning\nprompts, we tested them across  different LLMs. Table V                                                                          integrity. Multi-dimensional assessment and semantic verifica-\npresents the Factual Consistency Scores achieved by prompts                                                                    tion both significantly affect expert-judged Clinical Reliability\noptimized using our method and baselines when applied to                                                          (-8.7% and -9.4% respectively), underscoring their importance\nthree different models.                                                                    for generating  clinically trustworthy prompts. Component-\n  Our method demonstrates robust cross-model generaliza-                                                                     level crossover shows balanced contributions across all met-\ntion, maintaining its performance advantage across all tested                                                                              rics, demonstrating the value of structure-preserving evolu-\nmodels. The relative performance drop when moving from                                                                 tionary operations. Early stopping shows minimal impact on\nGPT-4  to other models  is smaller  for our method (7.3%                                                                          final performance (-1.2% to -2.1%), validating computational\nrelative decrease) compared  to baselines (8-9% decrease),                                                                    efficiency improvements. Guideline  verification  contributes\nindicating  that our optimized prompts are more robust to                                                                     significantly to clinical reliability (-6.8%), demonstrating the\nmodel variations.                                                           importance of evidence-based validation.\n\nF. Ablation Study                                   G. Parameter Sensitivity Analysis\n\n  To understand the contribution of individual components in   We conducted comprehensive sensitivity analysis for key\nour framework, we conducted an ablation study by removing   evolutionary algorithm parameters. Table VII shows perfor-\nkey components and measuring the  resulting performance  mance variations across different parameter settings.\nchange. Table VI presents the results of this analysis on the    The analysis reveals stable performance across reasonable\ndiagnostic scenario subset.                                   parameter ranges, with optimal values providing 1-3% im-\n\n10\n\n\n\n             Factual95      Consistency Score Progression During Evolutionary Optimization        TABLE  IX: Comparison  of  expert-crafted and  optimized\n          (%) 90                                                prompts for diagnostic reasoning.\n\n                                                                    Convergence Phase             Case: 72-year-old female with unilateral headache, scalp tenderness, jaw                Score 85                                 Progressive Optimization Phase\n                                                                                     claudication, vision changes, PMR history.\n                80                                                               Expert-Crafted:\n                75                                                        ”As a medical advisor, analyze this case... What is the most likely diagnosis?\n                          Rapid Improvement Phase                                         Explain reasoning and suggest next steps.”                                    Consistency\n                70                                                 Our Optimized:\n                                                                  ”You                                                                                         are a rheumatology                                                                                                                      consultant...                                                                                                  Apply                                                                                                                              diagnostic                                                                                                                          framework:                                                                                                                                                              (1) Ana-\n                65                                             Our                                                               Method                       Factual                                                                                 lyze cardinal                                                                                 symptoms, (2)                                                                                                     Consider                                                                                                                                      differential                                                                                                                           diagnoses                                                                                                                                   with confidence                                                                   Generic                                                                               Evolutionary Prompting\n                60                  0               10              20              30              40              50                   levels, (3) Identify critical features, (4) Recommend evidence-based workup.\n                                Evolution Generation                                  Distinguish between guidelines and clinical judgment areas.”\n                                                            Key Improvements: Specialty-specific framing, structured reasoning frame-\nFig. 4: Evolution of Factual Consistency Score over 50 gen-     work, confidence calibration, guideline integration.\nerations, comparing our approach with Generic Evolutionary\nPrompting. Our method converges faster and achieves higher\nfinal performance. Red line shows early stopping trigger point   This demonstrates the framework’s robustness across diverse\nat generation 34.                                                     clinical environments and practice patterns.\n\nTABLE VIII: Cross-institutional validation: Factual Consis-                                                                       VI. CASE STUDIES AND ANALYSIS\ntency Score (%) across different medical centers.\n                                                        A. Qualitative Analysis and Framework Components\n  Method    MIMIC-III   Hospital A   Hospital B   Hospital C\n  CNER          85.7          82.3          83.8          81.5          Table IX compares prompts for a temporal arteritis case.\n  CoT-Med       86.1          83.7          84.2          82.9       The optimized prompt demonstrates specialty-specific fram-\n   Ours           91.4          88.9          89.7          87.6\n                                                                     ing, structured reasoning framework, confidence calibration,\n                                                       and guideline integration, resulting in more comprehensive\n                                                                        differential diagnosis with calibrated confidence levels and\nprovement over suboptimal settings. This demonstrates the\n                                                            evidence-based recommendations.\nrobustness of our parameter selection and provides guidance\n                                                                   Structure encoding impact example: ”Analyze this chest\nfor practitioners implementing the framework.\n                                                             pain case and provide diagnosis” versus ”As an emergency\n                                                                 physician, systematically evaluate this chest pain presenta-\nH. Evolutionary Optimization Dynamics                        tion:  (1) Apply HEART  score components,  (2) Consider\n  We analyzed how prompt quality evolves during the op-   life-threatening causes first, (3) Integrate patient-specific risk\ntimization process. Figure 4 shows the progression of key   factors, (4) Recommend disposition with rationale.” The struc-\nmetrics over 50 generations of evolutionary optimization for   tured version guides systematic clinical reasoning, resulting in\nboth our method and the Generic Evolutionary Prompting  23% higher Reasoning Chain Accuracy scores.\nbaseline.                                                    Algorithm 1 provides boundary statement verification pseu-\n  Our method demonstrates significantly faster convergence   docode, implementing pattern matching for standard medical\n(reaching near-optimal performance by generation 30, with   disclaimers, completeness  scoring based on  risk  category\nearly stopping triggered  at generation 34 on average) and   coverage, and accuracy verification against medical liability\nachieves higher terminal performance. The structured com-   guidelines.\nponents and domain-specific operators enable more efficient\nsearch in the prompt space, avoiding the performance plateaus\n                                                         B. Evolutionary Component Analysis\nobserved in the generic approach.\n  The performance gain is particularly evident in early genera-     Figure 5 shows component modification rates across genera-\ntions (G5-G15), where our method makes rapid improvements   tions. Reasoning frameworks undergo significant modifications\nthrough targeted modifications of clinical components. This   in early generations (G1-G15), indicating their importance in\nsuggests that the structure-aware approach effectively lever-   establishing proper clinical reasoning structure. Role defini-\nages domain knowledge to guide the search process toward   tions stabilize quickly (by G20), while uncertainty expression\npromising regions of the prompt space.                     components evolve throughout, reflecting nuanced calibration\n                                                               requirements. Boundary statements see renewed modification\n                                                                    in later generations (G30-G50) as the system fine-tunes model\nI. Cross-Institutional Validation\n                                                                      limitations.\n  To  assess  generalizability  beyond  MIMIC-III  derived\ndatasets, we conducted validation using clinical cases from\n                                                      C. Error Analysisthree additional medical centers (anonymized as Hospital A,\nB, and C). Table VIII presents performance comparison across     Table X presents error type distributions. Our method sig-\ninstitutions.                                                         nificantly reduces factual inaccuracies, reasoning gaps, and\n  Our method maintains consistent performance advantages   overly general advice—the most critical error types from a\nacross different institutional contexts, with performance degra-   clinical perspective. However,  it shows increased  rates of\ndation of only 2.5-4.2% compared to 3.4-4.6% for baselines.   guideline misalignment (reduced from the originally reported\n\n11\n\n\n\n                                            TABLE X: Distribution of error types across different methods Algorithm 1: Boundary Statement Verification\n                                              (% of total errors).\n   Input: Prompt P, Risk category R\n  Output: Boundary score Vb(P)                                        Error Type              Baselines   Ours  ∆\n                                                                                          Factual inaccuracy           28.3      14.5    -13.8 1 Step 1: Pattern Matching for Presence\n                                                                                Reasoning gaps              25.7      12.3    -13.4\n 2 patterns ←[”consult healthcare provider”,                              Overly general advice        18.4       9.2      -9.2\n    ”emergency situations”, ”not substitute for medical                    Missing clinical context      15.2      19.8    +4.6\n    advice”]                                                                        Guideline misalignment       8.6       18.3    +9.7\n                                              found in P }|                           Ambiguous phrasing          3.8        7.5     +3.7\n 3 presence score ←|{p∈patterns:p|patterns|\n 4 Step 2: Completeness Assessment\n 5 required elements ←GetRequiredElements(R)                                  VII. DISCUSSION\n 6 completeness score ←\n                                                        A. Clinical Implications and Technical Insights     |{e∈required elements:e addressed in P }|\n              |required elements|                             The significant improvements demonstrated by our frame-\n 7 Step 3: Accuracy Verification                                                    work directly address key concerns about LLM  reliability\n 8 accuracy score ←\n                                                                    in healthcare settings. By systematically improving prompt\n    CheckAgainstLiabilityGuidelines(P)                                                                 design, we substantially reduce factually incorrect responses\n 9 Step 4: Weighted Combination                                                             without requiring model retraining. The cross-model gener-\n10 Vb(P) ←α1 · presence score + α2 ·                                                                      alization provides a model-agnostic method for improving\n   completeness score + α3 · accuracy score                                                                        clinical outputs, valuable given rapid LLM evolution.\n11 return Vb(P)                                                     Our evolutionary approach offers distinct advantages com-\n                                                            pared to recent prompt optimization techniques. Unlike soft\n       Modification Rates of Different Component Types During Evolution       prompt tuning [14], which requires model-specific parameter\n (%) 80                                                                 Role Definition          optimization, our method operates at the text level and gener-\n                                                                        Framework           Initial Optimization Phase                                 Reasoning\n                                                                         Uncertainty Rate 70                                                          Boundary StatementsExpression     alizesour approachacross differentmaintainsLLMs.interpretabilityComparedandto prefixallowstuningfor explicit[15],\n                          Mid-term Adjustment Phase           Information Requests\n                                                                incorporation of  clinical guidelines and safety  constraints.     60\n                                                           Fine-tuning Phase           Chain-of-thought prompting [8], while effective for structured\n     50                                                            reasoning,  lacks  the systematic optimization and domain-    Modification\n                                                                      specific adaptation that our framework provides.     40\n                                                     Our framework contributes to the evolving ecosystem of\n     30                                                       medical AI optimization techniques. While our focus addresses   Component                                                                 textual prompt optimization, the broader medical AI land-     20\n                                                         scape—including advances in 3D medical image understand-\n     10                                                          ing [23], vision-language pretraining for medical image seg-  Prompt\n           0              10             20             30             40             50      mentation [22], multimodal medical datasets [29], and special-\n                          Evolution Generation                                                                ized representation learning techniques [24], [26], [27]—sug-\nFig. 5: Percentage of prompts with significant modifications   gests opportunities for integrated optimization frameworks.\n to different component types across generations.             The success of synthetic data generation methods [30], [31]\n                                                       and domain adaptation techniques [28] in addressing medical\n                                                  AI challenges parallels our approach to systematically opti-\n36.7% through enhanced verification processes) and missing   mizing medical prompts through evolutionary methods.\n clinical context errors.                                          Future developments could combine our prompt optimiza-\n   Guideline Misalignment Example: In a hypertension man-   tion approach with multimodal medical AI systems, creating\nagement case, our optimized prompt generated ACE inhibitor   comprehensive clinical decision support tools that optimize\nrecommendations without noting pregnancy contraindications   both textual and visual medical AI components. The rep-\n for a 28-year-old female. This occurred because evolutionary   resentation learning insights from medical imaging applica-\noptimization prioritized general effectiveness over comprehen-   tions [22], [26] provide valuable directions for enhancing our\n sive safety considerations.                                   medical concept encoding mechanisms, while advances in\n   Potential  Solutions:  (1) Enhanced  constraint weighting   conditional latent coding [25] offer potential improvements\n for safety-critical scenarios, (2) Integration of contraindica-   for prompt representation efficiency.\n tion databases in real-time verification, (3) Specialty-specific     Several key technical insights emerge from our work: The\nguideline validation modules.                                terminology attention mechanism highlights the importance\n   This analysis suggests our approach effectively addresses   of domain-specific concept focus, while structure-preserving\nfundamental reasoning and factual accuracy issues, while more   evolutionary operations prove more efficient than generic ap-\nstructured outputs reveal subtle discrepancies with  clinical   proaches. The multi-dimensional quality assessment provides\n guidelines, providing direction for future improvements in   nuanced fitness optimization, avoiding single-metric failure\nguideline alignment and contextual comprehensiveness.       modes common in previous approaches. The success of evo-\n                                                                  lutionary optimization in related domains [36]–[39] validates\n\n12\n\n\n\nour choice of evolutionary approaches for complex, multi-   generate clinically robust prompts. The experimental results\ndimensional optimization problems in specialized domains.     demonstrate  significant improvements: 24.7% reduction  in\n  The integration of early stopping mechanisms and adaptive   factually incorrect content, 19.6% enhancement in domain\nparameter tuning addresses practical deployment concerns.   specificity, and 15.3% higher clinician preference in blinded\nOur framework reduces computational requirements by an   evaluations, with consistency across different clinical scenar-\naverage of 34% while maintaining optimization quality, mak-   ios, medical specialties, and LLM architectures. Key techni-\ning  it more  accessible  for resource-constrained healthcare   cal contributions include the medical terminology attention\nenvironments. The parameter sensitivity analysis demonstrates  mechanism, multi-dimensional quality assessment framework,\nrobustness across reasonable parameter ranges, reducing the   structure-aware evolutionary algorithm, and semantic verifica-\nneed  for extensive hyperparameter tuning  in new deploy-   tion system. Enhanced computational efficiency through early\nments. This computational efficiency consideration aligns with   stopping mechanisms and adaptive parameter selection makes\nbroader trends in medical AI toward  practical, deployable   the framework more practical for real-world deployment. The\nsolutions that balance performance with resource constraints.   framework’s robustness is demonstrated through comprehen-\n                                                                   sive sensitivity analysis and cross-institutional validation.\n                                                        While limitations  exist regarding computational require-\nB. Limitations\n                                                       ments and  specialized  medical knowledge  resources,  the\n  Despite promising  results, several  limitations should be  framework provides significant advancement in developing\nacknowledged: Our evaluation focuses on specific clinical sce-   clinically appropriate prompts for LLMs. Future work will\nnarios and may not capture performance across the full breadth   focus on addressing guideline alignment challenges, expanding\nof medical practice. The expert evaluation, while expanded   cross-cultural validation, and developing deployment tools for\nto 18 clinicians across 12 specialties, necessarily relies on a   healthcare organizations. Our work contributes to responsi-\nlimited number of clinicians. Our approach assumes access   ble AI integration in healthcare by providing a systematic\nto medical knowledge resources (UMLS, clinical guidelines)  method for optimizing the interface between clinical knowl-\nthat may not be universally available. However, the framework   edge and  artificial intelligence systems. As LLMs become\nincludes mechanisms for rapid updating when new medical   increasingly prevalent in medical applications, frameworks like\nknowledge or guidelines become available through modular  EMPOWER will be essential for ensuring their safe, effective,\nknowledge base integration.                               and beneficial use in clinical practice.\n  While cross-institutional validation demonstrates robustness\nacross  different medical  centers, broader generalization  to                   REFERENCES\ninternational healthcare systems, different languages, and vary-\ning practice patterns requires further investigation. Finally,     [1] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Marks, A. Nori, S. Hartzell,\nalthough computational efficiency has been improved through        C. Mayer, N. Peters, P. Divanji, et al., “Med-palm 2: Towards expert-\nearly stopping, the evolutionary optimization process may          level medical question answering with large language models,” Nature\n                                                                                Medicine, vol. 29, no. 10, pp. 2556–2568, 2023.\nstill require substantial computational resources compared to     [2] Y. Li, M. A. Patel, T. J. Callahan, P.-H. Chen, S. B. Hoebel, S. Kheter-\nsimpler prompting approaches.                                                     pal, M. A. Morris, B. Mukherjee, O. Uzuner, K. Xie, et  al., “Clin-\n                                                                                                  ical guardrails for large language models in healthcare,” npj Digital\n                                                                                Medicine, vol. 7, no. 1, p. 45, 2024.\nC. Practical Deployment Considerations                             [3] H. Jiang, J. Zhao, Y. Xiong, X. Wang, D. Zhang, and J. Zou, “Prompt-\n                                                                             based clinical decision support with large language models: A systematic\n  Real-world deployment faces several challenges: (1) Inte-         survey,” IEEE Journal of Biomedical and Health Informatics, vol. 28,\ngration with existing Electronic Health Record (EHR) systems         no. 2, pp. 762–775, 2024.\n                                                                                      [4]  S. Chen, L. Lin, W. Yang, X. Xie, and S. K. Zhou, “Uncertainty-\nrequires careful API design and security considerations, (2)                                                                           aware prompt engineering for medical image analysis,” Medical Image\nRegulatory compliance varies across jurisdictions and may         Analysis, vol. 88, p. 102947, 2024.\nrequire extensive validation studies, (3) Clinical workflow inte-     [5] Y. Chen, C. Liu, W. Huang, S. Cheng, R. Arcucci, and Z. Xiong, “Gen-\n                                                                                            erative text-guided 3d vision-language pretraining for unified medical\ngration must minimize disruption while maximizing utility, (4)                                                                        image segmentation,” arXiv preprint arXiv:2306.04811, 2023.\nContinuous updating mechanisms are needed to incorporate     [6] H. Wang,  J. Yang, Y. Liu,  J. Chen, M. Gao, Y. Wang, C. Wang,\nevolving medical knowledge and guidelines.                          X. Ren, and C. Xiao, “Adaptive prompt engineering for medical query\n                                                                                 understanding and  retrieval,” ACM Transactions on Computing  for\n  Despite these challenges, the framework’s modular design                                                                                  Healthcare, vol. 5, no. 1, pp. 1–24, 2023.\nfacilitates gradual implementation, allowing healthcare orga-     [7] K. Zhang, R. Miotto, F. Wang, J. T. Dudley, and B. Chen, “Bayesian\nnizations to deploy individual components (e.g., terminology        prompt optimization for medical knowledge elicitation,” IEEE Transac-\n                                                                                           tions on Medical Imaging, vol. 42, no. 12, pp. 3495–3507, 2023.\nverification) before full system integration.                                                                                      [8]  J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. Chi,\n                                                                         Q. Le, and D. Zhou, “Chain of thought prompting elicits reasoning\n                                                                                           in large language models,” Advances in Neural Information Processing\n                    VIII. CONCLUSIONS                                                                                   Systems, vol. 35, pp. 24824–24837, 2022.\n  This paper introduces EMPOWER, a comprehensive evo-     [9]  T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,\n                                                                         A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., “Language mod-\nlutionary framework  for optimizing medical prompts  that          els are few-shot learners,” Advances in Neural Information Processing\naddresses critical challenges in healthcare AI applications. Our         Systems, vol. 33, pp. 1877–1901, 2020.\napproach integrates specialized representation learning, multi-    [10]  P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-\n                                                                                                      train, prompt, and predict: A systematic survey of prompting methods\ndimensional quality assessment, structure-preserving evolu-          in natural language processing,” ACM Computing Surveys, vol. 55, no. 9,\ntionary optimization, and medical semantic  verification  to         pp. 1–35, 2023.\n\n13\n\n\n\n\n[11] O. Rubin, J. Herzig, and J. Berant, “Learning to retrieve prompts for    [31] H. Qian, Y. Chen, S. Lou, F. S. Khan, X. Jin, and D.-P. Fan, “Mask-\n      in-context learning,” Proceedings of the 2022 Conference of the North          factory: Towards high-quality synthetic data generation for dichotomous\n     American Chapter of the Association for Computational Linguistics,        image segmentation,” NeurIPS, 2024.\n     pp. 2655–2671, 2022.                                                    [32]  T. Back, Evolutionary Algorithms in Theory and Practice: Evolution\n[12]  T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh, “Auto-          Strategies, Evolutionary Programming, Genetic Algorithms.  Oxford\n     prompt: Eliciting knowledge from language models with automatically         University Press, 1996.\n     generated prompts,” Proceedings of the 2020 Conference on Empirical    [33] E. Real, A. Aggarwal, Y. Huang, and Q. V. Le, “Regularized evolution\n     Methods in Natural Language Processing, pp. 4222–4235, 2020.                for image  classifier  architecture  search,” Proceedings  of  the AAAI\n[13] Y. Zhou, A. Muresanu, Z. Han, K. Paster, S. Pitis, H. Chan, and J. Ba,        Conference on Artificial Intelligence, vol. 33, no. 01, pp. 4780–4789,\n     “Large language models are human-level prompt engineers,” Advances        2019.\n      in Neural Information Processing Systems, vol. 35, pp. 16777–16791,    [34] B. Xue, M. Zhang, W. N. Browne, and X. Yao, “A survey on evolutionary\n     2022.                                                                    computation approaches to feature selection,” IEEE Transactions on\n[14] B.  Lester, R. Al-Rfou, and N. Constant, “The power of scale for         Evolutionary Computation, vol. 20, no. 4, pp. 606–626, 2016.\n      parameter-efficient prompt tuning,” in Proceedings of the 2021 Confer-    [35]  S. R. Young, D. C. Rose, T. P. Karnowski, S.-H. Lim, and R. M. Patton,\n     ence on Empirical Methods in Natural Language Processing, (Online        “Optimizing deep learning hyper-parameters through an evolutionary\n     and Punta Cana, Dominican Republic), pp. 3045–3059, Association for         algorithm,” Proceedings of the Workshop on Machine Learning in High-\n     Computational Linguistics, Nov. 2021.                                     Performance Computing Environments, pp. 1–5, 2015.\n[15] X. L. Li and P. Liang, “Prefix-tuning: Optimizing continuous prompts    [36]  S. Wu, H. Chen, Y. Yin, S. Hu, R. Feng, Y.  Jiao, Z. Yang, and\n      for generation,” in Proceedings of the 59th Annual Meeting of the Asso-         Z. Liu, “Joint-motion mutual learning for pose estimation in video,” in\n      ciation for Computational Linguistics and the 11th International Joint        Proceedings of the 32nd ACM International Conference on Multimedia,\n     Conference on Natural Language Processing (Volume 1: Long Papers),         pp. 8962–8971, 2024.\n      (Online), pp. 4582–4597, Association for Computational Linguistics,    [37] H. Chen, S. Wu, Z. Wang, Y. Yin, Y. Jiao, Y. Lyu, and Z. Liu, “Causal-\n     Aug. 2021.                                                                       inspired multitask learning for video-based human pose estimation,” in\n[16] B. Patel, Y. H. Chen,  J. Patel, A. Abughanam, P. Boshier, A. Rao,        Proceedings of the AAAI Conference on Artificial Intelligence, vol. 39,\n    M. Tan, R. Talbot, B. Rini, R. Neves, et al., “Evaluation of gpt-4 for         pp. 2052–2060, 2025.\n     medical summary generation,” IEEE Transactions on Medical Imaging,    [38]  S. Wu, Z. Liu, B. Zhang, R. Zimmermann, Z. Ba, X. Zhang, and K. Ren,\n      vol. 42, no. 12, pp. 3386–3395, 2023.                               “Do as i do: Pose guided human motion copy,” IEEE Transactions on\n[17]  T. H. Kung, M. Cheatham, A. Medenilla, C.  Sillos, L. De Leon,        Dependable and Secure Computing, vol. 21, no. 6, pp. 5293–5307, 2024.\n     C. Elepa˜no, M. Madriaga, R. Aggabao, G. Diaz-Candido, J. Maningo,    [39]  S. Wu, H. Zhang, Z. Liu, H. Chen, and Y. Jiao, “Enhancing human pose\n      et  al., “Performance of chatgpt on usmle: Potential  for  ai-assisted         estimation in internet of things via diffusion generative models,” IEEE\n     medical education using large language models,” PLOS Digital Health,          Internet of Things Journal, vol. 12, no. 10, pp. 13556–13567, 2025.\n      vol. 2, no. 2, p. e0000198, 2023.                                         [40] M. A. Fattah and F. Ren, “Automatic text summarization using evolu-\n[18]  J. W. Ayers, A. Poliak, M. Dredze, E. C. Leas, Z. Zhu, J. B. Kelley,         tionary algorithms,” Expert Systems with Applications, vol. 41, no. 17,\n      S. Mirsaidi, M. Owen, B. Bates, E. O. Nsoesie, et al., “Comparing physi-         pp. 7576–7586, 2014.\n      cian and artificial intelligence chatbot responses to patient questions    [41] M. Saraee and A. Bagheri, “An evolutionary approach to sentiment\n     about symptoms,” JAMA Internal Medicine, vol. 183, no. 11, pp. 1241–          analysis,” Journal of Information and Knowledge Management, vol. 12,\n     1248, 2023.                                                                    no. 03, p. 1350018, 2013.\n[19] L. Li et  al., “Few shot chain-of-thought driven reasoning to prompt    [42] Q. Guo, R. Yu, Y. Li, M. Xiao, K. Zhang, Y. Li, J. Gubbi, Z. Wang, and\n     llms  for open ended medical  question  answering,” arXiv  preprint         S. Liu, “Connecting large language models with evolutionary algorithms\n     arXiv:2403.04890, 2024.                                                         yields powerful prompt optimizers,” Advances in Neural Information\n[20] M. Komorowski, L. A. Celi, O. Badawi, A. C. Gordon, and A. A. Faisal,         Processing Systems, vol. 36, pp. 11989–12002, 2023.\n     “The artificial intelligence clinician learns optimal treatment strategies    [43] A. E. Johnson, T.  J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng,\n      for sepsis in intensive care,” Nature Medicine, vol. 24, no. 11, pp. 1716–       M. Ghassemi, B. Moody, P. Szolovits, L. Anthony Celi, and R. G. Mark,\n     1720, 2018.                                                                    “Mimic-iii, a freely accessible critical care database,” Scientific data,\n[21]  P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,          vol. 3, no. 1, pp. 1–9, 2016.\n     H. K¨uttler, M. Lewis, W.-t. Yih, T. Rockt¨aschel, S. Riedel, and D. Kiela,    [44]  J. Wang, Y. Chen, X. Liu, C. Liu, D. Liu, and Z. Xiong, “Masktwins:\n     “Retrieval-augmented generation for knowledge-intensive NLP tasks,” in        Dual-form complementary masking for domain-adaptive image segmen-\n     Advances in Neural Information Processing Systems, vol. 33, pp. 9459–          tation,” in ICML, 2025.\n     9474, Curran Associates, Inc., 2020.                                      [45] R. Yang, Y. Chen, Z. Zhang, X. Liu, Z. Li, K. He, Z. Xiong, J. Suo,\n[22] Y. Chen, C.  Liu, W. Huang, X.  Liu,  S. Cheng, R. Arcucci, and        and Q. Dai, “Unicompress: Enhancing multi-data medical image com-\n     Z. Xiong, “Generative text-guided 3d vision-language pretraining for         pression with knowledge distillation,” arXiv preprint arXiv:2405.16850,\n      unified medical image segmentation,” in ICCV workshop VLM3D, 2025.        2024.\n[23] C. Liu, C. Ouyang, Y. Chen, C. Quilodr´an-Casas, L. Ma, J. Fu, Y. Guo,    [46] E. Alsentzer, J. Murphy, W. Boag, W.-H. Weng, D. Jin, T. Naumann,\n     A. Shah, W. Bai, and R. Arcucci, “T3d: Towards 3d medical image        and M. McDermott,  “Publicly  available  clinical  bert embeddings,”\n     understanding through vision-language pre-training,” in ICCV workshop        Proceedings of the 2nd Clinical Natural Language Processing Workshop,\n    VLM3D, 2025. oral presentation.                                               pp. 72–78, 2019.\n[24] Y. Chen, H. Shi, X. Liu, T. Shi, R. Zhang, D. Liu, Z. Xiong, and F. Wu,    [47] D. Lozoya, A.  Berazaluce,  J.  Perches,  E.  L´ua, M. Conway, and\n     “Tokenunify: Scalable autoregressive visual pre-training with mixture         S. D’Alfonso, “Generating mental health transcripts with sape (spanish\n     token prediction,” in ICCV, 2025.                                              adaptive prompt engineering),” in Proceedings of the 2024 Conference\n[25]  S. Wu, Y. Chen, D. Liu, and Z. He, “Conditional latent coding with          of the North American Chapter of the Association for Computational\n      learnable synthesized reference for deep image compression,” AAAI,          Linguistics: Human Language Technologies (Volume 1: Long Papers),\n     2025. oral presentation.                                                        pp. 5096–5113, 2024.\n[26] Y. Chen, W. Huang, X. Liu, S. Deng, Q. Chen, and Z. Xiong, “Learning    [48] M. M. Derakhshani, E. Sanchez, A. Bulat, V. G. T. da Costa, C. G.\n      multiscale consistency for self-supervised electron microscopy instance        Snoek, G. Tzimiropoulos, and B. Martinez, “Bayesian prompt learn-\n     segmentation,” in ICASSP, pp. 1566–1570, IEEE, 2024.                        ing for image-language model generalization,” in Proceedings of the\n[27] Y. Chen, W. Huang, S. Zhou, Q. Chen, and Z. Xiong, “Self-supervised       IEEE/CVF International Conference on Computer Vision, pp. 15237–\n     neuron segmentation with multi-agent reinforcement learning,” in IJCAI,        15246, 2023.\n     2023.                                                                    [49] Y. Hu, Q. Chen,  J. Du, X. Peng, V. K. Keloth, X. Zuo, Y. Zhou,\n[28]  S. Deng, Y. Chen, W. Huang, R. Zhang, and Z. Xiong, “Unsupervised         Z. Li, X. Jiang, Z. Lu, et al., “Improving large language models for\n     domain adaptation for em image denoising with invertible networks,”          clinical named entity recognition via prompt engineering,” Journal of\n    IEEE Transactions on Medical Imaging, 2024.                                  the American Medical Informatics Association, vol. 31, no. 9, pp. 1812–\n[29] Y. Chen, C. Liu, X. Liu, R. Arcucci, and Z. Xiong, “Bimcv-r: A        1820, 2024.\n     landmark dataset for 3d ct text-image retrieval,” in MICCAI, pp. 124–    [50] A. Ahmed, M. Hou, R. Xi, X. Zeng, and S. A. Shah, “Prompt-eng:\n     134, Springer Nature Switzerland, 2024.                                      Healthcare prompt engineering: Revolutionizing healthcare applications\n[30] C. Liu, Z. Wan, H. Wang, Y. Chen, T. Qaiser, C.  Jin,  F. Yousefi,        with precision prompts,” in Companion Proceedings of the ACM Web\n     N.  Burlutskiy, and R. Arcucci, “Can medical vision-language  pre-        Conference 2024, pp. 1329–1337, 2024.\n      training succeed with purely synthetic data?,” in ACL findings, 2025.",
"headers": [
"EMPOWER: Evolutionary Medical Prompt",
"Optimization With Reinforcement Learning",
"arXiv:2508.17703v1  [cs.CL]  25 Aug 2025",
"…"
],
"tables": [
"|Method Performance Comparison Across Clinical Scenarios<br>95<br>(%)<br>90<br>Coverage<br>85<br>80<br>Concept<br>75<br>70 Medical<br>65 Expert Crafted BPO Prompt-eng<br>AMP CNER Ours<br>60<br>Diagnosis Treatment Medical History Education|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours|p|p||||\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours||||||\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours||||||\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours||||||\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours||||||\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours||~~Expert Crafted~~|~~BPO~~|~~Prom~~|~~pt-eng~~|\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours||<br>AMP|CNER|Ours||\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours||||||\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours|Diagnosis|Treatment|Medical History|Educa|ion|\n|Diagnosis<br>Treatment<br>Medical History<br>Education<br>60<br>65<br>70<br>75<br>80<br>85<br>90<br>95<br>Medical Concept Coverage (%)<br>Method Performance Comparison Across Clinical Scenarios<br>~~Expert Crafted~~<br>AMP<br>~~BPO~~<br>CNER<br>~~Prompt-eng~~<br>Ours|Perform<br> using the<br> demonst<br> with the|ance comparison<br>   Medical Conce<br> rates consistent<br>   most substantial|across different<br>    pt Coverage me<br>   improvements a<br>     gains in compl|clini<br>      tric.<br>    cross<br>       ex dia|clini<br>      tric.<br>    cross<br>       ex dia|\n||R|easoning Chain Accuracy|Comparison Across Medi|cal Spec<br>|cal Spec<br>|\n|Derm|atology|||Exp<br>~~AM~~<br>BP<br>CN|ert Crafted<br>~~P~~<br>O<br>ER|\n|Ps|ychiatry|||Pro<br>Our|mpt~~-~~eng<br> Method|\n|P|ediatrics|||||\n|E<br>|dii<br>ncology|||||\n|N<br>mergency|l<br> ecne|||||\n|Ca<br>|rdiology<br>uroogy|||||\n|Itl|dii|dii||||\n|Itl|dii|dii||||"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2508.17703v1.pdf"
}