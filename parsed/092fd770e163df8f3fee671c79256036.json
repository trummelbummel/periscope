{
"text": "Intent-based Prompt Calibration: Enhancing prompt\n                  optimization with synthetic boundary cases\n\n\n\n\n                               Elad Levi               Eli Brosh           Matan Friedmann\n2024                                            Abstract\n\n                           Prompt engineering is a challenging and important task due to the high sensitivityFeb                         of Large Language Models (LLMs) to the given prompt and the inherent ambi-\n                                guity of a textual task instruction. Automatic prompt engineering is essential to\n5\n                                achieve optimized performance from LLMs. Recent studies have demonstrated the\n                                   capabilities of LLMs to automatically conduct prompt engineering by employing\n                             a meta-prompt that incorporates the outcomes of the last trials and proposes an\n                            improved prompt. However, this requires a high-quality benchmark to compare\n                                   different prompts, which is difficult and expensive to acquire in many real-world\n                             use cases. In this work, we introduce a new method for automatic prompt engi-[cs.CL]                          neering, using a calibration process that iteratively refines the prompt to the user\n                                    intent. During the optimization process, the system jointly generates synthetic\n                               data of boundary use cases and optimizes the prompt according to the generated\n                                   dataset. We demonstrate the effectiveness of our method with respect to strong\n                                proprietary models on real-world tasks such as moderation and generation. Our\n                          method outperforms state-of-the-art methods with a limited number of annotated\n                               samples. Furthermore, we validate the advantages of each one of the system’s key\n                             components. Our system is built in a modular way, facilitating easy adaptation to\n                                other tasks. The code is available at https://github.com/Eladlev/AutoPrompt.\n\n\n                1  Introduction\n\n                       In recent years, there has been significant enhancements in the capabilities of Large Language\n                   Models (LLMs), demonstrating impressive generative performance across a variety of tasks [11, 4].\n                        Nevertheless, despite these advancements, the quality of the models’ outputs is highly sensitive to thearXiv:2402.03099v1                 conditioned prompt [18, 40]. Even a slight modification in the prompt format can significantly impact\n                        the model’s performance [27]. This issue is even more evident in popular proprietary models, where\n                      a change in model version results in drastic changes in model behaviour on a wide range of tasks [6].\n\n                        In order to tackle the prompt sensitivity issue, several methods [15, 16] proposed to use soft prompts\n                    which require access to the LLM itself in order to perform the optimization. Recently, [35, 37, 24]\n                      demonstrated the effectiveness of using LLMs themselves to optimize the prompt. To this end, each\n                    prompt is assigned a score based on a given benchmark and an appropriate metric. The optimization\n                       process is performed iteratively by providing a meta-prompt that incorporates the history of the last\n                    few prompt scores and guiding the model to suggest a better prompt with a higher score. However,\n                       the high-quality, large benchmarks required by this approach to evaluate the performance of the\n                          different prompts often do not exist in many real-world use cases. Moreover, iterating on such large\n                         datasets can be costly.\n\n                LLMs have proven to be highly effective in generating high-quality and rich datasets that boost model\n                     performance on a diverse set of tasks [25, 36, 19, 33]. Recent works demonstrate the capabilities\n                       of LLMs to refine the prompt provided by the user, resolving the initial prompt ambiguity [10].\n\nFigure 1: System diagram. (1) An initial prompt is provided by the user (2) Synthetic challenging\ncases are generated (3) A user or an LLM annotates the examples (4) After evaluating the prompt\nperformances, an LLM suggest a new prompt given the last prompt’s results. (5) This process is\nrepeated iteratively until a certain stop criterion (6) The system outputs a calibrated prompt.\n\n\n\nHowever, without additional information, the model has to guess the true intention of the user, which\nin many cases can lead to inaccurate results.\n\nIn this work, we introduce Intent-based Prompt Calibration (IPC), a system which aims to calibrate\nthe prompt according to the intention of the user, by using synthetic examples. The calibration\nprocess is performed by iteratively building a dataset of challenging boundary cases and optimising\nthe prompt according to the generated benchmark. This novel aspect of our method, producing a\nsmall benchmark tailored to the boundary cases of the user’s task as part of the optimization process,\nis highly valuable for explainability, LLM distillation, and other use cases. In contrast to previous\nworks, the system is optimized for real-world use cases such as moderation which usually suffers\nfrom imbalanced data distribution. We also extend the prompt optimization to a new family of\ngenerative tasks, by first fitting a ranking prompt and then performing the prompt optimization with\nthe learned ranker. Learning a prompt ranker allows us to optimize generative tasks with minimal\nannotation effort. As demonstrated in our experimentation section, using such an approach without\nsynthetic data of boundary cases, e.g., as done in previous methods, would not be efficient due to the\nnatural imbalance of the ranking distribution.\n\nLastly, our system is built in a modular way, such that each part of the components can be used\non its own in other tasks like synthetic data generation or prompt distillation between two LLMs.\nWe describe the system components in detail and demonstrate the effectiveness of our proposed\nmethod with respect to strong proprietary models like GPT-3.5/4-Turbo. We show that our method\noutperforms previous methods using a very small amount of data and iteration steps . This significantly\nreduces the total optimization efforts and costs, and makes the system applicable to various production\nuse cases.\n\n\n2  Method\n\nOur system is illustrated in Figure 1. We start with the initial prompt suggestion and a task description.\nThe user can also provide a few examples in a few-shot setting.  Then, during the calibration\noptimization process, the system iteratively: 1. Suggests a few samples of challenging and diverse\nboundary cases for the task and the current prompt. 2. Evaluates the current prompt on the generated\ndataset, and provides an analysis. 3. Given the history of the last few prompts, suggests a new prompt\nwith a higher score. The optimization process is terminated when either there is no improvement in\nthe last few steps, or when the maximum number of iterations has been reached.\n\nThe base configuration of our system is optimized for classification tasks, with accuracy set as the\nscore function, and the error analysis determined by a confusion matrix and the prompt misclassifica-\ntions. An example of the system flow can be seen in Figure 2. In each iteration, new challenging\nsamples are generated (according to the current prompt), and the misclassifications are used to refine\nthe prompt until it is calibrated to the user intent.\n\n\n                                       2\n\nFigure 2: Example of a real system flow. The user provides only the task description and initial\nprompt. The model iteratively generates challenging samples and refines the prompt according to the\ngenerated benchmark.\n\n\n2.1  Generative tasks\n\nTo extend the prompt calibration process from classification tasks to generative tasks, we split the\noptimization process into two parts. In the first part, we use an LLM to rephrase the initial prompt\nand task description in order to define a ranking task based on the modified initial prompt and task\ndescription. We then calibrate a prompt for the ranking task, treating it as a classification task using\nthe classification pipeline. Naturally, the ranker distribution tends to be a normal distribution with\nits mean at the mean score. This distribution is imbalanced, especially in the interesting range of\nthe top scores. Therefore, in the ranking case, the sample generator meta-prompt is instructed to\ngenerate challenging boundary samples from the top two scores. In the second part, we leverage the\nsame underlying process to optimize the original generative prompt. This step is done by iteratively\napplying steps 2 and 3, described in the system overview, using the calibrated ranking prompt as\nthe score function. It’s important to note that human annotations are required only in the ranking\ncalibration process. Furthermore, by treating the intent as a classification task, the prompt can be\ncalibrated using a small amount of annotation effort.\n\n2.2  Meta-Prompts\n\nThe meta-prompts consist of three separate prompts, as can be seen in Appendix A.\n\nSample generator. The sample generation meta-prompt is determined according to the system state:\nIn the first iteration, if the user doesn’t provide any samples (zero-shot setting), the meta-prompt\ninstructs the model to generate diverse adversarial samples with even class distribution. In the next\n\n\n                                       3\n\niterations, the prompt is extended with the following additional context: (1) A history with prompts\nand good adversarial samples that confused the prompts; and (2) A set of realistic samples from the\ndataset, where the model is instructed to preserve the dataset style. The context-realistic samples are\nchosen to be semantically close according to a given sentence embedding.\n\nAnalyzer. The analyzer meta-prompt receives the prompt score, a confusion matrix in the classifica-\ntion case, and a set of errors in all the classes. It is then instructed to produce an analysis summary of\nthe prompt performances and the major failure cases.\n\nPrompt generator. The input for the prompt generator meta-prompt is (1) A list of the last suggested\nprompts and their scores (2) The performance analysis of the last prompt that is produced by the\nAnalyzer prompt. The model is instructed to produce a prompt with a higher score according to the\nhistory and the analysis.\n\n\n2.3  System pipeline\n\nAn overview of the system architecture can be seen in Figure 8. The system consists of four primary\ncomponents.\n\nDataset. This component manages the dataset and performs operations such as insertion, modification,\ndeletion, and applying functions, on the dataset rows. The component also handles data cleaning by\nremoving semantic duplications and performing semantic sampling. Since the system is optimized\nfor small datasets, the current implementation is based on a local database using pandas.\n\nEstimator. The estimator is responsible for estimating a batch of samples. We implement this\ncomponent twice, once for the predictions and once for the annotations. This generic implementation\nfor both types of use cases, allows us to modify the system simply for diverse use cases such as\nprompt calibration, prompt distillation and prompt squashing. The currently supported types of\nestimators are: (1) Human annotation, using Argilla UI [32]. The system is connected to the Argilla\nserver and is waiting until the annotation task is completed; (2) LLM estimator, which uses an\nLLM to estimate the sample given a prompt. We support various types of LLMs, using Langchain\nintegration [5]. For efficiency, the system supports parallelism using both workers and async calls.\nThe system also supports sending a few samples in one prompt (prompt batching), which can reduce\nthe cost significantly; and (3) Batch estimator, the batch estimator runs multiple LLM estimators\nand integrates their outputs through an aggregation layer. It is mainly used for prompt-squashing,\nenabling users to optimize a single prompt that will perform as well as running few prompts multiple\ntimes. For example, when a user wants to apply several moderation rules simultaneously.\n\nEvaluator. The evaluator is responsible for evaluating the records after the prediction and annotation\nstage. The evaluator accepts a function and applies it to each row. It’s important to note that the\nfunction is generic. For example, in the generation pipeline, the function is performed by invoking an\nLLM. The evaluator is also responsible for defining the errors and handling the error analysis using\nthe Analyzer described in the meta-prompts section.\n\nOptimizer (Optimization Pipeline). The optimizer manager handles the whole optimization process\nflow, it performs the iteration steps described in the previous section and is responsible for stopping\nand returning the final calibrated prompt. The currently supported criteria are either convergence\n(determined by a patience hyper-parameter), or usage limit (determined by maximal cost if relevant,\nor by the number of generated tokens).\n\n\n3  Experiments\n\nWe test our system on scenarios that reflect real-world moderation and generation use cases on strong\nproprietary models (GPT-3.5/4-Turbo). We used the IMDB review dataset [20] as the base data for all\nour experiments. We compare our proposed IPC method to two SOTA prompt optimization methods\nthat are based on meta-prompts: 1. OPRO [35] and 2. The meta prompt provided by PE [37].\n\n\n3.1  Classification\n\nWe evaluate the prompt calibration process on three binary classification tasks: (1) Spoiler detection,\n(2) Sentiment analysis, and (3) Parental Guidance (PG) detection. In each experiment, we start with\n\n\n                                       4\n\nFigure 3: Accuracy on the spoiler and the PG classification tasks, with respect to the number of\ntraining steps. As shown, IPC outperforms other tested methods and results in lower variance.\n\n\n\nsome initial samples and a prompt, in addition to a short task description. To generate the ground\ntruth (GT) we composed a highly detailed prompt with specific preferences. For the GT generation,\nwe used a strong model (GPT-4 Turbo), as this process of generating the GT simulates a user’s\nparticular preference for the given task. The baseline methods were trained on samples from the\nIMDB dataset [20], whereas our proposed method was trained on the adversarial synthetic data which\nwas provided with 10 initial samples from the original IMDB training data. All methods were trained\nfor 50 iterations. The test dataset was taken from the IMDB reviews test split, with the generated\nannotations provided by the GT prompt. We then collected 250 samples for each class in each one of\nthe tested scenarios, such that the final dataset has equal class distribution. It’s important to note that\nthe IMDB dataset includes only highly polarizing reviews (no reviews with ratings in the range of\n4-7). To evaluate the method’s performance on more challenging cases, we also generate a synthetic\ntest dataset with 300 samples (using the initial prompt) for the sentiment classification task.\n\nWe present our results in Figures 3,7. As seen in the figures, IPC outperforms all other tested methods.\nIn particular, it’s important to note the high variance of the other methods, especially in the case of a\nsmall number of training samples. The gap in performance between the methods becomes even more\nevident in the synthetic data case, where there are more boundary cases, as can be seen in Figure 6.\nA qualitative comparison between the methods can be seen in Table 1. While OPRO [35] results\nin mainly rephrasing the initial prompt, and the PE [37] prompt only partly fits the GT prompt, the\nIPC prompt successfully captures the subtle details and nuances of the GT prompt. The significant\ndifferences in data distributions between the original data and the synthetic generated data can be\nseen in Figure 5. Both the spoiler and the PG classification tasks exhibit significant bias towards the\n’No’ labels, where the Synthetic data is almost balanced.\n\n\n3.2  Generation\n\nThe generation setting is composed of two parts: generating the ranker prompt and then using the\nranker to optimize the generation task prompt. We tested our generation pipeline on challenging\nambiguous tasks: (1) Generate a movie review that is enthusiastic, reliable and adheres to a given\nmovie description. (2) Generate a movie review that is sarcastic but has a positive sentiment. As in\nthe classification case, we chose highly detailed prompts to generate the ranker GT with a scale of 1\nto 5, which simulates the human preferences for the given task. For each tested method we fit a ranker\nusing 50 labeled samples, and then optimized the generative task prompt according to the learned\nranking model. The reported evaluation score is calculated by running the learned generative prompt\non a test set of size 50 and evaluating the result using the target ranking prompt GT. For the baseline\n\n\n                                       5\n\nFigure 4: Histogram of the ranking scores of the  Figure 5: Histogram of the ’Yes’ labels density\nIMDB review dataset vs the generated synthetic  on the parental guidance (PG) and spoiler classi-\ndataset on the Authentic and enthusiastic genera-  fication tasks, with respect to the IMDB review\ntion task. The real data distribution contains very  dataset and the generated synthetic dataset. The\nfew ranked 5 reviews, whereas the synthetic data  real data exhibits a heavy imbalance in favor\ncontains a more balanced dataset with respect to  of the ’No’ label, while the synthetic data ap-\nthe top scores.                                 proaches an even distribution.\n\n\n\n\n\nFigure 6: Accuracy of of sentiment classification task with respect to the synthetic dataset for different\nnumber of training steps. IPC outperforms other tested methods and results in lower variance.\n\n\nmethods, we took samples from the IMDB review dataset [20] and generated a movie description for\neach review. We then fed this data to the ranker optimization process. We ran both the ranker training\nand the generator training for 30 iteration steps.\n\nResults for GPT-4 Turbo LLM, including both ranker training and generation prompt training, are\npresented in Table 3. A qualitative comparison is provided in Table 4. We see that using IPC improves\nthe average ranking score of the generated reviews compared to the other tested methods in all tested\nscenarios. It’s important to note that all the tested methods, except for IPC, performed worse than the\ninitial prompt in some experiments. This can be explained by the distribution of the ranking scores in\nthe real data, which is shown in Figure 4, where there are almost no samples with the top score. In\ncontrast, the distribution of the generated synthetic samples is biased towards the top two scores.\n\n3.3  Ablation study\n\nWe examine the impact of each key component of the system on the spoiler classification task.\nSpecifically, we look at the 50 training samples case. The effect of each one of the components can\nbe seen in Table 2. Using synthetic data boosts model performance. It is also important to note that\nthe analyzer component substantially improves the model’s performance. This stands in contradiction\nto [35]’s findings that adding errors to the meta-prompts doesn’t improve the model performance,\nand can also emphasise the gap between the standard general benchmarks and use cases such as\nmoderation.\n\n4  Related Work\n\nPrompt Optimization. Several methods have been suggested to address the challenge of automating\nthe prompt engineering process. A commonly used approach is to optimize a task-specific embedding,\nin either a continuous [15, 16, 17] or discrete [34, 29] manner. This approach requires access to the\nLLM itself in order to perform the optimization. An alternative approach is to use reinforcement\n\n\n                                       6\n\nGT prompt    To improve the IMDB review spoiler classifier, label a review as ’Yes’ for containing\n                a spoiler if it: 1. Even subtly hints at the outcome of subplots or the development of\n                  the story, such as mentioning a character’s transformation or key relationships without\n                   explicit details. 2. Makes observations on the narrative structure, like pacing or the\n                  significance of certain scenes, which could indirectly indicate important plot points.\n                   3. Alludes to twists, endings, or character fates with veiled language that doesn’t\n                   explicitly outline the events but provides enough context to infer them. Conversely,\n                   label a review as ’No’ for no spoilers if it: 1. Focuses on broad discussions of character\n                       traits, emotional tone, or film structure without revealing any specific plot points. 2.\n                  Offers critiques or praise of film elements like pacing, genre, actor performances, and\n                filmmaking techniques that are independent of plot developments. 3. Explores the\n                   film’s themes or the emotional journey it offers in a way that avoids any direct or\n                   indirect plot or character spoilers.\n\n  Initial prompt  Does this movie review contain a spoiler? answer Yes or No\n\n OPRO [35]    Examine the movie synopsis with vigilance for spoiler content and succinctly affirm\n                    their presence with \"Yes\" or negate with \"No\".\n\n PE [37]        Analyze the IMDB review for elements that provide significant insights into the plot or\n                   reveal crucial turning points, even if mentioned subtly or indirectly. Look for elements\n                   that give away the resolution of central conflicts, character arcs, or the outcome of\n                   pivotal events. Additionally, distinguish between powerful scene descriptions and\n                  actual plot revelations; the former should not be classified as spoilers unless they\n                   disclose essential plot information. Based on your analysis, classify the review as ’Yes’\n                   for containing spoilers that impact the viewing experience, or ’No’ for free of such\n                    spoilers.\n\n IPC        IMDB Review Spoiler Identification Protocol: For the task of classifying IMDB\n                 reviews for the presence of spoilers, the classifier must label reviews with a heightened\n                    sensitivity to nuanced language and indirect spoiler cues. The classification labels are\n                 ’Yes’ for spoilers and ’No’ for non-spoilers. Apply the following criteria rigorously:\n                Label ’Yes’ if a review: - Contains subtle references or nuanced language that hints\n                    at plot developments or character arcs, without explicit detail. - Includes emotional\n                 responses or descriptive language that indirectly reveals plot outcomes or twists.  -\n              Employs suggestive language that points to future events or endings, even if it does\n                 not reveal specific information. Label ’No’ if a review: - Discusses technical aspects,\n                   acting, direction, or personal viewer impressions in a manner that does not hint at or\n                  reveal any plot details. - Comments on thematic elements, genre characteristics, or\n                   storytelling techniques without disclosing or implying crucial plot twists. - Expresses\n                 opinions on the movie’s quality, performances, or execution that are free from any\n                   storyline implications or potential spoiler content. In both ’Yes’ and ’No’ classifications,\n                   special attention must be given to the implicit meaning behind words and the context in\n               which they are used to prevent misclassification of subtle spoiler content and to ensure\n                 a genuine viewing experience for others.\n\nTable 1: A comparison of the prompts with the best training scores from each method on the Spoiler\ndetection task, using 50 training samples. IPC succeeded in capturing the nuances of the GT prompt.\n\n\n\n\n\nlearning [9, 39, 1]. This approach either requires access to the generated tokens’ probability or\nrequires a large dataset for training a model. Recent works used the LLMs themselves for prompt\noptimization [41, 24, 35, 37]. These methods can also be applied to proprietary LLMs, , where\naccess is limited to the final generated sentences. However, these methods still require a good valid\nbenchmark in order to evaluate and compare the different generated prompts, which is not always\navailable in real-world cases.\n\n\n                                       7\n\nEnthusiastic and reliable   Sarcastic and positive\n\n                     Initial               4.40±0.05                4.28±0.02\n           OPRO [35]          4.31±0.02                4.22±0.03\n            PE [37]             4.09±0.09                4.76±0.09\n              IPC                 4.80 ±0.1                4.92±0.07\n\n      Table 2: Average ranking score (std) of the top 5 prompts on the two generation tasks.\n\n\n\n                             Spoiler classification GPT-4 Turbo   Spoiler classification GPT-3.5\n\n IPC (default)                         88.4 ±1.7                         72.6±3.8\n  - Iterative data generation               87.3±1.8                         67.0±4.1\n  - Synthetic data                        83.3±2.4                         62.6±4.1\n  - Analyzer                             77.8±2.2                         64.3±3.8\n\nTable 3: Investigation of each component’s effect on the model accuracy. In each row, we removed\nthe investigated component from the system and trained the system without it.\n\n\n\nSynthetic data. The utilization of synthetic data produced by LLMs has demonstrated remarkable\neffectiveness across a wide range of tasks, including code generation [25, 36], mathematical rea-\nsoning [38, 19], text embedding [33] and text2image [3]. The advantage of using synthetic data is\nnot only in cost savings; it can also be beneficial for low-resource tasks or imbalanced data distribu-\ntions [21]. Following these works, our system generates high-quality evenly distributed synthetic\nboundary samples, that result in a more efficient optimization process and higher-quality results.\n\nSynthetic data was also proven to be an effective method to distil knowledge from black-box LLMs,\nby training on synthetic data that was generated by those models [31, 22, 12]. However, in these\nworks the generated data was used to fully train the student model. In contrast, our work demonstrates\nthe effectiveness of synthetic data to distil knowledge between two black-box models via automatic\nprompt engineering.\n\nCurriculum Learning. Arranging the data samples for training machine learning models in a\nmeaningful way, starting from easier samples and progressing to more challenging ones, can yield\nperformance enhancements compared to the conventional method of training based on random data\nshuffling. This approach is known as curriculum learning [30, 2]. Curriculum Learning has been\nproven to be effective in various fields such as object localization [13, 28], object detection [7, 26]\nand NLP [14, 23]. Inspired by these ideas, in [8] they propose to fine-tune LLMs by iteratively\ngenerating synthetic data and refining the policy to distinguish between the synthetic data and the\nhuman-annotated data. In our work, we use a similar approach, where the system iteratively generates\nmore challenging cases that resolve the previous prompt ambiguity in order to more efficiently tune\nto the user intent.\n\n\n5  Conclusions\n\nIn this work, we introduced IPC, a system for automatic prompt engineering. The system combines\na synthetic data generation module that generates challenging and diverse samples, and a prompt\noptimization module that suggests new prompts. Both of them are implemented by prompting LLMs,\nand they iteratively refine each other until the prompt converges. We further propose a new method to\nextend the meta-prompt based prompt optimization process to generative tasks. We demonstrate the\neffectiveness of our system on real-world use cases such as moderation and generation with respect\nto strong proprietary models (GPT-3.5/4-Turbo).Our method significantly enhances the resulting\nperformance of prompts in all tested scenarios.\n\nOur system is built in a modular and flexible way that allows for easy modification and addition of new\ncomponents. In future work, we intend to extend our system to new use cases such as multi-modality\nand in-context learning. We also intend to explore further possibilities to optimize the meta-prompts\nthemselves.\n\n\n                                       8\n\nReferences\n\n [1] A. F. Akyürek, E. Akyürek, A. Kalyan, P. Clark, D. T. Wijaya, and N. Tandon. RL4F: generating\n      natural language feedback with reinforcement learning for repairing model outputs. In A. Rogers,\n       J. L. Boyd-Graber, and N. Okazaki, editors, Proceedings of the 61st Annual Meeting of the\n     Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto,\n    Canada, July 9-14, 2023, pages 7716–7733. Association for Computational Linguistics, 2023.\n\n [2] Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In Proceedings of\n     the 26th Annual International Conference on Machine Learning, ICML ’09, page 41–48, New\n     York, NY, USA, 2009. Association for Computing Machinery.\n\n [3]  J. Betker, G. Goh, L. Jing, TimBrooks, J. Wang, L. Li, LongOuyang, JuntangZhuang, JoyceLee,\n     YufeiGuo, WesamManassra, PrafullaDhariwal, CaseyChu, YunxinJiao, and A. Ramesh. Improv-\n     ing image generation with better captions. 2023.\n\n [4] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,\n      P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child,\n    A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray,\n     B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Lan-\n    guage models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan,\n    and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages\n    1877–1901. Curran Associates, Inc., 2020.\n\n [5] H. Chase. Langchain, 2022. cff-version: 1.2.0, message: \"If you use this software, please cite it\n     as below.\", date-released: 2022-10-17.\n\n [6] L. Chen, M. Zaharia, and J. Zou. How is chatgpt’s behavior changing over time?  CoRR,\n     abs/2307.09009, 2023.\n\n [7] X. Chen and A. Gupta. Webly supervised learning of convolutional networks. In 2015 IEEE\n     International Conference on Computer Vision, ICCV 2015, Santiago, Chile, December 7-13,\n     2015, pages 1431–1439. IEEE Computer Society, 2015.\n\n [8] Z. Chen, Y. Deng, H. Yuan, K. Ji, and Q. Gu. Self-play fine-tuning converts weak language\n    models to strong language models. CoRR, abs/2401.01335, 2024.\n\n [9] M. Deng, J. Wang, C. Hsieh, Y. Wang, H. Guo, T. Shu, M. Song, E. P. Xing, and Z. Hu.\n     Rlprompt: Optimizing discrete text prompts with reinforcement learning.  In Y. Goldberg,\n     Z. Kozareva, and Y. Zhang, editors, Proceedings of the 2022 Conference on Empirical Methods\n      in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December\n     7-11, 2022, pages 3369–3391. Association for Computational Linguistics, 2022.\n\n[10] Y. Deng, W. Zhang, Z. Chen, and Q. Gu. Rephrase and respond: Let large language models ask\n      better questions for themselves. CoRR, abs/2311.04205, 2023.\n\n[11]  J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional\n     transformers for language understanding. In J. Burstein, C. Doran, and T. Solorio, editors,\n     Proceedings of the 2019 Conference of the North American Chapter of the Association for\n     Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Pa-\n      pers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational\n      Linguistics.\n\n[12] S. Gunasekar, Y. Zhang, J. Aneja, C. C. T. Mendes, A. D. Giorno, S. Gopi, M. Javaheripi,\n      P. Kauffmann, G. de Rosa, O. Saarikivi, A. Salim, S. Shah, H. S. Behl, X. Wang, S. Bubeck,\n     R. Eldan, A. T. Kalai, Y. T. Lee, and Y. Li. Textbooks are all you need. CoRR, abs/2306.11644,\n     2023.\n\n[13] R. T. Ionescu, B. Alexe, M. Leordeanu, M. Popescu, D. P. Papadopoulos, and V. Ferrari. How\n     hard can it be? estimating the difficulty of visual search in an image. In 2016 IEEE Conference\n    on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30,\n     2016, pages 2157–2166. IEEE Computer Society, 2016.\n\n[14] T. Kocmi and O. Bojar.  Curriculum learning and minibatch bucketing in neural machine\n      translation. In R. Mitkov and G. Angelova, editors, Proceedings of the International Conference\n     Recent Advances in Natural Language Processing, RANLP 2017, Varna, Bulgaria, September 2\n      - 8, 2017, pages 379–386. INCOMA Ltd., 2017.\n\n\n                                       9\n\n[15] B. Lester, R. Al-Rfou, and N. Constant. The power of scale for parameter-efficient prompt\n      tuning. In M.-F. Moens, X. Huang, L. Specia, and S. W.-t. Yih, editors, Proceedings of the 2021\n     Conference on Empirical Methods in Natural Language Processing, pages 3045–3059, Online\n     and Punta Cana, Dominican Republic, Nov. 2021. Association for Computational Linguistics.\n\n[16] X. L. Li and P. Liang. Prefix-tuning: Optimizing continuous prompts for generation. In C. Zong,\n      F. Xia, W. Li, and R. Navigli, editors, Proceedings of the 59th Annual Meeting of the Association\n      for Computational Linguistics and the 11th International Joint Conference on Natural Language\n     Processing (Volume 1: Long Papers), pages 4582–4597, Online, Aug. 2021. Association for\n     Computational Linguistics.\n\n[17] X. Liu, Y. Zheng, Z. Du, M. Ding, Y. Qian, Z. Yang, and J. Tang. GPT understands, too. CoRR,\n     abs/2103.10385, 2021.\n\n[18] Y. Lu, M. Bartolo, A. Moore, S. Riedel, and P. Stenetorp. Fantastically ordered prompts and\n    where to find them: Overcoming few-shot prompt order sensitivity. ArXiv, abs/2104.08786,\n     2021.\n\n[19] H. Luo, Q. Sun, C. Xu, P. Zhao, J. Lou, C. Tao, X. Geng, Q. Lin, S. Chen, and D. Zhang.\n    Wizardmath: Empowering mathematical reasoning for large language models via reinforced\n      evol-instruct. CoRR, abs/2308.09583, 2023.\n\n[20] A. L. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng, and C. Potts. Learning word vectors\n     for sentiment analysis.  In Proceedings of the 49th Annual Meeting of the Association for\n     Computational Linguistics: Human Language Technologies, pages 142–150, Portland, Oregon,\n    USA, June 2011. Association for Computational Linguistics.\n\n[21] A. G. Møller, J. A. Dalsgaard, A. Pera, and L. M. Aiello. Is a prompt and a few samples all\n    you need? using GPT-4 for data augmentation in low-resource classification tasks. CoRR,\n     abs/2304.13861, 2023.\n\n[22] S. Mukherjee, A. Mitra, G. Jawahar, S. Agarwal, H. Palangi, and A. Awadallah. Orca: Progres-\n      sive learning from complex explanation traces of GPT-4. CoRR, abs/2306.02707, 2023.\n\n[23] E. A. Platanios, O. Stretcu, G. Neubig, B. Póczos, and T. M. Mitchell. Competence-based\n     curriculum learning for neural machine translation. In J. Burstein, C. Doran, and T. Solorio, edi-\n      tors, Proceedings of the 2019 Conference of the North American Chapter of the Association for\n     Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis,\n    MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 1162–1172. Association\n      for Computational Linguistics, 2019.\n\n[24] R. Pryzant, D. Iter, J. Li, Y. Lee, C. Zhu, and M. Zeng. Automatic prompt optimization with\n     “gradient descent” and beam search. In H. Bouamor, J. Pino, and K. Bali, editors, Proceedings of\n     the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7957–7968,\n     Singapore, Dec. 2023. Association for Computational Linguistics.\n\n[25] B. Rozière, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez,\n       J. Rapin, A. Kozhevnikov, I. Evtimov, J. Bitton, M. Bhatt, C. Canton-Ferrer, A. Grattafiori,\n    W. Xiong, A. Défossez, J. Copet, F. Azhar, H. Touvron, L. Martin, N. Usunier, T. Scialom, and\n    G. Synnaeve. Code llama: Open foundation models for code. CoRR, abs/2308.12950, 2023.\n\n[26] E. Sangineto, M. Nabi, D. Culibrk, and N. Sebe. Self paced deep learning for weakly supervised\n     object detection. IEEE Trans. Pattern Anal. Mach. Intell., 41(3):712–725, 2019.\n\n[27] M. Sclar, Y. Choi, Y. Tsvetkov, and A. Suhr. Quantifying language models’ sensitivity to\n     spurious features in prompt design or: How I learned to start worrying about prompt formatting.\n    CoRR, abs/2310.11324, 2023.\n\n[28] M. Shi and V. Ferrari. Weakly supervised object localization using size estimates. In B. Leibe,\n       J. Matas, N. Sebe, and M. Welling, editors, Computer Vision - ECCV 2016 - 14th European\n     Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V, volume\n    9909 of Lecture Notes in Computer Science, pages 105–121. Springer, 2016.\n\n[29] T. Shin, Y. Razeghi, R. L. L. IV, E. Wallace, and S. Singh. Autoprompt: Eliciting knowledge\n     from language models with automatically generated prompts. In B. Webber, T. Cohn, Y. He, and\n     Y. Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language\n     Processing, EMNLP 2020, Online, November 16-20, 2020, pages 4222–4235. Association for\n     Computational Linguistics, 2020.\n\n\n                                       10\n\n[30] P. Soviany, R. T. Ionescu, P. Rota, and N. Sebe. Curriculum learning: A survey. Int. J. Comput.\n      Vis., 130(6):1526–1565, 2022.\n[31] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto.\n     Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/\n    stanford_alpaca, 2023.\n[32] D. Vila-Suero and F. Aranda.  Argilla - open-source framework for data-centric nlp, 2023.\n      cff-version: 1.2.0, message: \"If you use this software, please cite it as below.\", date-released:\n     2023-01-12.\n[33] L. Wang, N. Yang, X. Huang, L. Yang, R. Majumder, and F. Wei. Improving text embeddings\n     with large language models. CoRR, abs/2401.00368, 2024.\n[34] Y. Wen, N. Jain, J. Kirchenbauer, M. Goldblum, J. Geiping, and T. Goldstein. Hard prompts\n    made easy: Gradient-based discrete optimization for prompt tuning and discovery. CoRR,\n     abs/2302.03668, 2023.\n[35] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, and X. Chen. Large language models as\n     optimizers. CoRR, abs/2309.03409, 2023.\n[36] Y. Yang, A. K. Singh, M. Elhoushi, A. Mahmoud, K. Tirumala, F. Gloeckle, B. Rozière, C. Wu,\n    A. S. Morcos, and N. Ardalani. Decoding data quality via synthetic corruptions: Embedding-\n     guided pruning of code data. CoRR, abs/2312.02418, 2023.\n[37] Q. Ye, M. Axmed, R. Pryzant, and F. Khani. Prompt engineering a prompt engineer, 2023.\n[38] Z. Yuan, H. Yuan, C. Li, G. Dong, C. Tan, and C. Zhou. Scaling relationship on learning\n     mathematical reasoning with large language models. CoRR, abs/2308.01825, 2023.\n[39] T. Zhang, X. Wang, D. Zhou, D. Schuurmans, and J. E. Gonzalez. TEMPERA: test-time\n     prompting via reinforcement learning. CoRR, abs/2211.11890, 2022.\n[40] Z. Zhao, E. Wallace, S. Feng, D. Klein, and S. Singh. Calibrate before use: Improving few-shot\n     performance of language models. In M. Meila and T. Zhang, editors, Proceedings of the 38th\n     International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event,\n    volume 139 of Proceedings of Machine Learning Research, pages 12697–12706. PMLR, 2021.\n[41] Y. Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis, H. Chan, and J. Ba. Large language models\n     are human-level prompt engineers. In The Eleventh International Conference on Learning\n     Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023.\n\n\n\n\n\n                                       11\n\nAppendix\n\n\n A  Implementation details\n\n   In this section, we provide a additional information on the implementation details. An architecture\n  overview of our system is provided in Figure 8. We also provide a list of the meta-prompts utilized\n  within the pipeline of our system.\n\n\n  Generating initial samples (iteration 0)\n\n 1 Assistant is a large language model designed to generate challenging samples for\n       every task.\n 2 Generate a list of {num_samples} challenging samples for the following task.\n 3 ### Task description:\n 4 {task_description}\n 5 ### Task Instruction:\n 6 {instruction}\n 7 ###\n 8 The generated samples should be challenging and diverse such that using the task\n       instruction as a prompt will result in the wrong result.\n 9 The number of generated samples from each class should be balanced (i.e. the same\n       number of samples for each class)\n\n  Generating samples (iteration >0)\n\n 1 Assistant is a large language model designed to generate challenging samples for\n       every task.\n 2 Below a few prompts that were build to answer the given task description and their\n       failure case.\n 3 Task description:\n 4 {task_description}\n\n 5\n 6 ## Examples of common failure, each sample is followed by the the model prediction\n       and the GT (ground truth)\n 7 {history}\n 8 ######\n 9 Here are few unique samples derived from realistic scenarios for the task outlined\n       above.\n10 ## Realistic Samples\n11 {extra_samples}\n12 #####\n13 This was the new proposed prompt:\n14 ## Prompt\n15 {prompt}\n\n16\n17 Your task is to generate {num_samples} by following this guidelines:\n18 1. The generated samples should be diverse\n19 2. They should preserve the style and the length of the given examples\n20 3. The samples must be challenging and hard to classify by the model. This can be\n       achieved by:\n21     1. targeting the same weakness that the model failed on in the given examples\n22     2. targeting weakness that are different from the existing examples in the\n       failure cases\n23 4. The number of generated samples from each class should be balanced (i.e. the same\n        number of samples for each class)\n\n  Analyzer prompt\n\n 1 Assistant is a large language model designed to provide a high quality analysis for\n       every task.\n\n\n                                         12\n\n2 You are given the following task description\n 3 {task_description}\n\n 4\n 5 Here is the prompt instructions that was given to the model:\n 6 {prompt}\n\n 7\n 8 An expert ranker evaluated the model’s performance on the given task description.\n 9 and rank according to the following scale: {labels}\n\n10\n11 The mean score for this prompt is: {accuracy}\n12 ##\n13 Here is a list of challenging cases for the given prompt and their rank:\n14 ##Challenging Cases:\n15 {failure_cases}\n\n16\n17 ###\n18 Note that the ranker labels are __absolutely correct__, but the prompts (task\n       descriptions) may be incorrect and need modification.\n19 Your task is to provide a brief analysis of the given prompt performance.\n20 Guidelines:\n21 1. The analysis should contain only the following information:\n22     - A summary of the common mistakes of the prompt and the ways he can be improve\n       his generation, try to cluster the failure cases into groups and describe each\n       group.\n23 2. The total length of your analysis should be less than 200 token!\n24 ###\n25 Analysis:\n\n  Generating new proposed prompt\n\n 1 Assistant is a large language model designed to provide the best prompt for every\n       task.\n 2 Below are a few suggested prompts for the task and their score, for the following\n       task:\n 3 {task_description}\n\n 4\n 5 ## Examples\n 6 {history}\n 7 ######\n 8 This is the error analysis for the last prompt:\n 9 {error_analysis}\n10 ######\n11 Your task is to generate:\n12 1. A new prompt that is\n13     -Different from all the prompts above\n14     -Follows exactly the error analysis modification suggestions, and fix the prompt\n        to prevent the failure cases.\n15     -Has a higher score than all the prompts above.\n16 2. The predicted score of this prompt\n\n17\n18 You must adhere the error analysis instructions! even in case it seems there is a\n       contradiction between these instructions, and the task. The error analysis is\n       tested on a ground truth, thus represent the exact intent of the task.\n19 The generated prompt should be phrased as a clear classification instruction! it\n       should not include any instructions and descriptions on the modification that\n       should be done to the prompt.\n20 Note that the previous prompt contains an implicit assumptions on the intent of the\n       task that might be incorrect. You should replace this assumption with more\n       accurate assumptions using the score of the previous prompts and the error\n       analysis.\n21 The result prompt should indicate that the task is a classification class with the\n       following labels {labels}!\n\n  Modifying the task description for training the ranker\n\n\n\n                                         13\n\n1 Assistant is a large language model designed to generate a task description.\n 2 You are given a task description phrased as text generation task given some user\n       input. Your task is to rephrase it as a task that suppose to evaluate the\n       quality of the given generative task and how well it adhere to the user input.\n 3 #####\n 4 Input task description: {task_description}\n 5 #####\n 6 Rephrased task description:\n\n  Modifying the initial prompt for training the ranker\n\n 1 Assistant is a large language model designed to generate instructions for every task\n       .\n 2 You are given a instructions phrased as text generation task.\n 3 Your task is to write an instruction for a classification ranking task that suppose\n       to evaluate the quality of a generated sample given a user prompt for this\n       generative instruction.\n 4 Guidelines:\n 5 1. The classifier labels are {label_schema}. The result instructions should indicate\n        explicitly that the task is a classification class with the following labels {\n       label_schema}!\n 6 2. The generated instruction must also evaluate how well the generated sample adhere\n        the user prompt\n 7 #####\n 8 Input generative instruction: {prompt}\n 9 #####\n10 Rephrased classification quality evaluation instruction:\n\n\n B  Experiments: Additional details\n\n   In this section, we provide additional material on the experiments provided in the paper.\n\n\n\n\n\n   Figure 7: Accuracy on the sentiment classification task, with respect to different numbers of training\n   steps. IPC outperforms other tested methods, and results in lower variance.\n\n\n\n\n\n                                         14\n\nFigure 8: Architecture overview.\n\n\n\n\n\n            15\n\nGT ranker          Establish a revised five-point assessment scale for the movie review generator\n                        that emphasizes precise differentiation between all levels of reflective accuracy\n                   and expressed enthusiasm. Assign the classification labels \"1\", \"2\", \"3\", \"4\", and\n                       \"5\", with each level distinctly representing the depth and sincerity of reflection\n                  on the movie description as well as the intensity and authenticity of enthusiasm:\n                       1. Deficient Reflection and Lacking Enthusiasm (\"1\"): Reviews that funda-\n                    mentally misrepresent or ignore the movie description and display a lack of\n                    genuine enthusiasm, signaling a complete disconnect and an ineffective critique.\n                        2. Basic Reflection and Low Enthusiasm (\"2\"): Reviews that merely mention\n                     aspects of the movie description without depth and show only a low level of\n                     enthusiasm, resulting in a critique that lacks persuasive power and engagement.\n                       3. Adequate Reflection and Moderate Enthusiasm (\"3\"): Reviews that reflect\n                      the movie description accurately and convey moderate enthusiasm, offering a\n                          fair and constructive critique that is neither overly zealous nor dispassionate.\n                       4. Detailed Reflection and High Enthusiasm (\"4\"): Reviews that capture the\n                    nuances of the movie description in detail and exhibit high enthusiasm, present-\n                     ing a critique that is both engaging and substantively insightful. 5. Exceptional\n                     Reflection and Intense Enthusiasm (\"5\"): Reviews that deeply engage with\n                      the movie description, demonstrating both an exceptional level of reflection\n                  and intense enthusiasm, with critiques that significantly enhance the analysis\n                   and captivate the audience. This adjusted scale is designed to correct the prior\n                      misclassifications by ensuring clear and accurate recognition of each level of\n                     performance, thereby avoiding the underestimation of high-quality reviews and\n                     providing a fair representation for lower-quality outputs.\n\n  Initial Prompt      Generate an authentic enthusiastic movie review for the following movie\n (Mean rank: 4.4)\n\n OPRO [35]       Compose a compelling and positive movie review for a recent release, capturing\n (Mean rank: 4.3)   the film’s essence while highlighting unique elements that make it stand out.\n\n PE [37]            Create a movie review generator that articulates sophisticated genre-specific\n (Mean rank: 4.1)   language while ensuring that advanced terminology is immediately followed\n                  by comprehensible explanations. This approach guarantees that the review\n                   remains accessible to a broad readership, including both seasoned cinephiles\n                   and those new to film criticism. The generator must offer an in-depth narrative\n                        analysis, employing narrative theory to enrich the commentary on the film’s plot,\n                      character arcs, and thematic substance, all while maintaining an educational yet\n                   non-academic tone. It should craft reviews that exude excitement and provide\n                   an even-handed critique, spotlighting the film’s artistic accomplishments as\n                     well as constructively addressing areas for improvement. The result should be\n                   an authoritative and engaging review that captures the essence of the movie\n                    with enthusiasm and critical precision, appealing to a wide spectrum of movie\n                       enthusiasts.\n\n IPC               Devise a movie review generator that excels in providing a balanced and nu-\n (Mean rank: 4.8)   anced critique, ensuring that each review exudes genuine enthusiasm for the\n                    movie’s triumphs while offering an insightful, yet subdued, evaluation of its less\n                      successful elements. The generator must consistently utilize precise and vibrant\n                   examples to underpin its praises, such as remarkable performances, poignant\n                       plot developments, and groundbreaking directorial choices. It is vital to include\n                    a section in the review that thoughtfully places the film within its genre and\n                        historical cinematic context, highlighting its unique contributions and potential\n                      influence. Reviews should read as an authoritative, persuasive endorsement\n                     of the film’s merits, inviting readers to not only enjoy but also understand its\n                      significance in the film world, all while keeping the tone wholly positive and\n                     engaging.\n\nTable 4: A comparison between the prompt with the best training score in each method on the\nauthentic and enthusiastic generative task. The GT ranker is provided in the first row. While OPRO\nand PE result in a prompt that performs worse than the initial simple prompt. Using IPC results in a\nsignificantly better prompt.                                       16\n\nSentiment GT           Does this movie review have a positive sentiment? Answer Yes\n                           or No. Answer No only in case there is an explicit expression of\n                             dissatisfaction otherwise, answer yes.\n\nSentiment Initial Prompt   Does this movie review have a positive sentiment? answer Yes or\n                  No\n\nPG GT               Augment the IMDB review classifier to better recognize and\n                             classify reviews containing adult themes. The classifier should\n                            label a review as ’Yes’ when it detects not only explicit descrip-\n                            tions of sex, violence, and strong language but also subtle adult\n                         themes, such as suggestive dialogue, nuanced portrayals of rela-\n                             tionships, and indirect references to sex or desire. Additionally,\n                           the classifier should account for adult humour and jokes that are\n                           presented in a lighthearted manner, ensuring they are not missed.\n                                     It should also accurately identify implicit adult content conveyed\n                         through cinematic techniques or complex narratives, as well as\n                          non-graphic mature content like restrained portrayals of infidelity\n                          or taboo relationships. Furthermore, personal remarks on the\n                            attractiveness of actors or suggestive comments that reviewers\n                     make must be included in the ’Yes’ category. Conversely, reviews\n                              that lack explicit adult content, significant implications of mature\n                         themes, and any aforementioned subtleties should be classified\n                           as ’No’.\n\nPG Initial Prompt        Does this movie contain ah adult content? answer Yes or No\n\n             Table 5: Prompts for the PG and sentiment classification tasks.\n\n\n\n\n\n                                    17",
"headers": [
"Appendix",
"arXiv:2402.03099v1  [cs.CL]  5 Feb 2024",
"Intent-based Prompt Calibration: Enhancing prompt",
"optimization with synthetic boundary cases",
"Abstract",
"1",
"Introduction",
"2",
"Method",
"3",
"Experiments",
"4",
"Related Work",
"5",
"Conclusions",
"References",
"A",
"Implementation details",
"B",
"Experiments: Additional details"
],
"tables": [
"|GT prompt|To improve the IMDB review spoiler classifier, label a review as ’Yes’ for containing<br>a spoiler if it: 1. Even subtly hints at the outcome of subplots or the development of<br>the story, such as mentioning a character’s transformation or key relationships without<br>explicit details. 2. Makes observations on the narrative structure, like pacing or the<br>significance of certain scenes, which could indirectly indicate important plot points.<br>3. Alludes to twists, endings, or character fates with veiled language that doesn’t<br>explicitly outline the events but provides enough context to infer them. Conversely,<br>label a review as ’No’ for no spoilers if it: 1. Focuses on broad discussions of character<br>traits, emotional tone, or film structure without revealing any specific plot points. 2.<br>Offers critiques or praise of film elements like pacing, genre, actor performances, and<br>filmmaking techniques that are independent of plot developments. 3. Explores the<br>film’s themes or the emotional journey it offers in a way that avoids any direct or<br>indirect plot or character spoilers.|\n|---|---|\n|Initialprompt|Does this movie review contain a spoiler? answer Yes or No|\n|OPRO [35]|Examine the movie synopsis with vigilance for spoiler content and succinctly affirm<br>theirpresence with \"Yes\" or negate with \"No\".|\n|PE [37]|Analyze the IMDB review for elements that provide significant insights into the plot or<br>reveal crucial turning points, even if mentioned subtly or indirectly. Look for elements<br>that give away the resolution of central conflicts, character arcs, or the outcome of<br>pivotal events. Additionally, distinguish between powerful scene descriptions and<br>actual plot revelations; the former should not be classified as spoilers unless they<br>disclose essential plot information. Based on your analysis, classify the review as ’Yes’<br>for containing spoilers that impact the viewing experience, or ’No’ for free of such<br>spoilers.|\n|IPC|IMDB Review Spoiler Identification Protocol: For the task of classifying IMDB<br>reviews for the presence of spoilers, the classifier must label reviews with a heightened<br>sensitivity to nuanced language and indirect spoiler cues. The classification labels are<br>’Yes’ for spoilers and ’No’ for non-spoilers. Apply the following criteria rigorously:<br>Label ’Yes’ if a review: - Contains subtle references or nuanced language that hints<br>at plot developments or character arcs, without explicit detail. - Includes emotional<br>responses or descriptive language that indirectly reveals plot outcomes or twists. -<br>Employs suggestive language that points to future events or endings, even if it does<br>not reveal specific information. Label ’No’ if a review: - Discusses technical aspects,<br>acting, direction, or personal viewer impressions in a manner that does not hint at or<br>reveal any plot details. - Comments on thematic elements, genre characteristics, or<br>storytelling techniques without disclosing or implying crucial plot twists. - Expresses<br>opinions on the movie’s quality, performances, or execution that are free from any<br>storyline implications or potential spoiler content. In both ’Yes’ and ’No’ classifications,<br>special attention must be given to the implicit meaning behind words and the context in<br>which they are used to prevent misclassification of subtle spoiler content and to ensure<br>a genuine viewing experience for others.|",
"|GT ranker|Establish a revised fvie-point assessment scale for the movie review generator<br>that emphasizes precise differentiation between all levels of reflective accuracy<br>and expressed enthusiasm. Assign the classification labels \"1\", \"2\", \"3\", \"4\", and<br>\"5\", with each level distinctly representing the depth and sincerity of reflection<br>on the movie description as well as the intensity and authenticity of enthusiasm:<br>1. Deficient Reflection and Lacking Enthusiasm (\"1\"): Reviews that funda-<br>mentally misrepresent or ignore the movie description and display a lack of<br>genuine enthusiasm, signaling a complete disconnect and an ineffective critique.<br>2. Basic Reflection and Low Enthusiasm (\"2\"): Reviews that merely mention<br>aspects of the movie description without depth and show only a low level of<br>enthusiasm, resulting in a critique that lacks persuasive power and engagement.<br>3. Adequate Reflection and Moderate Enthusiasm (\"3\"): Reviews that reflect<br>the movie description accurately and convey moderate enthusiasm, offering a<br>fair and constructive critique that is neither overly zealous nor dispassionate.<br>4. Detailed Reflection and High Enthusiasm (\"4\"): Reviews that capture the<br>nuances of the movie description in detail and exhibit high enthusiasm, present-<br>ing a critique that is both engaging and substantively insightful. 5. Exceptional<br>Reflection and Intense Enthusiasm (\"5\"): Reviews that deeply engage with<br>the movie description, demonstrating both an exceptional level of reflection<br>and intense enthusiasm, with critiques that significantly enhance the analysis<br>and captivate the audience. This adjusted scale is designed to correct the prior<br>misclassifications by ensuring clear and accurate recognition of each level of<br>performance, thereby avoiding the underestimation of high-quality reviews and<br>providing a fair representation for lower-quality outputs.|\n|---|---|\n|Initial Prompt<br>**(Mean rank: 4.4)**|Generate an authentic enthusiastic movie review for the following movie|\n|OPRO [35]<br>**(Mean rank: 4.3)**|Compose a compelling and positive movie review for a recent release, capturing<br>the film’s essence while highlighting unique elements that make it stand out.|\n|PE [37]<br>**(Mean rank: 4.1)**|Create a movie review generator that articulates sophisticated genre-specific<br>language while ensuring that advanced terminology is immediately followed<br>by comprehensible explanations. This approach guarantees that the review<br>remains accessible to a broad readership, including both seasoned cinephiles<br>and those new to film criticism. The generator must offer an in-depth narrative<br>analysis, employing narrative theory to enrich the commentary on the film’s plot,<br>character arcs, and thematic substance, all while maintaining an educational yet<br>non-academic tone. It should craft reviews that exude excitement and provide<br>an even-handed critique, spotlighting the film’s artistic accomplishments as<br>well as constructively addressing areas for improvement. The result should be<br>an authoritative and engaging review that captures the essence of the movie<br>with enthusiasm and critical precision, appealing to a wide spectrum of movie<br>enthusiasts.|\n|IPC<br>**(Mean rank: 4.8)**|Devise a movie review generator that excels in providing a balanced and nu-<br>anced critique, ensuring that each review exudes genuine enthusiasm for the<br>movie’s triumphs while offering an insightful, yet subdued, evaluation of its less<br>successful elements. The generator must consistently utilize precise and vibrant<br>examples to underpin its praises, such as remarkable performances, poignant<br>plot developments, and groundbreaking directorial choices. It is vital to include<br>a section in the review that thoughtfully places the film within its genre and<br>historical cinematic context, highlighting its unique contributions and potential<br>influence. Reviews should read as an authoritative, persuasive endorsement<br>of the film’s merits, inviting readers to not only enjoy but also understand its<br>significance in the film world, all while keeping the tone wholly positive and<br>engaging.|",
"|Sentiment GT|Does this movie review have a positive sentiment? Answer Yes<br>or No. Answer No only in case there is an explicit expression of<br>dissatisfaction otherwise, answer yes.|\n|---|---|\n|Sentiment Initial Prompt|Does this movie review have a positive sentiment? answer Yes or<br>No|\n|PG GT|Augment the IMDB review classifier to better recognize and<br>classify reviews containing adult themes. The classifier should<br>label a review as ’Yes’ when it detects not only explicit descrip-<br>tions of sex, violence, and strong language but also subtle adult<br>themes, such as suggestive dialogue, nuanced portrayals of rela-<br>tionships, and indirect references to sex or desire. Additionally,<br>the classifier should account for adult humour and jokes that are<br>presented in a lighthearted manner, ensuring they are not missed.<br>It should also accurately identify implicit adult content conveyed<br>through cinematic techniques or complex narratives, as well as<br>non-graphic mature content like restrained portrayals of infidelity<br>or taboo relationships. Furthermore, personal remarks on the<br>attractiveness of actors or suggestive comments that reviewers<br>make must be included in the ’Yes’ category. Conversely, reviews<br>that lack explicit adult content, significant implications of mature<br>themes, and any aforementioned subtleties should be classified<br>as ’No’.|\n|PG Initial Prompt|Does this movie contain ah adult content? answer Yes or No|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/test/2402.03099v1.pdf"
}