{
"text": "Self-Supervised Prompt Optimization\n\n\n               Jinyu Xiang1*, Jiayi Zhang1,2*, Zhaoyang Yu1, Xinbing Liang1, Fengwei Teng2,\n            Jinhao Tu3, Fashen Ren2, Xiangru Tang4, Sirui Hong1, Chenglin Wu1†, Yuyu Luo2† ,\n             1DeepWisdom, 2The Hong Kong University of Science and Technology (Guangzhou),\n                                  3Independent Researcher, 4Yale University,\n\n\n\n\n                          Abstract\n\n                                                                                                                                       External\n                                                                                              Candidate\n                                                                                               Prompt                 Well-designed prompts are crucial for enhanc-                      Feedback       Question        Reference\n                                                                                                                                                                    Evaluate    New\n                                                                                                                                                    Feedback&                  ing Large language models’ (LLMs) reason-                                                                                                                                                     Prompt                                                                                                                                Revised\n                                                                                               LLM      Prompt                  ing capabilities while aligning their outputs                                                                                                                  LLM           Outputs                                                                                                                                             Optimize                                                                                                                                                                         Execute2025\n                 with task requirements across diverse domains.\n                However, manually designed prompts require                            (a) Prompt Optimization With External Reference\n                   expertise and iterative experimentation. WhileAug                   existing prompt optimization methods aim to\n                                                                                             Candidate Candidate                       Candidate\n\n                                                                                                                                                     Better\n                                                                                                                                     LLM\n                                                                                                                                                    Outputs&21           automateternal referencesthis process,such theyas groundrely heavilytruth onor ex-by             Prompt    Outputs        Question         OutputsEvaluate\n                humans, limiting their applicability in real-                                 Revised                                 Prompt\n                                                                                                                                        Outputs                world scenarios where such data is unavail-                          OptimizeLLM      Prompt       ExecuteLLM\n                  able or costly to obtain. To address this, we\n                                                                                                                                (b) Self-Supervised Prompt Optimization (Ours)\n                 propose Self-Supervised Prompt Optimization\n                (SPO), a cost-efficient framework that dis-\n                                                                     Figure 1: Comparison of Prompt Optimization Meth-[cs.CL]                  covers effective prompts for both closed and\n                                                                     ods. (a) illustrates the traditional prompt optimization\n                open-ended tasks without requiring external\n                                                                    process with external reference, where feedback from\n                   reference. Motivated by the observations that\n                                                                       the ground truth of humans is used to iteratively im-\n                prompt quality manifests directly in LLM out-\n                                                                 prove the best prompt. (b) presents our proposed self-\n                  puts and LLMs can effectively assess adher-\n                                                                       supervised prompt optimization, which utilizes pairwise\n                 ence to task requirements, we derive evalu-\n                                                                  comparisons of LLM’s own outputs to optimize prompts\n                   ation and optimization signals purely from\n                                                                    without relying on external reference.\n                  output comparisons.   Specifically, SPO se-\n                     lects superior prompts through pairwise out-\n                  put comparisons evaluated by an LLM eval-      and ensuring alignment with diverse task require-\n                    uator, followed by an LLM optimizer that       ments. However, creating effective prompts often\n                   aligns outputs with task requirements. Exten-        requires substantial trial-and-error experimentation\n                   sive experiments demonstrate that SPO out-      and deep task-specific knowledge.\n                 performs state-of-the-art prompt optimization\n                                                     To address this challenge, researchers have ex-\n                 methods, achieving comparable or superior re-arXiv:2502.06855v3                                                           plored Prompt Optimization (PO) methods that use                     sults with significantly lower costs (e.g., 1.1%\n                  to 5.6% of existing methods) and fewer sam-     LLMs’ own capabilities to automatically improve\n                    ples (e.g., three samples). The code is available       prompts. PO advances beyond traditional prompt\n                     at https://github.com/FoundationAgents/SPO.        engineering, by providing a more systematic and\n                                                                         efficient approach to prompt design. As shown\n          1  Introduction                                                                     in Figure 1(a), these methods typically involve an\n                                                                          iterative process of prompt optimization, execu-          As large language models (LLMs) continue to ad-\n                                                                          tion, and evaluation. The design choices for these             vance, well-designed prompts have become critical\n                                                       components significantly influence optimization              for maximizing their reasoning capabilities (Wei\n                                                                   effectiveness and efficiency. Existing approaches               et al., 2022; Zheng et al., 2024; Deng et al., 2023)\n                                                         have demonstrated success with both numerical\n                 *These authors contributed equally to this work.           evaluation mechanisms (Wang et al., 2024d; Yang\n                  †Corresponding authors: Chenglin Wu (E-mail: alexan-\n                                                                            et al., 2023; Fernando et al., 2024) and textual “gra-              derwu@deepwisdom.ai), Yuyu Luo (E-mail:yuyuluo@hkust-\n                gz.edu.cn)                                            dient” optimization strategies (Yüksekgönül et al.,\n\nGPOA             AGIEval             LIAR               WSC                BBH                Avg\n                                                                                                         100\n                               47                                                84                                                                                                                                  68      44                               46                       68                       82                       98                                                                                                                                  67\n      43                       45                                                80                       96                                                                                                                                  66                                                        66                       78      42                       44                                                                                                          94                                                                                                                                  65\n      41                       43                       64                       76                       92                       64                               42                                                74Performance                                                                                                                                  63      40                                                                                 72                       90                               41                       62                                                                                                                                  62                                                                                 70      39                                                                                                          88                               40\n                                                                                 68                                                61\n          10 1    100    101         10 1    100    101         10 1    100    101         10 1      100             10 1     100     101       10 1    100     101\n                                                        Cost($)\n                             APE        OPRO        PromptAgent        TextGrad        PromptBreeder        SPO\n\n\nFigure 2: Comparison of Performance (y-axis) and Optimization Costs in Dollars (x-axis) across Six Prompt\nOptimization Methods. SPO demonstrates competitive performance, consistently ranking among the top two\nmethods while maintaining significantly lower costs (ranging from 1.1% to 5.6% of the costs incurred by other\nmethods) across all datasets.\n\n\n2024). Through these innovations, PO methods    task requirements (Zheng et al., 2023; Li et al.,\nhave shown promise in reducing manual effort   2024b). These observations suggest that by lever-\nwhile enhancing task performance (Zhang et al.,   aging LLMs’ inherent ability to assess outputs\n2024a; Zhou et al., 2024; He et al., 2025).             that naturally reflect prompt quality, reference-free\n                                             prompt optimization becomes feasible.\n   Despite their potential, existing PO methods face\n                                                  Motivated by these insights, we propose a cost-significant challenges in real-world scenarios, as\n                                                           efficient framework that generates evaluation anddiscussed below. First, current methods often de-\n                                                  optimization signals purely from LLM outputs,pend heavily on external references for evaluation.\n                                                     similar to how self-supervised learning derivesMethods using ground truth for evaluation (Yang\n                                                       training signals from data. We term this approachet al., 2023; Fernando et al., 2024; Yüksekgönül\n                                                  Self-Supervised Prompt Optimization (SPO). Aset al., 2024; Pryzant et al., 2023) require large\n                                           shown in Figure 1, SPO builds upon the fundamen-amounts of annotated data to assess prompt qual-\n                                                                  tal Optimize-Execute-Evaluate loop while introduc-ity, yet such standard answers are often unavail-\n                                                   ing several innovative mechanisms:able in many practical applications, especially for\nopen-ended tasks. Similarly, methods relying on      (1) Output as Pairwise Evaluation Reference:\nhuman (Chen et al., 2024; Lin et al., 2024) require   At its core, SPO employs a pairwise comparison\nmanual evaluations or human-designed rules to gen-   approach that assesses the relative quality of out-\nerate feedback, which is time-consuming and con-   puts from different prompts. This evaluation mech-\ntradicts the goal of automation. Second, existing   anism leverages LLM’s inherent capability to un-\nmethods typically require evaluating prompts on    derstand task requirements, validating optimization\nnumerous samples to obtain reliable feedback, lead-    effectiveness without external references.\ning to substantial computational overhead (Wang       (2) Output as Optimization Guidance: SPO op-\net al., 2024d; Fernando et al., 2024).                 timizes prompts through LLM’s understanding of\n                                                         better solutions for the current best output. Rather  At the core of these challenges lies the absence\n                                                 than relying on explicit optimization signals, thisof reliable and efficient reference-free methods for\n                                                   process naturally aligns prompt modifications withassessing prompt quality.  Analysis of LLM be-\n                                                    the model’s comprehension of optimal task solu-havior reveals two key insights that inform our\n                                                           tions.approach. First, prompt quality inherently mani-\nfests in model outputs, as evidenced by how dif-     Contributions. Our main contributions are as\nferent prompting strategies significantly influence    follows:\nboth reasoning paths (Wei et al., 2022; Deng et al.,      (1) Self-Supervised Prompt Optimization\n2023) and response features (Wang et al., 2024b;   Framework. We introduce SPO, a novel frame-\nSchmidgall et al., 2025). Second, extensive stud-   work  that leverages pairwise comparisons of\nies on LLM-as-a-judge have demonstrated their   LLM’s outputs to guide prompt optimization with-\neffectiveness in evaluating output adherence to    out requiring external reference.\n\n(2) Cost-effective Optimization. SPO opti-    truth. These sources provide the basis for assessing\nmizes prompts with minimal computational over-   prompt performance.\nhead ($0.15 per dataset) and sample requirements     Evaluation Methods The evaluation method\n(3 samples), significantly reducing resource de-   defines how the evaluation sources are assessed\nmands.                                      and the associated costs.  Three common meth-\n   (3) Extensive Evaluation. As shown in Figure 2,   ods are used:  (1) Benchmark relies on prede-\nSPO requires only 1.1% to 5.6% of the cost of    fined metrics (Suzgun et al., 2023; Rein et al.,\nstate-of-the-art methods while maintaining superior   2023) or rules (Chen et al., 2024).  (2) LLM-as-\nperformance across both closed and open-ended    a-judge (Zheng et al., 2023) leverage LLMs capa-\ntasks.                                                      bility to understand and assess outputs based on\n                                                       task requirements. (3) Human Feedback (Lin et al.,\n2  Preliminary                               2024) provides the most comprehensive evaluation\n                                                 through direct human assessment of outputs.2.1  Problem Definition\n                                             While Human Feedback offers the most thor-\nPrompt Optimization aims to automatically en-                                          ough evaluation by capturing human preferences\nhance the effectiveness of a prompt for a given task                                            and task-specific needs,  it incurs substantially\ntype t ∈T . For a given type t, we observe a dataset                                                  higher costs than Benchmark or LLM-as-a-judge\nDt = {(Qi, Gi)}Nti=1, which each pair consists of   methods, creating a trade-off between evaluation\nan input query Qi and the optional ground truth Gi.                                                      quality and feasibility.\nA candidate prompt for type t is denoted Pt ∈P,                                           Feedback Types Feedback produced by eval-\nand the goal is to find a optimal prompt.                                                   uation methods typically take three forms:  (1)\n                                             Numerical Feedback provides quantitative perfor-\n  ∗                    h                  i   mance measures across the dataset. However, itP t = arg max E(Q,G)∼Dt  ϕeval ϕexe(Q, Pt), G   .\n       Pt∈P                                        requires substantial samples for stable evaluation\n                                                 (1)   and may overlook instance-specific details (Zhang\n  As illustrated in Figure 1, this optimization pro-    et al., 2024a).  (2) Textual Feedback offers rich,\ncess typically involves three fundamental func-   instance-specific guidance through analysis and\ntions: (1) Optimization function (ϕopt): generates    suggestions, directly generating optimization sig-\na revised prompt based on the candidate prompt;    nals (Yüksekgönül et al., 2024). (3) Ranking or Se-\n(2) Execution function (ϕexe): applies the revised    lection Feedback establishes relative quality order-\nprompt with an LLM to produce output O, con-   ing among outputs through either complete ranking\nsisting of a reasoning path and a final answer; (3)    or pairwise comparisons, providing clear optimiza-\nEvaluation function (ϕeval): assesses the quality of    tion direction without requiring absolute quality\nO and provides feedback F to guide further opti-   measures.\nmization, refining the candidate prompts iteratively.\n                                             Evaluation Framework  Building on the previ-\n  Among these functions, the evaluation func-\n                                              ous discussion on evaluation’s sources, methods,\ntion plays a pivotal role as its output (feedback\n                                            and feedback types, the evaluation framework de-\nF) guides the assessment and improvement of\n                                                 termines how sources are compared and assessed\nprompts. We will discuss the evaluation framework\n                                                   within the context of prompt optimization. Specifi-\nfor prompt optimization in Section 2.2.\n                                                              cally, we derive two evaluation frameworks to gen-\n2.2  Evaluation Framework in Prompt            erate feedback F for prompt optimization:\n     Optimization                                      (1) Output vs. Ground Truth (OvG): Feedback\n                                                                is generated by comparing the output Oi of query\nThis section outlines our evaluation framework for\n                                         Qi with ground truth Gi:\nprompt optimization, covering three key compo-\nnents: evaluation sources, evaluation methods, and\n                                                    fOvG = ϕeval ϕexe(Qi, Pt), Gi  .      (2)\nfeedback types, as shown in Figure 3. We conclude\nby introducing our selected evaluation framework     Although this approach allows for a direct qual-\nfor SPO.                                                  ity assessment through an external reference,  it\n  Evaluation Sources As shown in Figure 3(a),   requires well-defined ground truth, making it un-\ntwo primary sources can be used for evaluation:    suitable for open-ended tasks where ground truth\nLLM-generated outputs and task-specific ground   may not always be available or practical to define.\n\nOutput   First, we calculate…                                         Numerical Signal:      optimization signals. We propose Self-Supervised\n                                                                      0.95   The                   value     Groundfinal             exactTruth\n   is:\\[\\boxed{\\frac{1}                                             Prompt Optimization (SPO), a simple yet effective          exact                value   {350}}\\]The                      of $|           Benchmark\n      \\pi-3.14|+|\\pi-                                                             Selection Signal:\n      \\frac{22}{7}|$                     is $                                             Output B is Better …     framework that retains the basic Optimize-Execute-      \\frac{1}{350}$.\n                                  LLM-as-a-Judge         Rank                                                                  Signal:\n                                                                      B ≻ A                                                                            ≻ …           Evaluate loop while enabling reference-free opti-   Output A\n   The degree of a\n   polynomial              is                                                  mization                                                   by                                                                leveraging                                                                       only model outputs                                                                                              as both     Output                                 Human Feedback\n   determined                                                             Textual                                                                     Signal:      The              byB …of\n   The       finaldegreeanswer                    isa                       \\                                                                      The                                                                          consistency                                                                                      of      polynomial                 is\n   (\\boxed{42}\\).                                                    evaluation                                                             sources                                                             and optimization                                                                                    guidance.                                                                      outputs                                                                              is                                                                                 …      determined                 by                    …                                           (b) Evaluation                                           Methods\n      The final answer is \\                                           You need to modify it\n      (\\boxed{0}\\).                                                   …              As shown in Algorithm 1, SPO operates through\n      (a) Evaluation Sources                                                    (c) Feedback Types      three key components and the corresponding\nFigure 3: Components of the Evaluation Framework for   prompts are shown in Appendix A.1:\nPrompt Optimization.  (a) Evaluation Sources: Com-\npares different outputs, including ground truth and        • Optimization function (ϕopt): Generates new\nmodel-generated outputs, to assess quality. (b) Evalua-       prompts by analyzing the current best prompt\ntion Methods: Showcases various evaluation techniques,       and its corresponding outputs.\nincluding benchmark comparisons, LLM-as-a-Judge,\nand human feedback. (c) Feedback Types: Showcases a        • Execution function (ϕexe): Applies the gener-\nrange of feedback. For clarity, the rank-signal example                                                         ated prompts to obtain outputs.\nnow compares only Output A and Output B. The blue in\n(a), (b), and (c) indicate the specific evaluation approach        • Evaluation function (ϕeval): Uses an LLM to\nselected for SPO.\n                                               compare outputs and determine the superior\n                                                 prompt through pairwise comparisons.\n   (2) Output vs. Output (OvO): When ground\n                                                    This iterative process begins with a basic prompttruth is unavailable, we turn to direct output com-\n                                                 template  (e.g.,  Chain-of-Thought (Wei  et  al.,parison. The core idea behind OvO is that even\n                                                2022)) and a small question set sampled from thein the absence of perfect ground truth, comparing\n                                                        dataset.  In each iteration, SPO generates newoutputs generated by different prompts can offer\n                                                prompts, executes them, and performs pairwisevaluable signals about their relative quality. This\n                                                    evaluations of outputs to assess their adherence tomethod removes the dependency on external ref-\n                                                      task requirements.erences and is particularly useful for open-ended\n                                           The prompt associated with the superior outputtasks where multiple answers may be valid. It can\n                                                                is selected as the best candidate for the next iter-be formally expressed as:\n                                                        ation. The process continues until a predefined\n                                     maximum number of iterations is reached.\n      fOVO = ϕeval {ϕexe(Qi, Pi)}, Gi  .     (3)   A Running Example As illustrated in Figure 4,\n                                 SPO achieves high efficiency, requiring only 8\n  After introducing the OvG and OvO evaluation  LLM calls per iteration with three samples, sig-\nframeworks, we emphasize that OvO serves as the    nificantly lower than existing methods (Wang et al.,\ncore method in Self-Supervised Prompt Optimiza-   2024d; Fernando et al., 2024; Yüksekgönül et al.,\ntion (SPO). By comparing outputs generated by   2024; Shen et al., 2024a; Zhou et al., 2023). De-\ndifferent prompts, OvO provides valuable feedback    spite its simplicity, SPO demonstrates superior per-\non their relative quality without relying on external   formance across a range of tasks, as detailed in\nreference. This approach aligns with our objective    Section 4. In the following section, we analyze the\nof generating feedback directly from the outputs    theoretical foundations of its effectiveness.\nthemselves, thus facilitating iterative optimization\nin both closed and open-ended tasks.                3.2  Understanding the Effectiveness of SPO\n                                         The theoretical foundation of SPO is built upon\n3  Self-Supervised Prompt Optimization\n                                           two key observations:\nIn this section, we first overview our method (Sec-       First,  the outputs of LLMs inherently con-\ntion 3.1) and then analyze its effectiveness (Sec-    tain rich quality information that directly reflects\ntion 3.2).                                     prompt effectiveness, as evidenced by how step-\n                                                  by-step reasoning paths demonstrate the success\n3.1  An Overview of SPO                                                   of Chain-of-thought prompting (Wei et al., 2022).\nA core challenge in reference-free prompt optimiza-   Second, LLMs exhibit human-like task comprehen-\ntion is how to construct effective evaluation and    sion, enabling them to assess answer quality and\n\n(a) Prompt Optimization                                                       (b) Prompt Execution\n\n\n      PROMPT_OPTIMIZE_PROMPT = \"\"\"                                  You are an expert creative writing assistant skilled in\n      You are building a prompt to address user                     adopting various personas and perspectives …\n      requirement.                                                  1. Carefully analyze …\n      Based on the given prompt…\n      requirements: {requirements}                                  Q: Write an article about time travel …\n      reference prompt: {prompt}\n      The execution result of this reference\n      prompt is(some cases): {answers}\n                                                                # Introduction\n      Provide your analysis, optimization\n                                                                Imagine stepping into a machine, vanishing in a flash …\n      points, and the complete optimized prompt\n      using the following XML format …\n      \"\"\"\n\n                                                                                                        (c) Answer Evaluation\n      You are a creative writing assistant\n      skilled in adopting various personas and\n      perspectives …\n                                                                   ANSWER_EVALUATE_PROMPT = \"\"\"                A: # Intro\n      # Introduction                                               Based on the original requirements,         Imagine\n      The real enigma lies in traveling to …                       evaluate the two responses …                stepping into\n                                                                   # A {sample_1} # B {sample_2}               a machine …\n                                                                   Provide your analysis and the\n         Optimize                                                 choice you believe is better…               B: # Intro\n                                                                   \"\"\"                                         The real\n      You are an expert creative writing\n                                                                                                               enigma lies\n      assistant skilled in adopting various\n                                                                                                               in traveling\n      personas and perspectives …                               Response A is more creative …                  to the past …\n      1. Carefully analyze …\n\nFigure 4: A Running Example of SPO Framework: Pairwise evaluation on the outputs selects the  better one\nfrom corresponding prompts . The best output and prompt pair are highlited with pentagrams, which will be\nupdated after evaluation. Furthermore, using a case from MT-bench, we show the complete process of SPO’s ϕopt,\nϕexe, and ϕeval and corresponding prompt .\n\n\nAlgorithm 1 An Overview of SPO.                 optimization signals, SPO’s optimization essen-\nRequire: Dataset D                                          tially guides prompts toward the LLM’s optimal\nEnsure: Optimized Prompt P ∗                                                  understanding of the task.\n 1: Initialize P0; Sample 3 Questions Q from D\n 2: Best Prompt P ∗←P0                          Output as Pairwise Evaluation Reference Re-\n 3: Best Answer A∗←ϕexe(Q, P ∗)                     garding ϕeval design, by employing the evaluation\n 4: for iteration ←1 to Nmax do               ′                                     model to perform pairwise selection, we are effec- 5:  P ←ϕopt(P ∗, A∗)\n 6:   A′ ←ϕexe(Q, P ′)                                  tively leveraging the evaluation model’s inherent\n 7:   optimizationSuccess ←ϕeval(Q, A′, A∗)          preference understanding of tasks. This internal\n 8:     if optimizationSuccess then\n                               ′                                      signal can be obtained through simple pairwise 9:    P ∗←P\n10:   A∗←A′                                  comparisons of outputs, avoiding the need for large\n11:   end if                                    sample sizes to ensure scoring stability, which is\n12: end for\n                                                       typically required in score-based feedback meth-13: return P ∗\n                                                     ods.\n                                              While we mitigate potential biases through four\nidentify superior solutions based on task require-   rounds of randomized evaluation, these biases can-\nments. These complementary capabilities allow    not be completely eliminated (Zhou et al., 2024).\nSPO to perform prompt evaluation and optimiza-   However, these biases do not affect the overall op-\ntion without external references. These two aspects    timization trend because eval’s feedback merely\nof utilizing model outputs work together to enable    serves as a reference for the next round of opti-\neffective prompt optimization:                      mization. The overall optimization process nat-\n  Output as Optimization Guidance In terms of    urally aligns with the optimization model’s task\nϕopt design, unlike other methods that introduce    understanding, with the eval mechanism serving to\nexplicit optimization signals (Fernando et al., 2024;    validate the effectiveness of each iteration.\nYüksekgönül et al., 2024; Pryzant et al., 2023),\nϕopt optimizes directly based on the prompt and   4  Experiment\nits corresponding outputs. The optimization signal\n                                                    4.1  Experimental Setup\nstems from the LLMs’ inherent ability to assess\noutput quality, while the optimization behavior is   Datasets We evaluated SPO on a diverse set of\nguided by its understanding of what constitutes su-    tasks, including both closed tasks and open-ended\nperior solutions. Therefore, even without explicit    tasks, to comprehensively assess its effectiveness.\n\nTable 1: Comparison of performance between conventional prompt methods and prompt generated by prompt\noptimization methods in five benchmarks. All methods are executed with GPT-4o-mini on the divided test set, with\nresults averaged over three runs. SPO and SPO ∗use Claude-3.5-Sonnet and GPT-4o as their optimization models,\nrespectively. The Avg. Cost refers to the averaged optimization cost.\n\n\n                                                     Method Analysis\n  Method\n                          GPQA  AGIEval-MATH  LIAR  WSC   BBH-Navigate   Avg. Perf.   Avg. Cost($)\n  IO                                     38.9          42.1         63.5    72.4        91.3           61.6               -\n  CoT (Wei et al., 2022)                   41.6          44.5         65.4    77.8        89.7           63.8               -\n  Rephrase (Deng et al., 2023)             40.2          42.1         50.5    79.1        93.5           61.1               -\n  Step-back (Zheng et al., 2024)            42.4          47.5         62.8    78.7        93.5           65.0               -\n  APE (Zhou et al., 2023)                  41.1          44.4         65.9    80.2        92.5           64.8          9.07\n OPRO (Yang et al., 2023)                43.3          46.1         67.6    80.2        95.8           66.6          4.51\n  PromptAgent (Wang et al., 2024d)        41.3          41.4         64.1    82.7        95.7           65.0          2.71\n  PromptBreeder (Fernando et al., 2024)    40.9          45.9         63.2    76.7        96.3           64.5          4.82\n  TextGrad (Yüksekgönül et al., 2024)      40.2          44.4         65.7    78.0        91.3           63.9         13.14\n SPO (ours)                             43.6          46.1         67.1    82.0        97.2           66.9          0.15\n  SPO∗(ours)                            41.8          45.3         66.9    81.1        96.3           66.3          0.12\n\n\n  For closed tasks, we utilized five established   0 for execution) is used for both evaluation and\nbenchmarks: GPQA (Rein et al., 2023), AGIEval-   execution. The optimization process runs for 10\nMATH (Zhong  et  al.,  2024), LIAR (Wang,    iterations with three samples per iteration, while\n2017), WSC (Levesque et al., 2012), and BBH-   detailed baseline implementation settings are pro-\nnavigate (Suzgun et al., 2023). For WSC, LIAR,   vided in Appendix A.3.\nand BBH-Navigate, we sampled portions from their\noriginal datasets as test sets following Yan et al.   Metrics We evaluate performance using accu-\n(2024). For GPQA, we used the more challeng-   racy metrics for GPQA, LIAR, BBH-Navigate,\ning GPQA-Diamond subset as the test set, while   AGIEval-MATH and WSC, following Yan et al.\nfor AGIEval-Math, we used Level 5 problems as    (2024); Saad-Falcon et al. (2024); Rein et al. (2023).\nthe test set.  For open-ended tasks, we selected   For MT-Bench, we report win rates of SPO com-\nwriting, roleplay, and humanities tasks from MT-   pared to other methods. To assess cost-efficiency,\nBench (Zheng et al., 2023). Given the limited size   we also measure optimization costs. To verify the\nof the dataset, we manually constructed three vali-    stability of results, we include standard deviation\ndation sets for these tasks. Detailed descriptions of    metrics in Appendix A.4.\nthe datasets and the construction procedures for val-\nidation and test sets are provided in Appendix A.3.   4.2  Experimental Results and Analysis\n\n                                     Main Result of Closed Tasks  As shown in Ta-Baselines We evaluate SPO against two cate-\n                                                    ble 1, prompts optimized by SPO outperform allgories of methods on closed tasks:  (1) conven-\n                                                  conventional prompting methods on average, ex-tional prompting approaches, comprising io (direct\n                                                ceeding the best baseline by 1.9. Meanwhile, itllm invocation), chain-of-thought, rephrase, and\n                                                   achieves comparable performance to ground truth-step-back abstract; and (2) automated prompt opti-\n                                              dependent prompt optimization methods acrossmization methods, including APE, OPRO, Promp-\n                                            most datasets, and reaches optimal results ontAgent, PromptBreeder and TextGrad with their\n                               GPQA and BBH-navigate datasets. Specifically,evaluation framework setting, features detailed in\n                                          SPO’s superior average performance over other op-Appendix A.3.2.\n                                                     timization methods demonstrates that its pairwise  For open-ended tasks in MT-Bench (Zheng et al.,\n                                                      evaluation approach can generate more effective op-2023), we use GPT-4o to compare outputs gener-\n                                                     timization signals compared to the tested methodsated by SPO against those directly generated by\n                                                     relying on external reference. Furthermore, to ver-the model.\n                                                           ify the effectiveness of our method across different\nImplementation Details  SPO employs different    optimization models, we conducted experiments\nmodels for optimization, evaluation, and execu-   using GPT-4o as the optimization model, achieving\ntion.  In the main experiments, we use Claude-   an average performance of 66.3. While slightly\n3.5-Sonnet-20240620 and GPT-4o-0806 (temper-   lower than results using Claude-3-5-Sonnet as the\nature = 0.7) as optimization models, while GPT-   optimization model, this still ranks third among all\n4o-mini-0718 (temperature = 0.3 for evaluation,   compared methods.\n\nCost Analysis  We present a comprehensive com-   curves of all three optimization models exhibit sim-\nparison of optimization costs and performance be-    ilar patterns: performance initially improves with\ntween SPO (using Claude-3.5-Sonnet and GPT-4o    increased sample number but eventually converges\nas optimization models) and other optimization    or declines. For iteration rounds, when we extend\nmethods in Table 1. While maintaining compara-   the optimization process to 20 rounds, we find that\nble performance with other ground truth-dependent    the actual performance of the optimal prompt se-\nprompt optimization methods, SPO requires only    lected by SPO similarly shows a pattern of ini-\n1.1% to 5.6% of their optimization costs, with     tial improvement followed by degradation, which\nan average optimization cost of 0.15 $ per dataset.  we attribute to overfitting to the sample questions.\nThe low computational cost and no need for ground   Based on these experiments, we determine the final\ntruth make SPO ideal for real-world applications.    sample number and iteration rounds for SPO, with\n                                          more details shown in Appendix A.4.\n\nTable 2: Performance comparison on BBH-navigate:                  Win Rate of Model A on MT-Bench\nprompting methods and SPO with different evaluation\n                                                                                                                                  (a) Writing                (b) Roleplay              (c) Humanities\nmodels (rows) and execution models (columns). The         IO\noptimization model is set to Claude-3.5-Sonnet.                      50.0  41.7  55.0    50.0  36.7  50.0    50.0  35.0  43.3        100(%)\n\n                                                                                    58.3  50.0  65.0    63.3  50.0  71.7    65.0  50.0  51.7        80(%)\n                  GPT-4o-mini Llama3-70B Claude-3-Haiku\n IO                     91.3          82.7            62.2       A      45.0  35.0  50.0    50.0  28.3  50.0    56.7  48.3  50.0        60(%)\n COT                   89.7          86.2           68                                      Model SPO\n  Claude-3.5-Sonnet      95           86.8            68.2                   83.3  73.3  80.0    93.3  66.7  66.7    83.3  70.0  56.7        40(%)\n Llama3-70B            94.5          94.2            82.0\n                                                                                    76.7  86.7  83.3    93.3  76.7  80.0    93.3  86.7  93.3        20(%)\n GPT-4o-mini           97.8          90.7            82.0\n\n                                                                                    50.0  53.3  60.0    73.3  66.7  83.3    66.7  50.0  53.3        0(%)\n\n\nTable 3:  Performance comparison across different                                  Model B (IO)\noptimization models (rows) and execution models    Figure 5: Win rates comparison between different LLMs\n(columns) on BBH-navigate. The evaluation model is   and SPO across three tasks. The heatmap shows pair-\nset to GPT-4o-mini.                                 wise win rates (%) where each cell represents the row\n                                                   model’s win rate against the column model. Models\n                  GPT-4o-mini Llama3-70B Claude-3-Haiku   tested include Claude-3.5-Sonnet, DeepSeek-V3, and\n  Claude-3.5-Sonnet      97.2          86.7            89.7       GPT-4o-mini. Models are evaluated both in IO (top\n GPT-4o                96.3          85.5            73.0        three rows) and after SPO optimization (bottom three\n GPT-4o-mini           97.8          90.7            82.0\n                                                        rows). Win rates range from 0% to 100%, with higher\n DeepSeek-V3          94.7          83.7            77.2\n                                                       percentages indicating better performance. Gemma-3-12B          97.5          92.0            69.0\n\n\nAblation Study  To evaluate the transferability   Main Result of Open-ended Tasks  To validate\nof SPO across different optimization, evaluation,   SPO’s capability in open-ended tasks, we selected\nand execution models, we conducted ablation ex-    three categories from MT-Bench: “Writing”, “Role-\nperiments on the BBH-Navigate dataset. The ex-   play”, and “Humanities” for evaluation. We use\nperimental results in Table 2, 3 demonstrate that    Claude-3.5-Sonnet as the optimization model, GPT-\nSPO exhibits robust performance across different   4o-mini as the evaluation model, and selected\nmodels. Notably, the best performance (97.8) was    Claude-3.5-Sonnet, DeepSeek-V3, and GPT-4o-\nachieved when GPT-4o-mini was used as the op-   mini as execution models, conducting five iter-\ntimization, execution, and evaluation model. In    ations.  Subsequently, following the evaluation\nterms of execution, SPO effectively improves the   methodology in (Zheng et al., 2023), we employed\nperformance of weaker models, elevating Claude-   GPT-4o to perform pairwise comparisons between\n3-Haiku from 62.2 to 89.7, demonstrating SPO’s   model A and model B’s output in Figure 5. The\napplicability to weaker models and further expand-   experimental results shown in 5 demonstrate that\ning its potential for real-world applications.      SPO significantly improves model performance\n  We conduct an ablation study to investigate the    across all model configurations. Notably, smaller\nimpact of sample number and iteration rounds   models (such as GPT-4o-mini) using optimized\non SPO’s performance using the BBH-Navigate   prompts frequently outperformed larger models in\ndataset.  For sample number, the performance   most scenarios.\n\n4.3  Case Study                                   5.2  Prompt Optimization\n\nWe present optimization results on additional open-   The design of evaluation frameworks is crucial\nended tasks without datasets and SPO’s optimiza-    in Prompt Optimization (PO), determining both\ntion trajectories in the Appendix A.5. We also    optimization effectiveness and computational effi-\nprovide optimal prompt across five closed tasks    ciency. The evolution of evaluation mechanisms\ndiscoverd by SPO in the supplementary material.   in PO has progressed from simple feedback col-\nGiven that real-world applications often face chal-    lection to sophisticated optimization signal genera-\nlenges with limited datasets, we evaluate SPO’s    tion (Chang et al., 2024). Existing methods largely\nperformance on tasks that lack conventional bench-    rely on ground truth as the evaluation source with\nmarks. The experimental results, coupled with   benchmark-based numerical assessments (Zhou\nSPO’s cost efficiency, demonstrate its practical    et al., 2023; Guo et al., 2024a; Yang et al., 2023;\nvalue in real-world scenarios.  Specifically, we   Fernando et al., 2024; Wang et al., 2024d; Khat-\ndemonstrate the optimization results after 10 itera-   tab et al., 2023), often requiring substantial iter-\ntions using Claude-3.5-Sonnet as the optimization    ations and samples, while others use LLM-as-a-\nmodel, GPT-4o-mini as the evaluation model, and    judge (Zheng et al., 2023) to generate detailed tex-\nLlama-3-8B as the execution model across four    tual feedback (Yan et al., 2024; Yüksekgönül et al.,\ntasks: Advertising Design, Social Media Content,   2024; Wu et al., 2024b; Wang et al., 2024c; Pryzant\nModern Poetry Writing, and Concept Interpreta-    et al., 2023; Li et al., 2025), still depending on\ntion in Appendix A.5.2. Moreover, we provide a   ground truth data. Some approaches focus on hu-\ncomprehensive analysis of SPO’s optimization tra-  man preferences through evaluation rules or direct\njectory on the BBH-navigate dataset in Appendix   feedback (Chen et al., 2024; Lin et al., 2024), while\nA.5.1, presenting both successful and unsuccessful    others explore alternative criteria like output con-\nexamples to offer deeper insights into the optimiza-   sistency (Zhang et al., 2024c).\ntion process.                                          In contrast to these approaches, SPO introduces\n                                                 a novel evaluation paradigm that eliminates depen-\n5  Related Work                            dency on external references while maintaining ef-\n                                                            ficiency. By leveraging only model outputs through5.1  Prompt Engineering\n                                                   pairwise comparisons, SPO achieves robust evalu-\nResearch on prompting methods for large language                                                     ation without requiring ground truth, human feed-\nmodels has primarily evolved along two directions.                                                   back, or extensive sampling, making it particularly\nThe first focuses on task-agnostic prompting tech-                                                        suitable for real-world applications.\nniques that enhance LLMs’ general capabilities, in-\ncluding chain-of-thought (Wei et al., 2022; Kojima   6  Conclusion\net al., 2022), single-shot reasoning enhancement\n                                                This paper addresses a key challenge in prompt\n(Deng et al., 2023; Zheng et al., 2024; Wang et al.,\n                                                    optimization: dependency on external references.\n2024e), and output format specification (Zhang\n                                We introduce Self-Supervised Prompt Optimiza-\net al., 2024a; He et al., 2024; Tam et al., 2024).\n                                                         tion (SPO), a framework that overcomes this depen-\nThe second direction addresses domain-specific\n                                             dency while achieving remarkable cost-efficiency\nprompting for tasks in code generation (Hong et al.,\n                                                             at only $0.15 per dataset. Drawing inspiration from\n2024b; Ridnik et al., 2024; Shen et al., 2024a),\n                                                     self-supervised learning, SPO innovatively con-\ndata analysis (Hong et al., 2024a; Liu et al., 2024;\n                                                           structs evaluation and optimization signals through\nLi et al., 2024a), question answering (Wu et al.,\n                                                  pairwise comparisons of model outputs, enabling\n2024a; Zhu et al., 2024; Yang et al., 2024), decision-\n                                                       reference-free optimization without compromising\nmakings (Zhang et al., 2024b; Wang et al., 2024a),\n                                                         effectiveness. Our evaluation shows SPO achieves\nand other domains (Guo et al., 2024b; Ye et al.,\n                                                         state-of-the-art performance across diverse tasks\n2024; Shen et al., 2024b). As LLM applications\n                                                while requiring only 1.1%-5.6% of existing meth-\nexpand to increasingly complex scenarios, manu-\n                                                 ods’ costs. Success on both benchmarks and real-\nally crafting effective domain-specific prompts be-\n                                              world applications validates SPO’s effectiveness\ncomes impractical (Zhang et al., 2024a), motivating\n                                             and generalization capabilities, making prompt op-\nresearch in prompt optimization to systematically\n                                                      timization more accessible and practical across var-\ndevelop effective prompts rather than discovering\n                                                    ious domains.\ngeneral principles.\n\nLimitations                                             multi-agents: A survey of progress and challenges.\n                                                                Preprint, arXiv:2402.01680.\nDespite SPO’s promising performance and cost\nefficiency, several limitations should be acknowl-   Han He, Qianchu Liu, Lei Xu, Chaitanya Shivade,\n                                                     Yi Zhang, Sundararajan Srinivasan, and Katrin Kirch-edged. First, while our method eliminates depen-\n                                                                  hoff. 2025. Crispo: Multi-aspect critique-suggestion-\ndence on external references, its effectiveness re-                                                     guided automatic prompt optimization for text gen-\nmains contingent on the evaluation model’s ability       eration.  In Proceedings of the AAAI Conference\nto accurately assess output quality, which may in-     on Artificial Intelligence, volume 39, pages 24014–\ntroduce biases when the evaluation model lacks      24022.\nsufficient understanding of specialized domains.                                                               Jia He, Mukund Rungta, David Koleczek, Arshdeep\nSecond, our approach currently focuses on opti-      Sekhon, Franklin X Wang, and Sadid Hasan. 2024.\nmizing prompts for a single model; future work     Does prompt formatting have any impact on llm per-\nshould explore cross-model prompt optimization to      formance? Preprint, arXiv:2411.10541.\nenhance transferability across different LLMs with\n                                                            Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu,\nvarying capabilities.                                Binhao Wu, Danyang Li, Jiaqi Chen, Jiayi Zhang,\n                                                                 Jinlin Wang, Li Zhang, Lingyao Zhang, Min Yang,\nEthical Consideration                          Mingchen Zhuge, Taicheng Guo, Tuo Zhou, Wei\n                                                        Tao, Wenyi Wang, Xiangru Tang, Xiangtao Lu, and\nSPO offers significant advancements in prompt      6 others. 2024a. Data interpreter: An LLM agent for\nengineering for LLMs, offering benefits such as       data science. CoRR, abs/2402.18679.\ndemocratized access, reduced costs, and improved\n                                                            Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawuperformance across various tasks. However, it also\n                                                    Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang,\ncarries risks, including potential bias amplification,                                                                     Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang\nmisuse of harmful content generation, and over-     Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu,\nreliance on LLMs.                                   and Jürgen Schmidhuber. 2024b. Metagpt: Meta pro-\n                                                 gramming for A multi-agent collaborative framework.\n                                                           In ICLR. OpenReview.net.\nReferences\n                                         Omar Khattab, Arnav Singhvi, Paridhi Maheshwari,\nKaiyan Chang, Songcheng Xu, Chenglong Wang,      Zhiyuan Zhang, Keshav Santhanam,  Sri Vard-\n  Yingfeng Luo, Tong Xiao, and Jingbo Zhu. 2024.     hamanan, Saiful Haq, Ashutosh Sharma, Thomas T.\n   Efficient prompting methods for large language mod-       Joshi, Hanna Moazam, Heather Miller, Matei Za-\n   els: A survey. CoRR, abs/2404.01077.                      haria, and Christopher Potts. 2023. Dspy: Compiling\n                                                               declarative language model calls into self-improving\nYongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang,       pipelines. CoRR, abs/2310.03714.\n  Nicholas Roy, and Chuchu Fan. 2024. Prompt opti-\n   mization in multi-step tasks (PROMST): integrating    Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\n  human feedback and heuristic-based sampling. In       taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\n  EMNLP, pages 3859–3920. Association for Compu-      guage models are zero-shot reasoners. In NeurIPS.\n   tational Linguistics.\n                                                   Hector J. Levesque, Ernest Davis, and Leora Morgen-\nYihe Deng, Weitong Zhang, Zixiang Chen, and Quan-                                                                     stern. 2012. The winograd schema challenge. In KR.\n  quan Gu. 2023. Rephrase and respond: Let large                                        AAAI Press.\n   language models ask better questions for themselves.\n  CoRR, abs/2311.04205.                                             Boyan Li, Yuyu Luo, Chengliang Chai, Guoliang Li,\n                                                    and Nan Tang. 2024a. The dawn of natural languageChrisantha  Fernando,  Dylan  Banarse,  Henryk\n                                                              to SQL: are we fully ready?  Proc. VLDB Endow.,  Michalewski, Simon Osindero, and Tim Rock-\n                                                      17(11):3318–3331.   täschel. 2024.   Promptbreeder:  Self-referential\n  self-improvement via prompt evolution. In ICML.\n                                              Dawei Li, Bohan Jiang, Liangjie Huang, Alimohammad  OpenReview.net.\n                                                            Beigi, Chengshuai Zhao, Zhen Tan, Amrita Bhat-\nQingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao       tacharjee, Yuxuan Jiang, Canyu Chen, Tianhao Wu,\n  Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu      Kai Shu, Lu Cheng, and Huan Liu. 2024b. From gen-\n  Yang. 2024a.  Connecting large language models       eration to judgment: Opportunities and challenges of\n  with evolutionary algorithms yields powerful prompt       llm-as-a-judge. CoRR, abs/2411.16594.\n   optimizers. In ICLR. OpenReview.net.\n                                                 Yafu Li, Xuyang Hu, Xiaoye Qu, Linjie Li, and\nTaicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang,     Yu Cheng. 2025. Test-time preference optimization:\n  Shichao Pei, Nitesh V. Chawla, Olaf Wiest, and Xi-      On-the-fly alignment via iterative textual feedback.\n   angliang Zhang. 2024b. Large language model based       Preprint, arXiv:2501.12895.\n\nXiaoqiang Lin, Zhongxiang Dai, Arun Verma, See-   Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Man-\n  Kiong Ng, Patrick Jaillet, and Bryan Kian Hsiang       dlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and An-\n  Low. 2024. Prompt optimization with human feed-     ima Anandkumar. 2024a. Voyager: An open-ended\n   back. arXiv preprint arXiv:2405.17346.               embodied agent with large language models. Trans.\n                                                 Mach. Learn. Res., 2024.\nXinyu Liu, Shuyu Shen, Boyan Li, Peixian Ma, Runzhi\n   Jiang, Yuxin Zhang, Ju Fan, Guoliang Li, Nan Tang,   Lei Wang, Jianxun Lian, Yi Huang, Yanqi Dai, Haox-\n  and Yuyu Luo. 2024. A survey of nl2sql with large      uan Li, Xu Chen, Xing Xie, and Ji-Rong Wen. 2024b.\n  language models: Where are we, and where are we      Characterbox: Evaluating the role-playing capabil-\n  going? Preprint, arXiv:2408.05109.                           ities of llms in text-based virtual worlds.  CoRR,\n                                                        abs/2412.05631.\nReid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chen-\n                                               Wenyi Wang, Hisham A Alyahya, Dylan R Ashley, Oleg  guang Zhu, and Michael Zeng. 2023.  Automatic\n                                                           Serikov, Dmitrii Khizbullin, Francesco Faccio, and  prompt optimization with \"gradient descent\" and\n                                                       Jürgen Schmidhuber. 2024c. How to correctly do  beam search.  In EMNLP, pages 7957–7968. As-\n                                                         semantic backpropagation on language-based agentic   sociation for Computational Linguistics.\n                                                          systems. arXiv preprint arXiv:2412.03624.\nDavid Rein, Betty Li Hou, Asa Cooper Stickland,                                                  William Yang Wang. 2017. \"liar, liar pants on fire\": A\n  Jackson Petty, Richard Yuanzhe Pang, Julien Di-                                            new benchmark dataset for fake news detection. In\n   rani, Julian Michael, and Samuel R. Bowman. 2023.                                      ACL (2), pages 422–426. Association for Computa-\n  GPQA: A graduate-level google-proof q&a bench-                                                                 tional Linguistics.\n  mark. CoRR, abs/2311.12022.\n                                               Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Hao-\nTal  Ridnik, Dedy  Kredo,  and  Itamar  Friedman.       tian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P. Xing,\n  2024. Code generation with alphacodium: From      and Zhiting Hu. 2024d.  Promptagent:  Strategic\n  prompt engineering to flow engineering.  CoRR,      planning with language models enables expert-level\n  abs/2401.08500.                                   prompt optimization. In ICLR. OpenReview.net.\n\nJon Saad-Falcon, Adrian Gamarra Lafuente, Shlok   Xu Wang, Cheng Li, Yi Chang, Jindong Wang, and\n   Natarajan, Nahum Maru, Hristo Todorov, Etash     Yuan Wu. 2024e. Negativeprompt: Leveraging psy-\n  Guha, Estefany Kelly Buchanan, Mayee Chen, Neel      chology for large language models enhancement via\n  Guha, Christopher Ré, and Azalia Mirhoseini. 2024.      negative emotional stimuli. In IJCAI, pages 6504–\n  Archon:  An architecture search framework for      6512. ijcai.org.\n   inference-time techniques. CoRR, abs/2409.15254.\n                                                    Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nSamuel Schmidgall, Yusheng Su, Ze Wang, Ximeng     Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\n  Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Zicheng      and 1 others. 2022. Chain-of-thought prompting elic-\n   Liu, and Emad Barsoum. 2025. Agent laboratory:         its reasoning in large language models. Advances in\n  Using llm agents as research assistants.  Preprint,      Neural Information Processing Systems, 35:24824–\n  arXiv:2501.04227.                                   24837.\n\n                                                      Yifan Wu, Lutao Yan, Leixian Shen, Yunhai Wang, NanLeixian Shen, Haotian Li, Yun Wang, Tianqi Luo,\n                                                       Tang, and Yuyu Luo. 2024a. Chartinsights: Evaluat-  Yuyu Luo, and Huamin Qu. 2024a.  Data play-\n                                                          ing multimodal large language models for low-level   wright: Authoring data videos with annotated nar-\n                                                             chart question answering.  In EMNLP (Findings),   ration.  IEEE Transactions on Visualization and\n                                                      pages 12174–12200. Association for Computational  Computer Graphics, pages 1–14.\n                                                               Linguistics.\nShuyu Shen, Sirong Lu, Leixian Shen, Zhonghua Sheng,                                               Yurong Wu, Yan Gao, Bin Zhu, Zineng Zhou, Xi-\n  Nan Tang, and Yuyu Luo. 2024b. Ask humans or ai?                                                        aodi Sun, Sheng Yang, Jian-Guang Lou, Zhiming\n   exploring their roles in visualization troubleshooting.                                                      Ding, and Linjun Yang. 2024b.  Strago: Harness-\n   Preprint, arXiv:2412.07673.                                                         ing strategic guidance for prompt optimization. In\n                                    EMNLP (Findings), pages 10043–10061. Associa-\nMirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\n                                                                tion for Computational Linguistics.\n   bastian Gehrmann, Yi Tay, Hyung Won Chung,\n  Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi,    Cilin Yan, Jingyun Wang, Lin Zhang, Ruihui Zhao,\n  Denny Zhou, and Jason Wei. 2023.  Challenging      Xiaopu Wu,  Kai Xiong,  Qingsong  Liu, Guo-\n  big-bench tasks and whether chain-of-thought can       liang Kang, and Yangyang Kang. 2024.  Efficient\n   solve them. In ACL (Findings), pages 13003–13051.     and accurate prompt optimization:  the benefit of\n  Association for Computational Linguistics.           memory in exemplar-guided reflection.   Preprint,\n                                                        arXiv:2411.07446.\nZhi Rui Tam, Cheng-Kuang Wu, Yi-Lin Tsai, Chieh-\n  Yen Lin, Hung-yi Lee, and Yun-Nung Chen. 2024.   Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,\n   Let me speak freely? A study on the impact of format     Quoc V Le, Denny Zhou, and Xinyun Chen. 2023.\n   restrictions on performance of large language models.      Large language models as optimizers. arXiv preprint\n  CoRR, abs/2408.02442.                                arXiv:2309.03409.\n\nXudong Yang, Yifan Wu, Yizhang Zhu, Nan Tang,\n  and Yuyu Luo. 2024. Askchart: Universal chart un-\n   derstanding through textual enhancement. Preprint,\n  arXiv:2412.19146.\n\nYilin Ye, Jianing Hao, Yihan Hou, Zhan Wang, Shishi\n  Xiao, Yuyu Luo, and Wei Zeng. 2024. Generative AI\n   for visualization: State of the art and future directions.\n  CoRR, abs/2404.18144.\n\nMert Yüksekgönül, Federico Bianchi, Joseph Boen,\n  Sheng Liu, Zhi Huang, Carlos Guestrin, and James\n  Zou. 2024. Textgrad: Automatic \"differentiation\" via\n   text. CoRR, abs/2406.07496.\n\nJiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng,\n  Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin\n  Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng,\n  Bang Liu, Yuyu Luo, and Chenglin Wu. 2024a.\n  Aflow: Automating agentic workflow generation.\n   Preprint, arXiv:2410.10762.\n\nJiayi Zhang, Chuang Zhao, Yihan Zhao, Zhaoyang Yu,\n  Ming He, and Jianping Fan. 2024b. Mobileexperts:\n A dynamic tool-enabled agent team in mobile devices.\n  CoRR, abs/2407.03913.\n\nXuanchang Zhang, Zhuosheng Zhang, and Hai Zhao.\n  2024c. Glape: Gold label-agnostic prompt evaluation\n  and optimization for large language model. CoRR,\n  abs/2402.02408.\n\nHuaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,\n  Heng-Tze Cheng, Ed H. Chi, Quoc V. Le, and Denny\n  Zhou. 2024. Take a step back: Evoking reasoning\n   via abstraction in large language models. In ICLR.\n  OpenReview.net.\n\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\n  Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\n  Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang,\n  Joseph E. Gonzalez, and Ion Stoica. 2023. Judging\n   llm-as-a-judge with mt-bench and chatbot arena. In\n  NeurIPS.\n\nWanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang,\n  Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,\n  and Nan Duan. 2024.  Agieval: A human-centric\n  benchmark for evaluating foundation models.  In\n  NAACL-HLT (Findings), pages 2299–2314. Associ-\n   ation for Computational Linguistics.\n\nHan Zhou, Xingchen Wan, Yinhong Liu, Nigel Collier,\n   Ivan Vulic, and Anna Korhonen. 2024. Fairer prefer-\n  ences elicit improved human-aligned large language\n  model judgments.  In EMNLP, pages 1241–1252.\n  Association for Computational Linguistics.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\n  Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\n  Ba. 2023. Large language models are human-level\n  prompt engineers. In ICLR. OpenReview.net.\n\nYizhang Zhu, Shiyin Du, Boyan Li, Yuyu Luo, and\n  Nan Tang. 2024. Are large language models good\n   statisticians? CoRR, abs/2406.07815.\n\nA  Appendix\n                                                                        # Requirement\n                                                                        {requirement}\nA.1  Detailed Prompts of SPO\n                                                                        # A\nIn this section, we present the Meta Prompt used          {Answer_A}\nfor iteration. It should be noted that here we have          # B\nonly used the simplest and most straightforward          {Answer_B}\nPrompt. There is still room for improvement by                                                                        Provide your analysis and the choice you believe is\noptimizing the following Meta Prompt for specific        ,→  better, using XML tags to encapsulate your\n                                                            ,→  response.\ndomains.\n                                                                        <analyse>Some analysis</analyse>\n                                                                        <choose>A/B (the better answer in your\n    Optimize Function’s Prompt                              ,→  opinion)</choose>\"\"\"\n\n\n     PROMPT = \"\"\"You are building a prompt to address user\n    ,→  requirement.Based on the given prompt, please\n    ,→  reconstruct and optimize it. You can add, modify,        The  evaluation  template  uses  comparative\n    ,→         or            delete prompts.                            Please                                   include                                           a single\n    ,→         modification                      in XML                             tags in                                     your reply.                                                 During          analysis  to  assess  response  quality.     It  re-\n    ,→  the optimization, you can incorporate any              quires XML-formatted reasoning that analyzes\n    ,→  thinking models.\n     This is a prompt that performed excellently in a           strengths/weaknesses  of two responses (A/B)\n    ,→         previous                  iteration.                             You must make                                           further\n    ,→         optimizations                       and improvements                                        based                                              on this            against requirements, followed by a definitive\n    ,→  prompt. The modified prompt must differ from the        choice.\n    ,→  provided example.\n\n     requirements:\n    ```                                       A.2  Detailed Prompt Template of Iteration\n     {requirements}                                          Start\n    ```\n                                                                   Iteration template on the BBH-navigate dataset     reference prompt:\n    ```\n     {prompt}\n    ```\n                                                                        prompt: |\n     The execution result of this reference prompt is(some                Please think step by step.\n    ,→  cases):                                                          Ensure the response concludes with the answer in\n    ```                                                       ,→  the XML format:\n     {answers}                                                            <answer>[Yes or No]</answer>.\n    ```\n                                                                        requirements: |\n     Provide your analysis, optimization points, and the                  Must put the final answer at the end with XML.\n    ,→  complete optimized prompt using the following XML              ,→  (<answer>(Yes or No)</answer>,such as\n    ,→  format:                                                 ,→  <answer>Yes</answer>)\n                                                                          The provided prompt needs to adapt to all current\n     <analyse>Analyze what drawbacks exist in the results              ,→  types of questions.\n    ,→  produced by the reference prompt and how to\n    ,→  improve them.</analyse>                                        faq:\n     <modification>Summarize the key points for                           - question: |\n    ,→  improvement in one sentence</modification>                             If you follow these instructions, do you\n     <prompt>Provide the complete optimized                               ,→  return to the starting point? Always face\n    ,→  prompt</prompt>\"\"\"                                             ,→  forward. Take 7 steps left. Take 2 steps\n                                                                   ,→  backward. Take 7 steps backward. Take 7\n                                                                   ,→  steps backward. Take 3 steps forward.\n                                                                                Options:\n                                                                                - Yes\n  This prompt template guides LLMs to iteratively                 - No\nimprove existing prompts through structured XML             answer: |\nanalysis. It requires identifying weaknesses in ref-                 A lot of thinking and analysis processes.\n                                                                                ...\nerence prompt outputs, proposing modifications,                 Final Answer:\nand generating optimized versions. The template                  <answer>(Yes or No)</answer>\nemphasizes incremental improvements while main-           - question: |\n                                                                                If you follow these instructions, do you\ntaining requirement compliance.                                 ,→  return to the starting point? Always face\n                                                                   ,→  forward. Take 6 steps backward. Take 8\n                                                                   ,→  steps left. Take 3 steps right. Take 7\n    Evaluate Function’s Prompt                                     ,→  steps forward. Take 3 steps right. Take 9\n                                                                   ,→  steps right. Take 1 step backward. Take 7\n                                                                   ,→  steps left.\n     PROMPT = \"\"\"Based on the original requirements,                            Options:\n    ,→  evaluate the two responses, A and B, and                               - Yes\n    ,→  determine which one better meets the                                   - No\n    ,→  requirements. If a reference requirement is\n    ,→  provided, strictly follow the format/content of                    answer: |\n    ,→  the reference requirement.                                             A lot of thinking and analysis processes.\n                                                                                ...\n\na system’s ability to perform commonsense rea-\n             Final Answer:\n             <answer>(Yes or No)</answer>                   soning by resolving pronoun references in context.\n       - question: |                                 For our experiments, we sampled portions from\n             If you                    follow                           these                                 instructions,                                               do                                                  you                                                     the original dataset as test sets following Yan et al.          ,→                 return                        to                           the starting                                        point?                                               Turn                                                    left.\n          ,→  Turn left. Take 6 steps. Take 3 steps.          (2024). AGIEval-MATH AGIEval-MATH (Zhong\n          ,→  Turn around. Take 1 step. Take 3 steps.\n          ,→  Take 5 steps.                                  et al., 2024) is a subset of the AGIEval benchmark,\n             Options:\n             - Yes                                    focusing on mathematical problem-solving tasks.\n             - No                                                    It includes a variety of math problems designed\n         answer: |                                        to assess reasoning and computational abilities.\n             A               lot of thinking and analysis processes.         For our experiments, we used Level 5 problems             ...\n             Final Answer:                               as the test set and Level 4 problems as the train-\n             <answer>(Yes or No)</answer>\n                                                  ing and validation set. GPQA GPQA (Rein et al.,\n                                             2023) is a dataset designed to evaluate the perfor-\n  This YAML file demonstrates the initial configu-   mance of language models on graduate-level ques-\nration for our approach to iterating on the BBH-    tions across multiple disciplines, including biology,\nnavigate task.  By configuring a simple initial    physics, and chemistry. For our experiments, we\nPrompt and requirements, along with three specific    utilized the GPQA-Diamond subset as the test set,\nquestions, iterative optimization can be performed.   while constructing our training and validation set\nIt should be noted that the content shown here is   from questions that are exclusive to GPQA-main\nthe complete content of the file, and the content     (i.e., those present in GPQA-main but absent from\nin the answer section is not the actual answer but   GPQA-Diamond). MT-bench MT-bench (Zheng\nserves as a reference for the thought process and    et al., 2023) is a multi-task benchmark designed to\ncorrect output format.                                evaluate the generalization capabilities of language\n                                            models across diverse tasks, including text classi-\nA.3  Experiment Details                                                           fication, summarization, and question answering.\nA.3.1  Tasks and Data Details                   For our experiments, we selected writing, roleplay,\n                                             and humanities tasks from MT-Bench. These vali-\n       Table A1: Dataset sizes and data splits.                                                     dation questions are provided in the supplementary\n                                                       materials.        Dataset Name   Test Train&Validate\n       LIAR           461      3681\n                                                 A.3.2  Configuration\n        BBH-Navigate   200       50\n     WSC           150       50                 In our experiments, we configured different opti-\n       AGIEval-MATH  256       232               mization frameworks to align their optimization\n      GPQA          198       250                 costs as much as possible. These frameworks gen-\n        MT-bench       80        0\n                                                          erally allow setting some parameters to adjust opti-\n                                                 mization costs, including the number of iterations\n  LIAR LIAR (Wang, 2017) is an English fake   and the number of prompts generated per iteration.\nnews detection dataset consisting of 4,000 state-    Specifically, we compare the features of prompt\nments, each accompanied by contextual informa-   optimization methods we used in Table A2.\ntion and lie labels. For our experiments, we sam-\npled portions from the original dataset as test sets    Table A2: Comparison of evaluation frameworks across\nfollowing Yan et al. (2024). BBH-Navigate BBH-    different prompt optimization methods. OvG denotes\nNavigate (Suzgun et al., 2023) is a task from the    evaluation against ground truth, while OvO represents\n                                                         output-vs-output comparison. Methods are categorizedBIG-bench Hard dataset, a subset of the BIG Bench\n                                               by their evaluation source and method.\ndataset. This task focuses on navigation reason-\ning, requiring the model to determine whether an    Method        Evaluation Source  Evaluation Method\nagent, after following a series of navigation steps,   APE            OvG           Benchmark\nreturns to its starting point. For our experiments,   OPRO           OvG           Benchmark\nwe employed random sampling (seed=42) to obtain     PromptAgent       OvG           Benchmark\n200/25/25 test/train/validation splits. WSC The     PromptBreeder      OvG           Benchmark\nWinograd Schema Challenge (WSC) (Levesque     TextGrad         OvG       LLM as a judge\n                                         SPO           OvO      LLM as a judge\net al., 2012) is a benchmark designed to evaluate\n\nAPE APE employs a three-round iterative opti-    timizer LLM (Claude-3.5-Sonnet) to update the sys-\nmization process, selecting the top 10% (ratio=0.1)   tem prompt. The framework maintains a validation-\nperforming prompts from the current pool as elite   based reversion mechanism - if the updated prompt\nprompts in each round. To maintain diversity and   performs worse on the validation set compared to\nsize of the prompt pool, variant sampling is used    the previous iteration, the update is rejected and the\nto mutate these elite prompts, keeping the total   prompt reverts to its previous state. The optimiza-\nnumber of prompts at 50. Following the setting    tion process is guided by evaluating prompts using\nin original paper (Zhou et al., 2023), the optimiza-   Claude-3.5-Sonnet as the evaluation LLM, while\ntion process does not incorporate specific sample    the actual task execution uses GPT-4o-mini as the\nexecution results to guide LLM prompt optimiza-   execution LLM. Our experimental configuration\ntion. Instead, performance scores are obtained by    follows the prompt optimization setting provided\nevaluating prompts on the entire training set.         in the official TextGrad repository (Yüksekgönül\n OPRO OPRO uses a 10-round iterative optimiza-    et al., 2024).\ntion process, generating 10 candidate prompts per    SPO SPO  conducts  optimization  through\nround. OPRO evaluates prompt performance on the   10  iterations  per  task,  randomly  selecting 3\ncomplete training set and filters based on evaluation    questions (without answers) from the pre-split\nscores. OPRO doesn’t maintain a fixed-size prompt    Train&Validate dataset for each iteration. The opti-\npool but directly generates new candidates based    mization model defaults to Claude-3.5-Sonnet, the\non the current best prompt in each round. The opti-   evaluation model defaults to GPT-4o-mini, and the\nmization direction is guided through performance    execution model defaults to GPT-4o-mini. Notably,\nevaluation on the full training data.           SPO demonstrates effective prompt optimization\n  PromptAgent Except for the Liar dataset, on    using only questions without ground truth answers,\nwhich we sampled 150 data for both training and    validating its capability.\nvalidation, all other datasets follow the sizes spec-\n                                                 A.3.3  Baseline Promptified in Table A1.  PromptAgent uses a Monte\nCarlo Tree Search (MCTS) framework to optimize    In this section, we provide the Baseline Prompts for\nprompts. It starts with an initial prompt and gen-   comparison. Note that for all Prompt Optimization\nerates new candidates based on model error feed-   work requiring initial iteration prompts, we consis-\nback. The process is guided by evaluations with    tently provide the COT Prompt shown below.\nbenchmark on a sampled training set to identify\n                                                IO Prompt\nhigh-reward paths for improved task performance.\nFinally, we select the top 5 prompts that perform\nbest on the validation set for testing and choose          Ensure the response concludes with the answer in the\n                                                            ,→  format:\nthe optimal one. Key parameters of MCTS include          <answer>answer</answer>\nan expand width of 3, a depth limit of 8, and 12\niterations.\n  PromptBreeder  In  our implementation  of\n                                        COT Prompt\nPromptBreeder, we configure the system with 5\nmutation prompts and 5 thinking styles for initial-\nization. The evolution process runs for 20 genera-         Please think step by step.\n                                                                        Ensure the response concludes with the answer in the\ntions, with 20 evaluations performed on randomly        ,→  format:\nsampled training examples in each generation. The          <answer>answer</answer>.\noptimization model defaults to Claude-3.5-Sonnet\nand the execution model defaults to GPT-4o-mini.\n  TextGrad Except for the Liar dataset where the        Step-back Prompt\nTrain&Validate set is reduced to 50 samples, all\nother datasets follow the sizes specified in Table A1.\n                                                                        Please first think about the principles involved in\nTextGrad employs a three-epoch optimization pro-       ,→  solving this task which could be helpful.\ncess with three steps per epoch (epoch=3, steps=3),       ,→And question.Then provide a solution step by step for this\nusing a batch size of 3 for stochastic gradient de-         Ensure the response concludes with the answer in the\n                                                            ,→  format:\nscent. In each step, TextGrad generates gradients          <answer>answer</answer>.\nthrough back-propagation of feedback from the op-\n\nBBH-Navigate Prompt\n\n\n\n\n                                                                        Follow these steps to analyze the given instructions:\n\n    Rephrase Prompt                                                1. State the initial conditions:\n                                                                           - Starting point: (0, 0)\n                                                                           - Initial direction: positive x-axis (unless\n                                                               ,→  specified otherwise)\n\n     Please rephrase the question in a way that is easier\n                                                                        2. Use a coordinate system:\n    ,→  to understand, minimizing ambiguity and\n                                                                           - x-axis: left (-) and right (+)\n    ,→  considering edge cases.\n                                                                           - y-axis: backward (-) and forward (+)\n     And Then provide a solution step by step for the\n    ,→  question.\n                                                                        3. Analyze each step:\n     Ensure the response concludes with the answer in the\n                                                                           - For ambiguous instructions (e.g., \"Take X steps\"\n    ,→  format:\n                                                               ,→  without direction), assume forward movement\n     <answer>answer</answer>.\n                                                                           - Update coordinates after each step\n                                                                           - Briefly explain any assumptions made\n\n                                                                        4. After analyzing all steps:\n                                                                           - Summarize total movement in each direction\n                                                                           - State the final position\n\nA.3.4  Prompt Optimized by SPO                          5. Compare final position to starting point:\n                                                                           - Calculate the distance from (0, 0)\n\nIn this section, we present the optimized prompts          6. Provide concise reasoning, labeled as \"Reasoning:\"\n                                                                           - Explain key movements and their impact on\nobtained from our main  experiments,  where          ,→  position\nClaude-3.5-Sonnet  serves as  the optimization             - Justify your conclusion\nmodel, and GPT-4o-mini serves as both the evalua-         7. State your final answer, labeled as \"Final Answer:\"\ntion and execution model.                                        Conclude your response with the answer in this XML\n                                                            ,→  format:\n                                                                        <answer>[Yes or No]</answer>\n\n  GPQA Prompt                                                   Ensure your analysis adapts to all question types,\n                                                            ,→  handling both specific and ambiguous\n                                                            ,→  instructions.\n\n     Follow these guidelines to answer questions\n    ,→  efficiently and effectively:\n\n     1. Carefully read the entire question, identifying\n    ,→  all relevant information and key concepts.\n     2. Choose the most appropriate problem-solving\n    ,→  approach based on the question type.                 LIAR Prompt\n     3. Solve the problem using these steps:\n        a. State any relevant formulas, principles, or\n      ,→  assumptions\n        b. Show all necessary calculations or conceptual                Analyze the given statement(s) carefully, following\n      ,→  analysis                                            ,→  these steps for each question:\n        c. Evaluate all answer options, explaining why\n      ,→  incorrect options are wrong when relevant                   1. Consider the statement, speaker's background (if\n     4. Structure your response as follows:                        ,→  provided), and context.\n                                                                        2. Research and cite relevant facts and data related\n     [Analysis]                                                ,→  to the claim.\n     - Briefly state the main problem and key information               3. Evaluate the claim's validity based on available\n    ,→  (2-3 sentences max)                                     ,→  evidence.\n                                                                        4. Consider potential biases or motivations of the\n     [Solution]                                                ,→  speaker.\n     - Show your work step-by-step, including all relevant\n    ,→  calculations and reasoning                                     For each claim, structure your analysis as follows:\n     - For conceptual questions, provide a clear, logical\n    ,→  explanation                                                    CLAIM: [Restate the claim]\n                                                                        CONTEXT: [Summarize speaker background and context]\n     [Conclusion]                                                       FACT-CHECK:\n     - State the final answer in one clear sentence                     - [Key fact 1 with source]\n     - Briefly explain why this answer is correct and                   - [Key fact 2 with source]\n    ,→  others are incorrect (if applicable)                           - [Add more as needed]\n                                                                        ANALYSIS: [Provide a brief analysis of the claim's\n     <answer>[One letter representing the correct                   ,→  validity]\n    ,→  option]</answer>                                               RATING: [Use the following scale]\n                                                                        1 = False\n     Adapt this structure as needed for different question              2 = Mostly False\n    ,→  types, prioritizing clarity and conciseness.                   3 = Mixed / Unclear\n    ,→  Ensure that your response addresses all aspects                4 = Mostly True\n    ,→  of the question and demonstrates a clear                       5 = True\n    ,→  problem-solving process.                                       UNCERTAINTY: [Low / Medium / High - based on the\n                                                            ,→  quality and quantity of available evidence]\n                                                                        SUMMARY: [One-sentence conclusion about the claim's\n                                                            ,→  validity]\n\nA.4.2  Ablation Study on Sample Number\n     If there is insufficient information to make a\n    ,→         determination,                        clearly                                state                                      this and                                               explain        The performance curves (shown in Figure A1)of    ,→         what additional                         information                                     would                                           be needed.\n                                                                all three optimization models exhibit similar pat-\n     Conclude each analysis with a final true/false\n    ,→  judgment in XML tags:                                terns:  performance initially improves with in-\n     <answer>[Yes or No]</answer>                         creased sample number but eventually converges\n     After analyzing all claims, provide an overall             or decline. This phenomenon can be attributed to\n    ,→  summary of your findings.\n                                            two factors: insufficient samples lead to overfitting\n     Ensure            your response                          is objective,                                        based                                              on\n    ,→         verifiable                    information,                                 and cites                                           sources                                                   for all        in prompt optimization, while excessive samples\n    ,→  key facts used in the analysis.                    not only increase computational costs but also re-\n                                                            sult in longer context for the evaluation model, po-\n                                                          tentially degrading assessment quality. Based on\n   AGIEval-MATH Prompt                           extensive experiments, we determine that a sam-\n                                                     ple size of 3 achieves the optimal balance between\n                                                       cost-efficiency and performance.\n     1. Quickly identify key information\n     2. Devise fastest solution strategy\n     3. Execute minimal calculations                              Impact of Sample Number on Performance\n     4. Double-check answer\n\n     Rules:\n     - Use shortcuts and estimation when possible\n     - Skip detailed explanations\n     - Omit units in final answer\n     - Always present final answer as: \\boxed{}\n\n     Prioritize speed and accuracy. Manage time\n    ,→  efficiently. Aim for shortest valid solution.\n    ,→  Verify answer format before submission. If stuck,\n    ,→  make educated guess rather than spending too much\n    ,→  time.\n\n\n\n\n  WSC Prompt\n                                                     Figure A1: Impact of sample number on performance\n                                                         across different optimization models on BBH-Navigate\n     Analyze the question using these steps:                      dataset. We evaluate three optimization models: GPT-\n     1. Identify key elements and relationships.                4o-mini, GPT-4o, and Claude-3.5-Sonnet. The results     2. Consider multiple interpretations.\n     3. Evaluate evidence for each possibility.                 demonstrate an inverted U-shaped relationship between\n     4. Draw a logical conclusion.                         sample number and performance.     5. Summarize your reasoning.\n     Conclude with:\n     Final Answer:\n     <answer>[Single letter option]</answer>\n                                                 A.4.3  Ablation Study on Iteration Rounds\n\n                                          The choice of 10 iterations is based on comprehen-\n                                                      sive empirical analysis. Taking BBH task as an\nA.4  Addtional Experiments                                               example, we conducted extended optimization ex-\nA.4.1  Stability of SPO                           periments (up to 20 iterations) using three different\n                                                   optimization models (Claude-3.5-Sonnet, GPT-4o,Check the results in Table A3.\n                                               GPT-4o-mini), with GPT-4o-mini as both evalua-\nTable A3: Performance stability analysis of SPO. Stan-    tion and execution model. The performance of the\ndard deviation values are reported for the main experi-   best prompts (as judged by the evaluation model)\nments, where SPO and SPO ∗use Claude-3.5-Sonnet                                                            at different iteration steps is shown below (mean ±\nand GPT-4o as their optimization models, respectively.\n                                                        std over 3 runs):\n        Datasets        SPO     SPO∗           As demonstrated by the results (plotted in Fig-\n     GPQA           43.6 ± 0.31  41.8 ± 2.28          ure  A2), SPO typically discovers the optimal\n      AGIEval-MATH  46.1 ± 0.69  45.3 ± 1.43          prompts within 10 iterations. Further iterations not\n      LIAR            67.1 ± 0.59  66.9 ± 1.20          only increase computational costs but may lead to\n     WSC            82.0 ± 1.15  81.1 ± 1.01           question-specific overfitting, potentially degrading\n       BBH-Navigate   97.2 ± 0.29  96.3 ± 1.04           overall performance. For instance, with Claude-\n                                                   3.5-Sonnet, the performance peaks at iteration 7\n\n(95.8%) and gradually decreases afterwards. Simi-        Iteration 2 - Failed\nlar patterns are observed across different optimiza-      Please analyze the given instructions\ntion models.                                    step  by  step  and  summarize  your\n                                              reasoning clearly. Ensure the response\n                                              concludes with the answer in the XML\n        Impact of Sample Number on Performance\n                                              format: <answer>(Yes or No)</answer>.\n\n\n\n (%)\n     Performance\n\n\n\n\n                     Iteration Rounds                          Iteration 3 - Failed\nFigure A2: Impact of iteration rounds on performance                                              Please  analyze  the  provided  steps\nacross different optimization models on BBH-Navigate\n                                              thoroughly and document each movement.\ndataset. We evaluate three optimization models: GPT-\n                                              Ensure  your  reasoning  is  clear  and4o-mini, GPT-4o, and Claude-3.5-Sonnet.\n                                              logical  throughout.    Conclude  with\n                                              the final answer in the following XML\n                                              format: <answer>(Yes or No)</answer>.\n\n\nA.5  Case Study\n\n\nA.5.1  Optimization Trajectory\n\n\nWe present the prompt optimization trajectory of\nGPT-4o-mini on the BBH-navigate dataset, where\nit serves as the optimization model, evaluation\nmodel, and execution model. This includes whether\neach iteration was successful relative to the best\nprompt at that time, as well as the corresponding         Iteration 4 - Success\nprompt content.                                  Please  approach  the  question  with  a\n                                              clear  and  logical  reasoning  process,\n     Iteration 0 - Success\n                                              breaking it down step by step. Ensure   Please think step by step. Ensure the\n                                              to  summarize  your  findings  before   response concludes with the answer in\n                                              stating  the  final  answer  clearly  in   the following format: <answer>[Yes or\n                                              this  XML  format:   <answer>[Yes  or   No]</answer>\n                                              No]</answer>.\n                                              For  example,   if  the  question  is\n     Iteration 1 - Failed                             about returning to the starting point\n   Please analyze the following question      after a series of movements,  detail\n   step by step, ensuring clarity in your     each movement, updating your position\n   reasoning.  At the conclusion of your     accordingly, and conclude whether you\n   analysis, provide the final answer in      have returned to the starting point or\n   the specified XML format: <answer>(Yes      not.\n   or    No)</answer>.<br/><br/>Question:     Final   Answer:     <answer>(Yes   or\n   [Insert Question Here]                     No)</answer>\n\nIteration 5 - Success                                      Iteration 7 - Failed\nPlease analyze the question thoroughly     Please    evaluate    the    question\nby  breaking  it  down  step  by  step.     step-by-step,  clearly outlining  each\nClearly  outline  each  movement  or     movement  and  tracking  the  resulting\naction, updating your position or state      position.  At the conclusion of your\naccordingly. Conclude with a summary of      analysis,  summarize  the  journey  and\nyour findings to determine whether you      state  whether  the  final  position\nreturn to the starting point or achieve      returns to the starting point or meets\nthe stated outcome.  Finally, present      the  desired  criteria.    Ensure  the\nthe  answer  distinctly  in  this  XML     final answer is presented distinctly\nformat: <answer>[Yes or No]</answer>.      in this XML format:  <answer>[Yes or\nFor example, if asked about returning      No]</answer>.\nto  the  starting  point  after  several      For instance, if asked about returning\nmovements,   document  each  movement      to the starting point after a series\nclearly,  track  your  position,  and      of movements, succinctly document each\nspecify if you have returned to the      step, track your position, and indicate\nstarting point.                            if you have returned to the starting\nFinal   Answer:     <answer>(Yes   or     point.\nNo)</answer>                               Final   Answer:     <answer>(Yes   or\n                                           No)</answer>\n\n\n\n\n\nIteration 6 - Success\nPlease     analyze     the     question        Iteration 8 - Success\nmethodically,  breaking  it  down  into      Please   methodically   analyze   the\nclear,  sequential  movements.  Define      question  by  breaking  it  down  into\nthe starting point and the direction of      concise  movements.    Start  from  a\neach movement, updating the position      defined   position   and   track   each\naccordingly  after  each  step.    At      step’s impact on your location. After\nthe  end,  summarize  the  journey  and      detailing each movement, summarize the\nexplicitly  state  whether  the  final      overall journey and explicitly state\nposition  returns  to  the  starting     whether  the  final  position  returns\npoint or achieves the desired outcome.     to the starting point or reaches the\nPresent  the  final  answer  distinctly     desired  outcome.   Present  the  final\nin this XML format:  <answer>[Yes or     answer distinctly in the following XML\nNo]</answer>.                              format: <answer>Yes or No</answer>.\nFor example, if asked about returning      For example, if asked whether following\nto the starting point after a series of      a  series  of  movements  returns  you\nmovements, document each step clearly,     to the starting point, document each\ntrack your position, and specify if you      step  clearly,  track  your  position\nhave returned to the starting point.       accurately, and specify the result.\nFinal   Answer:     <answer>(Yes   or     Final   Answer:     <answer>(Yes   or\nNo)</answer>                               No)</answer>\n\nIteration 9 - Failed                           due to suboptimal prompts. This trajectory shows\n   Please   begin   by   outlining   your   the system’s trial-and-error refinement mechanism.\n   movements systematically.  Start from\n   a  defined  position  and  detail  each       Optimize Function’s Prompt\n   step you take, including the direction\n   and distance moved.  After completing\n   your movements, summarize the overall        PROMPTEnsure =the\"\"\"Pleaseresponsethinkconcludesstep bywithstep.the answer in the\n   journey,  and  clearly  state  whether       ,→  XML format:\n                                                                        <answer>[Yes or No]</answer>.\"\"\"\n   your  final  position  returns  to  the\n                                                                        Question = \"\"\"If you follow these instructions, do\n   starting point or achieves the desired       ,→  you return to the starting point? Always face\n   outcome.   Make  sure  to  present  your       ,→  forward. Take 1 step right. Take 3 steps left.                                                            ,→  Take 2 steps right.\n   movements alongside the final answer in        Options:\n                                                                        - Yes\n   the following XML format: <answer>Yes        - No\"\"\"\n   or No</answer>.                                            Answer = \"\"\"Let's analyze the steps one by one:\n   For example, if asked whether following        1. **Starting Point**: We begin at the starting\n                                                            ,→  point, facing forward.\n   a  series  of  movements  returns  you        2. **Step 1**: Take 1 step right. Now we are 1 step to\n   to  the  starting  point,  you  should       ,→3. **Stepthe right2**:ofTakethe 3startingsteps left.point.From our current\n   document each step, track your position       ,→  position (1 step right), moving 3 steps left\n                                                            ,→  means:\n   accurately, and specify the result.               - 1 step left brings us back to the starting point.\n                                                                           - 2 steps left takes us 1 step to the left of the\n   Final   Answer:     <answer>(Yes   or         ,→  starting point.\n   No)</answer>                                                   - 3 steps left takes us 2 steps to the left of the                                                               ,→  starting point.\n                                                                        4. **Step 3**: Take 2 steps right. From our current\n                                                            ,→  position (2 steps left), moving 2 steps right\n                                                            ,→  means:\n     Iteration 10 - Success                                            - 1 step right brings us back to 1 step left of the\n   Please thoroughly analyze the provided         ,→  starting point.\n                                                                           - 2 steps right brings us back to the starting\n   movement  instructions  by  documenting         ,→  point.\n   each   step   clearly.      Begin   by       ,→Afterstartingcompletingpoint.all the steps, we end up back at the\n   defining  your  initial  position  and        Therefore, the answer is:\n                                                                        <answer>Yes</answer>\"\"\"\n   systematically  track  your  movements,\n   updating  your  position  after  each\n   step.  After completing the movements,\n   summarize your journey and determine\n   if your final position coincides with       Optimize Function’s Prompt\n   the  starting  point  or  achieves  the\n   desired outcome. Clearly indicate your        PROMPT = \"\"\"Please thoroughly analyze the provided\n   final  answer  using  the  XML  format:      ,→  movement instructions by documenting each step\n                                                            ,→  clearly. Begin by defining your initial position\n   <answer>Yes or No</answer>.                     ,→  and systematically track your movements, updating\n                                                            ,→  your position after each step. After completing\n   For  instance,  if  the  question  asks       ,→  the movements, summarize your journey and\n   whether a sequence of movements returns       ,→  determine if your final position coincides with                                                            ,→  the starting point or achieves the desired\n   you to the starting point, methodically       ,→  outcome. Clearly indicate your final answer using\n                                                            ,→  the XML format: <answer>Yes or No</answer>.\n   outline each step, track your position\n   accurately,  and  conclude  with  the       ,→For ofinstance,movementsif returnsthe questionyou toasksthe whetherstartinga point,sequence\n   result.                                               ,→  methodically outline each step, track your\n                                                            ,→  position accurately, and conclude with the result.\n   Final   Answer:     <answer>(Yes   or\n   No)</answer>                                                Final<answer>(YesAnswer:or No)</answer>\"\"\"\n\n                                                                        Question = \"\"\"If you follow these instructions, do\n                                                            ,→  you return to the starting point? Always face\n  The success/failure boxes demonstrate SPO’       ,→  forward. Take 1 step right. Take 3 steps left.\n                                                            ,→  Take 2 steps right.\noptimization process through 10 iterations of a          Options:\nBBH-navigation prompt.   Successful versions          -- YesNo\"\"\"\n(green) gradually improve the prompt to elicit bet-\n                                                                        Answer = \"\"\"Let's analyze the movement instructions\nter thought processes, while failed attempts (red)       ,→  step by step.\nmay lead to oversimplified or redundant thinking\n\n1. **Initial Position**: We start at the origin,                   Answer = \"\"\"1. **BLACK FRIDAY ALERT: Unbeatable Tech\n    ,→  which we can define as (0, 0).                            ,→  Deals Inside!**\n     2. **Facing Direction**: We are facing forward, which              2. **Tech Bonanza: Up to 50% Off Top Brands on Black\n    ,→  we will assume is towards the positive y-axis.              ,→  Friday!**\n     3. **Movement Instructions**:                                      3. **Don't Miss Out! Exclusive Black Friday Tech\n        - **Step 1**: Take 1 step right.                           ,→  Deals for You**\"\"\"\n         - Moving right from (0, 0) means moving along the              \"\"\"\n        ,→  x-axis. The new position is (1, 0).\n        - **Step 2**: Take 3 steps left.\n          - Moving left means moving in the negative\n        ,→  x-direction. From (1, 0), we move to (0, 0)\n        ,→  after 1 step left, then to (-1, 0) after 2\n        ,→  steps left, and finally to (-2, 0) after 3\n        ,→  steps left.                                     Performance After Optimization\n        - **Step 3**: Take 2 steps right.\n          - Moving right from (-2, 0) means moving back\n        ,→  towards the positive x-direction. After 1\n        ,→  step right, we move to (-1, 0), and after 2\n                                                                        PROMPT = \"\"\"Analyze the given advertising task and\n        ,→  steps right, we move to (0, 0).\n                                                            ,→  create compelling copy tailored to the specified\n     4. **Final Position**: After completing all the\n                                                            ,→  platform(s) and industry. Consider current\n    ,→  movements, we end up at (0, 0).\n                                                            ,→  trends, competitor strategies, and the target\n     5. **Summary of Journey**:\n                                                            ,→  audience's demographics and psychographics.\n        - Started at (0, 0).\n                                                            ,→  Provide at least 3 distinct creative options,\n        - Moved to (1, 0) after 1 step right.\n                                                            ,→  each with a unique angle or approach. Include\n        - Moved to (0, 0) after 1 step left.\n                                                            ,→  rationales for your choices and explain how they\n        - Moved to (-1, 0) after 2 steps left.\n                                                            ,→  align with the brand voice and marketing\n        - Moved to (-2, 0) after 3 steps left.\n                                                            ,→  objectives. Incorporate industry-specific best\n        - Moved to (-1, 0) after 1 step right.\n                                                            ,→  practices and platform-specific formatting\n        - Moved to (0, 0) after 2 steps right.\n                                                            ,→  guidelines. Suggest ways to adapt the copy for\n     6. **Conclusion**: The final position (0, 0) is the\n                                                            ,→  different channels or formats, including specific\n    ,→  same as the starting position (0, 0).\n                                                            ,→  instructions on tone, style, and structure for\n     Final Answer:\n                                                            ,→  each platform. Additionally, provide\n     <answer>Yes</answer>\"\"\"\n                                                            ,→  recommendations for visual elements or multimedia\n                                                            ,→  content that could enhance the effectiveness of\n                                                            ,→  the advertising copy.\"\"\"\n\n                                                                        Question = \"Write email subject lines for Black\n  By comparing the output results of the initial        ,→  Friday tech sale\"\nprompt at iteration 0 and the final prompt at itera-         Answer = \"\"\"**Advertising Task:**\ntion 10, the “iterative optimization of thought pro-\n                                                                        Create compelling email subject lines for a Black\ncesses” becomes evident. In this case, the model        ,→  Friday tech sale, targeting tech-savvy consumers\n                                                            ,→  who are likely to be interested in the latest\nevolves from initially using textual descriptions to        ,→  gadgets and deals.\nreason about positions to eventually demonstrat-         **Target Audience:**\ning the ability to use coordinates, even though the\n                                                                        * Demographics: 25-45 years old, male and female\nprompt did not explicitly emphasize the use of co-         * Psychographics: Tech enthusiasts, early adopters,\nordinates.                                                  ,→* Interests:and bargainTechnology,hunters  gadgets, innovation, and\n                                                            ,→  savings\nA.5.2  Real-World Applications\n                                                                        **Competitor Strategies:**\nIn this section, we demonstrate the optimization re-\n                                                                        * Emphasize discounts and promotions\nsults after 10 iterations using Claud-3.5-Sonnet as          * Highlight new releases and limited-time offers\nthe optimization model, GPT-4o-mini as the eval-       ,→* Usescarcityurgencymessagingtactics, such as countdown timers and\nuation model, and Llama-3-8B as the execution\n                                                                        **Current Trends:**\nmodel across four tasks: Advertising Design, So-\ncial Media Content, Modern Poetry Writing, and          ** Mobile-firstPersonalizationapproachand segmentation\nConcept Interpretation. Additionally, we provide          * Storytelling and emotional connections\nthe YAML configuration files used during the itera-         **Creative Options:**\ntions and the optimized prompts obtained from the          **Option 1:** \"Unlock the Future: Up to 50% Off Top\nprocess.                                                    ,→  Tech Deals\"\n  Advertising Design                                            * Angle: Focus on the excitement and thrill of\n                                                            ,→  getting the latest tech at a discounted price\n                                                                        * Rationale: This subject line creates a sense of\n    Performance Before Optimization                         ,→  FOMO (fear of missing out) and emphasizes the\n                                                            ,→  value of the sale\n                                                                        * Brand Voice: Fun, energetic, and playful\n                                                                        * Marketing Objectives: Drive sales and increase\n     PROMPT = \"\"\"Analyze the given advertising task and              ,→  brand awareness\n    ,→  create compelling copy.\"\"\"\n                                                                        **Option 2:** \"Your Black Friday Tech Bonanza Awaits\"\n     Question = \"Write email subject lines for Black\n    ,→  Friday tech sale\"                                              * Angle: Emphasize the idea of a treasure trove of\n                                                            ,→  tech deals waiting to be discovered\n\nPerformance Before Optimization\n     * Rationale: This subject line creates a sense of\n    ,→  anticipation and curiosity, encouraging the\n    ,→  reader to open the email\n     * Brand Voice: Friendly, approachable, and inviting\n                                                                        PROMPT = \"\"\"Create engaging tweets.\"\"\"\n     * Marketing Objectives: Drive engagement and\n    ,→  conversions\n                                                                        Question = \"Create an engagement tweet for a coffee\n                                                            ,→  brand\"\n     **Option 3:** \"Don't Miss Out: Exclusive Black Friday\n    ,→  Deals for Tech Lovers\"\n                                                                        Answer = \"\"\"\n                                                                        **Tweet:** \"Good morning, coffee lovers! We're giving\n     * Angle: Highlight the exclusivity and limited-time\n                                                            ,→  away a FREE cup of our signature blend to the\n    ,→  nature of the sale\n                                                            ,→  first 10 people who share their favorite way to\n     * Rationale: This subject line creates a sense of\n                                                            ,→  take their coffee in the comments below! #coffee\n    ,→  urgency and importance, making the reader feel\n                                                            ,→  #coffeeaddict #morningmotivation\"\n    ,→  like they're part of a special group\n     * Brand Voice: Confident, authoritative, and exclusive\n                                                                        This tweet aims to engage with the audience in\n     * Marketing Objectives: Drive conversions and build\n                                                            ,→  several ways:\n    ,→  brand loyalty\n     \"\"\"\n                                                                        1. **Call to action**: The tweet asks followers to\n                                                            ,→  share their favorite way to take their coffee,\n                                                            ,→  encouraging them to participate and interact with\n                                                            ,→  the brand.\n                                                                        2. **Incentive**: The promise of a free cup of coffee\n                                                            ,→  is a great incentive for people to engage with\n                                                            ,→  the tweet and share their thoughts.\n  The pre-optimization ad titles were generic, such          3. **Hashtags**: The use of relevant hashtags like\nas “BLACK FRIDAY ALERT: Unbeatable Tech        ,→,→  #coffee,helps to #coffeeaddict,reach a wider audienceand #morningmotivationand attract new\nDeals Inside!”, lacking specificity and creative        ,→  followers.\n                                                                        4. **Personal touch**: The tweet starts with a\ndepth, and failing to highlight the target audience’s        ,→  friendly \"Good morning\" and addresses the\ncharacteristics or brand personality. The optimized        ,→,→  audiencepersonal asand\"coffeeapproachable.lovers\", making it feel more\ntitles, like “Unlock the Future: Up to 50% Off\n                                                                        By responding to this tweet, the coffee brand can\nTop Tech Deals”, are more compelling, using “Un-       ,→  start a conversation with their followers, gather\n                                                            ,→  feedback, and build a sense of community around\nlock the Future” to emphasize technological innova-       ,→  their brand.\"\"\"\ntion while combining discount information to both\nspark curiosity and highlight value, better aligning\nwith tech enthusiasts’ psychological needs.\n\n                                                        Performance After Optimization\n\n    Iteration template on the BBH-navigate dataset\n\n\n                                                                        PROMPT = \"\"\"Create engaging social media content for\n                                                            ,→  any platform based on the given topic or brand.\n     prompt: |                                                 ,→  Follow these guidelines:\n       Analyze the given advertising task and create\n     ,→  compelling copy.                                             1. Identify the target audience and platform (if\n                                                            ,→  specified).\n     requirements: |                                                    2. State the content's primary goal (e.g., awareness,\n       None                                                   ,→  engagement, promotion).\n                                                                        3. Choose an appropriate content format (e.g., text,\n     faq:                                                     ,→  image, video).\n       - question: |                                                    4. Develop a unique angle or concept related to\n          Write Apple-style product launch headlines for a            ,→  current trends.\n         ,→  sustainable fashion brand called \"EcoWear\"               5. Craft a catchy headline or opening (max 10 words).\n         answer: |                                                      6. Write concise, platform-appropriate content\n           None                                                ,→  (50-100 words).\n                                                                        7. Include 2-3 relevant hashtags.\n       - question: |                                                    8. Add a clear call-to-action.\n           Create social media carousel ads for luxury                  9. Suggest a visual element or enhancement.\n         ,→  Maldives resort\n         answer: |                                                      Provide one piece of social media content based on\n           None                                                ,→  these guidelines, adapting to the given topic or\n                                                            ,→  brand. Focus on creating authentic, relatable\n       - question: |                                            ,→  content that resonates with the target audience\n           Write email subject lines for Black Friday tech            ,→  and fits current social media trends. If no\n         ,→  sale                                             ,→  specific requirements are given, make reasonable\n         answer: |                                             ,→  assumptions and explain your choices.\"\"\"\n           None\n                                                                        Question = \"Create an engagement tweet for a coffee\n                                                            ,→  brand\"\n\n                                                                        Answer = \"\"\"\n                                                                        **Target audience:** Coffee lovers, young adults\n                                                            ,→  (18-35)\n  Social Media Content                                        **Platform:** Twitter\n                                                                        **Primary goal:** Engagement\n                                                                        **Content format:** Text\n\nPerformance Before Optimization\n     **Unique angle:** Share a relatable moment that\n    ,→  coffee lovers can identify with\n     **Catchy headline:** \"When coffee is the only adult\n    ,→  in the room\"\n                                                                        PROMPT = \"\"\"Create poetry in the requested style and\n     **Content:** \"Who else has had a morning where coffee\n                                                            ,→  format.\"\"\"\n    ,→  is the only one keeping it together? Share your\n    ,→  most chaotic morning stories and let's\n                                                                        Question = \"Write a modern sonnet about climate\n    ,→  commiserate #CoffeeSavesTheDay\n                                                            ,→  change\"\n    ,→  #MorningMotivation\"\n     **Hashtags:** #CoffeeSavesTheDay #MorningMotivation\n                                                                        Answer = \"\"\"\n     **Call-to-action:** Share your own chaotic morning\n                                                                        In fiery skies, a warning we behold\n    ,→  story in the comments!\n                                                                        Of rising temperatures, a tale of old\n     **Visual element:** A funny meme or GIF of a person\n                                                                        The earth, a victim of our reckless hold\n    ,→  surrounded by chaos, with a cup of coffee as the\n                                                                        As carbon emissions, like a plague, unfold\n    ,→  calm center.\n\n                                                                        The polar ice, a melting, fragile throne\n     This tweet aims to engage with coffee lovers by\n                                                                        The seas, a rising, threatening to atone\n    ,→  sharing a relatable moment that many can identify\n                                                                        For human greed, a debt we cannot own\n    ,→  with. The use of humor and a lighthearted tone\n                                                                        As climate change, a crisis, overthrown\n    ,→  makes it easy to connect with the audience. The\n    ,→  hashtags #CoffeeSavesTheDay and\n                                                                        But still we hesitate, in denial's sway\n    ,→  #MorningMotivation are popular and relevant,\n                                                                        As scientists, in anguish, cry and pray\n    ,→  increasing the tweet's visibility. The\n                                                                        For action swift, before it's too late's day\n    ,→  call-to-action encourages users to share their\n                                                                        To save the planet, from our reckless way\n    ,→  own stories, fostering a sense of community and\n    ,→  encouraging engagement.\n                                                                        Yet still we hope, in love and human might\n     \"\"\"\n                                                                        To turn the tide, and bring forth new light.\n                                                                        \"\"\"\n\n\n  The pre-optimization tweet used free giveaways\nas a lure, with direct content lacking emotional\n                                                        Performance After Optimization\nresonance, such as “Good morning, coffee lovers!\nWe’re giving away a FREE cup...”. The optimized\ntweet, through the humorous expression “When          PROMPT = \"\"\"Craft boundary-pushing poetry that defies\n                                                            ,→  conventional expectations, adhering to these\ncoffee is the only adult in the room”, cleverly in-       ,→  enhanced guidelines:\ntegrated coffee into daily life scenarios, making it          1. Deconstruct and reimagine the requested poetic\nmore relatable and interactive, such as “Who else        ,→  form, pushing its structural limits while\n                                                            ,→  maintaining a semblance of its essence.\nhas had a morning where coffee is the only one          2. Approach the theme from an entirely unexpected\n                                                            ,→  angle, such as from the perspective of an\nkeeping it together?”, successfully sparking user        ,→  inanimate object, a abstract concept, or a\nengagement and emotional connection.                   ,→  microscopic entity.                                                                        3. Employ surreal, avant-garde imagery that\n                                                            ,→  challenges the reader's perception of reality\n                                                            ,→  while still conveying the core emotional truth of\n    Iteration template on the BBH-navigate dataset             ,→  the theme.\n                                                                        4. Integrate unconventional elements such as\n                                                            ,→  mathematical symbols, scientific notation, or\n                                                            ,→  programming language to create a unique\n     prompt: |                                                 ,→  linguistic landscape.\n       Create engaging tweets.                                          5. Experiment with typography, line breaks, and white\n                                                            ,→  space to create visual poetry that enhances the\n     requirements: |                                            ,→  thematic exploration.\n       None                                                             6. Incorporate synesthesia-like sensory experiences,\n                                                            ,→  blending different senses in startling ways to\n     faq:                                                     ,→  evoke powerful emotional responses.\n       - question: |                                                    7. Conclude with an ending that simultaneously\n           Create a thread explaining quantum computing              ,→  disorients and illuminates, leaving the reader\n         ,→  using Star Wars references                          ,→  with a profound sense of transformation.\n         answer: |\n           None                                                         Before writing, imagine the most radical way to\n                                                            ,→  approach both the theme and the poetic form. Aim\n       - question: |                                            ,→  to create a piece that challenges the very\n          Write a viral-style tweet about the moon landing            ,→  definition of poetry while still resonating on a\n         ,→  as if it's happening now                            ,→  deep emotional level.\n         answer: |\n           None                                                         Provide only the poem in your response, without any\n                                                            ,→  additional explanation or analysis.\"\"\"\n       - question: |\n           Create an engagement tweet for a coffee brand                Question = \"Write a modern sonnet about climate\n         answer: |                                             ,→  change\"\n           None\n                                                                        Answer = \"\"\"\n                                                                        In fractal whispers, the Earth's pulse beats slow\n                                                                        As carbon's dark stain seeps into the snow\n                                                                        A calculus of despair, where equations grow\n                                                                        In exponential decay, the future's woe\n  Modern Poetry Writing\n\nThe thermodynamic dance of life unwinds\n     As entropy's cold hand grasps the planet's mind                    In the world of mRNA vaccines, the \"dish\" is the\n     The once-blue skies now shrouded, a heavy bind                  ,→  immune system's response to a specific virus or\n     Of particulate haze, where sunbeams are left behind              ,→  disease. The \"ingredients\" are the genetic\n                                                            ,→  instructions (mRNA) that tell the body how to\n     In this eerie twilight, where shadows roam                     ,→  make a specific protein, which is then used to\n     The ghosts of glaciers whisper, \"This is home\"                  ,→  trigger an immune response.\n     A requiem for ice, where memories are stored\n     In frozen echoes, where the past is explored                       Here's how it works:\n\n     Yet, in this desolate landscape, a spark remains                   1. **Recipe selection**: The mRNA vaccine is like\n     A quantum leap of hope, where love sustains                    ,→  choosing a recipe book. You select the specific\n     \"\"\"                                                      ,→  mRNA sequence that corresponds to the protein you\n                                                            ,→  want to create, which is the key to triggering an\n                                                            ,→  immune response against a particular virus or\n                                                            ,→  disease.\n  The pre-optimization sonnet, while structurally        ,→2. **Ingredientlike a set ofpreparation**:instructions ThethatmRNAtellssequencethe bodyis\nneat, used traditional imagery like “rising tempera-       ,→  how to make the specific protein. The mRNA is\n                                                            ,→  prepared in a lab, and it's like measuring out\ntures” and “melting ice”, lacking novelty. The opti-       ,→  the right amount of each ingredient (amino acids)\n                                                            ,→  to create the protein.\nmized poem introduced scientific concepts such as          3. **Delivery**: The mRNA is delivered to the body,\n\"fractal whispers\" and “thermodynamic entropy”,       ,→  just like you would add the ingredients to the                                                            ,→  dish. In this case, the mRNA is packaged in a\nlike \"In fractal whispers, the Earth’s pulse beats        ,→  tiny particle called a lipid nanoparticle (LNP),\n                                                            ,→  which helps it reach the cells in the body.\nslow\" and “The thermodynamic dance of life un-         4. **Cellular cooking**: Once the mRNA reaches the\nwinds”, using interdisciplinary metaphors to imbue        ,→,→  cells,pot. Theit'scellslikereadaddingthe themRNAingredientsinstructionsto andthe\nthe climate theme with deeper philosophical reflec-       ,→  start making the specific protein. This protein\n                                                            ,→  is then displayed on the surface of the cells,\ntion, enhancing the poem’s artistic and intellectual        ,→  like a flag, to alert the immune system that\ndepth.                                                      ,→5. **Immunethere's response**:a foreign invaderThe immunepresent.system responds to\n                                                            ,→  the protein by producing antibodies and\n                                                            ,→  activating immune cells, like a chef responding\n    Iteration template on the BBH-navigate dataset             ,→  to a delicious aroma by adding the finishing\n                                                            ,→  touches to the dish. The immune system then\n                                                            ,→  remembers how to respond to this specific\n                                                            ,→  protein, so if it encounters it again in the\n     prompt: |                                                 ,→  future, it can quickly mount a defense.\n       Create poetry in the requested style and format.\n                                                                        In summary, mRNA vaccines are like a recipe for the\n     requirements: |                                            ,→  immune system. They provide the genetic\n       None                                                   ,→  instructions for the body to make a specific\n                                                            ,→  protein, which triggers an immune response and\n     faq:                                                     ,→  helps protect against diseases.\"\"\"\n       - question: |\n           Write a modern sonnet about climate change\n         answer: |\n           None\n\n       - question: |\n           Create a haiku series about New York City\n         answer: |                                          Performance After Optimization\n           None\n\n       - question: |\n           Write a free verse poem about social media                   PROMPT = \"\"\"Explain complex concepts in accessible\n         answer: |                                             ,→  terms.\"\"\"\n           None\n                                                                        Question =\"Explain mRNA vaccines using a cooking\n                                                            ,→  analogy\"\n\n                                                                        Answer = \"\"\"\n                                                                        **Definition:** mRNA vaccines are a type of vaccine\n  Concept Interpretation                                ,→  that uses a piece of genetic material called\n                                                            ,→  messenger RNA (mRNA) to teach our cells how to\n                                                            ,→  fight diseases.\n    Performance Before Optimization\n                                                                        **Analogy:** Imagine you're a master chef, and you\n                                                            ,→  want to create a new recipe for a delicious dish.\n                                                            ,→  You wouldn't send your sous chef to the store to\n     PROMPT = \"\"\"Explain complex concepts in accessible              ,→  buy all the ingredients, only to have them figure\n    ,→  terms.\"\"\"                                             ,→  out how to assemble the dish on their own.\n                                                            ,→  Instead, you'd provide them with a recipe card\n     Question =\"Explain mRNA vaccines using a cooking                ,→  that outlines the exact steps to follow. In a\n    ,→  analogy\"                                              ,→  similar way, mRNA vaccines work by providing our\n                                                            ,→  cells with a recipe card - the mRNA - that\n     Answer = \"\"\"                                              ,→  contains the instructions for making a specific\n     Imagine you're a master chef, and you're preparing a             ,→  protein, which helps our immune system fight off\n    ,→  delicious dish for your guests. You have all the             ,→  diseases.\n    ,→  ingredients, but you need to make sure they're in\n    ,→  the right order and combination to create the                  **Key Components:**\n    ,→  perfect flavor and texture.\n\n1. **mRNA**: The recipe card that contains the                         answer: |\n    ,→  instructions for making a specific protein. Think                    None\n    ,→  of it like a blueprint for your cells to follow.\n     2. **Cells**: The sous chefs in our body that receive                - question: |\n    ,→  the mRNA recipe card and use it to make the                          Describe inflation using social media examples\n    ,→  protein.                                                           answer: |\n     3. **Protein**: The final dish that our cells                            None\n    ,→  produce, which helps our immune system recognize\n    ,→  and fight off diseases.\n\n     **Narrative:** When we receive an mRNA vaccine, our\n    ,→  cells take the recipe card (mRNA) and use it to\n    ,→  make the specific protein. This protein then          A.6  Full Related Work\n    ,→  triggers an immune response, teaching our body\n    ,→  how to recognize and fight off the disease. It's        A.6.1  Prompt Engineering\n    ,→  like our cells are following a recipe to create a\n    ,→  delicious dish that helps keep us healthy!            Research on effective prompting methods for large\n     **Interactive Element:** Can you think of a time when       language models has primarily evolved along two\n    ,→  you received a recipe from someone else and had\n    ,→  to follow it to create a dish? How did it make        main directions. The first focuses on task-agnostic\n    ,→         you             feel?                   Now,                        imagine                                your                                     cells                                           receiving                                                     a\n    ,→         recipe                card                     from                          an mRNA                                  vaccine                                          and                                              using it                                                       to       prompting techniques that enhance LLMs’ gen-\n    ,→  create a protein that helps fight off a disease.         eral capabilities.  Notable examples include the\n    ,→  How might that make you feel?\n                                                  chain-of-thought (Wei et al., 2022; Kojima et al.,\n     **Visual              Representation:**                                A simple                                         diagram                                                 showing\n    ,→         the mRNA                  molecule, cells                                  receiving                                            the mRNA,                                                      and       2022) which improved reasoning across various\n    ,→  the protein being produced.                           tasks, techniques for enhancing single-shot reason-\n     **Limitation:** mRNA vaccines are still a relatively        ing (Deng et al., 2023; Zheng et al., 2024; Wang\n    ,→         new             technology,                         and                             more research                                           is                                              needed                                                     to            et al., 2024e), and methods for output format speci-    ,→         understand                    their                          long-term                                    effects                                            and                                                potential\n    ,→  side effects.                                       fication (Zhang et al., 2024a; He et al., 2024; Tam\n     **Conclusion:** mRNA vaccines are a game-changer in           et al., 2024). These techniques, developed through\n    ,→  the fight against diseases. By providing our\n    ,→  cells with a recipe card, we can teach our immune      human insights and extensive experimentation, pro-\n    ,→         system                how                    to recognize                                 and fight                                           off                                               diseases                                                        in       vide essential optimization seeds for automated    ,→         a more                targeted                         and effective                                       way.                                            What                                                 do you\n    ,→  think the future of mRNA vaccines might hold?         prompt optimization research.\n     \"\"\"\n                                            The second direction addresses domain-specific\n                                                prompting, where researchers have developed\n                                                    specialized techniques for tasks in code genera-\n  The pre-optimization explanation, while using                                                       tion (Hong et al., 2024b; Ridnik et al., 2024; Shen\na cooking analogy, was lengthy and lacked focus,                                                           et al., 2024a), data analysis (Hong et al., 2024a;\nsuch as “Imagine you’re a master chef...”. The                                               Liu et al., 2024; Li et al., 2024a), question answer-\noptimized version, through the core metaphor of a                                                   ing (Wu et al., 2024a; Zhu et al., 2024; Yang et al.,\n\"recipe card\", like “The mRNA sequence is like a                                                 2024), decision-makings (Zhang et  al., 2024b;\nset of instructions that tells the body how to make                                      Wang et al., 2024a), and other domains (Guo et al.,\nthe specific protein”, simplified complex concepts                                              2024b; Ye et al., 2024; Shen et al., 2024b). How-\ninto easy-to-follow steps, while using the “chef-                                                        ever, as applications of LLMs expand to increas-\nsous chef” role interaction to make the explanation                                                      ingly complex real-world scenarios, manually craft-\nmore vivid and intuitive, helping readers quickly                                                    ing effective prompts for each domain becomes im-\ngrasp the key points.                                                         practical (Zhang et al., 2024a). This challenge has\n                                                 motivated research in prompt optimization, which    Iteration template on the BBH-navigate dataset\n                                             aims to systematically develop effective domain-\n                                                       specific prompts rather than discovering general\n     prompt: |                                     prompting principles.       Explain complex concepts in accessible terms.\n\n     requirements: |                                  A.6.2  Prompt Optimization\n       None\n                                         The design of evaluation frameworks is crucial in     faq:\n       - question: |                               Prompt Optimization (PO), as it determines both\n           Explain blockchain using Game of Thrones\n         ,→  references                                optimization effectiveness and computational effi-\n         answer:                 |                                       ciency. The evolution of evaluation mechanisms           None\n                                                        in PO has progressed from simple evaluation feed-\n       - question: |\n           Explain mRNA vaccines using a cooking analogy        back collection to sophisticated optimization signal\n                                                    generation (Chang et al., 2024). Existing PO meth-\n\nods can be categorized based on their evaluation\nsources and mechanisms.\n  The most common approach relies on ground\ntruth as the evaluation source, utilizing benchmark-\nbased numerical assessments (Zhou et al., 2023;\nGuo et al., 2024a; Yang et al., 2023; Fernando et al.,\n2024; Wang et al., 2024d; Khattab et al., 2023).\nWhile these methods have demonstrated success\nin specific tasks, they typically require substantial\niterations and samples to ensure evaluation stability,\nleading to significant computational overhead.\n  To reduce sample requirements, several methods\n(Yan et al., 2024; Yüksekgönül et al., 2024; Wu\net al., 2024b; Wang et al., 2024c; Pryzant et al.,\n2023; Li et al., 2025) use LLM-as-a-judge (Zheng\net al., 2023) to generate detailed textual feedback.\nAlthough this approach provides richer evaluation\nsignals with fewer samples,  it still depends on\nground truth data, limiting its applicability in open-\nended tasks where reference answers may not exist.\n   Alternative approaches focus on human prefer-\nences, either through manually designed evaluation\nrules or direct human feedback (Chen et al., 2024;\nLin et al., 2024). While these methods can han-\ndle open-ended tasks effectively, their reliance on\nextensive human involvement contradicts the goal\nof automated prompt optimization. Meanwhile,\nsome researchers explore different evaluation cri-\nteria, such as Zhang et al. (2024c)’s proposal to\nevaluate prompt effectiveness through output con-\nsistency. However, this approach faces a fundamen-\ntal challenge: the non-linear relationship between\nconsistency and effectiveness often leads to subop-\ntimal evaluation signals.\n   In contrast to these approaches, SPO introduces\na novel evaluation paradigm that eliminates depen-\ndency on external references while maintaining ef-\nficiency. By leveraging only model outputs through\npairwise comparisons, SPO achieves robust evalu-\nation without requiring ground truth, human feed-\nback, or extensive sampling, making it particularly\nsuitable for real-world applications.",
"headers": [
"arXiv:2502.06855v3  [cs.CL]  21 Aug 2025",
"Self-Supervised Prompt Optimization",
"Jinyu Xiang",
", Jiayi Zhang",
", Zhaoyang Yu",
", Xinbing Liang",
", Fengwei Teng",
",",
"Jinhao Tu",
"Fashen Ren",
"Xiangru Tang",
"Sirui Hong",
"Chenglin Wu",
"Yuyu Luo",
"DeepWisdom,",
"The Hong Kong University of Science and Technology (Guangzhou),",
"Independent Researcher,",
"Yale University,",
"Abstract",
"1",
"Introduction",
"2",
"Preliminary",
"3",
"4",
"Experiment",
"5",
"Related Work",
"6",
"Conclusion",
"Limitations",
"Ethical Consideration",
"References",
"A",
"Appendix"
],
"tables": [
"|Candidate<br>Prompt|Candidate<br>Outputs|\n|---|---|",
"|Output<br>First, we calculate…<br>TheG frionuanl de xTacrtu tvhalue<br>is:\\[\\boxed{\\frac{1}<br>{35T0h}e} \\e]xact value of $|<br>\\pi-3.14|+|\\pi-<br>\\frac{22}{7}|$ is $<br>\\frac{1}{350}$.<br>Output A<br>The degree of a<br>polyOnuomtipaul ti sB<br>d T (e h \\t e be oT p dr f xh o em i ee l ti n d y en a {d n re l 4e o md 2g m i a }r i nb n \\e a ey s )e l d w . … eo i brf s y ia …s \\<br>The final answer is \\<br>(\\boxed{0}\\).<br>(a) Evaluation Sources|Benchmark<br>LLM-as-a-Judge<br>Human Feedback<br>(b) Evaluation Methods|Numerical Signal:<br>0.95<br>Selection Signal:<br>Output B is Better …<br>Rank Signal:<br>B ≻ A ≻ …<br>Textual Signal:<br>The consistency of<br>outputs is …<br>You need to modify it<br>…<br>(c) Feedback Types|\n|---|---|---|",
"|(a) Prompt Optimization<br>PROMPT_OPTIMIZE_PROMPT = \"\"\"<br>You are building a prompt to address user<br>requirement.<br>Based on the given prompt…<br>requirements: {requirements}<br>reference prompt: {prompt}<br>The execution result of this reference<br>prompt is(some cases): {answers}<br>Provide your analysis, optimization<br>points, and the complete optimized prompt<br>using the following XML format …<br>\"\"\"<br>You are a creative writing assistant<br>skilled in adopting various personas and<br>perspectives …<br># Introduction<br>The real enigma lies in traveling to …<br>Optimize<br>You are an expert creative writing<br>assistant skilled in adopting various<br>personas and perspectives …<br>1. Carefully analyze …|(b) Prompt Execution<br>You are an expert creative writing assistant skilled in<br>adopting various personas and perspectives …<br>1. Carefully analyze …<br>Q: Write an article about time travel …<br># Introduction<br>Imagine stepping into a machine, vanishing in a flash …<br>(c) Answer Evaluation<br>ANSWER_EVALUATE_PROMPT = \"\"\" A: # Intro<br>Based on the original requirements, Imagine<br>evaluate the two responses … stepping into<br># A {sample_1} # B {sample_2} a machine …<br>Provide your analysis and the<br>choice you believe is better… B: # Intro<br>\"\"\" The real<br>enigma lies<br>in traveling<br>Response A is more creative … to the past …|\n|---|---|\n|Figure 4: A Running Example of** SPO** Framework: Pairwise evaluation on the outputs selects the better one<br>from corresponding prompts . The best output and prompt pair are highlited with pentagrams, which will be<br>|Figure 4: A Running Example of** SPO** Framework: Pairwise evaluation on the outputs selects the better one<br>from corresponding prompts . The best output and prompt pair are highlited with pentagrams, which will be<br>|",
"|Col1|Optimize|\n|---|---|",
"|Method|Method Analysis<br>GPQA AGIEval-MATH LIAR WSC BBH-Navigate Avg. Perf. Avg. Cost($)|Col3|Col4|Col5|Col6|Col7|Col8|\n|---|---|---|---|---|---|---|---|\n|IO<br>CoT (Wei et al., 2022)<br>Rephrase (Deng et al., 2023)<br>Step-back(Zheng et al., 2024)|38.9<br>42.1<br>63.5<br>72.4<br>91.3<br>61.6<br>-<br>41.6<br>44.5<br>65.4<br>77.8<br>89.7<br>63.8<br>-<br>40.2<br>42.1<br>50.5<br>79.1<br>93.5<br>61.1<br>-<br>42.4<br>**47.5**<br>62.8<br>78.7<br>93.5<br>65.0<br>-|38.9<br>42.1<br>63.5<br>72.4<br>91.3<br>61.6<br>-<br>41.6<br>44.5<br>65.4<br>77.8<br>89.7<br>63.8<br>-<br>40.2<br>42.1<br>50.5<br>79.1<br>93.5<br>61.1<br>-<br>42.4<br>**47.5**<br>62.8<br>78.7<br>93.5<br>65.0<br>-|38.9<br>42.1<br>63.5<br>72.4<br>91.3<br>61.6<br>-<br>41.6<br>44.5<br>65.4<br>77.8<br>89.7<br>63.8<br>-<br>40.2<br>42.1<br>50.5<br>79.1<br>93.5<br>61.1<br>-<br>42.4<br>**47.5**<br>62.8<br>78.7<br>93.5<br>65.0<br>-|38.9<br>42.1<br>63.5<br>72.4<br>91.3<br>61.6<br>-<br>41.6<br>44.5<br>65.4<br>77.8<br>89.7<br>63.8<br>-<br>40.2<br>42.1<br>50.5<br>79.1<br>93.5<br>61.1<br>-<br>42.4<br>**47.5**<br>62.8<br>78.7<br>93.5<br>65.0<br>-|38.9<br>42.1<br>63.5<br>72.4<br>91.3<br>61.6<br>-<br>41.6<br>44.5<br>65.4<br>77.8<br>89.7<br>63.8<br>-<br>40.2<br>42.1<br>50.5<br>79.1<br>93.5<br>61.1<br>-<br>42.4<br>**47.5**<br>62.8<br>78.7<br>93.5<br>65.0<br>-|38.9<br>42.1<br>63.5<br>72.4<br>91.3<br>61.6<br>-<br>41.6<br>44.5<br>65.4<br>77.8<br>89.7<br>63.8<br>-<br>40.2<br>42.1<br>50.5<br>79.1<br>93.5<br>61.1<br>-<br>42.4<br>**47.5**<br>62.8<br>78.7<br>93.5<br>65.0<br>-|38.9<br>42.1<br>63.5<br>72.4<br>91.3<br>61.6<br>-<br>41.6<br>44.5<br>65.4<br>77.8<br>89.7<br>63.8<br>-<br>40.2<br>42.1<br>50.5<br>79.1<br>93.5<br>61.1<br>-<br>42.4<br>**47.5**<br>62.8<br>78.7<br>93.5<br>65.0<br>-|\n|APE (Zhou et al., 2023)<br>OPRO (Yang et al., 2023)<br>PromptAgent (Wang et al., 2024d)<br>PromptBreeder (Fernando et al., 2024)<br>TextGrad (Yüksekgönül et al., 2024)|41.1<br>44.4<br>65.9<br>80.2<br>92.5<br>64.8<br>9.07<br>43.3<br>46.1<br>**67.6**<br>80.2<br>95.8<br>66.6<br>4.51<br>41.3<br>41.4<br>64.1<br>**82.7**<br>95.7<br>65.0<br>2.71<br>40.9<br>45.9<br>63.2<br>76.7<br>96.3<br>64.5<br>4.82<br>40.2<br>44.4<br>65.7<br>78.0<br>91.3<br>63.9<br>13.14|41.1<br>44.4<br>65.9<br>80.2<br>92.5<br>64.8<br>9.07<br>43.3<br>46.1<br>**67.6**<br>80.2<br>95.8<br>66.6<br>4.51<br>41.3<br>41.4<br>64.1<br>**82.7**<br>95.7<br>65.0<br>2.71<br>40.9<br>45.9<br>63.2<br>76.7<br>96.3<br>64.5<br>4.82<br>40.2<br>44.4<br>65.7<br>78.0<br>91.3<br>63.9<br>13.14|41.1<br>44.4<br>65.9<br>80.2<br>92.5<br>64.8<br>9.07<br>43.3<br>46.1<br>**67.6**<br>80.2<br>95.8<br>66.6<br>4.51<br>41.3<br>41.4<br>64.1<br>**82.7**<br>95.7<br>65.0<br>2.71<br>40.9<br>45.9<br>63.2<br>76.7<br>96.3<br>64.5<br>4.82<br>40.2<br>44.4<br>65.7<br>78.0<br>91.3<br>63.9<br>13.14|41.1<br>44.4<br>65.9<br>80.2<br>92.5<br>64.8<br>9.07<br>43.3<br>46.1<br>**67.6**<br>80.2<br>95.8<br>66.6<br>4.51<br>41.3<br>41.4<br>64.1<br>**82.7**<br>95.7<br>65.0<br>2.71<br>40.9<br>45.9<br>63.2<br>76.7<br>96.3<br>64.5<br>4.82<br>40.2<br>44.4<br>65.7<br>78.0<br>91.3<br>63.9<br>13.14|41.1<br>44.4<br>65.9<br>80.2<br>92.5<br>64.8<br>9.07<br>43.3<br>46.1<br>**67.6**<br>80.2<br>95.8<br>66.6<br>4.51<br>41.3<br>41.4<br>64.1<br>**82.7**<br>95.7<br>65.0<br>2.71<br>40.9<br>45.9<br>63.2<br>76.7<br>96.3<br>64.5<br>4.82<br>40.2<br>44.4<br>65.7<br>78.0<br>91.3<br>63.9<br>13.14|41.1<br>44.4<br>65.9<br>80.2<br>92.5<br>64.8<br>9.07<br>43.3<br>46.1<br>**67.6**<br>80.2<br>95.8<br>66.6<br>4.51<br>41.3<br>41.4<br>64.1<br>**82.7**<br>95.7<br>65.0<br>2.71<br>40.9<br>45.9<br>63.2<br>76.7<br>96.3<br>64.5<br>4.82<br>40.2<br>44.4<br>65.7<br>78.0<br>91.3<br>63.9<br>13.14|41.1<br>44.4<br>65.9<br>80.2<br>92.5<br>64.8<br>9.07<br>43.3<br>46.1<br>**67.6**<br>80.2<br>95.8<br>66.6<br>4.51<br>41.3<br>41.4<br>64.1<br>**82.7**<br>95.7<br>65.0<br>2.71<br>40.9<br>45.9<br>63.2<br>76.7<br>96.3<br>64.5<br>4.82<br>40.2<br>44.4<br>65.7<br>78.0<br>91.3<br>63.9<br>13.14|\n|**SPO** (ours)<br>|**43.6**|46.1|67.1|82.0|**97.2**|**66.9**|0.15|\n|**SPO**_∗_(ours)|41.8|45.3|66.9|81.1|96.3|66.3|**0.12**|",
"|41.7|55.0|\n|---|---|\n|50.0|65.0|\n|35.0|50.0|",
"|50.0|36.7|50.0|\n|---|---|---|\n|63.3|50.0|71.7|\n|50.0|28.3|50.0|\n||||\n|93.3|66.7|66.7|\n|93.3|76.7|80.0|\n|73.3|66.7|83.3|",
"|50.0|35.0|43.3|\n|---|---|---|\n|65.0|50.0|51.7|\n|56.7|48.3|50.0|\n||||\n|83.3|70.0|56.7|\n|93.3|86.7|93.3|\n|66.7|50.0|53.3|",
"|Col1|GPT-4o-mini Llama3-70B Claude-3-Haiku|\n|---|---|\n|IO<br>COT|91.3<br>82.7<br>62.2<br>89.7<br>86.2<br>68|\n|Claude-3.5-Sonnet<br>Llama3-70B<br>GPT-4o-mini|95<br>86.8<br>68.2<br>94.5<br>94.2<br>82.0<br>**97.8**<br>90.7<br>82.0|",
"|73.3|80.0|\n|---|---|\n|86.7|83.3|\n|53.3|60.0|",
"|Col1|GPT-4o-mini Llama3-70B Claude-3-Haiku|\n|---|---|\n|Claude-3.5-Sonnet<br>GPT-4o<br>GPT-4o-mini<br>DeepSeek-V3<br>Gemma-3-12B|97.2<br>86.7<br>89.7<br>96.3<br>85.5<br>73.0<br>**97.8**<br>90.7<br>82.0<br>94.7<br>83.7<br>77.2<br>97.5<br>92.0<br>69.0|",
"|Dataset Name|Test Train&Validate|\n|---|---|\n|LIAR<br>BBH-Navigate<br>WSC<br>AGIEval-MATH<br>GPQA|461<br>3681<br>200<br>50<br>150<br>50<br>256<br>232<br>198<br>250|\n|MT-bench|80<br>0|",
"|Method|Evaluation Source Evaluation Method|Col3|\n|---|---|---|\n|APE<br>OPRO<br>PromptAgent<br>PromptBreeder<br>TextGrad|OvG<br>Benchmark<br>OvG<br>Benchmark<br>OvG<br>Benchmark<br>OvG<br>Benchmark<br>OvG<br>LLM as ajudge|OvG<br>Benchmark<br>OvG<br>Benchmark<br>OvG<br>Benchmark<br>OvG<br>Benchmark<br>OvG<br>LLM as ajudge|\n|**SPO**|**OvO**|LLM as ajudge|",
"|Datasets|SPO SPO∗|\n|---|---|\n|GPQA<br>AGIEval-MATH<br>LIAR<br>WSC<br>BBH-Navigate|43.6 ± 0.31 41.8 ± 2.28<br> 46.1 ± 0.69 45.3 ± 1.43<br>67.1 ± 0.59 66.9 ± 1.20<br>82.0 ± 1.15 81.1 ± 1.01<br>97.2 ± 0.29 96.3 ± 1.04|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2502.06855v3.pdf"
}