{
"text": "StraGo: Harnessing Strategic Guidance for Prompt Optimization\n\n             Yurong Wu1*  Yan Gao2  Bin Benjamin Zhu2  Zineng Zhou3*   Xiaodi Sun2\n                  Sheng Yang1*  Jian-Guang Lou2†  Zhiming Ding1  Linjun Yang2\n                         1Institute of Software, CAS & University of Chinese Academy of Sciences\n                                                   2Microsoft\n                 3Institute of Computing Technology, CAS & University of Chinese Academy of Sciences\n                       {wuyurong20, zhouzineng22, yangsheng22}@mails.ucas.ac.cn;\n               {yan.gao, binzhu, sunstifler, jlou, Yang.Linjun}@microsoft.com; zhiming@iscas.ac.cn\n\n\n                          Abstract                    depends on prompt quality, and crafting effective\n                                                         prompts remains a complex, labor-intensive task               Prompt engineering  is pivotal for harness-\n                  ing the capabilities of large language models        that requires considerable expertise.\n              (LLMs) across diverse applications. While ex-        To overcome the challenge of crafting effective\n                    isting prompt optimization methods improve       prompts, recent research has focused on creating\n                prompt effectiveness, they often lead to prompt      and optimizing prompts automatically. Early ap-2024\n                      drifting, wherein newly generated prompts can                                                            proaches utilized reinforcement learning (Deng\n                  adversely impact previously successful cases\n                                                                            et al., 2022) or gradient-based methods (Shin et al.,\n                 while addressing failures. Furthermore, theseOct                                                              2020), though these techniques often require ad-                methods tend to rely heavily on LLMs’ intrinsic\n                    capabilities for prompt optimization tasks. In        ditional training or depend on the model’s inter-11\n                     this paper, we introduce STRAGO (Strategic-       nal state, limiting their applicability for API-based\n               Guided Optimization), a novel approach de-     LLMs like ChatGPT and GPT-4. Recent studies\n                 signed to mitigate prompt drifting by leverag-      have leveraged LLMs themselves as prompt gener-\n                  ing insights from both successful and failed        ators (Zhou et al., 2022) or optimizers (Yang et al.,\n                  cases to identify critical factors for achieving                                                                2023). Advanced search algorithms, such as Monte\n                  optimization objectives. STRAGO employs a[cs.CL]                                                      Carlo Tree Search (MCTS) (Wang et al., 2023)\n                 how-to-do methodology, integrating in-context\n                                                         and evolutionary algorithms (Guo et al., 2023; Fer-                   learning to formulate specific, actionable strate-\n                   gies that provide detailed, step-by-step guid-      nando et al., 2023), have also been applied to dis-\n                 ance for prompt optimization. Extensive ex-       cover effective prompts.  Additionally, some re-\n                 periments conducted across a range of tasks,       search has exploited the reflective capabilities of\n                  including reasoning, natural language under-     LLMs (Shinn et al., 2023; Chen et al., 2023), op-\n                   standing, domain-specific knowledge, and in-                                                                timizing prompts by using erroneous examples\n                    dustrial applications, demonstrate STRAGO’s\n                                                                    to guide refinement, either explicitly or implic-\n                   superior performance. It establishes a new state-\n                                                                                itly (Pryzant et al., 2023; Yang et al., 2023; Hu                    of-the-art in prompt optimization, showcasing\n                         its ability to deliver stable and effective prompt         et al., 2023; Tang et al., 2024). These LLM-based\n                 improvements.                                   optimization methods have demonstrated effective-\n                                                               ness across various tasks and hold promise for im-\n          1  Introduction\n                                                             proving prompt quality.arXiv:2410.08601v1            Recent advancements in large language models     However, search-based algorithms often suffer\n           (LLMs), such as ChatGPT and GPT-4, have signif-   from inefficiency in prompt optimization due to the\n              icantly enhanced their analytical, reasoning, and   absence of a clear optimization direction at each\n             contextual understanding capabilities (Yue et al.,    step. Reflection-oriented methods aim to accelerate\n            2024; Chang et al., 2023; Xu et al., 2024). LLMs   convergence by focusing on iteratively analyzing\n             are employed in various applications, such as Mi-   and correcting erroneous cases. However, concen-\n              crosoft Copilot and New Bing, where users interact    trating on failure cases can sometimes negatively\n            with the models through prompts. These prompts    affect correct ones, especially when the errors ex-\n             play a crucial role in guiding the LLMs’ responses,    hibit outlier characteristics. Both search-based and\n             ensuring outputs are accurate, relevant, and use-    reflection-oriented approaches can result in prompt\n                ful. However, the performance of LLMs heavily     drift, where a newly generated prompt resolves cer-\n                   *This work was done during an internship at Microsoft.      tain failures but inadvertently disrupts previously\n                  †Corresponding author.                               successful cases.\n\nAdditionally, these methods typically provide         potential in tasks where they initially lack\nthe LLM with a task description and context with-         sufficient expertise.\nout offering specific guidance on how to achieve\n                                                            3. Broad Validation Across Diverse Tasks:the desired outcomes, relying solely on the LLM’s\n                                    We extensively evaluate STRAGO across var-inherent capabilities. For example, OPRO (Yang\n                                                        ious tasks, including reasoning, languageet al., 2023) supplies historical prompts with cor-\n                                                       understanding, domain-specific knowledge,responding scores and task-specific data, expect-\n                                                and industrial applications, demonstratinging the LLM to generate more effective prompts.\n                                                               that STRAGO achieves state-of-the-art perfor-EvoPrompt (Guo et al., 2023) asks the LLM to\n                                             mance in prompt optimization.merge two prompts into a new one without any\ninstructions or strategy for doing so.  Similarly,                                       2  Methodology\nAPO (Pryzant et  al., 2023) presents erroneous\ncases and asks the LLM to correct them with new    2.1  Preliminaries\nprompts, but without providing actionable guid-   2.1.1  Task Formulation\nance. This heavy reliance on the LLM’s intrinsic                                             Given a task dataset D, our objective is to find the\nabilities can be problematic for complex tasks, as                                                 optimal prompt p∗that enables an LLM to gener-\nthe model may lack the necessary skills, leading to                                                        ate responses closely matching the desired outputs.\nsuboptimal prompt generation.                                                 This problem can be formalized as follows:\n   In this paper, we introduce STRAGO (Strategic-\nGuided Optimization), a novel reflection-based    min  J(p∗) = X  loss(LLM(p∗, x), y), (1)\n                                                             p∗\nprompt optimization method designed to overcome                     (x,y)∈D\nthe limitations of existing approaches.  Unlike\n                                           where x and y represent the input and its corre-\nprior methods, STRAGO avoids bias towards fail-\n                                              sponding desired output from the task dataset D,\nure cases by analyzing both successful and failed                                            and p∗is the optimal prompt that minimizes the\noutcomes in each iteration, identifying key factors\n                                                      loss between the LLM’s output and the desired\nnecessary for task success and understanding the\n                                                   output for all input-output pairs in D.\ncauses of failures. Using this analysis, STRAGO\nemploys in-context learning to develop specific, ac-   2.1.2  Assessment Metrics\ntionable strategies that offer detailed, step-by-step   Accuracy is the primary metric for evaluating the\nguidance for prompt refinement. These strategies,    effectiveness of a prompt in solving a task using\ncombined with the analysis results, are used to opti-   an LLM. However, during iterative prompt opti-\nmize the prompt. Our extensive experiments across    mization,  it is equally important to assess how\nreasoning, natural language understanding, domain   new prompts affect both previously successful and\nknowledge, and industrial applications demonstrate    failed cases. To capture this, we introduce two ad-\nthat this approach effectively corrects failures while    ditional metrics: Adverse Correction Rate (ACR)\nminimizing adverse effects on successful cases.   and Beneficial Correction Rate (BCR):\nThis unbiased iterative process, coupled with de-\ntailed guidance, achieves the best overall accu-\n                                 Pni=1 1 ppre(xi) = yi ∧ppost(xi) ̸= yiracy improvements post-optimization, setting a new   ACR =\n                                     Pni=1 1 ppre(xi) = yistate-of-the-art in prompt optimization.\n                                                                                                        (2)  Our major contributions are as follows:\n                                 Pni=1 1 ppre(xi) ̸= yi ∧ppost(xi) = yi\n                                    BCR =\n  1. Unbiased    Reflective    Optimization:           Pni=1 1 ppre(xi) ̸= yi\n   STRAGO  mitigates  prompt  drifting  by                                                                                                        (3)\n     incorporating both successful and failed cases\n     in the optimization process, resulting in more     where  ppre(xi) and  ppost(xi)  represent  the\n     stable and reliable prompt refinement.          model’s predictions before and after optimization,\n                                                        respectively, for each input xi and its ground truth\n  2. Actionable    Strategy    Development:    yi.\n   STRAGO  leverages  in-context  learning    ACR measures the negative impact of optimiza-\n     to craft step-by-step, actionable strategies that    tion by capturing the proportion of correct predic-\n     guide prompt optimization, unlocking LLMs’    tions that become incorrect after applying the new\n\nprompt. In contrast, BCR quantifies the positive    that require specific context or domain knowledge,\nimpact by measuring the proportion of previously    as illustrated in Figure 1(a), where the prompt lacks\nincorrect predictions that are corrected. Together    specific context or topic. To improve LLM perfor-\nwith accuracy, these metrics offer a comprehensive   mance in such cases, the Refiner adopts a two-step\nevaluation of the new prompt’s overall effective-   process: strategy formulation and strategy selec-\nness, highlighting both its potential drawbacks and    tion.\nimprovements.                                    Strategy formulation: As noted by Ma et al.\n                                                   (2024), LLM-generated errors tend to follow spe-\n2.2  STRAGO                                            cific patterns. For instance, miscalculations com-\nIn each optimization iteration, STRAGO samples   monly occur in mathematical tasks, while misun-\nboth successful and failed cases to identify key fac-   derstandings or lack of contextual comprehension\ntors for achieving task objectives and to understand    are frequent issues in language tasks. These pat-\nwhy the current prompt leads the LLM to succeed    terns necessitate tailored strategies, making them\nor fail (Analyzer). Based on this analysis, it gener-    ideal in-context learning demos. We focus on three\nates executable strategies that offer detailed, step-   prevalent error types: calculation errors in math\nby-step guidance for optimization (Refiner). These    tasks, misunderstandings in language tasks, and\nstrategies are then combined with the analysis re-    logical inference errors in reasoning tasks. We de-\nsults to optimize the prompt (Optimizer). Figure 1   velop corresponding strategies for each error type\nillustrates the three main steps of STRAGO, using   and use them as in-context learning demos to help\nthe TREC task (Voorhees and Tice, 2000) as an    the LLM generate strategies that improve prompts\nexample. Each module is discussed in detail in the   based on both positive and negative experiences.\nfollowing subsections. All meta prompts used in     For each aforementioned error type, we select\nSTRAGO are provided in Appendix D.             one or more representative examples. The LLM\n                                                                      first generates an experience for each example and\n2.2.1  Analyzer                                 proposes a specific, actionable strategy to address\nSTRAGO differs from previous reflection-based      it, which is then refined through manual revision.\nmethods by equally prioritizing the analysis of   These examples, along with their associated expe-\nboth correct and incorrect examples.  Given a    riences and strategies, serve as in-context learning\ndataset D = (x1, y1), (x2, y2), . . . , (xn, yn), the   demos, guiding the LLM in formulating detailed,\nmodel partitions it into two subsets after evalua-   step-by-step execution plans for both successful ex-\ntion: Dcorrect for correctly predicted samples and   amples (positive experiences) and failed examples\nDincorrect for incorrectly predicted samples. From    (negative experiences). In our implementation, we\neach subset, K examples are selected for deep anal-   generate N strategies for each example based on\nysis. The Analyzer examines these selected ex-    its experience. Figure 1(b) illustrates three distinct\namples to uncover the factors driving success in    strategies generated by the Refiner for N = 3 to\nDcorrect and the reasons for failures in Dincorrect.   address a negative experience from a failed exam-\nThese insights, termed positive experiences and    ple.\nnegative experiences, guide LLMs by highlighting      Strategy selection: For the N strategies gener-\nkey actions to take and common errors to avoid.   ated by the Refiner for each example and its corre-\nIn our implementation, each example generates   sponding experience, we use an LLM to evaluate\nM positive or negative experiences, depending on   and score them based on criteria such as alignment,\nwhether it belongs to Dcorrect or Dincorrect.            clarity, and feasibility. The strategy with the high-\n                                                           est score is then selected to address the experience.\n2.2.2  Refiner                                  We assess the strategies across several dimen-\nAccording to cognitive science principles (Swan-    sions: Match with Experience, which evaluates\nborn, 2010), humans typically approach problem-  how well the strategy addresses the identified is-\nsolving through three dimensions: identification    sues; Clarity of Strategy, which determines whether\n(What it is), causation (Why it is), and method    the strategy is clear and detailed; and Effectiveness\n(How to do it). In this context, experiences relate    in Addressing the Issue, which measures the like-\nto the identification dimension. While LLMs are    lihood that the strategy will efficiently resolve the\ngenerally capable of handling straightforward tasks,   problem. To mitigate potential self-enhancement\nthey may struggle with more complex challenges    bias during evaluation (Zheng et al., 2024), we use\n\nEvaluate Prompt\n                                                                                               Filtered\n                                       Experience                                     Strategies\n   Initial                      positivepositive                        Strategystrategy 1 1                       candidate\n               Analyzer                          Refiner                           Optimizer\n  prompt                                                                                 prompt\n                                  negativenegative                      Strategystrategy 2 2\n\n\n\n\n                                                                                                                       1. Read the prompt and the entire question carefully …\n                                                                                                                   1.                                                                                      Read                                                                                                   prompt                                                                                                                                 the                                                                                                                                               entire                                                                                                                                      question                                                                                                                                                         carefully                                                                …               Select                     the                     most                            appropriate                                                                                                               1.                                                                                   Read                                                                                                              the                                                                                                promptthe                                                                                                       and                                                                                                          andthe                                                                                                                                           entire                                                                                                                                  question                                                                                                                                                     carefully                                                              …                                                                                                                       2.                                                                                                Analyze                                                                                                                         the                                                                                                                                                       Is                                                                                                                                                                                                         it                                                                                                                                  asking                                                                                                                                                         for                                                                                                                                                        description                                                                                                                                                                                                                                                                        ...                                                                                                         1.                                                                               Read                                                                                                         the                                                                                            prompt                                                                                                  and                                                                                                                                     entirequestion:                                                                                                                                                carefully                                                            …a                                                                                                                   2.                                                                                             Analyze                                                                                                                         thequestion:                                                                                                                                                                                                   it                                                                                                                              asking                                                                                                                                     a                                                                                                                                                    description                                                                                                                                                                                                                                                                  ...                                                                                                               2.                                                                                         Analyze                                                                                                                 the                                                                                                                     question:the                                                                                                                                              Is it                                                                                                                                                   Isquestionasking                                                                                                                                                for                                                                                                                                  afor                                                                                                                                          -                                                                                                                                            If                                                                                                                     the                                                                                                                    question                                                                                                                          asks                                                                                                                   'who                                                                                                                                                                                                               is',                                                                                                                                               thedescription                                                                                                                              answer                                                                                                                                                                                            is...                                                                                                                                                          usually                                                                                                                                'Human             type                    of                  answer                        from                                    options.                                                                                                         2. Analyze                                                                                                            the                                                                                                                                         Is it                                                                                                                                           for                                                                                                                             a                                                                                                                                     -                                                                                                                                       If                                                                                                                the                                                                                                                question                                                                                                                      asks                                                                                                               'who                                                                                                                           answer                                                                                                                                                                                                                                                   ...is                                                                                                                                                      usually                                                                                                                             'Human                                                                                                                                -                                                                                                                                  If                                                                                                             the                                                                                                                question:question                                                                                                                   asks                                                                                                                      asking'who                                                                                                                                                                                                   is',                                                                                                                                       theis',                                                                                                                                           descriptionanswerthe                                                                                                                                                                                  is                                                                                                                                                  usually                                                                                                                          'Human                                                                                                                                             87                                                                                                         being’                                                                                                                          -                                                                                                                            If                                                                                                       question                                                                                                              asks                                                                                                        'who                                                                                                                                                                                            is',                                                                                                                                  the                                                                                                                   answer                                                                                                                                                                            is                                                                                                                                             usually                                                                                                                      'Human                                                                                                                                                        being’                                                                                                     being’                                                                                                 being’the                                                                                                                                   82  87  87                                                                                                                                          -                                                                                                                                            If                                               …                               Execute                                   Prompt                                                                                                                          -                                                                                                                            If                                          …                                                                                                                                     -                                                                                                                                       If                                              …                                                                                                                                -                                                                                                                                  If                                            …\n                                                                                                                      1. Begin by closely reading the question …\n                                                                                                                      closely                                                           …                                                                                                                            thereading                                                                                                                                   question…                                                                                          by                                                                                                                   reading                                                                                                                          questionthe                                                                                                                      2.                                                                                                 Trycloselyby                                                                                                                         toreading                                                                                                              understand                                                                                                                                  the                                                                                                                               questionthecontext.                                                         …If                                                                                                                                                                    there\\'s                                                                                                                           no                                                                                                                                                      evident                                                                                                                                                             context                                                                                                                                                            given                                                                                                                                                                                         in the\n                                                                                                          understand                                                                                                                     the                                                                                                                                                             Ifcontext.                  Correct              Incorrect                              1.2. TryBegin1.2.toTryBegin1.2.byunderstandTryBegintoclosely                                                                                                      understandto                                                                                                                                                      context                                                                                                              question,                                                                                                                                  trycontext.                                                                                                                          theto                                                                                                                          derivecontext.the                                                                                                                                                      there\\'sit                                                                                                                fromIf there\\'s                                                                                                                                                                        Ifnothethere\\'s                                                                                                                                         evidentwordingno                                                                                                                                              evidentnocontextevidentand                                                                                                                                                                   structuregivencontextgiven                                                                                                                                                                           inofthegiventhein                                                                                                                                                                            question.thein the\n                examples           examples                           question,question,question,try toReadingtryderivetotryderivetotheit fromderivequestionit fromtheit fromwordingmultiplethe wordingthe wordingandtimesstructureandcanandstructureoftenstructureof thebeofquestion.helpfultheof question.theinquestion.uncovering the\n                                                                                          Reading                                                                                                                                                                               the                                                                                  Reading                                                                                                         the                                                                                       Reading                                                                                                              the                                                                                                             questionthe questionmultiplemultiplemultipletimestimescantimesoftencan canoftenbe helpfuloftenbe helpfulbeinhelpfuluncoveringin uncoveringin uncoveringthe                                                                                                                                                                            the                                                                                                        questioncontext.                                                                                                                                             82                                                                                                           context.                                                                                                  context.                                                                                                       context.                                                                                                                                      82                                                                                                                                          82                                                                                                                      3.                                             …            should        should not                                                                                                                                   87                                                                                                                  3.                                            …                                                                                                        3. …                                                                                                              3. …\n                                                                                                        1. Read the question1. Readcarefullythe questionto understandcarefully toitsunderstandessence ... its essence ...\n                                                                                                                  1.                                                                                      Read                                                                                                                                  carefully                                                                                                              1.                                                                                   Read                                                                                                              the                                                                                                             questionthe                                                                                                                                          to                                                                                                                       2.                                                                                                                        thecarefullyprovided                                                                                                                                 optionsunderstandto                                                                                                                                understand...    its essenceits essence...   ...                                                                                                        2.                                                                            Look                                                                                                                      at                                                                                                           the                                                                                                     providedLook                                                                                                                 questionatoptions                                                                                                                                                                                                               ...                             The                                 is              TheThe keykeyis                                      The                                             promptprompt                                                                 doesn\\'t                                                   doesn\\'tprovide                                                                                                                  2.                                                                                   Look                                                                                                              provided                                                                                                                             options                                                                                                                                                                                                                               ...                                                                                                              2.                                                                                Look                                                                                                                            at                                                                                                                                 at providedthe                                                                                                                         options                                                                                                                                                                                                                         ...                                                                                                                       3.                                              …the                                                                                                                                                    78.5 78.5  78.78.5                                                                                                        3.                                        …               …                                             a                                                         context                                                                           topic.                                  providespecific                  …  or               understandunderstand           …                                                                                                                  3.                                            …                                                                                                              3.                                          …\n\n        (a)Analyzer: summary experiences           (b) Refiner: formulate & select strategies\n\n                                                    optimize                                  Cached prompts\n               The key is...             strategy 1             p1                                                                                  PromptPrompt 1 1     ScoreScore 1 1                                                                          crossover\n                                                                                                    paraphrase                                                    optimize                                                                           hybrid\n               The prompt...            strategy 2            p2            prompt           current prompt\n                                        (c) Optimizer: optimize then paraphrase\n\n\n                                     Figure 1: Flowchart of STRAGO\n\n\na different LLM (Claude) for scoring. Additionally,   other for those based on negative experiences.\nfollowing the scoring method used in Thomas et al.     Crossover:  Following the approach of Guo\n(2023), we conduct five assessments with the LLM    et al. (2023), which shows that combining LLMs\nand average their scores for enhanced stability and   with evolutionary algorithms can improve prompt\nreliability. Figure 1(b) presents the averaged score    fusion (similar to genetic algorithms), we select\nfor each of the three strategies addressing a neg-   two prompts, one from each set, and perform a\native experience from a failed example, with the    crossover operation to produce a hybrid prompt.\nhighest-scoring strategy (shown in the middle) be-     Paraphrase: A cache is maintained to store\ning selected.                                        the top n prompts and their corresponding scores\n                                             from previous evaluations on a validation set. Each\n2.3  Optimizer                                                 hybrid prompt is paraphrased using the prompts\nAlthough LLMs can process long text inputs, they    in the cache, and both the paraphrased and hybrid\noften struggle to thoroughly consider every detail   prompts are evaluated as candidate prompts. The\nwhen handling both positive and negative experi-   best prompt is either selected for the next iteration\nences, along with their associated strategies. To    of optimization if the stopping condition has not\nmitigate this issue, we implement an optimization   been met or output as the optimized prompt. The\nmethod that processes these experiences separately   cache is then updated with the evaluation results.\nand then combines them through a crossover pro-\ncedure. The optimizer operates in three main steps:   3  Experiments\nOptimize, Crossover, and Paraphrase.\n                                                    3.1  Evaluation Tasks\n  Optimize: For each selected successful or failed\nexample, the Analyzer generates M positive or  We select five relatively challenging tasks from\nnegative experiences. The Refiner then generates a  BBH (Suzgun et al., 2022), chosen for their his-\nstrategy for each experience, and the Optimizer cre-    torically low performance scores, though they are\nates a revised prompt based on the strategy. These   among the simpler tasks included in our evaluation.\nrevised prompts are divided into two sets: one for      In addition to these tasks, we incorporate two\nprompts derived from positive experiences and the   well-known natural language understanding (NLU)\n\ntasks: SST-5 (Socher et al., 2013), a sentiment    3.3  Experimental Details\nclassification task based on movie reviews, and                                We conduct extensive experiments using GPT-\nTREC (Voorhees and Tice, 2000), which identifies                                          4 (Achiam et al., 2023) to evaluate the effective-\ntypes of responses. We also include MedQA (Jin                                                  ness of STRAGO and the baseline methods. APO,\net al., 2021) and MedMCQA (Pal et al., 2022) to                                     OPRO, and STRAGO all start with the same ini-\nevaluate our method’s effectiveness in tasks related                                                                  tial prompt, while EvoPrompt uses 14 additional\nto medical and pharmacological knowledge.                                                         variations.\n  To evaluate the effectiveness of our method in                               A subset of the test set is selected as the valida-\nindustrial scenarios, we select an internal personal-\n                                                       tion set for prompt optimization. In each iteration,\nized search task named Personalized Intent Query.                                                    the validation set is used to assess prompt qual-\nThis task uses anonymized search data to determine\n                                                                    ity. During the final testing phase, the remaining\nwhether non-personalized search results should be                                                             test samples are used to evaluate the optimized\nreordered based on user-specific information such\n                                                 prompts. For each method, we select the top 5 op-\nas location, language, and search history.  The\n                                                   timized prompts with the highest validation scores\ntask involves step-by-step initial prompts typical\n                                              and evaluate them on the test samples, reporting the\nof complex industrial tasks and diverse, extensive                                              performance of the best-performing prompt. For\ndata content that often includes redundant infor-                                      STRAGO, we set K, M and N to 3. To ensure\nmation. These characteristics represent common                                                     consistent evaluation, the temperature is set to 0.\nchallenges in industrial-level prompt optimization.                                      As outlined by Ma et al. (2024), all methods per-\nFor detailed data specifications, please refer to Ap-\n                                            form approximately the same number of prompt\npendix A.1.\n                                                      searches. Detailed parameter settings are provided\n                                                        in Appendix A.3.3.2  Baselines\n\nThe following prompt optimization methods serve    3.4  Main Results\nas baselines for comparison with our method:\n                                         The experimental results are reported in Table 1,\n    • CoT: CoT (Wei et al., 2022; Kojima et al.,   where STRAGO consistently outperforms all base-\n    2022) is a popular baseline in many studied.    lines across the six tasks, showcasing the effective-\n     In our setup, CoT is initiated by appending    ness of our approach.\n     the phrase \"Let’s think step by step.\" after the\n                                          Performance  on BBH  and NLU  tasks.\n     question without utilizing any examples.\n                                   STRAGO achieves 79.77% accuracy on BBH,\n                                          56.34% on SST-5, and 87.21% on TREC, surpass-    • APO: APO (Pryzant et al., 2023) generates\n                                                  ing previous state-of-the-art (SOTA) methods by     natural language-level gradients from incor-\n                                             2.37%, 0.82%, and 2.31%, respectively. These     rect examples and uses these gradients to\n     reverse-edit the prompt. APO represents ex-    results demonstrate STRAGO’s strong performance\n                                          on relatively straightforward tasks.  In contrast,      plicit feedback methods.\n                                          EvoPrompt shows smaller improvements than\n    • OPRO: OPRO (Yang et al., 2023) utilizes  APO and OPRO on BBH and TREC, suggesting\n     implicit feedback by tracking a historical tra-    that search-based methods like EvoPrompt may\n     jectory of previous prompts and their asso-   face challenges  in  rapid convergence.   This\n     ciated scores. During prompt optimization,    highlights the importance of precise and targeted\n   OPRO leverages these trajectories to guide the    optimization strategies for rapid convergence in\n   LLM in generating prompts aimed at achiev-    iterative prompt optimization.\n     ing higher scores.\n                                           Performance on Domain-specific Tasks. A no-\n    • EvoPrompt: EvoPrompt (Guo et al., 2023)    table trend is that on domain-specific tasks like\n     applies evolutionary algorithms, such as ge-  MedQA and MedMCQA, all baselines show lim-\n     netic algorithms and differential evolution, to    ited improvements, with none exceeding 1%. Some\n     generate prompts that optimize performance   methods, particularly EvoPrompt, even exhibit per-\n    on validation sets.  It serves as a represen-   formance declines, likely because they don’t lever-\n     tative method for search-based optimization   age feedback from the data. In domain-specific\n     techniques.                                       tasks, relying solely on LLMs’ intrinsic capabili-\n\nMethod       BBH  SST-5 TREC MedQA MedMCQA  Per. Query\n\n         MI (Manual Instructions)        -    54.48   71.10    77.83      65.87       67.97\n          CoT (Wei et al., 2022)     69.43  53.86   64.40    49.10      59.07             -\n        APO (Pryzant et al., 2023)   76.50  55.52   84.90    77.41      65.93       67.10\n        OPRO (Yang et al., 2023)   77.40  55.31   83.10    76.56      66.00             -\n         EvoPrompt (Guo et al., 2023)  75.48  55.15   81.65    77.15      65.47             -\n            STRAGO (Ours)        79.77  56.34   87.21    80.05      67.20       69.26\n\n\nTable 1: Performance across six tasks using GPT-4 as the evaluator with Q_END zero-shot evaluation results. The\ninitial instruction is CoT for BBH and the manual instructions for the other tasks. Bold text indicates the best\nperformance achieved.\n\n\nties often fails to yield prompts well-suited to the    sults are reported in Table 21\ndata’s characteristics. In contrast, STRAGO demon-    As shown in Table 2, STRAGO exhibits the low-\nstrates improvement, with a 1.22% gain on MedQA    est ACR and the highest BCR for four of the six\nand a 1.33% gain on MedMCQA. This suggests    tasks, indicating that its optimized prompts correct\nthat STRAGO’s step-by-step prompt-revising strat-   more erroneous samples while adversely affecting\negy is more effective at inducing relevant domain   fewer correctly predicted samples than the base-\nknowledge and generating prompts tailored to the    line methods. This demonstrates STRAGO’s supe-\nspecific expertise required for these tasks.             rior performance compared to the baselines. The\n                                               impact of maintaining correct samples is particu-\nPerformance on Industrial Scenario Tasks.  In    larly significant in tasks with high-quality initial\nthe Personalized Intent Query task, we compare   prompts. For instance, in MedQA, where the ac-\nSTRAGO only with APO due to the unique char-   curacy is 77.83%, although APO corrects more\nacteristics of its data. As shown in Table 1, APO    errors than STRAGO (34.62% or 90 erroneous sam-\nexperiences performance degradation when pro-   ples compared to 26.92% or 70 erroneous sam-\ncessing step-by-step instructions, likely because it    ples), it also adversely affects more correct samples\nstruggles to accurately identify the specific steps   (10.41% or 95 correct samples compared to 4.49%\nthat require editing in lengthy directives. In con-   or 41 correct samples). This results in a decline in\ntrast, STRAGO achieves a 2.16% performance im-   performance for APO compared to STRAGO, as\nprovement, demonstrating that its approach of in-   shown in Table 1. We attribute this to STRAGO’s\ncrementally integrating experiences while formu-    integration of correct examples and positive expe-\nlating step-by-step strategies provides valuable con-   riences during prompt optimization, which helps\ntextual information for optimization.                avoid significant deviations from overall task objec-\n  In summary, STRAGO proves effective not only    tives, especially when the initial prompt is already\nfor simple prompts but also for addressing complex    effective.\ntasks, including those encountered in industrial sce-\n                                                    4.2  Ablation Study\nnarios.\n                                We conduct an in-depth analysis on two tasks:\n                                                    the readily optimized TREC task and the domain4  Analysis\n                                                 knowledge-intensive MedMCQA task.  In this\n4.1  Data Analysis                                  study, we systematically remove both positive and\n                                                   negative experiences from the Analyzer, as well\nTo validate the importance of maintaining correctly                                                   as strategies from the Refiner. The experimental\npredicted samples while correcting mispredicted                                                          results are presented in Table 3.\nones during prompt optimization, we analyze the\nprompt drifting effect of each optimization method.  The Impact of Experience.  The results in Ta-\nSpecifically, we compare the final prompts gener-   ble 3 indicate that removing positive experiences\nated by various methods with the initial prompts, as-    significantly increases ACR, leading to perfor-\nsessing how many new errors an optimized prompt                                                            1Note that the denominators for calculating ACR and BCR\nintroduces while correcting existing ones. The re-     differ.\n\nBBH       SST-5     TREC    MedQA   MedMCQA   Per. Query\n  Method\n          ACR  BCR  ACR  BCR  ACR  BCR  ACR  BCR  ACR  BCR  ACR  BCR\n\n   APO     7.77  40.57  8.48  12.42  3.56   56.5   10.41  34.62  5.16   9.96   6.37  10.81\n  OPRO    7.53  41.59  9.11  12.73  4.57  53.75   8.87   25.38  5.36  10.74     -        -\n EvoPrompt  8.72  37.29  8.10  11.21  5.08  50.00   9.30   24.61  4.66   7.81      -        -\n  STRAGO   4.59  49.98  7.47  13.03  3.86  65.25   4.49   26.92  4.35   12.3   3.82  12.12\n\n\nTable 2: ACR and BCR values for different optimization methods. The results for BBH represent the average across\nthe five subtasks. Underlined values indicate the smallest (best) ACR, while bold values denote the largest (best)\nBCR.\n\n\nmance declines for STRAGO across both tasks.       Task     Method   ACR  BCR   ACC.\nThis underscores the critical role of positive experi-\n                                                             Ours        3.86   65.25  87.21\nences in maintaining correctly predicted samples\n                                                                      w/o. pos.   4.67   56.75  84.18\nand enhancing overall task performance. Addition-     TREC                                                                      w/o. neg.   4.17   61.5   85.62\nally, comparisons with Table 1 reveal that STRAGO,                                                                      w/o. strat.   4.27   59.25  85.19\nwhen utilizing only positive experiences and strate-\n                                                             Ours        4.35   12.3   67.20gies, can effectively optimize performance, consis-\n                                                                      w/o. pos.   8.10   16.02  66.00\ntently outperforming all baseline methods in the    MedMCQA\n                                                                      w/o. neg.   4.15   9.96   66.53\nTREC task. Conversely, eliminating negative ex-\n                                                                      w/o. strat.   5.06   9.18   65.67\nperiences results in a reduction in BCR, indicating\nthat these experiences provide vital information for                                                     Table 3: Results of the ablation study on TREC and\ncorrecting erroneous samples and adapting to the  MedMCQA tasks: Impact of omitting positive experi-\nsubset of mispredicted data. Their absence impairs    ences (w/o pos.), negative experiences (w/o neg.), and\nthe Optimizer’s ability to modify the prompt effec-     all strategies (w/o strat.) on STRAGO.\ntively, hindering the incorporation of pivotal text\nrelevant to this data subset.\n                                                          set score above 80%, STRAGO requires the explo-\nThe Impact of Strategies.  Analysis of Table 3 re-    ration of only 10 prompts, whereas methods like\nveals that STRAGO maintains robust performance  APO need over 90 prompts. This rapid conver-\nin simpler tasks even without explicit strategies.   gence is likely due to STRAGO providing more\nHowever, the omission of strategies significantly   valuable reference information than its counter-\ndiminishes STRAGO’s effectiveness in tasks re-    parts. In a single optimization cycle, the Optimizer\nquiring domain knowledge.  This disparity may    not only utilizes positive and negative experiences\narise from the fact that, in simpler tasks, LLMs    but also incorporates corresponding strategies. This\ncan leverage their inherent capabilities to extract   approach allows the Optimizer to access more com-\nuseful knowledge for prompt optimization. In con-   prehensive information and generate prompts with\ntrast, these capabilities are often insufficient for   enhanced generalization capabilities.\nknowledge-intensive tasks. By integrating explicit\n                                                    4.4  Cost Analysisexecution strategies, STRAGO enhances the LLMs’\nability to engage in deeper analytical thinking, un-  We compare the resource consumption of STRAGO\ncovering more domain-specific insights and provid-   with that of baseline methods by estimating the\ning valuable guidance for the Optimizer.           number of API calls and total token usage (see Ap-\n                                                pendix B for detailed estimation methods). The re-\n4.3  Convergence Analysis                                                            sults for the TREC dataset are presented in Table 4.\nWe analyze the convergence of STRAGO in com-  As shown, APO requires the fewest API calls, fol-\nparison to the three baseline methods on the TREC   lowed closely by STRAGO. Unlike OPRO and Evo-\ntask, with results shown in Figure 2.  Notably,   Prompt, both of these methods leverage the UCBan-\nSTRAGO converges significantly faster than the    dit algorithm to filter out many candidate prompts,\nbaseline methods. For example, to achieve a test    thus reducing evaluation costs on the validation set.\n\na finely tuned strategic prompt. This phenomenon\n                                                has been noted in other studies (Zeng et al., 2023;\n                                Ma et al., 2024). Detailed results can be found in\n                                            Appendix C.\n\n                                       5  Case Study\n\n                                                This section provides an in-depth examination of\n                                                     the strategies developed by the Refiner and the op-\n                                                     timization processes undertaken by the Optimizer,\n                                                     as illustrated through tow cases detailed in Table 5.Figure 2: Convergence curves for the TREC task: Com-\nparison of test set scores for the optimal prompt across     The first case pertains to a movie recommenda-\ndifferent search sizes and various prompt optimization    tion task. In this scenario, the Analyzer identifies\nmethods.                                            the prompt’s failure, attributing it to the absence\n                                                   of a clear similarity criterion. To rectify this, the\n                                                  Refiner develops a strategy focusing on identify-\nIn terms of token consumption, EvoPrompt and\n                                                  ing such criteria, particularly by scrutinizing out-\nSTRAGO exhibit the highest usage. EvoPrompt’s\n                                                                lier data. Subsequently, the Optimizer refines the\nelevated consumption arises from the need to eval-\n                                            prompt by addressing this diagnosed error and in-\nuate numerous candidate prompts on the validation\n                                                       tegrating the strategic insights.\nset, while STRAGO’s higher usage is due to the\n                                             The second case involves the Snarks task, where\nlonger length of its optimized prompts compared\n                                                     the Analyzer underscores the importance of focus-\nto other methods. However, given STRAGO’s sig-\n                                                  ing on contextual clues, such as specific words or\nnificant performance improvement (from 84.90%\n                                                    phrases. The Refiner then crafts a strategy that\nto 87.21%) over the other methods, this resource\n                                                  not only incorporates these basic experiential in-\nexpenditure is considered justified.\n                                                        sights but also emphasizes the analysis of sentence\n                                                      tone, specifically to discern exaggeration or over-\n          API Tokens Search Size Score\n                                                     statement. These additional insights are pivotal in\n   APO   18.4K 3.31M     315     84.90     determining the ironic intent of a sentence.\n  OPRO   93.3K 4.11M    310     83.10\n EvoPrompt 61.3K 5.46M     300     81.65    6  Related Work\n  STRAGO  23.8K 5.46M     310     87.21\n                                                    6.1  Automatic Prompt Engineering\n\n      Table 4: Cost comparison on TREC Task.        Prompt optimization aims to discover the most ef-\n                                                       fective prompts for specific tasks (Sahoo et al.,\n                                               2024; Liu et al., 2023).  Initially, this optimiza-\n4.5  Performance Using Different Models                                                      tion relied heavily on manually crafted templates\nWe evaluate STRAGO and baseline methods us-   designed by experts (White et al., 2023), which is\ning GPT-3.5-turbo and GPT-4 as evaluators (the    labor-intensive, especially for complex tasks. To\ntask models used to assess prompt performance),   address this, researchers have developed various\nwith GPT-4 also serving as the optimizer (the   automated optimization techniques, broadly cate-\nmodel used to enhance the prompt). The exper-   gorized into discrete and continuous methods (Li\nimental results are reported in Table 6. STRAGO   and Liang, 2021; Zhang et al., 2021). Discrete op-\nachieves a performance improvement of 5.45%    timization modifies the prompt text by adjusting\non GPT-3.5-turbo and 10.34% on GPT-4. Addi-    specific tokens. For instance, a prompt like \"Let’s\ntionally, STRAGO outperforms the best baseline    think step by step\" could be modified to \"Take\nby 1.86% on GPT-3.5-turbo and 2.37% on GPT-   a deep breath and work on this problem step-by-\n4.  This suggests that STRAGO performs better    step\" (Yang et al., 2023). Continuous optimization,\nwith more advanced models. The superior perfor-    in contrast, manipulates prompt embeddings by\nmance observed with GPT-4 may be attributed to   appending a latent space vector to the start of the\nits improved adherence to instructions compared   embedding (Lester et al., 2021; Wen et al., 2023).\nto GPT-3.5-turbo, which appears to struggle with   Our approach, STRAGO, focuses on editing dis-\ncapturing specific instructional nuances, even with    crete text without requiring additional training.\n\nTask             Experience and Corresponding Strategy\n\n                      Negative Experience: Ambiguity in the similarity criterion: The prompt asks to find a movie similar to a given set\n                        of movies without specifying the basis of similarity ...\n\n                        Strategy: ... 3. Recognize Outliers: Also pay attention to the odd ones out, or the movies that don’t share the above\n                            listed common factors. This could potentially give hints on what the ’similarity’ criterion could be ...\n        Movie\n    Recommendation  Refined Prompt: Let’s carefully analyze each step. Given a set of movies, determine which option is most similar\n                      based on common factors such as genre, era, theme, actors, or director. Be aware of any outliers in the set, as this\n                      might give hints on what the ’similarity’ criterion could be. Remember, in the absence of clear instructions or when\n                         there are multiple potential correct answers, it might be necessary to make an educated guess. Let’s begin.\n\n                        Positive Experience: Contextual Clues: Notice words or phrases that may indicate sarcasm.  This can be a\n                       circumstance or expectation that sounds out of ordinary, such as losing money for winning in example.\n\n                        Strategy: ... 2. Look for any words or phrases that contradict usual or expected situations ... 3. Pay special attention\n    Snarks              to the tone of the statement ... 4. Locate any exaggeration or hyperbole in the statement ...\n\n                      Refined Prompt: Please identify the sarcastic statement from the given options. Remember, sarcasm often involves\n                        statements that contradict usual situations or expectations and has a mocking or scornful tone. Look for statements\n                           that are implausible or absurd under normal circumstances and note any exaggerations or hyperbole. The context of\n                         the statement can also help you understand its sarcastic nature.\n\nTable 5: Two cases illustrating the strategy and optimization of STRAGO. Note that the refined prompts displayed\ndo not represent the best optimization result.\n\n\n                GPT-3.5-turbo GPT-4          cessful and failed cases.   This innovative ap-\n                                               proach identifies critical factors for achieving ob-\n       CoT         56.37       69.43                                                        jectives while providing insights into the reasons\n      APO         59.96       76.50                                                       for failures. By leveraging in-context learning,\n     OPRO        59.78       77.40                                   STRAGO delivers detailed, step-by-step guidance\n     EvoPrompt      59.67       75.48                                                       for prompt optimization. Experiments conducted\n     STRAGO       61.82       79.77                                                    across diverse tasks—ranging from simple scenar-\n                                                        ios to domain-specific and complex industrial con-\nTable 6: Performance of GPT-3.5-turbo and GPT-4 on\n                                                texts—demonstrate that STRAGO significantly out-BBH Task.\n                                               performs existing prompt optimization methods,\n                                                      establishing a new state-of-the-art in the field.\n6.2  LLM-based Prompt Optimization\n                                       8  Limitations\nRecent  studies increasingly  utilize LLMs  for\nprompt optimization (Zhou et  al., 2022).  Ad-   Our limitations are outlined as follows:\nvanced search techniques, such as Monte Carlo\n                                               Fairness of Comparison:  To ensure fair com-Tree Search (MCTS) (Wang et al., 2023) and evo-\nlutionary algorithms (Guo et al., 2023; Fernando    parisons, we adjust certain parameters in the offi-\net al., 2023), are employed to iteratively refine and    cial code of baseline methods, aligning the number\nintegrate potential candidate prompts, enhancing    of searches across all methods to approximately\ntheir effectiveness.  Additionally, some research   300-315. While slight variations in the number of\nleverages the self-reflective capabilities of LLMs,   searches may exist between methods, these differ-\ngenerating prompts that preemptively avoid errors   ences are minimal and within an acceptable range\nby analyzing incorrect examples and their underly-    to maintain the fairness of the comparison results.\ning causes (Pryzant et al., 2023; Yang et al., 2023;   However, it is important to note that for specific\nYe et al., 2023; Tang et al., 2024). This reflective    tasks, we cannot guarantee that methods like OPRO\napproach allows models to learn from past mis-   will not exhibit significant performance improve-\ntakes, improving both the accuracy and relevance   ments after exceeding 1600 searches. Given that\nof future prompts.                                   the primary objective of prompt optimization is to\n                                                            efficiently identify the optimal prompt, we consider\n7  Conclusion                                 a search limit of 300-315 sufficient for evaluating\n                                                     the overall performance of each method.\nIn this paper, we introduce STRAGO, a strategy-\nguided, reflective-based optimization method that   Model Selection:  In our experiments, we uti-\nutilizes balanced iterations to analyze both suc-    lized GPT-3.5-turbo and GPT-4 as our task mod-\n\nels. While proprietary models like these may un-   Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning:\ndergo upgrades or discontinuation, potentially pos-      Optimizing continuous prompts for generation. arXiv\n                                                             preprint arXiv:2101.00190.ing challenges for reproducibility, our results indi-\ncate that STRAGO performs more effectively with    Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\nmore advanced models. Therefore, we anticipate      Hiroaki Hayashi, and Graham Neubig. 2023. Pre-\n                                                                      train, prompt, and predict: A systematic survey ofthat STRAGO will remain competitive as newer and\n                                                    prompting methods in natural language processing.\nmore sophisticated models become available.                                    ACM Computing Surveys, 55(9):1–35.\n\n                                                   Ruotian Ma, Xiaolei Wang, Xin Zhou, Jian Li, Nan\nReferences                                       Du, Tao Gui, Qi Zhang, and Xuanjing Huang. 2024.\n                                                  Are large language models good prompt optimizers?\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama                                                        arXiv preprint arXiv:2402.02101.\n  Ahmad,  Ilge Akkaya,  Florencia Leoni Aleman,\n  Diogo Almeida, Janko Altenschmidt, Sam Altman,   Ankit Pal, Logesh Kumar Umapathi, and Malaikan-\n  Shyamal Anadkat, et al. 2023. Gpt-4 technical report.     nan Sankarasubbu. 2022. Medmcqa: A large-scale\n  arXiv preprint arXiv:2303.08774.                        multi-subject multi-choice dataset for medical do-\n                                                main question answering. In Conference on health,\nYupeng Chang, Xu Wang, Jindong Wang, Yuan Wu,                                                               inference, and learning, pages 248–260. PMLR.\n  Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi,\n  Cunxiang Wang, Yidong Wang, et al. 2023. A sur-   Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chen-\n  vey on evaluation of large language models. ACM      guang Zhu, and Michael Zeng. 2023.  Automatic\n  Transactions on Intelligent Systems and Technology.      prompt optimization with\" gradient descent\" and\n                                              beam search. arXiv preprint arXiv:2305.03495.\nXinyun Chen, Maxwell Lin, Nathanael Schärli, and\n  Denny Zhou. 2023. Teaching large language models                                                  Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha,\n   to self-debug. arXiv preprint arXiv:2304.05128.                                                           Vinija Jain, Samrat Mondal, and Aman Chadha.\n                                                       2024. A systematic survey of prompt engineering inMingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan\n                                                               large language models: Techniques and applications.  Wang, Han Guo, Tianmin Shu, Meng Song, Eric P.\n                                                        arXiv preprint arXiv:2402.07927.  Xing, and Zhiting Hu. 2022. Rlprompt: Optimizing\n   discrete text prompts with reinforcement learning.                                                      Taylor Shin, Yasaman Razeghi, Robert L Logan IV,\n                                                            Eric Wallace, and Sameer Singh. 2020. Autoprompt:Chrisantha  Fernando,  Dylan  Banarse,  Henryk\n                                                               Eliciting knowledge from language models with  Michalewski, Simon Osindero, and Tim Rock-\n                                                          automatically generated prompts.  arXiv preprint   täschel. 2023.   Promptbreeder:  Self-referential\n                                                        arXiv:2010.15980.  self-improvement via prompt evolution.   arXiv\n   preprint arXiv:2309.16797.\n                                           Noah Shinn, Beck Labash, and Ashwin Gopinath.\n                                                      2023.  Reflexion: an autonomous agent with dy-Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao\n                                                  namic memory and self-reflection. arXiv preprint  Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yu-\n                                                        arXiv:2303.11366.   jiu Yang. 2023. Connecting large language models\n  with evolutionary algorithms yields powerful prompt\n                                                   Richard Socher, Alex Perelygin, Jean Wu, Jason\n   optimizers. arXiv preprint arXiv:2309.08532.\n                                                     Chuang, Christopher D Manning, Andrew Y Ng, and\nXinyu Hu, Pengfei Tang, Simiao Zuo, Zihan Wang,      Christopher Potts. 2013. Recursive deep models for\n  Bowen Song, Qiang Lou, Jian Jiao, and Denis      semantic compositionality over a sentiment treebank.\n   Charles. 2023.  Evoke: Evoking critical thinking       In Proceedings of the 2013 conference on empiri-\n   abilities in llms via reviewer-author prompt editing.      cal methods in natural language processing, pages\n  arXiv preprint arXiv:2310.13855.                     1631–1642.\n\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,   Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\n  Hanyi Fang, and Peter Szolovits. 2021. What disease       bastian Gehrmann, Yi Tay, Hyung Won Chung,\n  does this patient have? a large-scale open domain      Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny\n   question answering dataset from medical exams. Ap-      Zhou, , and Jason Wei. 2022. Challenging big-bench\n   plied Sciences, 11(14):6421.                              tasks and whether chain-of-thought can solve them.\n                                                        arXiv preprint arXiv:2210.09261.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\n   taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-    Peter Swanborn. 2010. Case study research: What, why\n  guage models are zero-shot reasoners. Advances in      and how? Case Study Research, pages 1–192.\n  neural information processing systems, 35:22199–\n  22213.                                       Xinyu Tang, Xiaolei Wang, Wayne Xin Zhao, Siyuan\n                                                       Lu, Yaliang Li, and Ji-Rong Wen. 2024. Unleashing\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021.      the potential of large language models as prompt op-\n  The power of scale for parameter-efficient prompt       timizers: An analogical analysis with gradient-based\n   tuning. arXiv preprint arXiv:2104.08691.              model optimizers. arXiv preprint arXiv:2402.17564.\n\nPaul Thomas, Seth Spielman, Nick Craswell, and   Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\n  Bhaskar Mitra. 2023. Large language models can ac-     Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\n   curately predict searcher preferences. arXiv preprint     Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.\n  arXiv:2309.10621.                                   Judging llm-as-a-judge with mt-bench and chatbot\n                                                            arena. Advances in Neural Information Processing\nEllen M Voorhees and Dawn M Tice. 2000. Building a       Systems, 36.\n   question answering test collection. In Proceedings\n   of the 23rd annual international ACM SIGIR confer-   Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\n  ence on Research and development in information      Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\n   retrieval, pages 200–207.                             Ba. 2022. Large language models are human-level\n                                                    prompt engineers. arXiv preprint arXiv:2211.01910.\nXinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai,\n  Haotian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P\n                           A  More Experiment Details  Xing,  and  Zhiting Hu.  2023.    Promptagent:\n   Strategic planning with language models enables\n                                            A.1  Data Details   expert-level prompt optimization.  arXiv preprint\n  arXiv:2310.16427.                              For the BBH task, we roughly randomly select 50\n                                                   pieces of data as training data and use the remain-Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\n  Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,   ing data as the test set. During the experiment,\n   et al. 2022. Chain-of-thought prompting elicits rea-   the first 50 pieces of the test set are used as vali-\n   soning in large language models. Advances in neural                                                   dation data. For natural language understanding\n   information processing systems, 35:24824–24837.\n                                                     tasks and Domain Knowledge tasks, the test set\nYuxin Wen, Neel Jain, John Kirchenbauer, Micah Gold-   contains more than 1000 pieces of data. We sample\n  blum, Jonas Geiping, and Tom Goldstein. 2023. Hard   300 or 400 pieces as validation data using strati-\n  prompts made easy: Gradient-based discrete opti-\n                                                          fied sampling. The detailed data division is shown\n   mization for prompt tuning and discovery.\n                                                      in Table 7. For the Industry application task, we\nJules White, Quchen Fu, Sam Hays, Michael Sandborn,   choose internal search data. The data part includes:\n  Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse                                                      user’s location, language, query keywords, some\n  Spencer-Smith, and Douglas C Schmidt. 2023. A\n                                                  non-personalized query results (including URL, ti-  prompt pattern catalog to enhance prompt engineer-\n   ing with chatgpt. arXiv preprint arXiv:2302.11382.     tle, and rich text), search history (including query\n                                                keywords, query time, whether clicked, URL, title,\nXinrun Xu, Yuxin Wang, Chaoyi Xu, Ziluo Ding,\n                                            and rich text). The task goal is to measure the ex-\n  Jiechuan Jiang, Zhiming Ding, and Börje F Karls-\n   son. 2024. A survey on game playing agents and    tent to which search history supports the reordering\n   large models: Methods, applications, and challenges.   of non-personalized queries (1-5), with 1 repre-\n  arXiv preprint arXiv:2403.10249.                    senting \"no help\" and 5 representing \"Extremely\n                                                         helpful\". The detailed data distribution is shown inChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,\n  Quoc V Le, Denny Zhou, and Xinyun Chen. 2023.   Figure 3\n  Large language models as optimizers. arXiv preprint\n  arXiv:2309.03409.                            A.2  Prompt Initialization\n\nQinyuan Ye, Maxamed Axmed, Reid Pryzant, and    In this paper, all prompts are formulated in the\n   Fereshte Khani. 2023. Prompt engineering a prompt  Q_END format, meaning instructions are added af-\n   engineer. arXiv preprint arXiv:2311.05661.             ter the original question. For example, in the BBH\nChongjian Yue, Xinrun Xu, Xiaojun Ma, Lun Du,    tasks, we append \"Let’s think step by step\" after\n  Hengyu Liu, Zhiming Ding, Yanbing Jiang, Shi Han,    the question. Table 8 lists the initial prompts for all\n  and Dongmei Zhang. 2024. Enabling and analyzing    tasks (for EvoPrompt, we use LLMs to randomly\n  how to efficiently extract information from hybrid                                                   generate several synonymous variants).\n  long documents with llms.\nZhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya   A.3  Experiment Settings\n  Goyal, and Danqi Chen. 2023.  Evaluating large                                         To fairly compare the performance of different\n  language models at evaluating instruction following.\n                                                methods, we make appropriate modifications to the  arXiv preprint arXiv:2310.07641.\n                                                            official code to ensure that the number of prompt\nNingyu Zhang, Luoqiu Li, Xiang Chen, Shumin Deng,   searches for each method is roughly the same.\n  Zhen Bi, Chuanqi Tan, Fei Huang, and Huajun\n                                                        Specifically, for the APO method, we set the can-  Chen. 2021. Differentiable prompt makes pre-trained\n  language models better few-shot learners.  arXiv    didate set size to 5, with each prompt generating 5\n   preprint arXiv:2108.13161.                       improved versions and 10 synonymous variants per\n\nTask                           Train   Eval   Test\n                                                       timization, and cross-rewriting. In this stage, each\n Big-Bench Hard\n Logical deduction five objects       50     50    200    prompt requires about 14 API calls. When using\n Movie recommendation            50     50    200     the UCB bandits algorithm for filtering, the number\n Causal judgement                50     50    137                                                     of API calls is P ×R×|S|, where P is the number\n Snarks                         50     50    128\n Salient translation error detection    50     50    200     of prompts generated in each round, R is the num-\n General NLU                                       ber of evaluation rounds, and |S| is the number of\n SST-5                         100    400   1450    samples. In the evaluation stage, each candidate\n TREC                         100    300   1384    prompt needs to be tested on the validation set, so\n Domain Knowledge                                   the total number of calls is C × |E|, where C is\n MEDQA                       100    300   1173\n                                                     the number of candidate prompts retained in each MEDMCQA                    100    400   1500\n                                                  round, and |E| is the size of the validation set.\n Industry Application\n Personal Query Intent             50     50    231       For the estimation of token consumption, we\n                                                      calculate the average length of each meta prompt,\n                Table 7: Data splits.                  optimized prompt, generated strategy, and task data,\n                                            and use these values to estimate the total number         Task              Initial Prompt\n                                                     of tokens L required to generate one prompt in the\n      BBH            Let’s think step by step.\n                                                    generation stage. Therefore, the token consumption\n        SST-5           Select the most accurate emo-\n                                                       in the generation stage is L × N, where N is the                            tion description from the op-\n                              tions.                              total search size. In the filtering and evaluation\n          Trec            Select the most appropriate       stages, all operations are tested based on task data,\n                         type of answer from options.       so the token consumption of these steps is (P ×\n MedQA / MedMCQA   Please use your domain knowl-   R × |S|) × (Lprompt + Ldata). By determining the\n                       edge in medical area to solve       total number of steps, we can estimate the total\n                           the questions.\n                                                token consumption in the filtering and evaluation\n                                                        stages.              Table 8: Initial prompts.\n\n                           C  Detailed Results of BBH\niteration. For OPRO, we set the expansion size to                                                 Table 10 presents the overall performance compar-\n10. For EvoPrompt, the initial setting is 15 prompts,                                                   ison of all methods on GPT-3.5-turbo and GPT-4.\ngenerating 30 prompts per iteration. To reduce API                                                This table clearly demonstrates that STRAGO out-\nusage, we use the UCB Bandits algorithm for pre-                                               performs other methods across all tasks. Table 11\nliminary screening and retain the top 15 offspring                                                         details the modifications each method underwent\nwith the highest evaluation scores. This part of                                                        in 5 BBH tasks, where both ACR and BCR are cal-\nthe code references the official implementations                                                   culated based on CoT. The data reveal that in 4/5\nof Pryzant et al. (2023) 2, Yang et al. (2023)3 and                                                          tasks, STRAGO not only corrected the most errors\nGuo et al. (2023)4. STRAGO generates 5 prompts                                                   but also made the fewest incorrect changes. Al-\nper round and creates 1 synonymous variant for                                              though STRAGO’s performance slightly declines\neach memory-based prompt. Detailed parameter                                           on GPT-3.5-turbo, its highest BCR or lowest ACR\nconfigurations are provided in Table 9.                                            on this model still underscores STRAGO’s superior\n                                                 performance.B  Cost Estimate\nWe refer to the method of Guo et al. (2023) for cost  D  Meta Prompts\nestimation. Overall, we divide the entire frame-                                We present all meta prompts used in STRAGO in\nwork into three stages: generation, filtering, and                                                  Tables 12 to 18\nevaluation. For the estimation of API calls, taking\nSTRAGO as an example, the generation stage in-  E  Prompt Optimization Results\ncludes operations such as analyzing experiences,\n                                We present all prompt optimized by STRAGO onformulating strategies, strategy scoring, strategy op-\n                                                 Table 19 and 20.\n   2https://github.com/microsoft/LMOps/tree/main/\nprompt_optimization\n   3https://github.com/google-deepmind/opro\n   4https://github.com/beeevita/EvoPrompt\n\nOfficial Search Strategy            Prompt Updating              Our Experiments Settings\n     Methods\n                       Initial  Expansion   Candidates   Total                           Initial  Expansion   Candidates   Total   Total\n                                                               Method Type\n                     size     size per step    size per step    Steps                         size     size per step    size per step    Steps   Search\n\n    APO           1      |Pt−1| × 12        4         6       Explicit Reflection      1      |Pt−1| × 15        5         5      315\n\n    OPRO         1          8        −        200      Implicit Reflection      1         10       −         31     310\n\n      EvoPrompt     10         10           10        10     Evolution Algorithm     15         30           15        10     300\n\n     StraGo               -               -                   -               -       Explicit Reflection      1      |Pt−1| × 10        5         7      310\n\n                                   Table 9: Detailed parameter settings.\n\n\n\n\n\nFigure 3: Left side: Distribution of data length in the training and test sets; Right side: Number of data entries in\neach length interval for the training and test sets.\n\n\n\n\n\n             Method  Logic Dec. Movie Rec. Casual Jud. Snarks Salient Trans. Avg.\n\n             CoT      39.50       58.5        61.31     76.56      46.00     56.37\n            APO      50.50      60.00       64.96     77.34      47.00     59.96\n      GPT-3.5\n           OPRO      48.5       61.50       63.50     78.90      46.50     59.78\n        -turbo\n             EvoPrompt   47.50      61.00       64.23     78.12      47.50     59.67\n           STRAGO    52.00       62.5        66.42     79.69      48.50     61.82\n\n             CoT      70.00      70.50       69.34     82.81      54.50     69.43\n            APO      81.50      78.50       70.07     85.94      66.50     76.50\n      GPT-4   OPRO     82.00      78.50       72.26     86.72      67.50     77.40\n             EvoPrompt   80.00      76.00       70.80     83.59      67.00     75.48\n           STRAGO    83.00      81.00       74.45     91.41      69.00     79.77\n\n\nTable 10: The results of GPT-3.5-turbo and GPT-4 on 5 tasks from BBH, with the highest accuracy results highlighted\nin bold.\n\nLogic Dec.   Movie Rec.   Casual Jud.     Snarks     Salient Trans.\n Model    Method\n                 ACR  BCR  ACR  BCR  ACR  BCR  ACR  BCR  ACR   BCR\n\n         APO     32.91  39.67  11.97  20.48  26.19  50.94  13.27  46.67  15.22   14.81\n GPT-3.5   OPRO    35.44  37.19  12.82  25.30  20.24  37.74  15.31  60.00  10.87   10.19\n  -turbo   EvoPrompt  37.97  38.02  10.26  20.48  23.81  45.28  14.29  53.33  15.22   15.74\n         STRAGO   26.58  38.02  11.11  25.30  21.43  47.17  12.24  53.33  14.13   16.67\n\n         APO     12.14  66.67   2.84   33.90  11.58  28.57   2.83   31.82   5.50   34.07\n         OPRO    13.57  71.67   3.55   35.59  10.53  33.33   2.83   36.36   7.34   34.07\n GPT-4\n         EvoPrompt  12.86  55.88   4.96   30.51  13.68  35.71   4.72   27.27   7.34   32.97\n         STRAGO   10.00  66.67   1.42   38.98   5.26   28.57   1.89   59.09   5.50   42.86\n\n\nTable 11: Comparative performance of different optimization methods on 5 BBH tasks, measured in terms of ACR\nand BCR. A single underline denotes the lowest ACR, while a double underline indicates the highest BCR.\n\n\n\n\n\nAs a logician, you are good at breaking down the internal logic of the problem step by step.\n\n<prompt>{{prompt}}</prompt>\n<examples>{{examples}}</examples>\n\nI have provided you with a prompt and several examples that include triples of questions, actual answers,\nand reference answers. Your task is to summarize the {{num}} most valuable key points to improve your\naccuracy in solving this type of task.\n\n\n                                  Table 12: Collect positive experiences.\n\n\n\n\n\nAs a logician, you are good at breaking down the internal logic of the problem step by step.\n\n<prompt>{{prompt}}</prompt>\n<examples>{{examples}}</examples>\n\nI have provided you with a prompt and several examples that include triples of questions, wrong answers,\nand reference answers. Your task is to identify {{num}} primary reasons why the prompt causes these\nwrong answers.\n\n\n                                  Table 13: Collect negative experiences.\n\nAs an experienced prompt engineering expert, your task is to evaluate a proposed strategy based on a\nspecific experience. Rate the strategy for its appropriateness, clarity, and effectiveness in addressing the\nexperience.\n\n# Experience\n<experience>{{experience}}</experience>\n\n# Strategy\n<strategy>{{strategy}}</strategy>\n# Rating Criteria\n1. Match with Experience(M): The strategy should be directly aimed at mitigating the issue described in\nthe experience. A perfect alignment where the strategy completely addresses the experience issue scores\n100 points, whereas a poor match scores lower, depending on how well it addresses the problem.\n2. Clarity of Strategy(C): The strategy must be explained clearly and in detail. A strategy that is easy to\nunderstand and can be practically implemented by any teacher scores 100 points, while a strategy that is\npoorly described scores less or 0.\n3. Effectiveness in Addressing the Issue(E): Consider how comprehensively the strategy deals with\npreventing errors and promoting understanding in steps. A strategy that effectively addresses both what\nshould do and what should avoid to minimize errors scores 100 points. A strategy that partially addresses\nthese aspects scores less.\n\nWe asked 5 experts to rate the strategy. Each expert evaluate the strategy independently.\n\n# Output Format: [{’M’: 78, ’C’: 85, ’E’: 90}, {’M’:45,...]\n\n# Output [{\n\n\n                                            Table 14: Score.\n\n\n\n\n\n# Instruction-Score\n{{instruction_score}}\n\nMutate the following instruction reference [# Instruction-Score] and generate a better instruction.\n\n{{instruction}}\n\nNew instruction:\n\n\n                                          Table 15: Paraphrase.\n\nAs an expert in prompt engineer, your task is to create a step-by-step strategy guide on how to use specific\nexperience based on provided prompt.\n\n# Begin Demos\n<demo>\n<prompt>read the given paragraph and identify the most logical answer among the options.</prompt>\n\n<example>\nquestion: The following paragraphs each describe a set of five objects arranged in a fixed order. The\nstatements are logically consistent within each paragraph. In a golf tournament, there were five golfers:\nEve, Amy, Ada, Rob, and Joe. Amy finished second-to-last. Rob finished below Eve. Ada finished above\nJoe. Joe finished second.\nOptions:\n(A) Eve finished last\n(B) Amy finished last\n(C) Ada finished last\n(D) Rob finished last\n(E) Joe finished last\nAnswer: (B) Amy finished last\nTarget: (D) Rob finished last\n</example>\n\n<experience> One primary reason mistakes occur in this task is due to misunderstanding or\nmisinterpretation of the logical order and relationships presented in the paragraphs </experience>\n\n<strategy>\nHere is a strategy guide how to achieve \"understanding or interpretation of the logical order and\nrelationships\":\n1. Carefully read the entire paragraph to understand the context and the objects or individuals involved.\n2. Identify the logical relationships or orderings described in the paragraph.\n3. Create a visual aid such as a list or a diagram. Place the objects or individuals from left to right based\non the logical relationships. The leftmost object or individual would be the first in the order and the\nrightmost would be the last.\n4. As you read each relationship, adjust the positions of the objects or individuals in your visual aid\naccordingly.\n5. Once all relationships have been considered, your visual aid should represent the correct order of the\nobjects or individuals.\n</strategy>\n</demo>\n\n{additional demos}\n# End Demos\n\nMy current prompt is:\n<prompt>{{prompt}}</prompt>\n\nAnd here is the task data:\n<example>{{example}}</example>\n\nThrough comprehensive analysis of the data, I’ve gained an experience that can improve the prompt:\n<experience>{{experience}}</experience>\n\nBased on my current prompt, please generate a strategy to address the above experience.\nThe strategy is:\n\n\n                                       Table 16: Generate strategy.\n\nMy current instruction is:\n<prompt>{{prompt}}</prompt>\n\nAnd Here are some task data:\n<example>{{example}}</example>\n\nThrough comprehensive analysis of the data, I get a experience and corresponding strategy:\n\n# Experience\n<experience>experience</experience>\n# Strategy\n<strategy>{{strategy}}</strategy>\n\nBased on my current prompt, refer to this experience and the strategy, write 1 different improved prompt.\nThe improved prompt is:\n\n\n                                           Table 17: Optimize.\n\n\n\n\nAs an experienced instruction writer, your task is to carefully analyze the provided task cases and\ninstructions in order to generate an improved instruction that will guide an AI system to solve the task\nmore effectively.\n\n# Task Cases\nThe task cases and instructions can be found below:\n{{examples}}\n# Instruction 1\n{{prompt1}}\n# Instruction 2\n{{prompt2}}\n\nPlease use the following step-by-step process:\n- Step 1: Review the task cases to understand the key objectives and requirements that the instruction\nneeds to address.\n- Step 2: Analyze Instruction 1 and identify its strengths and weaknesses in terms of guiding the AI\nsystem to solve the task.\n- Step 3: Perform the same analysis on Instruction 2.\n- Step 4: Determine how to best combine the strengths of the two instructions while addressing their\nindividual weaknesses.\n- Step 5: Write an improved, combined instruction that incorporates the insights from the previous steps.\nThe instruction should provide clear guidance for the AI system to solve the task based on the given task\ncases.\n- Step 6: Output the improved instruction surrounded by XML tags as follows:\n<instruction>\nYour improved instruction goes here.\n</instruction>\n\n\n                                          Table 18: Crossover.\n\nTable 19: Results on GPT-4.\n\n\nTask                         Prompt\n\n                                              Let´s approach this problem logically and systematically. Begin by reading the question and the provided statements\n                                       carefully to understand the order of the objects. Identify the crucial information from each statement, such as the\nlogical_deduction_five_objects       age or position of each object relative to the others. Use this information to construct a preliminary sequence. Then,\n                                         refine this sequence based on the given relationships. Ensure the final sequence is in line with all the statements.\n                                          Finally, use this order to answer the question and review your answer to ensure it is logical and consistent with the\n                                    given information. Let´s proceed step by step to avoid any mistakes.\n\n                                 Begin by thoroughly understanding the question and the list of movies it provides. Look for common factors like\n                                   themes, genres, actors, directors, or the time period they were made in. Proceed to meticulously evaluate each\nmovie_recommendation              option in light of these common elements. Make a well-informed choice and pick the movie that most closely\n                                  matches these elements.\n\n                                             Let´s dissect the situation in a systematic manner, identifying crucial actions and their subsequent effects, to\ncasual_judgement\n                                comprehend the causation and arrive at a logical conclusion.\n\n                                         Start by meticulously reading the question and all the options to fully comprehend the context. Bear in mind that\nsnarks\n                                   sarcasm typically involves irony or exaggeration and often presents a situation that contradicts common expectations.\n                                 Hence, examine the tone and the implicit meaning of each statement. Search for any overstatements or unlikely\n                                       scenarios in the statements. The statement that seems to convey the opposite of what is logically expected or appears\n                                     exaggerated is most likely the sarcastic one. Compare all the options, and choose the one that best embodies sarcasm.\n                                    After selecting, take a moment to reassess your choice to ensure it accurately pinpoints the sarcastic statement.\n                               Remember, a good understanding of the subject matter can significantly assist in identifying sarcasm, so take into\n                                   account the topic context while making your decision.\n\n                                Begin by gaining a thorough understanding of each error category: named entities, numerical values, modifiers\n                                     or adjectives, negation or antonyms, factual errors, and dropped content. Next, meticulously read the source and\nsalient_translation_error_detection    translated text, comparing them to identify any discrepancies. Focus on differences in named entities, numerical\n                                       values, modifiers or adjectives, negation or antonyms, and facts. Based on these discrepancies, identify the type\n                                     of error and select the corresponding option from the given choices. Remember, the key to accurately identifying\n                                      the error lies in the details, so be thorough in your examination of each element of the text. After identifying the\n                                           error, review the content again to ensure no other errors have been missed. If a mistake is found, take the time to\n                                     understand why it occurred and use this knowledge to avoid similar errors in the future. Repeat this process for each\n                                     question to ensure consistent accuracy and improvement in task performance.\n\n                                          Start by thoroughly examining the given text, keeping a keen eye on the overall tone and context, as well as specific\n                                  language or expressions that suggest sentiment. Recognize positive sentiment through the presence of words or\nSST-5                              phrases that indicate approval, satisfaction, or happiness; identify negative sentiment through signs of criticism,\n                                     unhappiness, or disapproval; and discern neutral sentiment through impartial or unemotional language. Evaluate the\n                                         intensity of the sentiment, noting that words like ’extremely’, ’highly’, or ’remarkably’ can amplify the sentiment.\n                            Be mindful of cultural nuances and language subtleties that could influence the sentiment. After your detailed\n                                         analysis, select the sentiment description from the provided options that most accurately matches your assessment.\n                                  Ensure to maintain objectivity and make sure your choice accurately reflects the sentiment present in the text. Once\n                                    chosen, reassess the text and your selection to confirm there’s no misinterpretation or overlooked details.\n\n                                  For each question presented, your task is to dissect it and identify the type of answer it demands. You should\n                                       categorize the expected answer into one of these six classifications: (A) Description and abstract concept, (B) Entity,\nTREC                             (C) Abbreviation, (D) Human being, (E) Location, or (F) Numeric value. To do this, clarify the main point of the\n                                      question, focus on its keywords or key phrases, and judiciously examine what kind of response it seeks. Each\n                                    category signifies a specific nature of response. For clarification, (A) Description and abstract concept refers to\n                                       explanations, meanings or theories; (B) Entity pertains to organizations, objects or events; (C) Abbreviation denotes\n                                 acronyms or initials; (D) Human being means names of individuals; (E) Location signifies places; and (F) Numeric\n                                    value is for numbers, dates or quantities. Your categorization should be based on the type of answer that would\n                                     optimally satisfy the query. Elaborate on your observation skills and understanding of the question along with the\n                                       categories to get the correct answer.\n\n                                            Firstly, read the question carefully to understand the patient’s medical scenario, paying attention to the patient’s\n                                  medical history, symptoms, and test results. Secondly, apply logical analysis to eliminate options that clearly\nMedQA                        do not align with the given scenario. Thirdly, use your comprehensive understanding of medical terminologies,\n                                     procedures, and protocols to interpret the medical information provided in the question. Fourthly, employ your\n                                   medical knowledge and critical thinking to further narrow down the options, considering less obvious connections\n                                 between symptoms and diseases. Finally, compare the details in the question with the options provided and select\n                                       the most appropriate answer that represents the best course of action or the most likely diagnosis or treatment based\n                               on the comparison. Output the selected answer.\n\n                             As a medical professional, your deep comprehension of medical terminologies and principles is paramount for this\n                                          task. You will come across several multiple-choice questions related to different medical conditions and scenarios.\nMedMcQA                     To answer these questions correctly, you need to scrutinize each question and every option carefully, using your\n                                  medical knowledge to identify and eliminate incorrect options. In cases where you encounter unfamiliar medical\n                                   terms or situations, rigorous research is advisable. Keep in mind that the devil is in the details and often, medical\n                                     questions may contain very specific or nuanced details that could be easily overlooked. As part of a continuous\n                                      learning approach, remember to learn from your past mistakes and apply the lessons to future, unseen medical\n                                         situations. Regular practice and consistent review of both the mistakes and successful attempts will aid your\n                                    understanding of medical terminologies and principles drastically. To reduce the scope of errors, take a moment to\n                                     re-check your answers against any established medical guidelines and principles before submitting them\n\nTable 20: Results on GPT-3.5-turbo.\n\n\nTask                         Prompt\n\n                                Begin by thoroughly examining the problem statement, paying attention to the context and the involved parties.\n                                        Identify any relationships or sequences mentioned and document them. Use a diagram or list to help visualize and\nlogical_deduction_five_objects        structure this data, arranging the parties in the order provided. Once the correct sequence is established, examine\n                                   each alternative in relation to your determined order or relationships. Select the alternative that best aligns with the\n                                    given information. Finally, confirm your solution by reviewing your logic and work, making sure no details have\n                                 been overlooked or mistakes made.\n\n                                            Initiate the process by performing an exhaustive examination of the movies given in the task, identifying shared\n                                       features like genre, themes, directorial approach, cast, and time of release. Use these noted commonalities as a\nmovie_recommendation               yardstick for evaluating your choices. If you find any options that you’re not well-acquainted with, take a moment\n                                        to briefly research these movies to grasp their genre, theme, and other vital characteristics. Choose the film that\n                                        aligns most closely with the shared elements identified in the provided movies. Having a comprehensive knowledge\n                                      of a vast range of films and the film industry will prove beneficial in this task. Conclude by revisiting your chosen\n                                 answer to ascertain that it logically corresponds with the detected shared features from the initial list of movies.\n\n                                 Begin by thoroughly analyzing the scenario provided in the question, paying close attention to the actions of the\ncasual_judgement\n                                       individuals involved. Identify the action or event that is being questioned as the potential cause and the subsequent\n                                    event or result as the effect. Trace the sequence of actions that led to this outcome and evaluate if these actions\n                                          directly resulted in the outcome. Assess if the identified cause is both necessary and sufficient for the effect to occur.\n                                Based on your comprehensive analysis, select the option that accurately answers the question.\n\n                                  Thoroughly examine the question and the given statements, grasping the context and searching for any inconsistency\nsnarks\n                                     or contradiction. Assess the tone of each statement, keeping in mind that sarcasm typically exhibits a mocking,\n                                          ironic, or overstated tone. Contrast the options and utilize these observations to judiciously determine which\n                                     statement is sarcastic.\n\n                                Begin by gaining a thorough understanding of each error category: named entities, numerical values, modifiers\n                                     or adjectives, negation or antonyms, factual errors, and dropped content. Next, meticulously read the source and\nsalient_translation_error_detection    translated text, comparing them to identify any discrepancies. Focus on differences in named entities, numerical\n                                        values, modifiers or adjectives, negation or antonyms, and facts. Based on these discrepancies, identify the type of\n                                        error and select the corresponding option from the given choices.",
"headers": [
"arXiv:2410.08601v1  [cs.CL]  11 Oct 2024",
"StraGo: Harnessing Strategic Guidance for Prompt Optimization"
],
"tables": [
"|Col1|Col2|Col3|Col4|1. Read the prompt and the entire question carefully …<br>n-t z e1 2 bh e n gIe . . eea f qa AR td l up t n-hy h ee 2 brn gt eIz eoh sa f. ea e q med il qA t n- -y u h ot up t phn gz I Ie nh er tef fea ’s oe s q at al t …q t m t iy h u sp n ih ou o kz e er dp e ne neo s t :qs tq t m 'th aita Iu wh u oi ssenp oee e n k d sit n se ts q t at:a n i t i a u 'o shn iIot wsk sie sned n kr s sh e i: i e at t t o tn 'ih In s wq ho a gs ke it u en s shi si fekre ': t ao ,oe s 'n i I nw a tn rt istq hi ss si g o ha wu ekr i ' , te n o fe i d a etn o asq hec i n rgs rt s su eai s k i' o ca, r swfe i ae r on tns d unih efrt pgueci ssr eo a t us wa l f iil n ac or aso dy ee nr lnr e c ui r lf s …p saua sw.ict . r usl .i 'del r e o ay uief r lpnu us s l… it yucl ms.il . or a y . 'ui aHlnp ls n… yt uu. i . bmo a. 'H eln al iu y nn. m. . 'H ’au nm 8a 2n 8787<br>’ i ’ t i s h o ' , y H g 87<br>- If …- If …|Col6|Col7|Col8|Col9|Col10|Col11|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n|1<br>2|1<br>2|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|1.<br>2. A<br> <br>bei<br> <br>. Read<br>. Analy<br>- If th<br>- If …|\n|1<br>2|1.<br>2.|<br> <br> <br> <br>1. B<br>2. T<br> Begin<br> Try to|<br> <br> <br> <br>1. B<br>2. T<br> Begin<br> Try to|1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given<br>question try to derive it from the wording and structure of the questi<br>1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given in th<br> <br>  …<br> egin by closely reading the question …<br> ry to understand the context. If there\\'s no evident context given in the<br>  by closely reading the question …<br>   understand the context. If there\\'s no evident context given in the|1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given<br>question try to derive it from the wording and structure of the questi<br>1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given in th<br> <br>  …<br> egin by closely reading the question …<br> ry to understand the context. If there\\'s no evident context given in the<br>  by closely reading the question …<br>   understand the context. If there\\'s no evident context given in the|1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given<br>question try to derive it from the wording and structure of the questi<br>1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given in th<br> <br>  …<br> egin by closely reading the question …<br> ry to understand the context. If there\\'s no evident context given in the<br>  by closely reading the question …<br>   understand the context. If there\\'s no evident context given in the|1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given<br>question try to derive it from the wording and structure of the questi<br>1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given in th<br> <br>  …<br> egin by closely reading the question …<br> ry to understand the context. If there\\'s no evident context given in the<br>  by closely reading the question …<br>   understand the context. If there\\'s no evident context given in the|1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given<br>question try to derive it from the wording and structure of the questi<br>1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given in th<br> <br>  …<br> egin by closely reading the question …<br> ry to understand the context. If there\\'s no evident context given in the<br>  by closely reading the question …<br>   understand the context. If there\\'s no evident context given in the|1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given<br>question try to derive it from the wording and structure of the questi<br>1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given in th<br> <br>  …<br> egin by closely reading the question …<br> ry to understand the context. If there\\'s no evident context given in the<br>  by closely reading the question …<br>   understand the context. If there\\'s no evident context given in the|1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given<br>question try to derive it from the wording and structure of the questi<br>1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given in th<br> <br>  …<br> egin by closely reading the question …<br> ry to understand the context. If there\\'s no evident context given in the<br>  by closely reading the question …<br>   understand the context. If there\\'s no evident context given in the|in the<br>            on.<br>          ng the<br>             e<br>           he|\n|1<br>2|1.<br>2.|<br> <br> <br> <br>1. B<br>2. T<br> Begin<br> Try to|<br> <br> <br> <br>1. B<br>2. T<br> Begin<br> Try to|1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given<br>question try to derive it from the wording and structure of the questi<br>1. Begin by closely reading the question …<br>2. Try to understand the context. If there\\'s no evident context given in th<br> <br>  …<br> egin by closely reading the question …<br> ry to understand the context. If there\\'s no evident context given in the<br>  by closely reading the question …<br>   understand the context. If there\\'s no evident context given in the|<br>stion try to deri<br>   understand the<br> <br>   derstand the con<br>   nd the context.|<br>   ve it f<br>     conte<br> <br>     text.<br>      If the|<br>     ro<br>     xt.<br> <br>      If t<br>       re\\|<br>     m the<br>      If the<br> <br>       here\\'s<br>       's no e|<br>       ording and structure of th<br>       re\\'s no evident context giv<br> <br>        no evident context given i<br>         vident context given in the|<br>           e questi<br>           en in th<br> <br>            n the<br>|<br>           e questi<br>           en in th<br> <br>            n the<br>|\n|1<br>2|qu<br>R|<br> <br> <br>est<br>d|<br> <br> <br>ques<br> <br>ion,<br>|<br>Rea<br>question<br>Reading<br> <br>tion, try<br> <br> try to d<br> h|,<br>ding the question multiple times can often be helpful in uncoveri<br>, try to derive it from the wording and structure of the question.<br> the question multiple times can often be helpful in uncovering t<br> <br>  to derive it from the wording and structure of the question.<br> <br>   erive it from the wording and structure of the question.<br>  ti ltil ti  ft b hlfl i i th|,<br>ding the question multiple times can often be helpful in uncoveri<br>, try to derive it from the wording and structure of the question.<br> the question multiple times can often be helpful in uncovering t<br> <br>  to derive it from the wording and structure of the question.<br> <br>   erive it from the wording and structure of the question.<br>  ti ltil ti  ft b hlfl i i th|,<br>ding the question multiple times can often be helpful in uncoveri<br>, try to derive it from the wording and structure of the question.<br> the question multiple times can often be helpful in uncovering t<br> <br>  to derive it from the wording and structure of the question.<br> <br>   erive it from the wording and structure of the question.<br>  ti ltil ti  ft b hlfl i i th|,<br>ding the question multiple times can often be helpful in uncoveri<br>, try to derive it from the wording and structure of the question.<br> the question multiple times can often be helpful in uncovering t<br> <br>  to derive it from the wording and structure of the question.<br> <br>   erive it from the wording and structure of the question.<br>  ti ltil ti  ft b hlfl i i th|,<br>ding the question multiple times can often be helpful in uncoveri<br>, try to derive it from the wording and structure of the question.<br> the question multiple times can often be helpful in uncovering t<br> <br>  to derive it from the wording and structure of the question.<br> <br>   erive it from the wording and structure of the question.<br>  ti ltil ti  ft b hlfl i i th|,<br>ding the question multiple times can often be helpful in uncoveri<br>, try to derive it from the wording and structure of the question.<br> the question multiple times can often be helpful in uncovering t<br> <br>  to derive it from the wording and structure of the question.<br> <br>   erive it from the wording and structure of the question.<br>  ti ltil ti  ft b hlfl i i th|,<br>ding the question multiple times can often be helpful in uncoveri<br>, try to derive it from the wording and structure of the question.<br> the question multiple times can often be helpful in uncovering t<br> <br>  to derive it from the wording and structure of the question.<br> <br>   erive it from the wording and structure of the question.<br>  ti ltil ti  ft b hlfl i i th|\n|1<br>2|<br>co<br>3|<br><br> <br>a<br>nte<br>|<br><br> <br>Rea<br>cont<br> <br>ng<br>xt.|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|<br>**82**<br>          g the<br>**7**<br>|**82**<br>**82**<br>|\n|1<br>2|<br>co<br>3|<br><br> <br>a<br>nte<br>|<br><br> <br>Rea<br>cont<br> <br>ng<br>xt.|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|context.<br>3. …<br> <br>context.<br>3. …<br>ing the question multiple times can often be helpful in uncoverin<br>ext.<br> <br>**8**<br> e queson mupe mes can oen e epu n uncoverng|<br>**82**<br>          g the<br>**7**<br>||",
"|Methods|Official Search Strategy|Col3|Col4|Col5|Prompt Updating|Our Experiments Settings|Col8|Col9|Col10|Col11|\n|---|---|---|---|---|---|---|---|---|---|---|\n|**Methods**|Initial<br>size|Expansion<br>size per step|Candidates<br>size per step|Total<br>Steps|Method Type|Initial<br>size|Expansion<br>size per step|Candidates<br>size per step|Total<br>Steps|Total<br>Search|\n|**APO**<br>**OPRO**<br>**EvoPrompt**<br>**StraGo**|1<br>1<br>10<br>-|_|Pt−_1_| ×_ 12<br>8<br>10<br>-|4<br>_−_<br>10<br>-|6<br>200<br>10<br>-|Explicit Reflection<br>Implicit Reflection<br>Evolution Algorithm<br>Explicit Reflection|1<br>1<br>15<br>1|_|Pt−_1_| ×_ 15<br>10<br>30<br>_|Pt−_1_| ×_ 10|5<br>_−_<br>15<br>5|5<br>31<br>10<br>7|315<br>310<br>300<br>310|",
"|Task|Prompt|\n|---|---|",
"|logical deduction fvie objects<br>_ _ _|Lets´ approach this problem logically and systematically. Begin by reading the question and the provided statements<br>carefully to understand the order of the objects. Identify the crucial information from each statement, such as the<br>age or position of each object relative to the others. Use this information to construct a preliminary sequence. Then,<br>refine this sequence based on the given relationships. Ensure the final sequence is in line with all the statements.<br>Finally, use this order to answer the question and review your answer to ensure it is logical and consistent with the<br>given information. Lets´ proceed step by step to avoid any mistakes.|\n|---|---|",
"|movie recommendation<br>_|Begin by thoroughly understanding the question and the list of movies it provides. Look for common factors like<br>themes, genres, actors, directors, or the time period they were made in. Proceed to meticulously evaluate each<br>option in light of these common elements. Make a well-informed choice and pick the movie that most closely<br>matches these elements.|\n|---|---|",
"|casual judgement<br>_|Lets´ dissect the situation in a systematic manner, identifying crucial actions and their subsequent effects, to<br>comprehend the causation and arrive at a logical conclusion.|\n|---|---|",
"|snarks|Start by meticulously reading the question and all the options to fully comprehend the context. Bear in mind that<br>sarcasm typically involves irony or exaggeration and often presents a situation that contradicts common expectations.<br>Hence, examine the tone and the implicit meaning of each statement. Search for any overstatements or unlikely<br>scenarios in the statements. The statement that seems to convey the opposite of what is logically expected or appears<br>exaggerated is most likely the sarcastic one. Compare all the options, and choose the one that best embodies sarcasm.<br>After selecting, take a moment to reassess your choice to ensure it accurately pinpoints the sarcastic statement.<br>Remember, a good understanding of the subject matter can significantly assist in identifying sarcasm, so take into<br>account the topic context while making your decision.|\n|---|---|",
"|salient translation error detection<br>_ _ _|Begin by gaining a thorough understanding of each error category: named entities, numerical values, modifiers<br>or adjectives, negation or antonyms, factual errors, and dropped content. Next, meticulously read the source and<br>translated text, comparing them to identify any discrepancies. Focus on differences in named entities, numerical<br>values, modifiers or adjectives, negation or antonyms, and facts. Based on these discrepancies, identify the type<br>of error and select the corresponding option from the given choices. Remember, the key to accurately identifying<br>the error lies in the details, so be thorough in your examination of each element of the text. After identifying the<br>error, review the content again to ensure no other errors have been missed. If a mistake is found, take the time to<br>understand why it occurred and use this knowledge to avoid similar errors in the future. Repeat this process for each<br>question to ensure consistent accuracy and improvement in task performance.|\n|---|---|",
"|SST-5|Start by thoroughly examining the given text, keeping a keen eye on the overall tone and context, as well as specific<br>language or expressions that suggest sentiment. Recognize positive sentiment through the presence of words or<br>phrases that indicate approval, satisfaction, or happiness; identify negative sentiment through signs of criticism,<br>unhappiness, or disapproval; and discern neutral sentiment through impartial or unemotional language. Evaluate the<br>intensity of the sentiment, noting that words like ’extremely’, ’highly’, or ’remarkably’ can amplify the sentiment.<br>Be mindful of cultural nuances and language subtleties that could influence the sentiment. After your detailed<br>analysis, select the sentiment description from the provided options that most accurately matches your assessment.<br>Ensure to maintain objectivity and make sure your choice accurately reflects the sentiment present in the text. Once<br>chosen, reassess the text and your selection to confirm there’s no misinterpretation or overlooked details.|\n|---|---|",
"|TREC|For each question presented, your task is to dissect it and identify the type of answer it demands. You should<br>categorize the expected answer into one of these six classifications: (A) Description and abstract concept, (B) Entity,<br>(C) Abbreviation, (D) Human being, (E) Location, or (F) Numeric value. To do this, clarify the main point of the<br>question, focus on its keywords or key phrases, and judiciously examine what kind of response it seeks. Each<br>category signifies a specific nature of response. For clarification, (A) Description and abstract concept refers to<br>explanations, meanings or theories; (B) Entity pertains to organizations, objects or events; (C) Abbreviation denotes<br>acronyms or initials; (D) Human being means names of individuals; (E) Location signifies places; and (F) Numeric<br>value is for numbers, dates or quantities. Your categorization should be based on the type of answer that would<br>optimally satisfy the query. Elaborate on your observation skills and understanding of the question along with the<br>categories to get the correct answer.|\n|---|---|",
"|MedQA|Firstly, read the question carefully to understand the patient’s medical scenario, paying attention to the patient’s<br>medical history, symptoms, and test results. Secondly, apply logical analysis to eliminate options that clearly<br>do not align with the given scenario. Thirdly, use your comprehensive understanding of medical terminologies,<br>procedures, and protocols to interpret the medical information provided in the question. Fourthly, employ your<br>medical knowledge and critical thinking to further narrow down the options, considering less obvious connections<br>between symptoms and diseases. Finally, compare the details in the question with the options provided and select<br>the most appropriate answer that represents the best course of action or the most likely diagnosis or treatment based<br>on the comparison. Output the selected answer.|\n|---|---|",
"|MedMcQA|As a medical professional, your deep comprehension of medical terminologies and principles is paramount for this<br>task. You will come across several multiple-choice questions related to different medical conditions and scenarios.<br>To answer these questions correctly, you need to scrutinize each question and every option carefully, using your<br>medical knowledge to identify and eliminate incorrect options. In cases where you encounter unfamiliar medical<br>terms or situations, rigorous research is advisable. Keep in mind that the devil is in the details and often, medical<br>questions may contain very specific or nuanced details that could be easily overlooked. As part of a continuous<br>learning approach, remember to learn from your past mistakes and apply the lessons to future, unseen medical<br>situations. Regular practice and consistent review of both the mistakes and successful attempts will aid your<br>understanding of medical terminologies and principles drastically. To reduce the scope of errors, take a moment to<br>re-check your answers against any established medical guidelines and principles before submitting them|\n|---|---|",
"|Task|Prompt|\n|---|---|",
"|logical deduction fvie objects<br>_ _ _|Begin by thoroughly examining the problem statement, paying attention to the context and the involved parties.<br>Identify any relationships or sequences mentioned and document them. Use a diagram or list to help visualize and<br>structure this data, arranging the parties in the order provided. Once the correct sequence is established, examine<br>each alternative in relation to your determined order or relationships. Select the alternative that best aligns with the<br>given information. Finally, confirm your solution by reviewing your logic and work, making sure no details have<br>been overlooked or mistakes made.|\n|---|---|",
"|movie recommendation<br>_|Initiate the process by performing an exhaustive examination of the movies given in the task, identifying shared<br>features like genre, themes, directorial approach, cast, and time of release. Use these noted commonalities as a<br>yardstick for evaluating your choices. If you find any options that you’re not well-acquainted with, take a moment<br>to briefly research these movies to grasp their genre, theme, and other vital characteristics. Choose the film that<br>aligns most closely with the shared elements identified in the provided movies. Having a comprehensive knowledge<br>of a vast range of films and the film industry will prove beneficial in this task. Conclude by revisiting your chosen<br>answer to ascertain that it logically corresponds with the detected shared features from the initial list of movies.|\n|---|---|",
"|casual judgement<br>_|Begin by thoroughly analyzing the scenario provided in the question, paying close attention to the actions of the<br>individuals involved. Identify the action or event that is being questioned as the potential cause and the subsequent<br>event or result as the effect. Trace the sequence of actions that led to this outcome and evaluate if these actions<br>directly resulted in the outcome. Assess if the identified cause is both necessary and sufficient for the effect to occur.<br>Based on your comprehensive analysis, select the option that accurately answers the question.|\n|---|---|",
"|snarks|Thoroughly examine the question and the given statements, grasping the context and searching for any inconsistency<br>or contradiction. Assess the tone of each statement, keeping in mind that sarcasm typically exhibits a mocking,<br>ironic, or overstated tone. Contrast the options and utilize these observations to judiciously determine which<br>statement is sarcastic.|\n|---|---|",
"|salient translation error detection<br>_ _ _|Begin by gaining a thorough understanding of each error category: named entities, numerical values, modifiers<br>or adjectives, negation or antonyms, factual errors, and dropped content. Next, meticulously read the source and<br>translated text, comparing them to identify any discrepancies. Focus on differences in named entities, numerical<br>values, modifiers or adjectives, negation or antonyms, and facts. Based on these discrepancies, identify the type of<br>error and select the corresponding option from the given choices.|\n|---|---|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2410.08601v1.pdf"
}