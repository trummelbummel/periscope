{
"text": "iPrOp: Interactive Prompt Optimization for\n                  Large Language Models with a Human in the Loop\n\n\n                                       Jiahui Li and Roman Klinger\n                Fundamentals of Natural Language Processing, University of Bamberg, Germany\n                            {jiahui.li,roman.klinger}@uni-bamberg.de\n\n\n\n\n                          Abstract                   prompt brittleness (Ceron et al., 2024). The ques-\n                                                                      tion of how to design a well-crafted prompt has re-               Prompt engineering has made significant con-\n                    tributions to the era of large language mod-       ceived an increasing amount of attention. Although\n                      els, yet its effectiveness depends on the skills        there exists research on analyzing which prompts2025            of a prompt author.  This paper introduces        are more effective for tasks like classification and\n                 iPrOp, a novel interactive prompt optimization       question answering (Liu et al., 2022; Lu et al.,\n                 approach, to bridge manual prompt engineer-                                                            2022; Xu et al., 2022), the need to efficiently iden-Jun            ing and automatic prompt optimization while                                                                            tify high-quality prompts has sparked increased\n                   offering users the flexibility to assess evolv-\n                                                                       attention into automatic prompt optimization (Shin27            ing prompts. We aim to provide users with\n                                                                         et al., 2020; Pryzant et al., 2023). However, they                    task-specific guidance to enhance human en-\n                gagement in the optimization process, which is       tend to overlook the inherent contextuality and the\n                   structured through prompt variations, informa-      domain-dependent nature of prompt engineering\n                     tive instances, predictions generated by large        (Pei et al., 2025; Anthropic, 2024). There is a lack\n                 language models along with their correspond-       of studies that combines user-guided prompt op-[cs.CL]            ing explanations, and relevant performance                                                                 timization with data-driven prompt optimization.\n                   metrics.  This approach empowers users to\n                                                        Given that the user constitutes the ultimate author-\n                choose and further refine the prompts based\n                                                                              ity to develop prompts that satisfy the varying trade-               on their individual preferences and needs.  It\n                can not only assist non-technical domain ex-        offs across different aspects of a specific task, we\n                    perts in generating optimal prompts tailored to       consider this an important research gap.\n                     their specific tasks or domains, but also enable        Combining prompt optimization with a user in\n                    to study the intrinsic parameters that influence        the loop comes with the potential for a more guided\n                   the performance of prompt optimization. The                                                                engineering process, from which any user may ben-\n                   evaluation shows that our approach has the ca-\n                                                                                       efit. Two examples are particularly prominent:\n                     pability to generate improved prompts, leading\n                                                                    (1) Technical laypeople may require help with                    to enhanced task performance.\n                                                        prompt development for dedicated tasks. (2) Man-\n                                                                  ual prompt engineering may lead to biased config-\n          1  Introduction\n                                                                     urations, as generic prompts often fail to capturearXiv:2412.12644v2\n           With the advancement of large language models    the complexities and nuances specific to particular\n           (LLMs), prompt engineering emerged for instruct-   domains, such as medical knowledge (Lu et al.,\n             ing these models to generate responses that align    2023). Prior research has demonstrated the role of\n            with users’ requirements. Prompting allows LLMs   human-in-the-loop methodologies in building ro-\n              to perform user-specified tasks, including tasks in    bust systems across a variety of tasks, including de-\n             previously unseen scenarios or particular domains   bugging text classifiers (Lertvittayakumjorn et al.,\n            (Devlin et al., 2019; Raffel et al., 2020; Mishra    2020), hate speech classification (Kotarcic et al.,\n               et al., 2022).                                      2022), and question answering chatbots (Afzal\n             However, prompt-based natural language pro-    et al., 2024).\n             cessing (NLP) has demonstrated limited robust-     To achieve the goal of supporting users in their\n             ness across domains, instances, or label schemes   prompt development process, we hypothesize that\n              (Plaza-del Arco et al., 2022; Yin et al., 2019; Zhou    a set of prompt properties is important to decide if a\n               et al., 2022). It is also challenging to develop reli-   prompt p is considered better than another prompt\n             able methods for evaluation of LLMs that factor in     p′.  These are (a) the performance of a prompt\n\n5. Pr ompt Optim ization\n\n\n\n\n\n                                               System Answer\n\n\n                                                                                                                           User Input\n\n                    1. Star t/Tr ack a Conver sation\n\n\n\n\n                                                            2. Select a LLM\n\n\n                                                                                         3. Upload Your Dataset                4. Input Text\n\n\n\n\n\n           Figure 1: Screenshot of the iPrOp Web application, where key components are annotated.\n\n\non some annotated data, for instance measured by    niques such as cloze prompts (Cui et al., 2021) and\nF1 (we focus in this paper on text classification    prefix prompts (Li and Liang, 2021), the latter fo-\ntasks); (b) The readability and interpretability of    cuses on manually crafted prompts (Brown et al.,\nthe prompt; (c) The quality of an explanation of   2020) and automated prompt templating processes\nthe predictions of the prompt; and (d), the align-   (Shin et al., 2020). Our work is derived from the lat-\nment of the annotations with the users expectations.    ter case with the addition of human interventions.\nWe therefore propose an interactive prompt opti-     The output of an LLM is influenced by the qual-\nmization approach with a human-in-the-loop that    ity of prompts (Lu et al., 2022). Prompts need to\nconsiders all these aspects. The proposed approach   be adapted to particular domains (Karmaker Santu\nenables studies on the interaction between these   and Feng, 2023; Wei et al., 2021), and for different\nvarious parameters in the spirit of an iterative opti-  LLMs (Chen et al., 2023). Previous work therefore\nmization in which the automatic evaluation of an    attempted to search through paraphrases of prompts\nobjective function is supported by a human. We    (Jiang et al., 2020), by compiling prompts based on\nfurther envision that some decisions may be made    templates and class-triggering tokens (Shin et al.,\nautomatically, while others require the human to    2020), or by learning soft prompts (Qin and Eisner,\ndecide on the prompt quality. Such collaborative    2021). Another approach is to combine gradient de-\ndecision process helps to maintain the high quality    scent method with hard prompts (Wen et al., 2023;\nof the prompts, while limiting the required user   Pryzant et al., 2023). In contrast, our framework\ninteractions to those of particularly high value.       focuses on multiple factors such as task selection,\n  The repository of a prototypical web interface    choice of LLM, and user-provided feedback as ex-\nfor the iPrOp approach and an explanation video    ternal parameters. Further, we exploit the capabil-\nis available at https://www.uni-bamberg.de/    ities of LLMs as prompt engineers (Zhou et al.,\nnlproc/ressourcen/iprop/. Figure 1 presents   2023; Ye et al., 2024; Fernando et al., 2024; Men-\na screenshot of the web-based user interface.        chaca Resendiz and Klinger, 2025).\n\n2  Related Work                                                    2.2  Cooperative Artificial Intelligence\n2.1  Prompt Engineering for LLMs                                                This work is related to the field of cooperative ar-\nPrompt engineering is the process of designing     tificial intelligence, which touches upon topics of\nand optimizing prompts to guide a language model   human-machine interaction and efficient protocols\nfor effective results on a downstream task. Liu    of information exchange, enabling humans to solve\net al.’s (2023) survey categorizes previous works    tasks collaboratively with machines. Such methods\nin prompt shapes and human-designed prompt tem-    also influenced NLP tasks, such as question answer-\nplates. While the former category includes tech-   ing (Benamara and Saint Dizier, 2003), information\n\nHuman-in-the-loop            Workflow                     Simulation\n\n                                                                         1.                                                                               Initial Prompt                   ontological task description                       user-specified prompt\n                                                                                       LLM-generated prompt\n\n                                                                Optimization\n\n                    manual adjustment                     2a.                           prompt rephrasing model                                                      Prompt Update\n\n                 manual assessment based                 2b.                       human behavior prediction                                                     Prompt Evalution\n                  on instances, explanation,                                             by instances, explanation,\n                   performance, readability                                                performance, structure\n\n                                                                         3.\n                                                      Prompt Output\n\n\nFigure 2: The conceptual workflow of our iPrOp approach. The general workflow is shown in the middle. The\nleft part shows potential human interaction in the various modules. To limit the amount of user interactions, each\nmodule can be supported by a simulated interaction.\n\n\nretrieval (Manning et al., 2008), and chatbot inter-   plexity of LLMs. An alternative is to leverage the\nactions (Hancock et al., 2019). More recent papers    inherent explainability of LLMs (Mavrepis et al.,\ndraw their attention on collaborative annotation pro-   2024). Wu et al.’s (2024) analysis of strategies\ncesses and model direct manipulation (Baur et al.,    to enhance the transparency of LLMs. Bills et al.\n2020; Wang et al., 2021). However, we introduce a   (2023) demonstrate that LLMs are able to explain\nhuman-in-the-loop via replacing the automatic eval-   individual neurons in LLMs. This work motivates\nuation of an objective function by a human. Prior   our attempt to prompt LLMs for the explanations\nresearch has explored incorporated human feed-   of their predictions.\nback by presenting users with responses generated\nfrom paired prompts and asking for their prefer-   3  Methods\nences (Lin et al., 2024). In contrast, our framework                                                  Figure 2 visualizes the conceptual workflow of our\noffers a more comprehensive structure, encompass-                                           iPrOp approach. The workflow begins with an ini-\ning a broader range of factors that should be con-                                                                     tial seed prompt and proceeds through iterations of\nsidered during human evaluation.                                              prompt updates and evaluations, led by informative\n                                                 samples, explanations, and data evaluation with\n2.3  Explainable Artificial Intelligence\n                                               performance metrics. To reduce human workload,\nUsers which manually change properties of a sys-   each step can, in principle, be performed either by\ntem benefit from a good understanding of the    the user or automatically.\nmodel’s decisions. This task is approached by ex-    We formalize the process of the workflow as\nplainable artificial intelligence (XAI) techniques    follows. The user is presented prompts in iterations\n(Roscher et al., 2020). One prominent work that   and selects the preferred prompt p∗based on their\nintroduced the interaction between model interven-   assessment H:\ntion and XAI is Teso and Kersting (2019). Another\nstudy combines explanatory interactive machine-         p∗= arg max H(I(pi)),\n                                                        p∈P∪M(P)\nlearning methods with fair machine learning for\nthe bias-mitigation problem (Heidrich et al., 2023).                                                Here, M(P) is a prompt paraphrasing model that\nThey both integrate interpretability methods for ma-                                                       varies the prompts P selected from the previous it-\nchine learning models, such as SHAP (Lundberg                                                          eration. I(pi) is a presentation of prompt properties\nand Lee, 2017), LIME (Ribeiro et al., 2016), and                                                        to the user, which consists of\nAnchors (Ribeiro et al., 2018).\n  Although these tools offer intuitive explanations         I(pi) = (pi, Tαpi , E(Tα, pi), F1(T βpi ))) .\nfor classifiers, their reliance on perturbations makes\nthem computationally expensive to apply to LLMs     The user provides a (potentially small) training\nbecause of the high-dimensional nature and com-    set T for their task, from which we sample two\n\nF1 for GE & TEC             F1 for TE\n             Prompt 1                   Prompt 2\n                                                   0.48                                 0.66\n       Classification task with labels:   Classify the emotion of text\n      joy and sadness.                 into joy and sadness.\n                  Text               Prompt 1     Prompt 2          0.46                                 0.64\n           I like watching TV. (joy)           joy + Exp.      joy + Exp.\n     Work is challenging. (sadness) sadness + Exp.    joy + Exp.\n     The food was fine. (sadness)      joy + Exp.   sadness + Exp.\n                                                   0.44                                 0.62\n                  Performance Metrices (e.g. F1)\n             Prompt 1                   Prompt 2\n                  0.46                           0.53                 0.42                                  0.6\n     Which prompt is better?          Prompt 1     Prompt 2                                         TE        TEC  GE\n                                                                                                                                                  validation          train\n                                                       0.4                                 0.58\n                                                    00       55      1010      1515\n Figure 3: User interface prototype for an emotion analy-\n                                                                               Iterations\n sis example during the interactive prompt optimization\n process. \"Exp.\" refers to explanations for why a specific                                                      Figure 4: F1 scores for three datasets, shown sepa-\n label is predicted by the model.                                                              rately on training and validation data. The abbrevia-\n                                                              tions GE, TEC, and TE correspond to the GROUNDED-\n                                         EMOTIONS (blue), TEC (red), and TALES-EMOTION\n                                                         (green) datasets, respectively. The left violet y-axis\n                                                       corresponds to GROUNDED-EMOTIONS and TEC. The\n subsets Tα ⊆T and Tβ ⊆T according to strate-\n                pi                                               right green y-axis corresponds to TALES-EMOTION.\n gies α, β. T α  consists of instances to be shown to\n the user together with model based explanations\n E(Tα, pi). Tβ serves to calculate an evaluation   4  Evaluation\n               pi\n score F1(T β ) (we focus on text classification tasks                                 We envision our iPrOp approach to enable future\n for simplicity).\n                                                      research on the interaction of the various aspects to\n                                                    consider when humans make preference decisions   This procedure is also visualized in Figure 2.\n                                           on particular prompts under the available infor-The initialization of seed prompts ((1) in Figure 2)\n                                                 mation. To validate the principled feasibility of requires users to describe the task. In simulation\n                                                our approach, we run experiments on three emo- scenarios, this process can be substituted with an\n                                                       tion classification datasets using the llama3.1:8b- ontological task description or prompts generated\n                                                      instruct-fp16 model1 (Dubey et al., 2024). In this automatically by LLMs. Subsequently, the initial\n                                                  experiment, we only consider automated classifi- prompts are passed to the optimization modules.\n                                                      cation performance scores and leave an automated In the prompt update module (2a), prompts are\n                                                      evaluation of the other measures or a user study for paraphrased. As an example, this paraphrasing of\n                                                      future work. In this simulation, the prompt is se-‘Classification task with labels: joy and sadness.’\n                                                        lected corresponding to the weighted F1 score over with a meta-prompt of an LLM ‘Rephrase the fol-\n                                                a fixed subset of the training data. We expect to lowing prompt’ may lead to ‘Classify the emotion\n                                                 demonstrate a rising trend during the optimization of text into joy and sadness.’\n                                                   process to verify the effectiveness of our approach.\n   In the prompt evaluation stage (2b), the human in                                                  Datasets. We select three datasets for single la-\n the loop assesses the prompt quality, as described                                                  beled emotion classification task from Bostan and\n above. Figure 3 further provides a prototypical dis-                                                   Klinger (2018), namely TEC, covering general top-\n play of the relevant information for two prompts to                                                          ics on tweets (Mohammad, 2012); GROUNDED-\n be chosen from. In the current prototype interface,                                        EMOTIONS, focusing on event-related topics on\n the explanations are automatically generated by                                                  tweets (Liu et al., 2017); and TALES-EMOTION,\n prompting a LLM. For instance, the specific prompt                                                            built upon fairytales (Alm and Sproat, 2005).\n used is: ‘In your answer, provide only the label you\n choose and the explanation of your choice.’. Ex-   Result.  Figure 4 illustrates the F1 scores over 15\n amples of the generated explanations during the    iterations. We observe an overall increasing trend\n evaluation process are provided in the Appendix A.    in both training and validation data.\nThe optimization process is terminated once the       1https://ollama.com/library/llama3.1:\n user is satisfied (3).                                 8b-instruct-fp16\n\n5  Conclusions and Future Work             time remains significant, and as a result, the stream-\n                                                    ing output is not effectively communicated to users.\nWe proposed interactive prompt optimization as\n                                                Second, developing an effective strategy to address\na novel approach to configure instruction-tuned\n                                              problems related to train-validation-test splitting\nlanguage models. The user is guided by informa-\n                                                         for user-provided datasets of varying sizes remains\ntion that is distilled from the prompt and its perfor-\n                                             an ongoing challenge. Third, the development of\nmance on user-provided data. With this approach,\n                                            prompt optimization iterations partially depends\nwe suggested to aggregate information that may be\n                                            on the quality and variability of prompt rephrasing.\nrelevant for users to decide on prompt preferences.\n                                                 This implies that rephrased prompts may occasion-\n  The proposed approach has revealed several chal-\n                                                         ally retain low quality across multiple iterations.\nlenges that deserve further investigation. There is                                                Furthermore, we observe that certain datasets ex-\na need to explore more effective methodologies\n                                                            hibit limited sensitivity to divergent prompts, allow-\nfor enhancing the diversity of rephrased prompts.\n                                                    ing a simple or even naive initial prompt to achieve\nIt is important to limit the numbers of instances                                                     superior performance.\nshown to the user, and that selection requires meth-\nods to do so. It is essential to optimize the various   Acknowledgments\nmeta-prompts in the approach. Additionally, the\n                                                 This paper is supported by the project INPROMPToptimization algorithm is essential to improving the\n                                                         (Interactive Prompt Optimization with the Humanefficiency and user-friendliness of our approach.\n                                                      in the Loop for Natural Language Understanding  We envision that our iPrOp approach lays the\n                                         Model Development and Intervention, funded bygroundwork for future research by addressing sev-\n                                                    the German Research Foundation, KL 2869/13-1,eral open questions: (Q1) Which parameters do\n                                                      project number 521755488).influence the performance of the workflow con-\nfiguration in this approach? We presume that the\n                                             Ethical Considerations\nexample selection to better understand how the\nprompt performs affects a user’s ability to estimate   Our approach is designed with careful attention to\nwhich prompt is preferable. Further, the methods    ethical standards in data usage, privacy, and com-\nto explain the prompt prediction are crucial. Fi-   pliance with the ACL Code of Ethics. Our method\nnally, underlying aspects such as the model and its   does not contribute to the republication or redistri-\nrobustness are relevant factors for the approach to    bution of any datasets. The datasets used for testing\nsucceed. (Q2) How do prompts evolve throughout   and evaluation are publicly available and we ensure\nthe optimization iterations? An aspect of this ques-    that they have been collected according to ethical\ntion is what is the difference between automatic    standards before using them. To safeguard user\nprompt optimization and the human optimization    privacy, all data provided by users is stored exclu-\nis, and in which cases the human intervention is    sively on their local machines. While potential\nindeed helpful. (Q3) To what extent can human    risks associated with the underlying LLMs could\ninvolvement be reduced while maintaining a bal-    result in the exposure of user-provided datasets, we\nanced trade-off across competing evaluation crite-   aim to mitigate these risks by offering more secure\nria? Can the interactive prompt optimization ap-    local models.  In addition, our approach cannot\nproach be a collaborative learning procedure, in    guarantee that the optimal prompts identified are\nwhich the machine only requests information if    state of the art for specific tasks. Furthermore, in-\nneeded? We propose to study these research ques-   dividual preferences may introduce biases, which\ntions based on the paradigm of interactive prompt   could potentially mislead users. We are commit-\noptimization introduced in this paper.                ted to continuously monitoring and improving the\n                                                         ethical performance of our approach.\nLimitations\n\nAlthough the iPrOp approach offers a convenient\n                                          References\ninterface for non-technical users to attain suitable\nprompts, it has several limitations that warrant con-  Anum Afzal, Alexander Kowsik, Rajna Fani, and Flo-\n                                                              rian Matthes. 2024. Towards optimizing and evalu-\nsideration in the future enhancement. First, in an                                                              ating a retrieval augmented QA chatbot using LLMs\neffort to provide comprehensive explanations of      with human-in-the-loop. In Proceedings of the Fifth\nLLM predictions, the challenge of computation      Workshop on Data Science with Human-in-the-Loop\n\n(DaSH 2024), pages 4–16, Mexico City, Mexico. As-      performance with model-adaptive prompt optimiza-\n   sociation for Computational Linguistics.                    tion. In Findings of the Association for Computa-\n                                                               tional Linguistics: EMNLP 2023, pages 3279–3304,\nCecilia Ovesdotter Alm and Richard Sproat. 2005. Emo-      Singapore. Association for Computational Linguis-\n   tional sequencing and development in fairy tales. In         tics.\n   Affective Computing and Intelligent Interaction, First\n   International Conference, ACII 2005, Beijing, China,   Leyang Cui, Yu Wu, Jian Liu, Sen Yang, and Yue Zhang.\n  October 22-24, 2005, Proceedings, volume 3784 of      2021. Template-based named entity recognition us-\n  Lecture Notes in Computer Science, pages 668–674.      ing BART. In Findings of the Association for Com-\n   Springer.                                                putational Linguistics: ACL-IJCNLP 2021, pages\n                                                   1835–1845, Online. Association for Computational\nAnthropic. 2024. The claude 3 model family: Opus,       Linguistics.\n   sonnet, haiku.\n                                                   Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nTobias Baur, Alexander Heimerl,  Florian Lingen-                                                            Kristina Toutanova. 2019. BERT: Pre-training of\n   felser, Johannes Wagner, Michel F. Valstar, Björn W.                                                   deep bidirectional transformers for language under-\n   Schuller, and Elisabeth André. 2020. explainable co-                                                             standing. In Proceedings of the 2019 Conference of\n   operative machine learning with NOVA. Künstliche                                                           the North American Chapter of the Association for\n   Intell., 34(2):143–164.                                                     Computational Linguistics: Human Language Tech-\n                                                            nologies, Volume 1 (Long and Short Papers), pages\nFarah Benamara and Patrick Saint Dizier. 2003. WEB-                                                     4171–4186, Minneapolis, Minnesota. Association for\n  COOP: A cooperative question answering system on                                                      Computational Linguistics.\n   the web. In 10th Conference of the European Chap-\n   ter of the Association for Computational Linguistics,\n                                            Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,\n  Budapest, Hungary. Association for Computational\n                                                    Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,\n   Linguistics.\n                                                     Akhil Mathur, Alan Schelten, Amy Yang, Angela\n                                                          Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang,Steven  Bills,  Nick  Cammarata,  Dan  Mossing,\n                                                     Archi Mitra, Archie Sravankumar, Artem Korenev,  Henk  Tillman,  Leo  Gao,  Gabriel  Goh,  Ilya\n                                                       Arthur Hinsvark, Arun Rao, Aston Zhang, Aurélien   Sutskever,  Jan  Leike,  Jeff Wu,  and  William\n                                                       Rodriguez, Austen Gregerson, Ava Spataru, Bap-  Saunders.  2023.    Language  models  can  ex-\n                                                                         tiste Rozière, Bethany Biron, Binh Tang, Bobbie   plain  neurons  in  language  models.    Online:\n                                                      Chern, Charlotte Caucheteux, Chaya Nayak, Chloe  https://openaipublic.blob.core.windows.\n                                                              Bi, Chris Marra, Chris McConnell, Christian Keller,  net/neuron-explainer/paper/index.html.\n                                                       Christophe Touret, Chunyang Wu, Corinne Wong,\n                                                                Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Al-Laura-Ana-Maria Bostan and Roman Klinger. 2018.\n                                                                 lonsius, Daniel Song, Danielle Pintz, Danny Livshits,  An analysis of annotated corpora for emotion clas-\n                                                  David Esiobu, Dhruv Choudhary, Dhruv Mahajan,   sification in text. In Proceedings of the 27th Inter-\n                                                    Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes,   national Conference on Computational Linguistics,\n                                                  Egor Lakomkin, Ehab AlBadawy, Elina Lobanova,  pages 2104–2119, Santa Fe, New Mexico, USA. As-\n                                                  Emily Dinan, Eric Michael Smith, Filip Radenovic,   sociation for Computational Linguistics.\n                                                      Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Geor-\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie       gia Lewis Anderson, Graeme Nail, Grégoire Mialon,\n  Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind     Guan Pang, Guillem Cucurell, Hailey Nguyen, Han-\n   Neelakantan, Pranav Shyam, Girish Sastry, Amanda      nah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov,\n   Askell,  Sandhini Agarwal,  Ariel  Herbert-Voss,      Imanol Arrieta Ibarra, Isabel M. Kloumann, Ishan\n  Gretchen Krueger, Tom Henighan, Rewon Child,      Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan\n  Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,       Geffert, Jana Vranes, Jason Park, Jay Mahadeokar,\n  Clemens Winter, Christopher Hesse, Mark Chen, Eric       Jeet Shah, Jelmer van der Linde, Jennifer Billock,\n   Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,      Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi,\n  Jack Clark, Christopher Berner, Sam McCandlish,      Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu,\n  Alec Radford, Ilya Sutskever, and Dario Amodei.      Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph\n  2020. Language models are few-shot learners. CoRR,      Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia,\n  abs/2005.14165.                                   Kalyan Vasuden Alwala, Kartikeya Upasani, Kate\n                                                         Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, and\nTanise Ceron, Neele Falk, Ana Bari´c, Dmitry Nikolaev,       et al. 2024. The llama 3 herd of models. CoRR,\n  and Sebastian Padó. 2024. Beyond prompt brittle-      abs/2407.21783.\n   ness: Evaluating the reliability and consistency of\n   political worldviews in LLMs. Transactions of the    Chrisantha  Fernando,  Dylan  Banarse,  Henryk\n  Association for Computational Linguistics, 12:1378–      Michalewski, Simon Osindero, and Tim Rock-\n  1400.                                                        täschel. 2024.   Promptbreeder:  Self-referential\n                                                       self-improvement via prompt evolution.  In Forty-\nYuyan Chen, Zhihao Wen, Ge Fan, Zhengyu Chen, Wei         first International Conference on Machine Learning,\n  Wu, Dayiheng Liu, Zhixu Li, Bang Liu, and Yanghua     ICML 2024, Vienna, Austria, July 21-27, 2024.\n  Xiao. 2023. MAPO: Boosting large language model      OpenReview.net.\n\nBraden Hancock, Antoine Bordes, Pierre-Emmanuel    Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\n  Mazare, and Jason Weston. 2019.  Learning from      Hiroaki Hayashi, and Graham Neubig. 2023. Pre-\n  dialogue after deployment: Feed yourself, chatbot!        train, prompt, and predict: A systematic survey of\n   In Proceedings of the 57th Annual Meeting of the As-      prompting methods in natural language processing.\n   sociation for Computational Linguistics, pages 3667–    ACM Comput. Surv., 55(9):195:1–195:35.\n  3684, Florence, Italy. Association for Computational\n   Linguistics.                                        Vicki Liu, Carmen Banea, and Rada Mihalcea. 2017.\n                                                Grounded emotions. In Seventh International Con-\nLouisa Heidrich, Emanuel Slany, Stephan Scheele, and       ference on Affective Computing and Intelligent Inter-\n  Ute Schmid. 2023. Faircaipi: A combination of ex-       action, ACII 2017, San Antonio, TX, USA, October\n   planatory interactive and fair machine learning for      23-26, 2017, pages 477–483. IEEE Computer Soci-\n  human and machine bias reduction. Mach. Learn.       ety.\n  Knowl. Extr., 5(4):1519–1538.\n                                              Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham      and Pontus Stenetorp. 2022. Fantastically ordered\n  Neubig. 2020. How can we know what language      prompts and where to find them: Overcoming few-\n  models know? Transactions of the Association for       shot prompt order sensitivity. In Proceedings of the\n  Computational Linguistics, 8:423–438.                  60th Annual Meeting of the Association for Compu-\n                                                                tational Linguistics (Volume 1: Long Papers), pages\n                                                     8086–8098, Dublin, Ireland. Association for Compu-Shubhra Kanti Karmaker Santu and Dongji Feng. 2023.\n                                                                  tational Linguistics.  TELeR: A general taxonomy of LLM prompts for\n  benchmarking complex tasks.  In Findings of the\n                                                  Yuxing Lu, Xukai Zhao, and Jinzhuo Wang. 2023. Med-  Association for Computational Linguistics: EMNLP\n                                                                      ical knowledge-enhanced prompt learning for diagno-  2023, pages 14197–14203, Singapore. Association\n                                                                        sis classification from clinical text. In Proceedings of   for Computational Linguistics.\n                                                             the 5th Clinical Natural Language Processing Work-\n                                                          shop, pages 278–288, Toronto, Canada. Association\nAna Kotarcic, Dominik Hangartner, Fabrizio Gilardi,\n                                                                for Computational Linguistics.\n   Selina Kurer, and Karsten Donnay. 2022. Human-in-\n   the-loop hate speech classification in a multilingual\n                                                        Scott M. Lundberg and Su-In Lee. 2017. A unified\n   context. In Findings of the Association for Computa-\n                                                     approach to interpreting model predictions. In Ad-\n   tional Linguistics: EMNLP 2022, pages 7414–7442,\n                                                        vances in Neural Information Processing Systems 30:\n  Abu Dhabi, United Arab Emirates. Association for\n                                                  Annual Conference on Neural Information Process-\n  Computational Linguistics.\n                                                           ing Systems 2017, December 4-9, 2017, Long Beach,\n                                                CA, USA, pages 4765–4774.\nPiyawat  Lertvittayakumjorn,  Lucia  Specia,  and\n  Francesca Toni. 2020. FIND: Human-in-the-Loop                                                        Christopher D. Manning, Prabhakar Raghavan, and Hin-\n  Debugging Deep Text Classifiers. In Proceedings of                                                              rich Schütze. 2008. Introduction to information re-\n   the 2020 Conference on Empirical Methods in Natu-                                                                     trieval. Cambridge University Press.\n   ral Language Processing (EMNLP), pages 332–348,\n   Online. Association for Computational Linguistics.                                                            Philip Mavrepis, Georgios Makridis, Georgios Fatouros,\n                                                            Vasileios Koukos, Maria Margarita Separdani, and\nXiang Lisa Li and Percy Liang. 2021. Prefix-tuning:      Dimosthenis Kyriazis. 2024. XAI for all: Can large\n  Optimizing continuous prompts for generation. In      language models simplify explainable ai?  CoRR,\n  Proceedings of the 59th Annual Meeting of the Asso-      abs/2401.13110.\n   ciation for Computational Linguistics and the 11th\n   International Joint Conference on Natural Language    Yarik Menchaca Resendiz and Roman Klinger. 2025.\n  Processing (Volume 1: Long Papers), pages 4582–     Mopo: Multi-objective prompt optimization for af-\n  4597, Online. Association for Computational Lin-       fective text generation. In Proceedings of the 31st\n   guistics.                                                  International Conference on Computational Linguis-\n                                                                          tics, Abu Dhabi, UAE. International Committee on\nXiaoqiang Lin, Zhongxiang Dai, Arun Verma, See-      Computational Linguistics.\n  Kiong Ng, Patrick Jaillet, and Bryan Kian Hsiang\n  Low. 2024. Prompt optimization with human feed-   Swaroop Mishra, Daniel Khashabi, Chitta Baral, and\n   back. CoRR, abs/2405.17346.                      Hannaneh Hajishirzi. 2022. Cross-task generaliza-\n                                                                tion via natural language crowdsourcing instructions.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,      In Proceedings of the 60th Annual Meeting of the\n  Lawrence Carin, and Weizhu Chen. 2022. What      Association for Computational Linguistics (Volume\n  makes good in-context examples for GPT-3?   In      1: Long Papers), pages 3470–3487, Dublin, Ireland.\n  Proceedings of Deep Learning Inside Out (DeeLIO      Association for Computational Linguistics.\n  2022): The 3rd Workshop on Knowledge Extrac-\n   tion and Integration for Deep Learning Architectures,    Saif Mohammad. 2012. #emotional tweets. In *SEM\n  pages 100–114, Dublin, Ireland and Online. Associa-     2012: The First Joint Conference on Lexical and\n   tion for Computational Linguistics.                    Computational Semantics – Volume 1: Proceedings\n\nof the main conference and the shared task, and Vol-       for scientific insights and discoveries. IEEE Access,\n  ume 2: Proceedings of the Sixth International Work-      8:42200–42216.\n  shop on Semantic Evaluation (SemEval 2012), pages\n  246–255, Montréal, Canada. Association for Compu-    Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric\n   tational Linguistics.                                     Wallace, and Sameer Singh. 2020. AutoPrompt: Elic-\n                                                                   iting Knowledge from Language Models with Auto-\nAihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, and       matically Generated Prompts. In Proceedings of the\n  Ju Jia. 2025. SelfPrompt: Autonomously evaluat-     2020 Conference on Empirical Methods in Natural\n   ing LLM robustness via domain-constrained knowl-     Language Processing (EMNLP), pages 4222–4235,\n  edge guidelines and refined adversarial prompts. In       Online. Association for Computational Linguistics.\n  Proceedings of the 31st International Conference on\n  Computational Linguistics, pages 6840–6854, Abu    Stefano Teso and Kristian Kersting. 2019. Explanatory\n  Dhabi, UAE. Association for Computational Linguis-       Interactive Machine Learning.  In Proceedings of\n   tics.                                                     the 2019 AAAI/ACM Conference on AI, Ethics, and\n                                                               Society, pages 239–245, Honolulu, HI, USA. ACM.\nFlor Miriam Plaza-del Arco, María-Teresa Martín-\n   Valdivia, and Roman Klinger. 2022.  Natural lan-    Zijie J. Wang, Dongjin Choi, Shenyu Xu, and Diyi Yang.\n  guage inference prompts for zero-shot emotion clas-      2021. Putting humans in the natural language pro-\n   sification in text across corpora. In Proceedings of       cessing loop: A survey. In Proceedings of the First\n   the 29th International Conference on Computational     Workshop on Bridging Human–Computer Interac-\n   Linguistics, pages 6805–6817, Gyeongju, Republic       tion and Natural Language Processing, pages 47–52,\n   of Korea. International Committee on Computational       Online. Association for Computational Linguistics.\n   Linguistics.\n                                                    Colin Wei, Sang Michael Xie, and Tengyu Ma. 2021.\nReid Pryzant, Dan Iter, Jerry Li, Yin Lee, Chenguang                                     Why do pretrained language models help in down-\n  Zhu, and Michael Zeng. 2023. Automatic prompt op-                                                        stream tasks? an analysis of head and prompt tuning.\n   timization with “gradient descent” and beam search.                                                          In Advances in Neural Information Processing Sys-\n   In Proceedings of the 2023 Conference on Empiri-                                                      tems 34: Annual Conference on Neural Information\n   cal Methods in Natural Language Processing, pages                                                        Processing Systems 2021, NeurIPS 2021, December\n  7957–7968, Singapore. Association for Computa-                                                           6-14, 2021, virtual, pages 16158–16170.\n   tional Linguistics.\n                                                  Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Gold-\nGuanghui Qin and Jason Eisner. 2021. Learning how                                                       blum, Jonas Geiping, and Tom Goldstein. 2023. Hard\n   to ask: Querying LMs with mixtures of soft prompts.                                                    prompts made easy: Gradient-based discrete opti-\n   In Proceedings of the 2021 Conference of the North                                                       mization for prompt tuning and discovery.  In Ad-\n  American Chapter of the Association for Computa-                                                        vances in Neural Information Processing Systems 36:\n   tional Linguistics: Human Language Technologies,                                                  Annual Conference on Neural Information Process-\n  pages 5203–5212, Online. Association for Computa-                                                         ing Systems 2023, NeurIPS 2023, New Orleans, LA,\n   tional Linguistics.                                               USA, December 10 - 16, 2023.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\n                                               Xuansheng Wu, Haiyan Zhao, Yaochen Zhu, Yucheng  Lee, Sharan Narang, Michael Matena, Yanqi Zhou,\n                                                              Shi, Fan Yang, Tianming Liu, Xiaoming Zhai, Wen-  Wei Li, and Peter J. Liu. 2020. Exploring the limits\n                                                                     lin Yao, Jundong Li, Mengnan Du, and Ninghao   of transfer learning with a unified text-to-text trans-\n                                                           Liu. 2024. Usable XAI: 10 strategies towards ex-   former. J. Mach. Learn. Res., 21:140:1–140:67.\n                                                              ploiting explainability in the LLM era.  CoRR,\nMarco Túlio Ribeiro, Sameer Singh, and Carlos      abs/2403.08946.\n   Guestrin. 2016. \"why should I trust you?\": Explain-\n   ing the predictions of any classifier. In Proceedings    Lei Xu, Yangyi Chen, Ganqu Cui, Hongcheng Gao,\n   of the 22nd ACM SIGKDD International Conference      and Zhiyuan Liu. 2022. Exploring the universal vul-\n  on Knowledge Discovery and Data Mining, San Fran-       nerability of prompt-based learning paradigm.  In\n                                                       Findings of the Association for Computational Lin-   cisco, CA, USA, August 13-17, 2016, pages 1135–\n                                                                guistics: NAACL 2022, pages 1799–1810, Seattle,  1144. ACM.\n                                                     United States. Association for Computational Lin-\nMarco Túlio Ribeiro, Sameer Singh, and Carlos        guistics.\n   Guestrin. 2018.  Anchors: High-precision model-\n   agnostic explanations. In Proceedings of the Thirty-   Qinyuan Ye, Mohamed Ahmed, Reid Pryzant, and\n  Second AAAI Conference on Artificial Intelligence,      Fereshte Khani. 2024. Prompt engineering a prompt\n  (AAAI-18), the 30th innovative Applications of Arti-      engineer. In Findings of the Association for Com-\n   ficial Intelligence (IAAI-18), and the 8th AAAI Sym-      putational Linguistics: ACL 2024, pages 355–385,\n  posium on Educational Advances in Artificial Intel-     Bangkok, Thailand. Association for Computational\n   ligence (EAAI-18), New Orleans, Louisiana, USA,       Linguistics.\n  February 2-7, 2018, pages 1527–1535. AAAI Press.\n                                             Wenpeng Yin, Jamaal Hay, and Dan Roth. 2019. Bench-\nRibana Roscher, Bastian Bohn, Marco F. Duarte, and      marking zero-shot text classification: Datasets, eval-\n  Jochen Garcke. 2020. Explainable machine learning       uation and entailment approach. In Proceedings of\n\nthe 2019 Conference on Empirical Methods in Natu-\n   ral Language Processing and the 9th International\n   Joint Conference on Natural Language Processing\n  (EMNLP-IJCNLP), pages 3914–3923, Hong Kong,\n  China. Association for Computational Linguistics.\n\nChunting Zhou, Junxian He, Xuezhe Ma, Taylor Berg-\n   Kirkpatrick, and Graham Neubig. 2022. Prompt con-\n   sistency for zero-shot task generalization. In Find-\n   ings of the Association for Computational Linguistics:\n  EMNLP 2022, pages 2613–2626, Abu Dhabi, United\n  Arab Emirates. Association for Computational Lin-\n   guistics.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\n  Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\n  Ba. 2023. Large language models are human-level\n  prompt engineers.  In The Eleventh International\n  Conference on Learning Representations, ICLR 2023,\n   Kigali, Rwanda, May 1-5, 2023. OpenReview.net.\n\nA  Appendix\n\n\n     Text                                         Predicted Label & Explanation\n     hey you! Hope school is going well for you!   Joy. The presence of the ♡symbol and the affectionate message\n     Love ya♡                                   (\"Love ya\") convey a positive emotional tone, indicating joy.\n   Mmmm breakfast in bed :)                        Joy. The person is expressing excitement and delight through\n                                                        the use of a happy emoticon :).\n   A wonderful story about how an act of kindness   Joy. The use of \"wonderful\" to describe the story suggests a\n     can change someone’s life.                        positive tone, and the sharing of it on social media implies that\n                                                        the act of kindness is uplifting and inspiring.\n      Someday....                                   Sadness. The use of the word \"someday\" can imply a sense of\n                                                    longing or wistfulness, and the fact that it´s used in conjunction\n                                                  with two links to online content may suggest that the author is\n                                                            reflecting on something they´ve written in the past.\n     With immigration drop, who needs a wall?       Sadness. The text mentions an \"immigration drop\", which im-\n                                                           plies a negative change or decrease in something related to im-\n                                                        migration. This is likely to evoke feelings of sadness or concern\n                                                          rather than joy. The use of the phrase \"who needs a wall\" also\n                                                       suggests a sense of pessimism or hopelessness, further indicating\n                                                            that the overall tone of the text is more negative and therefore\n                                                             classified as sadness.\n     do not try to stop them                         Sadness. The use of \"do not try to stop them\" is a warning or\n                                                      cautionary statement, often implying something bad or undesir-\n                                                      able is happening. The link provided does not provide context,\n                                                     but the tone of the message suggests a sense of urgency and\n                                                      possibly desperation, which are common indicators of sadness\n                                                       or concern.\n\n Table 1: Examples of an explanation generated for a predicted label in the GROUNDED-EMOTIONS dataset task.",
"headers": [
"arXiv:2412.12644v2  [cs.CL]  27 Jun 2025",
"iPrOp: Interactive Prompt Optimization for",
"Large Language Models with a Human in the Loop",
"Jiahui Li and Roman Klinger",
"Fundamentals of Natural Language Processing, University of Bamberg, Germany",
"{jiahui.li,roman.klinger}@uni-bamberg.de",
"Abstract",
"1",
"Introduction",
"2",
"Related Work",
"3",
"Methods",
"4",
"Evaluation",
"5",
"Conclusions and Future Work",
"Acknowledgments",
"Ethical Considerations",
"Limitations",
"References",
"A",
"Appendix"
],
"tables": [
"|Col1|Optimization<br>2a.<br>Prompt Update<br>2b.<br>Prompt Evalution|Col3|\n|---|---|---|\n||||",
"|Prompt 1|Prompt 2|\n|---|---|\n|<br>Text<br>Classification task with labels:<br>joy and sadness.<br>I like watching TV. (joy)<br>Work is challenging. (sadness)<br>The food was fine. (sadness)|<br>Prompt 1            Prompt 2<br> <br>Classify the emotion of text<br>into joy and sadness.<br>joy + Exp.<br>sadness + Exp.<br>joy + Exp.<br>joy + Exp.<br>joy + Exp.<br>sadness + Exp.|\n|Performance M<br>Prompt 1<br>0.46<br>Which prompt is better?|etrices (e.g. F1)<br>Prompt 2<br>0.53<br>                          Prompt 1           Prompt 2|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2412.12644v2.pdf"
}