{
"text": "JPPO: Joint Power and Prompt Optimization for\n       Accelerated Large Language Model Services\n\n               Feiran You1, Hongyang Du1, Kaibin Huang1, Fellow, IEEE, and Abbas Jamalipour2, Fellow, IEEE\n                        1Department of Electrical and Electronic Engineering, University of Hong Kong, Hong Kong SAR, China\n                                2School of Electrical and Computer Engineering, University of Sydney, Sydney, Australia\n                                Emails: fryou@eee.hku.hk, duhy@eee.hku.hk, huangkb@eee.hku.hk, a.jamalipour@ieee.org\n\n\n\n           Abstract—Large Language Models (LLMs) have demonstrated                                                   Conventional Network-aided LLM Service\n         remarkable capabilities in various tasks, leading to their increas-\n          ing deployment in wireless networks for a wide variety of user\n           services. However, the growing longer prompt setting highlights                                                          WirelessTransmission LLM Inference Time2025          the crucial issue of computational resource demands and huge                                                  Time                                                                                                                                                          Feedback\n        communication  load. To address  this  challenge, we propose                                              Our Proposed Design                                                              First\n                                                                                                                      User            Long Prompt\n          Joint Power and Prompt Optimization (JPPO), a framework                                                                                                                                                                                                                                      TokenFeb   that combines Small Language Model (SLM)-based prompt\n                                                                                                                                                 LLM Inference                                                                                                                                                              SLM-aided                                                                                                                      Components                                                                                                                                                                             of                                                                                                                                                               the Original         compression                      with                              wireless                               power                                                allocation                                                         optimization.                                                     By                                                                                                                                                                                   Saved                                                                                                                                                              Prompt                                                                                                                          Prompt                                                                                                                             and Total                                                                                                                                         Token                                                                                                                                                      Length                                                                                                                                                                                        Time                                                                                                                                                               Compression  Short         deploying SLM                            at                             user devices                                              for                                       prompt compression                                                         and22                                                                                                                                   Total Token Length:     Lins      Ldems     Lque      Time         Prompt         employing Deep Reinforcement Learning for joint optimization\n          of compression ratio and transmission power, JPPO effectively\n         balances service quality with resource efficiency. Experimental                                                       ComponentsPrompt and Totalof theTokenCompressedLength\n           results demonstrate that our framework achieves high service\n                                                                                                                                                                                                         Total Token Length:    Lins   Ldems Lque\n            fidelity and low bit error rates while optimizing power usage\n          in wireless LLM services. The system reduces response time by\n         about 17%, with the improvement varying based on the length                                                                                               Fig. 1.  Time consumption comparison of  first token generation between\n          of the original prompt.                                                   conventional network-aided LLM inference service architecture and our design[eess.AS]     Index Terms—Large language models, prompt engineering,   under long user prompts.\n        power allocation, joint optimization\n\n                                                                     Consequently, the  efficient deployment of LLMs  in wire-                                        I. INTRODUCTION\n                                                                                 less networks demands innovative solutions that can balance\n          Large Language Models (LLMs) have revolutionized natural  prompt inputs and resource efficiency requirements [9].\n        language processing, demonstrating unprecedented capabilities      Prior research has tried to address these challenges from\n         across various tasks [1]. As these models increasingly drive   different angles. The authors in [10] introduced LLMLingua,\n          intelligent IoT devices and edge computing applications, their   a coarse-to-fine prompt compression method that demonstrates\n        deployment over wireless networks to provide services to   significant potential for compressing LLM prompts while pre-\n         end-users has become a critical scenario [2]. However, this   serving their semantic integrity. LLMLingua utilizes a small\n          integration faces significant challenges from the computational   language model for compression, which can be aligned with\n        demands of LLMs and the inherent constraints of wireless   the target LLM through instruction tuning. While this approach\n        communication systems [3].                              shows promise for reducing communication overhead, it does\n       A key issue lies in the growing length of prompts used   not fully account for the challenges posed by wireless trans-arXiv:2411.18010v2   to  elicit advanced reasoning from LLMs  [4],  particularly   mission. The work in [11] proposes LLM-Slice, a system that\n         with the advent of techniques like Chain-of-Thought (CoT)   creates dedicated network slices for LLM services to improve\n        prompting [5] and In-Context Learning (ICL) [6]. While these   wireless resource management and reduce response delays.\n        methods substantially enhance LLM performance, they often   Although LLM-Slice advances wireless network architecture\n          necessitate prompts that can extend to tens of thousands of   for LLM services,  it focuses solely on communication re-\n         tokens [7]. This trend creates a fundamental trade-off: On the   source allocation without considering prompt optimization for\n        one hand, longer, more sophisticated prompts unlock the full   individual user requirements. Addressing these issues requires\n          potential of LLMs; on the other, they impose severe burdens   solving two key questions:\n        on communication bandwidth and computing resources in      • Q1) How to achieve adjustable prompt compression with-\n         wireless  settings. Moreover, the transmission of these ex-                                                                            out significantly degrading LLM inference performance\n          tensive prompts consumes significant network resources and                                                                   and service quality?\n         introduces considerable latency, potentially undermining the      • Q2) How to jointly design wireless resource allocation,\n          real-time responsiveness crucial for many applications  [8].                                                                                    particularly transmission power, to meet the latency and\n          This conference paper was accepted by ICC 2025.                        power consumption constraints of network-aided LLM\n\nservices while maintaining high service quality?      N  users with diverse task requirements,  e.g., prompts. As\nFor Q1, natural language processing methods offer poten-   illustrated in Fig. 2, our proposed framework consists of three\ntial solutions for prompt compression. However, traditional   key components: an SLM agent deployed at user devices or\nNLP compression techniques like text summarization or key-   edge servers for prompt compression, a JPPO scheme for\nword extraction often fail to capture the complex reasoning   reliable wireless transmission, and a target LLM for infer-\npatterns and task-specific requirements embedded in LLM   ence service. On the user side, the SLM agent leverages its\nprompts, leading to degraded inference performance. Alter-   semantic understanding capability to compress prompts while\nnative AI-based approaches, such as large autoencoder mod-   preserving task-critical information. The compressed prompts\nels or  specialized compression networks,  require substan-   are then transmitted through wireless channels with jointly\ntial computational resources and introduce additional infer-   optimized power allocation, and finally processed by the target\nence latency at user terminals, making them impractical for  LLM for inference. This framework adaptively adjusts both\nresource-constrained wireless scenarios. Small language mod-   compression ratios and transmission power based on channel\nels (SLMs), which can be easily deployed at user terminals, of-   conditions and prompt characteristics to achieve high LLM\nfer a promising solution through their semantic understanding   service quality.\ncapability to compress LLM prompts while preserving task-                                                             B. Prompt Compression\ncritical information. SLM has been adapted as an effective\n                                                     To efficiently reduce prompt sizes while preserving semanticway to employ transformers for edge applications in [12].\n                                                                          integrity, we adopt a coarse-to-fine compression approach inBuilding upon this insight and addressing the Q2, we propose\n                                                 SLMs. Our compression method is designed to achieve twoJoint Power and Prompt Optimization (JPPO), a framework\n                                                          primary objectives:that combines SLM-based prompt compression with wireless\npower allocation optimization, as illustrated in Fig. 1. JPPO      • Preserve critical information in the prompt while ensuring\ncaptures the trade-off between compression ratio and wireless        the recoverability of the original semantic meaning.\nresource consumption, adapting to both channel conditions      • Enable flexible compression ratios that can be dynami-\nand prompt content. This integrated approach enables efficient        cally adjusted together with communication resources.\nwireless LLM services while maintaining response quality     Let us formally define the prompt structure and compression\nthrough intelligent prompt optimization. The contributions of   process. Consider an original prompt x that consists of three\nthis paper are summarized as                               components:\n   • We employ a small, aligned language model as a prompt                   x = (xins, xdems, xque) ,                  (1)\n     compressor. This approach preserves useful information\n                                                      where xins represents the instruction component, xdems denotes\n     while significantly reducing prompt size. The SLM ef-\n                                                                 the demonstrations or examples, and xque contains the specific\n     ficiently captures  essential meaning without requiring                                                              question or task. As depicted in Fig. 1, the token length of each\n     training at the transmitter.                                                     component is denoted by Lins, Ldems, and Lque respectively.\n   • We formulate an optimization problem for our JPPO                                                   The total token length Lx of the original prompt is given by:\n    framework. This problem balances compression quality,\n     wireless transmission performance, and LLM inference               Lx = Lins + Ldems + Lque.                (2)\n     efficiency. The objective function is the quality of ser-\n                                                   Our SLM-based compression mechanism generates a com-\n     vice (QoS), considering energy limitation and end-to-end\n                                                              pressed prompt  ˆx with length Lˆx. The compression ratio κ\n     latency, with compression ratio and transmission power\n                                                                               is defined as:\n     as key decision variables.                                                                Lˆx\n                                                            κ =      ,  κ ∈[0, 1]                  (3)\n   • To solve the complex JPPO optimization problem, we                    Lx\n    employ a Deep Reinforcement Learning (DRL) approach.\n                                                      where κ = 1 indicates no compression and smaller values of\n    The DRL agent learns to make optimal decisions on\n                                              κ represent higher compression rates.\n    compression and transmission strategies, effectively re-\n                                          We use a comprehensive fidelity metric f capturing three\n    ducing communication overhead and accelerating LLM\n                                                                     essential aspects of semantic preservation during information\n     inference  services  in latency-constrained and  variable\n                                                               transmission [13] to evaluate the quality of prompt compres-\n     channel scenarios.\n                                                                     sion. The fidelity metric is composed of three key components:\n                         II. SYSTEM MODEL                          • Representation accuracy (f1), which measures how ac-\n  In  this  section, we present the system model of wire-        curately the compressed prompt preserves the semantic\nless network-aided LLM inference services, the SLM-based       meaning of the original prompt and maintains semantic\nprompt compression method, and the wireless transmission         integrity. f1 is measured by the similarity metric based\nmodel with power consumption and delay constraints.            on the comparison between the representations of the\n                                                                         original prompt and the compressed prompt.\nA. Wireless Network-aided LLM Services                          • Transmission completeness (f2), which evaluates the in-\n  We consider a heterogeneous wireless network where a Data         tegrity of information preservation during the compres-\nCenter Operator (DCO) provides LLM inference services to        sion process. f2  is calculated as the token retained in\n\nPrompt Compression Ratio        Joint Power and Prompt Optimization\n\n\n                                                                                      Transmission Power\n                             …\n\n                            Long Prompt   Mobile Phone    Edge Server    Short Prompt\n                                                                                                                         Large                                                                                         Wireless Transmission   Base\n                      User                                                                                         Station  Language\n                                                                                                          Model\n                                                Small Language Model\n                                                                                                    Data Center Operator\n                                                                                            Inference Results\n\n\nFig. 2. System model of wireless network-aided LLM services and overview of our proposed JPPO, where user-generated long prompts are first compressed\nthrough SLM-based edge computing, then transmitted with optimized power allocation via wireless networks to LLM server, and finally inference results are\nreturned to users.\n\n\n     the compressed prompt compared to the original prompt,  where s represents the bit length of the compressed prompt ˆx\n     considering the transmission channel’s Bit Error Rate   with compression ratio κ, PT is the transmit power, R is the\n    (BER).                                                   transmission rate that can be expressed as\n   • Understanding accuracy (f3), which quantifies how well                                                                                 PTgd−α\n     the receiver (target LLM) can interpret the compressed     R = W log2 (1 + γ) = W log2  1 +                 .    (8)                                                                                          σ2\n    prompt correctly. f3 is given by the similarity metric to\n     evaluate the proximity of the response to the compressed   Here, W  is the bandwidth of the offloading link between\n    prompt received and the predefined response to the orig-   the user and DCO, γ  is the Signal-to-Noise-Ratio (SNR),\n     inal prompt.                                   PT denotes the transmission power, g  is the Rayleigh fad-\n                                                              ing coefficient (exponentially distributed with unit mean), d\n  The overall fidelity metric f can be defined as a weighted\n                                                                 represents the distance between user and DCO, α is the path-\nsum of these components:\n                                                                    loss exponent, σ2 represents the Gaussian noise term in the\n                                                             Additive White Gaussian Noise (AWGN) channel.\n                     f = α1f1 + α2f2 + α3f3,                (4)\n                                                      D. Service Delay\nwhere α1, α2, and α3 are weight factors determining the                                                     The total time consumption T comprises three components:\nrelative importance of each fidelity component. These weights\n                                                          encoding delay in SLM and LLM, and transmission delay,\ncan be adjusted based on application requirements and QoS\n                                                            expressed as:\npriorities.\n                                                  T (κ, PT ) = tSLMe   (κ) + tLLMe    (κ) + tt (κ, PT ) .     (9)\nC. Energy Consumption                                                                                  III. JOINT POWER AND PROMPT OPTIMIZATIOM\n  For one user, the total energy consumption E in the one-     This section introduces the JPPO for wireless network-aided\nshot LLM service request process consists of two components:  LLM services. After formulating the problem, we propose a\nencoding energy Ee and transmission energy Et. This can be  Double Deep Q-Network (DQN) method [15] to address the\nexpressed as:                                                         joint optimization problem.\n\n                                                             A. Problem Formulation        E (κ, PT ) = Ee (κ) + Et (κ, PT ) .           (5)\n                                                            For our JPPO framework, we formulate an optimization\nThe encoding energy consumption Ee, which represents the   problem that balances three key aspects: prompt compression\nenergy used by the SLM encoder for prompt compression, is   quality, wireless transmission  efficiency, and LLM service\ncalculated as [14]                                           performance. The objective is to maximize the overall fidelity\n                                                           while satisfying power and latency constraints in the wireless\n  Ee = tSLMe   (κ) nSLMgpu P gpuSLM + tLLMe    (κ) nLLMgpu PgpuLLM ,    (6)   network-aided LLM service system.  Specifically, the  joint\n                                                               optimization problem can be formulated as\nwhere tSLMe    represents the GPU execution time in SLM, ngpu\n                                                       max  f (κ, η (PT )) ,                  (10)denotes the number of GPUs utilized, and Pgpu is the thermal                      {κ,PT }\ndesign power per GPU, and superscript LLM denotes the                                                                                                                          s.t. E (κ, PT ) ≤Eth,             (10a)\ncorresponding parameters for the LLM.\n                                                                     PT ≤Pth,                    (10b)  The transmission energy consumption Et is\n                                                               T ≤Tth,                     (10c)\n                               s (κ)\n              Et = tt (κ) PT =     PT,                (7)                                  f > fth,                      (10d)\n                    R\n\nwhere η is the BER that is affected by the wireless environ-   current Q-network, making the learning process of the Double\nment and the transmit power, Pth is the maximum allowable  DQN more stable.\npower consumption, Tth represents the maximum tolerable\nend-to-end latency, fth defines the minimum required fidelity.  Algorithm 1 Double DQN Algorithm\nThe constraints are designed to ensure practical system oper-   Input: Initialize the action space A = {A1, · · · , AN} and\nation. Constraint (10a) is the energy constraint that represents        target privacy (ϵ, δ).\nthe total energy budget limitation at the edge device side,  Output: Reward.\nintroducing a  critical  trade-off: while higher transmission      1: Initialization: s0.\npower PT can lead to lower BER η and thus improved wireless      2: for each episode k ∈{1, ..., K} do\ntransmission fidelity f2 to enhance the overall fidelity f, the      3:   Explore actions and obtain initial states.\nenergy constraint forces a higher compression ratio κ to reduce      4:    for each step in the episode do\nboth the SLM/LLM inference energy cost and wireless trans-      5:     Take action at according to current policy.\nmission energy consumption; however, an excessively high      6:      Receive reward rt and observe the next state st+1.\ncompression ratio can result in significant information loss      7:        if s′ is the final state then\nfrom the original prompt, potentially degrading both the se-      8:       y = R′.\nmantic preservation fidelity f1 and LLM service quality fidelity      9:      else\nf3. Constraint (10b) ensures the power consumption remains    10:       y = R′+[αrt+1+γ maxa Q(st+1, a)−Q(st, at)].\nwithin the device’s power budget, Constraint (10c) guarantees    11:     end if\nthat the total service latency meets real-time requirements,    12:     Sample a mini-batch of experiences from memory\nConstraint (10d) maintains the quality of service by enforcing    13:      for each experience (s, a, r, s′) in the batch: do\na minimum threshold on fidelity. This optimization framework    14:        Calculate target Q-values according to (13)\nallows us to find the optimal balance between compression    15:       Compute the loss according to (12)\nratio and transmission power while maintaining high-quality    16:       Perform gradient descent to minimize loss:\nLLM service delivery.                                                   17:       Update ϵ: ϵ = max (ϵ ∗ϵdecay, ϵmin)\n                                                                              18:       Update the target Q-network every few episodes.\nB. Double DQN Solution\n                                                                              19:       Accumulate total reward and update state:\n  To solve  the complex JPPO optimization problem, we    20:          total reward+ = r, s = s′\ndeploy a centralized Double DQN method to find optimal    21:     end for\nprompt compression and transmission strategies for N users,    22:   end for\nas shown in Algorithm 1. The key elements of the proposed    23: end for\nDouble DQN design are                                                 24: Update the policy parameter.\n   • Environment: The environment of the Double DQN algo-    25: Terminate the training when the policy converges or after\n     rithm in the proposed framework is the communication       a predefined number of iterations.\n    environment with N users.\n   • State: The state information includes the current fidelity\n                                                     The update steps of DQN are:\n     of the transmitted message, SNR, and BER. The state\n     information of nth user is captured in a 3-dimensional               Q(st, at) ←Q(st, at) + [αrt+1\n                                                                                                                        (11)     vector: [fn(ηn), γn, ].                            + µ max Q(st+1, a) −Q(st, at)],\n                                                                                a   • Action: The actions include selecting compression and\n    power  levels. The  action space  is denoted as A =  where Q(st, at)  is the estimated Q-value updated by the\n    {A1, · · · , AN}, where An  is the action of user n and  Bellman equation for taking action at in state st. α is the\n     consists of a tuple with discrete values of compression   learning rate. rt+1 is the reward received after taking action\n     ratio and transmission power  level. The compression   at in state st and transitioning to state st+1. µ is the discount\n     ratio level  is discrete values range from 0 to 4. The   factor. maxa Q(st+1, a) is the maximum estimated Q-value\n     transmission power level is discrete values ranging from   for all possible actions in state st+1.\n    0 to 9, which affects BER.                                  In DQN, the loss function is the mean squared error (MSE)\n   • Reward: The reward of user n is Rn, and in each episode,   between the predicted Q-values and the target Q-values:\n     the agent accumulates rewards based on the  actions.\n                                                                h                                             i2    The reward function maximizes fidelity while minimizing   Li(θi) =  rt+1 + µ max Qtarget(st+1, a′; θ∗i ) −Q(st, at; θi)    ,\n                                                                                                            a′\n     penalties related to BER and power usage.                                                                         (12)\n  The key design of the Double DQN is to decouple action  where Li(θi) is the loss for the i-th iteration with parameter\nselection from evaluation and address the over-estimation issue   θi. rt+1 and st+1 are the reward and next state observed after\nby using two separate networks:Current Q-network, which   taking action at in state st. Qtarget(st+1, a′; θ∗i ) is the target\npredicts Q-values based on the current state, and Target Q-   Q-value estimated by the target network with parameters θ∗i .\nnetwork, which calculates target Q-values during updates and   Q(st, at; θi) is the predicted Q-value by the current Q-network\nevaluates the Q-value of the best next action selected by the   with parameters θi.\n\nPrompt Example: Madam Court, could you please read docket 1239? Certainly. Docket 1239. The Committee on\n                  Government Operations, to which was referred on December 1st, 2021, docket number 1239 message an order authorizing\n                     the creation of a sheltered market program in conformity with the requirements of general laws. Chapter 30 B Section 18.\n                    This authorization applies to contracts for goods, professional services and support services. This authorization is for no\n                 more than six contracts, which must be awarded by June 30th, 2022. This sheltered market program shall be available for\n                    disadvantaged, minority and women only vendors, for whom there is a demonstrated substantial disparity in the city's 2020             f1                        disparities. Study submits a report recommending the order ought to pass. Thank you so much, Madam Clerk. The Chair\n                    recognizes Councilor Edwards, chair of the committee. Councilor Edwards. You have the floor. This is this is actually a\n                      matter, I believe, sponsored by the. Mayor in Cannes. In conformance with the recommendations from the disparity study\n                 and making sure that we opt in to this this pilot program under mass general laws 30 Section 18. Again, it's really just\n                      following the recommendations of an already studied issue, which which demonstrates a disparity between minority\n                     contractors or women contractors receiving contracts in the city of Boston. … Question: What is the subject of Docket\n                 0863?\n                  Tokens: 626                                                                                                             f3\n                                                 f2                    Long Prompt                                           Response : The subject of Docket 0863 is\n                                                                                an order for a hearing to discuss pest control\n                                                                                and illegal dumping in the city of Boston.\n                            SLM     Wireless Transmission    LLM         Response : The subject of Docket 0863 is\n                      Short Prompt                                                         \"pest control and illegal dumping in Boston.\n\n                 4x Compression: Madam Court read docket 1239? Committee Government Operations referred December 1st 2021\n                    sheltered market program laws Chapter 30 B Section 18. contracts goods services  six contracts June 30th 2022\n                   disadvantaged minority women vendors disparity city 2020 disparities order pass Chair recognizes Councilor Edwards\n                  sponsored Mayor disparity study pilot program laws 30 Section 18. disparity minority women contractors Boston … Question:\n                What is the subject of Docket 0863?\n                 Tokens: 151 (4x)\n\n\nFig. 3.  The example illustrates wireless network-aided LLM services with SLM-based prompt compression, with a 4x compression ratio. The highlighted\nparts represent key information from the original prompt. Additionally, we show the corresponding steps of measuring the three sub-performance metrics (f1,\nf2 and f3) of the fidelity metric f throughout the process.\n\n\n\n                      TABLE I\n            SIMULATION PARAMETER CONFIGURATION                     1000\n\nParameter           Value                                               800\nLearning rate       10−3\nα1, α2, and α3       0.4, 0.3 and 0.3                                     600\nTotal test runs range [1, 10]                                                                                                                                                      RewardEpisodes per test run 10, 000\n                                                                        400\n\n                                                                        200            Raw Reward  The update steps of the Double DQN can be expressed as                                                                                            Moving Average Reward of DRL Algorithm\n    y = r + µ · Qtarget  s′, arg max Q(s′, a′; θ); θ−   ,    (13)           0\n                                        a′                                         0           5000         10000         15000\n                                                                                               Episode\nwhere Q(s, a; θ) is the estimated Q-value from the current Q-\nnetwork with parameter θ and Qtarget(s′, a′; θ−) is the Q-value    Fig. 4.  The convergence performance of reward for the proposed Double\nfrom the target network with parameter θ−.               DQN algorithm.\n\n                IV. NUMERICAL RESULTS\n  We design a customized environment with variable fidelity,   the SLM. Furthermore, even with the significant reduction in\nSNR, and BER to simulate the wireless network-aided LLM  prompt length, the accuracy of the responses from the LLM\nservice framework. The centralized DQN agent manages the   has not been compromised, indicating the effectiveness of the\nenvironment, which involves selecting compression and power   proposed SLM-based design.\nlevels.  Its goal  is to balance  fidelity, minimize errors, and      Fig. 4 shows the number of episodes and the reward con-\noptimize power usage. We employ the LLMLingua platform,   vergence of the proposed Double DQN method when running\nutilizing the SLM model with GPT-Neo 125M to do prompt   10, 000 episodes. We can observe from the figure that as\ncompression and use GPT-J 6B to generate the response [16].   training episodes progress, the reward increases over episodes\nThe simulations are carried out on MeetingBank-transcript   with exploration and then stabilizes within the range of 700 to\ndataset [?]. The parameter settings are listed in Table. 1.       800. Using the optimal policy from our trained DRL model,\n   Fig. 3 shows one example of prompt compression with  we conducted end-to-end inference experiments. Specifically,\na 4x compression ratio. We can observe that the length of   for a short original prompt of 44 tokens, the total response\nthe original prompt’s text has been significantly reduced by   time was reduced from 56.1 seconds to 46.9 seconds. When\n\ntesting with a longer prompt of 388 tokens, the total response                       V. CONCLUSION\ntime decreased from 85.3 seconds to 71.2 seconds. Further                                          We proposed a novel power and prompt optimization frame-\nevaluation across our  test dataset showed  that the overall                                                    work for wireless network-aided accelerated LLM services.\nperformance improvement fluctuates around 17%.                                                   The proposed mechanism achieves effective performance in\n                                                           high service fidelity and relatively low BER, and the power\n                          Average Fidelity over Episodes\n       1                                                   consumption is maintained in constraint. Experimental evalua-\n                                                                    tion shows that the proposed algorithm achieves stable conver-\n       0.5                                                       gence, indicating its potential for future practical deployment         Fidelity\n                                                                    in LLM service systems.\n\n       0         0        2000       4000       6000       8000      10000      12000                        REFERENCES\n                                       Episode\n                                                                                      [1] B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz,                           Average BER over Episodes\n                                                                                  E. Agirre, I. Heintz, and D. Roth, “Recent advances in natural language\n       0.4                                                                           processing via large pre-trained language models: A survey,” ACM\n       0.3                                                                 Computing Surveys, vol. 56, no. 2, pp. 1–40, 2023.\n   BER                                                                                 [2] O. Friha, M. Amine Ferrag, B. Kantarci, B. Cakmak, A. Ozgun, and       0.2\n                                                                         N. Ghoualmi-Zine, “LLM-based edge intelligence: A comprehensive\n       0.1                                                                         survey on architectures, applications, security and trustworthiness,” IEEE\n       0                                                           Open Journal of the Communications Society, vol. 5, pp. 5799–5856,\n         0        2000       4000       6000       8000      10000      12000\n                                       Episode                                      2024.\n                           Average Power over Episodes                              [3]  F. Jiang, Y. Peng, L. Dong, K. Wang, K. Yang, C. Pan, D. Niyato, and\n      10                                                                  O. A. Dobre, “Large language model enhanced multi-agent systems for\n       8                                                     6G communications,” IEEE Wireless Communications, 2024.\n      Power 6                                                                              [4] promptingB. Xiao, B.forKantarci,LLM-basedJ. Kang,generativeD. Niyato,internetandof M.things,”Guizani,IEEE“EfficientInternet\n       4                                                                                  of Things Journal, pp. 1–1, 2024.\n       2                                                                              [5]  J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le,\n         0        2000       4000       6000       8000      10000      12000             D. Zhou et al., “Chain-of-thought prompting elicits reasoning in large\n                                       Episode                                      language models,” Adv. Neural Inf. Process. Syst., vol. 35, pp. 24 824–\n                                                                       24 837, 2022.\n                                                                                      [6]  T.  Li,  G.  Zhang,  Q.  D.  Do,  X.  Yue,  and W.  Chen,  “Long-\nFig. 5.  The training performance of the proposed Double DQN algorithm.         context LLMs struggle with long in-context learning,” arXiv preprint\nFigs. 5(a), 5(b), and 5(c) show the fidelity performance, the BER, and the         arXiv:2404.02060, 2024.\npower consumption, respectively.                                                   [7]  F. Xue, Y. Fu, W. Zhou, Z. Zheng, and Y. You, “To repeat or not to\n                                                                                           repeat: Insights from scaling LLM under token-crisis,” Adv. Neural Inf.\n   Fig. 5 shows the proposed algorithm’s performance over         Process. Syst., vol. 36, 2024.\ntraining episodes. Fig. 5(a) plots the average  fidelity over     [8] M. Xu, H. Du, D. Niyato,  J. Kang, Z. Xiong,  S. Mao, Z. Han,\n                                                                         A. Jamalipour, D.  I. Kim, X. Shen et al., “Unleashing the power of\nepisodes. Fidelity measures the accuracy between the model’s                                                                               edge-cloud generative ai in mobile networks: A survey of aigc services,”\noutput and the reference before and after compression. The       IEEE Communications Surveys & Tutorials, 2024.\ncloser the fidelity value is to 1, the more accurate it is after     [9] O. Friha, M. A. Ferrag, B. Kantarci, B. Cakmak, A. Ozgun, and\n                                                                         N. Ghoualmi-Zine, “LLM-based edge intelligence: A comprehensive\nprompt compression, indicating that the compressed prompt                                                                                survey on architectures, applications, security and trustworthiness,” IEEE\nretains most of the original information. We can observe that       Open Journal of the Communications Society, 2024.\nthe fidelity increases with episode growth and maintains a    [10] H. Jiang, Q. Wu, C.-Y. Lin, Y. Yang, and L. Qiu, “LLMLingua: Com-\n                                                                                     pressing prompts for accelerated inference of large language models,”\nrange around 0.9. This indicates that the proposed design is                                                                               arXiv preprint arXiv:2310.05736, 2023.\nachieving high levels of accuracy after prompt compression.    [11] B. Liu, J. Tong, and J. Zhang, “LLM-Slice: Dedicated wireless network\nFig. 5(b) plots the average BER over episodes and shows a de-          slicing for large language models,” in Proc. ACM Conf. Embedded Netw.\n                                                                              Sensor Syst., 2024, pp. 853–854.\ncreasing trend across the episodes. The closer the BER is to 0,                                                                               [12] M. Scherer, L. Macan, V. J. B. Jung, P. Wiese, L. Bompani, A. Burrello,\nthe higher the accuracy that is achieved for the communication          F. Conti, and L. Benini, “Deeploy: Enabling energy-efficient deployment\nsystem. Even in our simulated harsh environment without error         of small language models on heterogeneous microcontrollers,” IEEE\n                                                                                  Transactions on Computer-Aided Design of Integrated Circuits and\ncorrection coding, It is shown that BER drops to a low level                                                                                   Systems, vol. 43, no. 11, pp. 4009–4020, 2024.\nas episodes increase and remains below 0.2, demonstrating    [13]  P. A. Stavrou and M. Kountouris, “The role of fidelity in goal-oriented\nthe system’s effectiveness in minimizing transmission errors.         semantic communication: A rate distortion approach,” IEEE Transac-\n                                                                                           tions on Communications, vol. 71, no. 7, pp. 3918–3931, 2023.\nFig. 5(c) plots the average power consumption over episodes.                                                                               [14] A.  Faiz,  S. Kaneda, R. Wang, R.  Osi,  P. Sharma,  F. Chen, and\nWe can see that the power usage is well-regulated, staying         L. Jiang, “LLMCarbon: Modeling the end-to-end carbon footprint of\nwithin a range of 4 W to 5 W. This controlled power con-          large language models,” in prof. Int. Conf. Learn. Represent.  ICLR,\n                                                                              2024.\nsumption is particularly noteworthy given the inherent trade-                                                                               [15] H. Van Hasselt, A. Guez, and D. Silver, “Deep reinforcement learning\noffs: higher compression ratios can allow more transmit power         with double q-learning,” in Proceedings of the AAAI conference on\nfor reliable transmission, while lower power may compromise           artificial intelligence, vol. 30, no. 1, 2016.\n                                                                               [16] D. Rothman, Transformers for Natural Language Processing: Build,\ntransmission quality. The results in Fig. 5 demonstrate that our                                                                                                 train, and fine-tune deep neural network architectures for NLP with\nproposed algorithm effectively balances multiple objectives -         Python, Hugging Face, and OpenAI’s GPT-3, ChatGPT, and GPT-4.\nmaintaining high fidelity and low BER while keeping energy         Packt Publishing Ltd, 2022.\nconsumption within acceptable limits.",
"headers": [
"JPPO: Joint Power and Prompt Optimization for",
"Accelerated Large Language Model Services",
"arXiv:2411.18010v2  [eess.AS]  22 Feb 2025",
"f"
],
"tables": [
"|Col1|Col2|Col3|\n|---|---|---|\n||||\n||||",
"|Col1|Col2|\n|---|---|",
"|Lins|Ldems|Lque|\n|---|---|---|",
"|Lins|Ldem|s Lque|\n|---|---|---|",
"|f|Prompt Example: Madam Court, could you please read docket 1239? Certainly. Docket 1239. The Committee on<br>Government Operations, to which was referred on December 1st, 2021, docket number 1239 message an order authorizing<br>the creation of a sheltered market program in conformity with the requirements of general laws. Chapter 30 B Section 18.<br>This authorization applies to contracts for goods, professional services and support services. This authorization is for no<br>more than six contracts, which must be awarded by June 30th, 2022. This sheltered market program shall be available for<br>1 disadvantaged, minority and women only vendors, for whom there is a demonstrated substantial disparity in the city's 2020<br>disparities. Study submits a report recommending the order ought to pass. Thank you so much, Madam Clerk. The Chair<br>recognizes Councilor Edwards, chair of the committee. Councilor Edwards. You have the floor. This is this is actually a<br>matter, I believe, sponsored by the. Mayor in Cannes. In conformance with the recommendations from the disparity study<br>and making sure that we opt in to this this pilot program under mass general laws 30 Section 18. Again, it's really just<br>following the recommendations of an already studied issue, which which demonstrates a disparity between minority<br>contractors or women contractors receiving contracts in the city of Boston. … Question: What is the subject of Docket<br>0863?<br>f<br>Tokens: 626 3<br>f<br>2<br>Long Prompt Response : The subject of Docket 0863 is<br>an order for a hearing to discuss pest control<br>and illegal dumping in the city of Boston.<br>SLM Wireless Transmission LLM Response : The subject of Docket 0863 is<br>Short Prompt \"pest control and illegal dumping in Boston.<br>4x Compression: Madam Court read docket 1239? Committee Government Operations referred December 1st 2021<br>sheltered market program laws Chapter 30 B Section 18. contracts goods services six contracts June 30th 2022<br>disadvantaged minority women vendors disparity city 2020 disparities order pass Chair recognizes Councilor Edwards<br>sponsored Mayor disparity study pilot program laws 30 Section 18. disparity minority women contractors Boston … Question:<br>What is the subject of Docket 0863?<br>Tokens: 151 (4x)|\n|---|---|",
"|Mayor i|Col2|\n|---|---|\n|Mayor i|pilot program|",
"|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n||||||\n||||||\n||||||\n|<br>|<br>|aw Reward<br>Moving Average|Reward of DRL|Algorithm|\n|<br>|<br>||||"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2411.18010v2.pdf"
}