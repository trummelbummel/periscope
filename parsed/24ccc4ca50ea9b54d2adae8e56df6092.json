{
"text": "Robust Prompt Optimization for Large Language Models Against\n                                     Distribution Shifts\n\n                  Moxin Li1, Wenjie Wang1∗, Fuli Feng2, 3, Yixin Cao4, Jizhi Zhang2\n                                            Tat-Seng Chua1\n                 1National University of Singapore, 2University of Science and Technology of China\n                     3Institute of Dataspace, Hefei, Anhui, China, 4Singapore Management University\n                 limoxin@u.nus.edu, wangwenjie@u.nus.edu, fulifeng93@gmail.com,\n            caoyixin2011@gmail.com, cdzhangjizhi@mail.ustc.edu.cn,  dcscts@nus.edu.sg\n\n                          Abstract                                 Prompt Optimization\n                                                                                                                                     Training Samples                                                                                              Prompt\n                                                                                                Step 1\n                Large Language Model (LLM) has demon-                 Provide feedback          [Prompt]Light weight laptop      LLM\n                    strated significant ability in various Natural               onor experiencesvarious products...            withfeatures,new batteryamazing\n                Language Processing tasks. However, their ef-                         update              life is awesome.\n                                                                                                Step n                                                                                  !\"       y\n                    fectiveness is highly dependent on the phrasing\n                                                                                                            Provide a sentiment                             Accuracy = 78%\n                   of the task prompt, leading to research on auto-                  analysis of a given              feedback\n                                                                                                                         input text ...2024           matic prompt optimization using labeled task\n                    data. We reveal that these prompt optimization\n                  techniques are vulnerable to distribution shifts                 DeploymentFeb                 such as subpopulation shifts, which are com-                                      Test samples\n                                                                                                           LLM            !\"       y5         mon for LLMs in real-world scenarios such as                                     w/distributionthe same\n                 customer reviews analysis. In this light, we                 Task-specific           (source group)       ! Accuracy = 85%\n                 propose a new problem of robust prompt opti-               optimized prompt        Test samples\n                                                                                                           LLM            !\"       y                 mization for LLMs against distribution shifts,                                    w/distributiona different\n               which requires the prompt optimized over the                                           (target group)       \" Accuracy = ？\n                  labeled source group can simultaneously gen-[cs.CL]             eralize to an unlabeled target group. To solve        Figure 1: Illustration of prompt optimization under dis-\n                     this problem, we propose Generalized Prompt         tribution shifts. Existing prompt optimization solutions\n                 Optimization framework , which incorporates       aim to improve the LLM performance on the training\n                   the unlabeled data from the target group into         data, while it is unclear whether the optimized prompt\n                prompt optimization. Extensive experimental       can be generalized to testing data of the same task but\n                     results demonstrate the effectiveness of the pro-       with distribution shifts.\n                 posed framework with significant performance\n                improvement on the target group and compara-\n                   ble performance on the source group.              McDonell, 2021; Gao et al., 2021), making prompt\n                                                                optimization a promising research direction.\n          1  Introduction                                     Existing research has explored automatic prompt\n                                                               optimization methods to eliminate manual effort\n         LLMs have gained significant attention for their\n                                                                    in identifying effective prompts for a given task.\n            remarkable performance in a broad range of Nat-\n                                                        These methods can be gradient-based or gradient-arXiv:2305.13954v3        ural Language Processing (NLP) tasks (Ouyang                                                                           free, depending on the availability of model gradi-\n                et al., 2022; Chung et al., 2022; Brown et al., 2020;\n                                                                          ents. Gradient-based methods optimize the prompt\n           Touvron et al., 2023). This success has led to a\n                                                     by calculating  its gradients through the LLM\n               shift in the paradigm of solving NLP tasks, mov-\n                                                             (Schick and Schütze, 2021b,a; Hu et al., 2022).\n             ing away from training task-specific deep models\n                                                                Gradient-free methods update prompts based on\n             towards developing task-specific strategies to effec-\n                                      LLM outputs using techniques such as an itera-\n               tively utilize LLMs (Wei et al., 2022; Kojima et al.,\n                                                                            tive search-and-select over the prompt space (Zhou\n            2022; Wang et al., 2022a; Ye et al., 2023b). In the\n                                                                         et al., 2023; Prasad et al., 2022; Pryzant et al.,\n          new paradigm, the prompt becomes a crucial factor\n                                                               2023). This work focuses on gradient-free prompt\n              in ensuring the effectiveness of LLM on the NLP\n                                                                 optimization as LLMs are evolving into black-box\n              task, since even slight variations in prompt phras-\n                                                  API services (Sun et al., 2022).\n             ing can largely affect LLM output (Reynolds and\n                                                                 Current gradient-free prompt optimization meth-\n                  ∗Corresponding author.                          ods ignore distribution shifts (Wang et al., 2023),\n\nwhere the data an LLM serves may differ from      tasks, validating the rationality and effectiveness\nthe labeled data for prompt optimization.  Real-     of our proposed framework.\nworld NLP applications often encounter distribu-\ntion shifts, such as new user groups with distinct   2  Preliminary Experiments\nlinguistic habits in customer review analysis. It is\n                                         Prompt optimization aims to find the best prompt\nunclear if prompts hinder the robustness of LLMs\n                                       p that can instruct LLMs to predict the output y\nagainst distribution shifts. To answer this question,\n                                               based on the concatenation of p and task input\nwe conduct experiments with the representative gpt-\n                                                         x, where x, y and p are all sequences of tokens.\n3.5-turbo-0301 model and prompts optimized by\n                                                    Formally, given an NLP task with a dataset {(x, y)}\nAPE (Zhou et al., 2023) over paired data groups\n                                                  following a distribution P, the goal is to obtain\nwith distribution shifts. Results on 30 pairs of data\ngroups from six tasks show the risk of significant      po = arg max E(x,y)∼P [r(LLM(p, x), y)],   (1)\nperformance gaps under certain distribution shifts.             p∈Z\n  Based on this finding, we propose a new robust\n                                           where Z denotes the prompt optimization spaceprompt optimization problem, which aims to opti-\n                                              and r is the evaluation metric to compare the LLMmize task-specific prompts with consideration of\n                                                  output with the ground truth output y, e.g., Accu-performance on both source and target groups un-\n                                                        racy. Existing studies usually leverage gradient-der different distributions. Given an NLP task such\n                                               based or gradient-free methods to automaticallyas sentiment analysis, our problem setting has a\n                                                optimize the prompts. Since LLMs are evolvinglabeled source group similar as the conventional\n                                                         into black-box API services, gradient-free methodsprompt optimization setting and a unlabeled target\n                                         become increasingly important. However, they ig-group. We keep the target group unlabeled for the\n                                                  nore distribution shifts between training and testingconsideration that distribution shifts happen along\n                                                       data. In this light, we conduct controlled experi-time in practice. Labeling the newly coming target\n                                             ments to answer the following research question:group will cause unnecessary labor cost and latency.\nAccordingly, the main challenge for solving this ro-                                              Are prompts optimized by existing gradient-free\nbust prompt optimization problem is incorporating                                              methods robust to distribution shifts?\nunlabeled data into prompt optimization.\n  To this end, we propose the Generalized Prompt    2.1  Evaluation Protocol\nOptimization (GPO) framework to obtain a task-\n                                We conduct the controlled experiments between\nspecific prompt for both source and target groups.\n                                                a pair of data groups with distribution shifts, i.e.,\nTo jointly considering the two groups in prompt op-\n                                                a source group {(xs, ys)} following a distributiontimization, the key lies in labeling the target group\n                                                  Ps, and a target group {(xt, yt)} with a distribu-in an automatic and reliable manner by adapting\n                                                      tion Pt, where Pt ̸= Ps. We intend to examine\nknowledge from the labeled source group. Towards                                              whether the prompt ps optimized on the source\nthis goal, we leverage the strong power of LLM\n                                             group can generalize to the target group. Specifi-\nin zero-shot labeling, and prompt ensemble to en-                                                              cally, given ps and pt optimized on the target group,\nhance the labeling robustness. Experimental results                                    we compare the performance of ps on the target\non three tasks demonstrate the effectiveness of our\n                                             group E(x,y)∼Pt[r(LLM(ps, x), y)] with that of ptframework in improving the performance on the\n                                                E(x,y)∼Pt[r(LLM(pt, x), y)].target group and simultaneously preserving a com-\nparable performance on the source group. To sum    Datasets. We select 16 datasets from six popu-\nup, our contributions are threefold:                     lar NLP tasks, where each pair of groups under\n                                                    the same task is treated as the source and tar-\n• We reveal the robustness issue of prompt opti-                                                    get groups. Following recent out-of-distribution\n  mization against distribution shifts and propose                                     (OOD) research (Yang et al., 2022), we take each\n  a new robust prompt optimization problem.                                                        dataset as a group and regard different backgrounds\n                                            and topics across the datasets as the distribution• We propose the Generalized Prompt Optimiza-\n                                                             shifts. For the sentiment analysis task, we adopt  tion framework, which generates robust prompts\n                                              Yelp (Zhang et al., 2015), Flipkart (Vaghani and  considering both labeled and unlabeled data.\n                                        Thummar, 2023), IMDB (Maas et al., 2011) and\n• We conduct extensive experiments on three NLP   Amazon (Zhang et al., 2015) of different topics.\n\nTarget                                                              Target\n                       MNLI        ANLI             Source             Yelp        Flipkart    IMDB     Amazon    Source\n                                                                         Yelp              79.7 ± 0.7   78.4 ± 1.9   87.1 ± 1.9   88.4 ± 1.9\n   MNLI                     73.4 ± 1.0       45.4 ± 1.9\n                                                                                      Flipkart           69.1 ± 8.7   85.1 ± 2.9   85.2 ± 9.4   85.9 ± 12.5\n   ANLI                      73.3 ± 1.3       46.0 ± 1.5                                                    IMDB            71.1 ± 8.2   76.9 ± 13.4   91.9 ± 0.9   90.4 ± 5.2\n                                                            Amazon          75.5 ± 1.5   85.6 ± 2.1   91.5 ± 0.8   93.5 ± 1.4\n                  (a) Natural language inference\n                   Target                                                                   (a) Sentiment analysis\n                         RTE        HANS\n    Source                                                                          Target\n                                                                                    SocialIQA    PIQA     OpenbookQA\n   RTE                       78.3 ± 0.8       67.2 ± 1.1          Source\n   HANS                     79.0 ± 0.8       68.4 ± 1.8          SocialIQA          75.6 ± 1.4    82.0 ± 6.0     71.2 ± 5.2\n                                                     PIQA               68.9 ± 6.9    83.6 ± 2.9     69.2 ± 5.1\n                     (b) Textual entailment                     OpenbookQA       79.9 ± 1.0    84.5 ± 1.6     80.1 ± 2.4\n             Target\n                DSTC7    Ubuntu Dialog   MuTual                           (b) Commonsense QA\n  Source\n                                                                                        Target\n  DSTC7           58.4 ± 0.8     78.9 ± 0.3     74.2 ± 2.2                             Number         Spans                                                                   Source\n  Ubuntu Dialog    56.9 ± 1.3     78.7 ± 0.5     74.4 ± 2.1\n  MuTual           52.2 ± 4.4     74.7 ± 6.0     76.7 ± 3.4        Number                    51.9 ± 2.8       20.1 ± 1.3\n                                                                 Spans                      57.7 ± 2.9       63.1 ± 2.2\n                             (c) Dialog\n                                                                                                    (c) DROP\nTable 1: Results for tasks without large generalization\n                                                       Table 2: Results for tasks with significant generalizationperformance gap across groups.\n                                                    performance gap across groups. Bold font indicates the\n                                                               largest value for each column.\n\nFor the natural language inference task, we uti-\nlize MNLI (Williams et al., 2018), and ANLI (Nie\n                                                     data to report the averaged results. More implemen-\net al., 2020) which is an adversarial dataset for\n                                                         tation details can be found in Appendix A.2.\nMNLI. For the textual entailment, we use RTE\n(Wang et al., 2018) and its OOD dataset HANS\n                                                    2.2  Experimental Results\n(McCoy et al., 2019). For commonsense QA, we\nuse SocialIQA (Sap et al., 2019), PIQA (Bisk et al.,   Demonstration of Generalization Performance\n2020), and OpenbookQA (Mihaylov et al., 2018),   Gap.  Table 1 shows the tasks without a large\nwhich focus on different types of commonsense    generalization gap between the performance of\nknowledge. For the multi-turn dialog reasoning,   prompts ps and pt, and Table 2 shows the tasks\nwe use DSTC7 (Gunasekara et al., 2019), Ubuntu   with large gaps (Accuracy gap>8.0) on some\nDialog (Lowe et al., 2015), and MuTual (Cui et al.,   groups. The row headers refer to the source groups\n2020). Besides, for the numerical QA task, we use    for prompt optimization while the column headers\nthe samples of two different answer types (i.e., nu-   show the target groups to test optimized prompts.\nmerical values and text spans) in DROP (Dua et al.,   The generalization performance gap between ps\n2019) as two groups. See Appendix A.1 for details.   and pt can be observed by comparing the values in\n                                                     the same column.\nExperimental Setup. We adopt APE (Zhou et al.,\n                                         From the tables, we can observe: 1) The gener-2023), an effective gradient-free prompt optimiza-\n                                                       alization performance gap may not exist for pre-tion method, for prompt generalization analysis.\n                                                  viously studied OOD and adversarial groups (seeTo highlight the effect of prompts, we conduct ex-\n                                                Table 1), including the groups of the natural lan-periments under the zero-shot setting without in-\n                                            guage inference and the textual entailment tasks.context examples. For the backbone LLMs, we\n                                                 This is possibly attributed to the strong generaliza-leverage gpt-3.5-turbo-0301 by calling the OpenAI\nAPI1. For all classification tasks (all tasks except    tion ability of LLMs. 2) However, under some data\n                                               groups of Table 2 such as the sentiment analysisfor DROP), we use accuracy as the evaluation met-\n                                                       datasets (e.g., Flipkart and Yelp) and the common-ric. For DROP, we utilize its standard evaluation\n                                                   sense QA datasets with different topics (e.g., PIQAmetric — F1. Following the setting of APE, we\n                                            and OpenbookQA), and the DROP groups withrandomly sample N-shot training and N-shot vali-\n                                                        different answer types, there are still significantdation samples for prompt optimization, and repeat\n                                                    generalization performance gaps, demonstratingthe experiments for five runs with different sampled\n                                                     the existence of the generalization issue of prompt\n   1https://chat.openai.com/.                        optimization. 3) Surprisingly, the prompt ps op-\n\nTarget                                                                SocialIQA    PIQA     OpenbookQA\n                      Yelp    Flipkart  IMDB   Amazon\n   Source                                                      word 1-gram      0.43            0.51       0.58\n   Yelp                     -       0.33       1.62      1.62              char 4-gram       0.50            0.60       0.65\n   Flipkart             0.30     -          0.57      0.56\n                                                                                            (a) The n-gram diversity.\n  IMDB              0.25    0.29         -        0\n  Amazon            0.25    0.27      0           -                                 Target      SocialIQA    PIQA     OpenbookQA\n                                                                            Source\n(a) Label distribution shifts. Smaller values indicate less distri-      SocialIQA                    -               0.39       0.38\nbution shifts.                                                 PIQA                   0.47               -           0.46\n                                                              OpenbookQA            0.51            0.52          -\n              Target\n                      Yelp    Flipkart  IMDB   Amazon\n   Source                                                               (b) The word 1-gram coverage ratio between groups.\n   Yelp                     -       0.65       0.73      0.76                             Target      SocialIQA    PIQA     OpenbookQA\n   Flipkart             0.59     -          0.55      0.63              Source\n  IMDB              0.70    0.63         -         0.81              SocialIQA                    -               0.51       0.51\n  Amazon            0.71    0.70       0.78       -              PIQA                   0.60               -           0.58\n                                                              OpenbookQA            0.66            0.64          -\n(b) Input similarity. Larger values indicate less distribution shifts.\n                                                                           (c) The character 4-gram coverage ratio between groups.\n\nTable 3: Results for (a) label distribution shifts (b) input                                                     Table 4: Evaluation on (a) the n-gram diversity and\nsimilarity of the sentiment analysis datasets. Bold font                                                            (b) word 1-gram coverage ratio (c) character 4-gram\nindicates the least distribution shift for each column.                                                    coverage ratio of commonsense QA datasets to study\n                                                         the even higher generalization performance. Bold font\n                                                            indicates the largest value for each column.\ntimized from the source group does not always\nperform worse than the prompt pt optimized on the\ntarget group. In Table 2(b), ps from OpenbookQA   formance. Nevertheless, the two metrics cannot\nperforms even better than pt for SocialIQA. Be-   perfectly explain the performance on all tasks (cf.\nsides, for DROP in Table 2(c), ps from Spans also   Appendix A.3). Therefore, Q1 is still a challenging\nperforms better than pt from Number. In the fol-   research question, requiring further exploration in\nlowing section, we try to explore the reasons for    future work.\nthe above three observations.                        For Q2, we conjecture that the outstanding gen-\n                                                        eralization performance is because a source group\nExploration on the Factors Affecting Prompt                                                with large diversity covers heterogeneous patterns\nRobustness.  Based on the above observations,                                                         in the target group, leading to a more robust prompt\nwe further explore two research questions.          ps than pt. To explore this, we measure the het-\nQ1: Why do the prompts optimized on source                                                  erogeneity of source and target groups by calcu-\ngroups perform differently on a target group?                                                        lating the percentage of unique n-grams, and the\nQ2: Why does the prompt optimized on the source    percentage of n-grams of the target group covered\ngroup perform even better than the prompt opti-   by the source group. For illustration, we present\nmized on the target group in some cases?             the results of the commonsense QA task in Table 4.\n  For Q1, we conjecture that the varied perfor-   From Table 4(a), we can observe that OpenbookQA\nmance gaps are attributed to different distribution    has the most diverse input according to the n-gram\nshifts between the source and target groups. To     statistics. Moreover, OpenbookQA covers a large\nverify this, we examine two metrics to measure    proportion of n-grams of SocialIQA and PIQA.\ntwo kinds of distribution shifts: 1) the label shifts   These partly explain the superiority of the prompts\nmeasured by the KL divergence, and 2) the input    optimized on OpenbookQA (see Table 2).\nsimilarity quantified by the n-gram similarity of\nthe input corpora of the two groups. Their detailed   3  Robust Prompt Optimization\nimplementation is illustrated in Appendix A.3. We\n                                                   In this section, we first formulate a robust promptshow the results of the sentiment analysis task as\n                                                  optimization problem and propose a GPO frame-an example in Table 3. We can observe that the\n                                          work to enhance the robustness of the prompts.smallest label distribution shifts and the largest in-\nput similarity in Table 3 generally coincide with\n                                                    3.1  Problem Definition\nthe best generalization performance on each tar-\nget group in Table 2, indicating the correlation   To enhance the generalization ability of prompts,\nbetween distribution shifts and generalization per-  we propose a robust prompt optimization prob-\n\nMeta Prompt                          more, the collected source group data cannot cover\n            My friend was given an\n                    instruction. Based on              K prompts     all potential target groups, and the prompts opti-\n                 the instruction, I gave\n                                                     Provide                                            mized on the source groups may inevitably test on                                                      Provide               him                     several inputs,                              and                                                       Provide                                   1        1                                                   feedback   Source  1                                                    feedback              he generated                              the                                                    feedback                                                      ononon                                                      the examples from previously unseen groups. Thus,   group\n                corresponding outputs.                               LLM      variousvariousvarious\n   data !\"      Here are the input-                    productsproductsproductsororor   we aim at improving the generalization ability of\n                 output examples:                                                     experiencesexperiencesexperiences.........\n                  [Input: … Output: …]                      one task-specific prompt across different groups.\n    3         The instruction is to             Ensemble\n                                               Labeling    2     3.2 GPO Framework\n                         Labeled\n               3                          2                               target                                         To obtain a robust prompt for both the source and   APE                                          LLM                         group\n          Upsampling                           data !%∗   Consistency > (             target groups, it is natural to jointly consider Gs\n   3                                                  2     and Gt for prompt optimization. However, Gt lacks\n                                                   Unlabeled Optimized                                                     the labels {yt} that are commonly required by the                                                             target  Prompt\n                                                  group      gradient-free optimization methods (refer to Ta-\n                                                      data {$%}\n                                                      ble 5 for the inferior results without labeling). With\n                                                    the impressive capabilities of LLMs on zero-shot\n           Figure 2: The GPO Framework.\n                                                         labeling, we propose to utilize LLMs to label {xt}.\n                                                  Considering that noisy labels may damage the qual-\nlem. Specifically, given an NLP task such as sen-\n                                                            ity of optimized prompts, we further present two\ntiment analysis, it aims to optimize a task-specific\n                                                         strategies to improve labeling accuracy.\nprompt for the data groups with different distri-\n                                          As illustrated in Figure 2, we first propose a Metabutions. We consider the popular scenario where\n                                           Prompt to instruct LLMs to acquire knowledge\na source group Gs = {(xs, ys)} following a dis-\n                                             from the labeled source group and generate a seriestribution Ps and {xt} in a unlabeled target group\n                                                     of prompts. Thereafter, we utilize a prompt ensem-\nGt = {(xt, yt)} ∼Pt (Pt ̸= Ps) are available\n                                                    ble labeling strategy to apply generated prompts\nwhile {yt} is unseen during prompt optimization.\n                                                      to an LLM for precise labeling of {xt}. In detail,The objective becomes utilizing Gs = {(xs, ys)}\n                                    we derive a three-step framework to perform theand {xt} to optimize a task-specific prompt robust\n                                                       labeling with two strategies, and then conduct joint\nto the samples from either Ps or Pt.\n                                             prompt optimization as shown in Figure 2.\nReasons for Access to Unlabeled Target Group.\nIn a real-world deployment, LLMs continually en-    1. Prompt Generation via Meta Prompt. Fol-\ncounter the testing data with distribution shifts. Col-      lowing APE, we utilize a Meta Prompt to ask\nlecting the input features {xt} of the target group    LLM to generate prompts for labeling by feed-\nis feasible. For example, when using LLMs as web      ing the examples of Gs (see an example in Fig-\nservices to solve user queries of certain NLP tasks,      ure 2). Based on strong language understanding\nit is easy to collect extensive user queries as unla-     and reasoning abilities, LLMs can infer the re-\nbeled target groups. However, labeling {xt} may       lationships between the inputs and outputs of\nbe time-consuming and costly, and thus we intend       the examples and provide general and precise\nto optimize robust prompts without the labels of       task prompts. We use different splits of Gs to\nthe target group.                                      generate K different prompts in total.\n\nA Task-Specific Prompt vs. One Prompt for    2. Prompt Ensemble Labeling Strategy. Given\nEach Group.  To tackle the generalization issue   K prompts, we utilize each of them to label {xt}\nof optimized prompts, an intuitive approach is to      with an LLM, and thus obtain K candidate la-\noptimize a separate prompt for each data group, yet       bels for each example. We adopt an ensembling\nthis simplistic approach faces several limitations       strategy and select the label with the highest\nin real scenarios. In real-world deployment, it not      consistency among the K candidate labels for\nonly requires additional computation costs to con-      each example.  Besides, inspired from Wang\nstruct more prompts, but also needs to accurately       et al. (2022a), we set a consistency threshold\nclassify each testing sample into the appropriate     T ∈[0, 1] to only accept the labeled examples\ngroup of the same distribution, thereby resulting        that have more than T percent of prompts agreed\nin increased computation costs, latency, and new     on the label. Eventually, we obtain a filtered la-\nchallenges for precise group classification. Further-      beled set G∗t for the target group.\n\n3. Joint Prompt Optimization. Finally, we mix                    Yelp (Source)             Flipkart (Target)\n\n                                                                        Top 1      Ensemble   Top 1      Ensemble  Gs and G∗t to run APE for joint prompt opti-\n   mization and obtain the final optimized prompt.    APE           79.7 ± 0.7   79.7 ± 1.0   78.4 ± 1.9   81.3 ± 1.4\n  As G∗t may have fewer samples than Gs after    APO          78.9 ± 0.5   79.7 ± 0.8   74.7 ± 3.0   76.4 ± 1.4                                                         APE+ut       78.9 ± 1.4   78.8 ± 1.4   80.3 ± 2.0   80.7 ± 2.1\n   filtering with T, we perform a random upsam-    GPO          79.1 ± 0.7   78.7 ± 0.9   80.5 ± 2.1   84.5 ± 2.0\n   pling on G∗t to have the same data number as Gs      Upper Bound   -               -            85.1 ± 2.9   87.2 ± 0.5\n   before running APE. A brief illustration about\n                                                                                             (a) Sentiment analysis.\n  APE can be found in Appendix A.2.\n                                                                              SocialIQA (Source)     OpenbookQA (Target)\n4  Experiments                                                    Top 1      Ensemble   Top 1      Ensemble\n                                                APE           75.6 ± 1.4   69.6 ± 5.3   71.2 ± 5.2   74.8 ± 3.2\n4.1  Setup                                    APO          76.1 ± 2.7   72.3 ± 2.6   72.4 ± 2.5   66.1 ± 7.2\n                                                         APE+ut       77.9 ± 1.3   78.9 ± 0.8   77.5 ± 3.0   79.2 ±1.2\nDatasets. We experiment GPO with three tasks:    GPO          76.7 ± 2.0   78.9 ± 1.2   78.7 ± 3.3   79.7 ± 0.8\nsentiment analysis, commonsense QA, and DROP.                                                             Upper Bound   -               -            80.1 ± 2.4   80.8 ± 1.1\nFor each task, we select a pair of groups with gen-\n                                                                                        (b) Commonsense QA.\neralization performance gap as source and target\ngroups, and ablate the labels for the target groups.                 Number (Source)        Spans (Target)\nCompared Methods. We adopt the following base-                  Top 1      Ensemble   Top 1       Ensemble\nline methods: 1) APE; 2) APO (Pryzant et al.,    APE           51.9 ± 2.8   51.0 ± 3.2   20.1 ± 1.3    18.2 ± 0.2\n                                              APO          55.7 ± 0.8   54.5 ± 2.1   20.2 ± 2.4    20.0 ± 2.2\n2023), the state-of-the-art gradient-free prompt op-     APE+ut       52.0 ± 1.8   53.1 ± 1.2   16.1 ± 3.5    17.7 ± 2.8\ntimization method for LLM; 3) APE-ut, a naive    GPO          52.2 ± 6.0   53.6 ± 3.0   27.7 ± 12.0   26.7 ± 4.9\ngeneralization solution by incorporating the unla-     Upper Bound   -               -            63.1 ± 2.2    63.7 ± 0.8\nbeled target group input into APE; 4) the Upper                                  (c) DROP.\nBound, which represents the performance of the\nprompt optimized on the target group data with    Table 5: Results of the compared methods. Bold font\n                                                            indicates the best performance for each column.\nground-truth labels by APE; and 5) our proposed\nGPO; We also show the results of simple human-\nwritten prompts that are general for the task, and                                             group does not largely hinder the source group.\nthe revised versions by PromptPerfect2 which is an                                         Compared with APE, GPO shows increased per-\nautomatic prompt engineering website.                                             formance on the source groups of SocialIQA and\nEvaluation Protocol. We utilize two strategies                                       Number by incorporating the target group data,\nfor testing: Top 1 and Ensemble. Top 1 refers to                                           which is in line with the finding in Table 2.  3)\nusing the single optimized prompt with the best                                              Across baselines, APO outperforms APE on the\nvalidation performance, while Ensemble refers to                                                   source groups of the last two tasks and achieve com-\nlabeling with all obtained K prompts and accept                                                   parable performance on sentiment analysis, show-\nthe output with the most agreement on the prompts.                                                    ing its effectiveness for prompt optimization. How-\nWe utilize the same N-shot data as the preliminary                                                         ever, the generalization ability is only comparable\nexperiments and also report the averaged results                                                      to APE since APO performs worse than APE on\nfor five runs. More implementation details are il-                                                       several target groups. 4) APE-ut achieves improved\nlustrated in Appendix A.4.                                                           target group performance for the first two task, indi-\n                                                      cating the benefit of incorporating unlabeled target4.2  Performance Comparison\n                                              group data for generalization. However, for Spans\nCompare to Generated Prompts. From Table 5,                                            where obtaining accurate target labels is challeng-\nwe can observe the followings: 1) GPO achieves                                                    ing (as shown by the low F1 values), APE-ut largely\nsuperior performance for all target groups in both                                               underperforms GPO, showing the importance of\nTop 1 and Ensemble testing, validating its effective-                                                         target group labeling especially for difficult tasks.\nness. However, there is still space for improvement                                       Compare to Human-written Prompts. From\ntowards the Upper Bound for all tasks, showing the                                                 Table 6, we further observe that GPO outperforms\nchallenge of the generalization problem. 2) GPO                                                human-written prompts and PromptPerfect for sen-\nachieves comparable source group performance for                                                   timent analysis and commonsense QA tasks. How-\nall tasks, showing its improvement on the target                                                         ever, on the most difficult task DROP, GPO under-\n   2https://promptperfect.jina.ai.                 performs human-written prompts. This is poten-\n\nYelp (Source)   Flipkart (Target)  SocialIQA (Source)  OpenbookQA (Target)  Number (Source)  Spans (Target)\n\n Human         78.7           80.0              71.3                 60.0                   54.9              37.1\n  PromptPerfect   77.3           83.3              74.7                 64.0                   54.0              26.9\n GPO best       78.7           84.5              78.9                 79.7                   52.2              27.7\n\nTable 6: Performance comparison for the human-written prompts, PromptPerfect and the more effect testing strategy\nof GPO (Top 1 or Ensemble, denoted as GPO best). Bold font indicates the best performance for each column.\n\n\ntially because the inaccurate labels for Spans hinder                       Flipkart  OpenbookQA  Spans\nthe prompt optimization. Similarly, PromptPerfect          w/o cons   81.9      69.8            3.6\nalso fail to optimize human-written prompts for       GPO      94.2      84.3            3.7\nDROP.\n                                                       Table 8: The labeling accuracy comparison for the target\n4.3  Ablation Study                               group training and validation data on GPO and w/o cons.\n                                              The results for Spans here is accuracy instead of F1.\n\n                   Yelp                      Flipkart\n                                              w/o cons and w/o cons+t-train, removing the target\n                 Top 1      Ensemble   Top 1      Ensemble\n                                               group training data benefits the Top 1 results of the GPO             79.1 ± 0.7   78.7 ± 0.9   80.5 ± 2.1   84.5 ± 2.0\n  w/o cons         78.8 ± 1.2   78.7 ± 0.4   81.5 ± 1.4   84.0 ± 0.9   source group, but harms the Ensemble results of\n  w/o cons+t-train   79.9 ± 0.8   79.7 ± 1.0   80.3 ± 3.2   81.3 ± 1.4   the target groups.  It has less effect on the target\n                      (a) Sentiment analysis.                group Top 1 results since the two methods still use\n                  SocialIQA            OpenbookQA           target group validation data.\n\n                 Top 1      Ensemble   Top 1      Ensemble\n\n GPO             76.7 ± 2.0   78.9 ± 1.2   78.7 ± 3.3   79.7 ± 0.8   4.4  In-depth Analysis\n  w/o cons         76.0 ± 2.8   78.1 ± 1.4   77.6 ± 3.8   78.8 ± 2.2\n  w/o cons+t-train   77.9 ± 1.6   69.6 ± 5.3   78.2 ± 2.2   74.8 ± 3.2\n                                                 Analysis on the Effect of the Consistency Thresh-\n                     (b) Commonsense QA.                  old.  To further reveal the effect of consistency\n                Number                Spans                threshold, we first show the labeling accuracy of\n                 Top 1      Ensemble   Top 1       Ensemble    the target group training and validation data for\n GPO             52.2 ± 6.0   53.6 ± 3.0   27.7 ± 12.0   26.7 ± 4.9  GPO and w/o cons in Table 8. We can observe that\n  w/o cons         49.3 ± 2.8   51.0 ± 2.1   20.6 ± 2.1    22.2 ± 3.2\n  w/o cons+t-train   51.3 ± 3.6   50.9 ± 1.6   20.4 ± 1.9    18.7 ± 2.2   applying the consistency threshold can improve\n                                                    the labeling accuracy for all target groups. By\n                             (c) DROP.\n                                             examining the relationship between this labeling\nTable 7: Ablation study. Bold-font and underline indi-   accuracy improvement and the performance differ-\ncate the best and second-best results, respectively.       ence between GPO and w/o cons in Table 7, it can\n                                             be explained that for Flipkart and OpenbookQA,\n  We study the effect of prompt ensemble labeling   where the labeling accuracy is already high under\nand joint prompt optimization by evaluating two   w/o cons, further improving the labeling accuracy\nmodifications of GPO: (1) setting the consistency   by the consistency threshold is unlikely to achieve\nthreshold as 0, denoted as w/o cons; and (2) remov-   large performance gain. Conversely, in the case\ning the target group training data during the final    of Spans with low labeling accuracy, even a minor\nprompt generation, denoted as w/o cons+t-train.   improvement can result in significant performance\nFrom Table 7, we can observe that: 1) In all cases    gains. To explore the connection between labeling\nexcept for Flipkart with Top 1 evaluation, GPO    accuracy and target group performance further, we\nperforms better than w/o cons on target groups,   conducted an experiment where we manually as-\nshowing the effectiveness of the consistency thresh-   signed incorrect labels to varying proportions (0%,\nold. 2) Among the three tasks, DROP has large   50%, and 90%) of the target training and valida-\nimprovement between w/o cons and GPO on both    tion data. The results are illustrated in Figure 3.\nsource and target groups then the other two tasks.    It can be observed that as the percentage of incor-\nWe hypothesis that this discrepancy is related to the    rect labels increases, the overall performance on\ndifferent degrees of improvement in the labeling    the target group generally decreases, emphasizing\naccuracy by the consistency threshold, which will    the importance of labeling accuracy for achieving\nbe further discussed in Section 4.4. 3) Comparing    effective generalization.\n\nFlipkart           OpenbookQA            Spans\n   90                    90                   100             and spurious correlation (Tang et al., 2023; Stolfo\n   85                    85                    80                 et al., 2022). Moreover, LLMs remain vulnerable\n   80                    80                    60                to adversarial perturbations and achieve inconsis-\n   75                        75                                              40                tent results (Wang et al., 2023; Ye et al., 2023a;Accuracy                                                                      Accuracy                                                                                                                                         Accuracy\n   70                    70                    20             Liang et al., 2022). Additionally, LLMs demon-\n   65                        65                                               0\n      0      50    90                            0      50    90                                                  0      50    90   strate high sensitivity to the prompt (Reynolds and\n    % Incorrect Label    % Incorrect Label    % Incorrect Label  McDonell, 2021; Zhu et al., 2023) and the selec-\nFigure 3: Target group performance under different per-    tion of in-context examples (Liu et al., 2022; Ru-\ncentage of wrong labels. The blue dotted line indicates    bin et al., 2022). Lastly, instruction tuning allows\nthe labeling accuracy of GPO as in Table 8.         LLMs to generalize to novel tasks (Ouyang et al.,\n                                                2022; Wang et al., 2022b,a). We specifically focus\n            Top 1                 Ensemble            on the generalization issue of prompt optimization\n          APE     GPO     APE     GPO       on the distribution shifts within one task.\n Vicuna-7B  38.4 ± 25.3 63.5 ± 15.6 43.9 ± 21.3 71.9 ± 13.1\n Vicuna-13B 66.8 ± 18.4 68.3 ± 13.7 60.7 ± 9.5  70.7 ± 10.8  Prompt  Optimization.  Obtaining   effective\n GPT-3.5    78.4 ± 1.9  80.5 ± 2.1  81.3 ± 1.4  84.5 ± 2.0   prompts for applying LLM in NLP tasks is a popu-\n GPT-4      77.5 ± 13.7 85.3 ± 2.7  83.3 ± 0.0  85.4 ± 2.4\n                                                             lar research area. Prompt tuning methods (Li and\n                                                 Liang, 2021; Lester et al., 2021; Qin and Eisner,Table 9: Performance comparison of APE and GPO on\n                                                 2021; Gu et al., 2022) learn soft continuous vectorsFlipkart of different backbone LLMs.\n                                                   as prompts in the LLM input using gradients\nGPO with Different Backbone LLMs.  We also                                            from the task objective. Recent studies have also\nconducted experiments with GPO using different                                                focused on gradient-free prompt optimization for\nbackbone LLMs, including Vicuna 7B and 13B                                                black-box LLM, such as reinforcement learning-\n(Chiang et al., 2023) which are notable smaller-                                               based methods (Zhang et al., 2023; Deng et al.,\nsized LLMs, and GPT-4 (OpenAI, 2023). Table 9                                               2022; Diao et al., 2022), search-based methods\nshows the generalization results on Flipkart with                                          (Brown et al., 2020; Prasad et al., 2022; Pryzant\nYelp as the source group for APE and GPO on dif-                                                           et al., 2023), and other gradient-free optimization\nferent backbone LLMs. Due to the small sizes of                                                    techniques like evolutionary algorithms (Sun et al.,\nthe Vicuna models, generating the exact sentiment                                              2022) and boosting (Hou et al., 2022). Among\nlabel as the answer can be challenging. Therefore,                                               them, the state-of-the-art methods leverage the\nwe extract the sentiment labels from their outputs                                           power of LLMs for prompt optimization, such as\nbefore calculating the accuracy. The results show                                            prompt generation and evaluation by LLM (APE\nthat there is room for enhancing the generalization                                            (Zhou et al., 2023)) and prompt editing following\nperformance in APE across various LLMs, and                                                        critiques (APO (Pryzant et al., 2023)), where we\nGPO consistently outperforms APE in all cases.                                              mainly compare with them. Notably, while some\nNotably, when applying GPO to the smaller Vicuna    previous work on prompt tuning has addressed\n7B model, there is a significant improvement that                                                     generalization across tasks and models (Su et al.,\nallows it to reach the same performance level as                                                 2022; Vu et al., 2021; Qin et al., 2023), and domain\nthe Vicuna 13B model. Across LLMs, the smaller-                                                     adaptation (Tam et al., 2022; Guo et al., 2022), this\nsized Vicuna models achieve relatively worse per-                                                paper specifically focuses on the generalization\nformance, and the powerful GPT-4 achieves the                                                      issue of gradient-free prompt optimization.\nbest performance on GPO.\n                                        6  Conclusion\n5  Related Work\n                                                    In this paper, we revealed the generalization issue\nGeneralization Ability and Robustness of LLM.   of prompt optimization for LLMs under distribu-\nResearchers have been investigating the gener-    tion shifts. We observed that the prompt optimized\nalization ability and robustness of LLMs since   on the source data group may have a performance\ntheir recent breakthrough. LLMs like ChatGPT   drop on the target group with distribution shifts.\nhave shown significant improvement in out-of-  We performed an initial analysis aiming at identi-\ndistribution (OOD) and adversarial tasks (Wang    fying the factors that correlate to the varied gen-\net al., 2023), although they are still imperfect (Chen    eralization performance across groups, including\net al., 2023). Some LLMs still rely on shortcuts    label distribution shift and input distribution sim-\n\nilarity. To enhance the generalization ability of\nLLMs, we proposed a Generalized Prompt Opti-\nmization framework to jointly consider the source\nand target groups for robust prompt optimization.\nExperimental results validated the effectiveness of\nour proposed framework in boosting the robustness\nof the prompts on the source and target groups. In\nfuture work, we plan to study the prompt general-\nization to unseen target groups without available\ninputs {xt}, and explore prompt generalization abil-\nity with in-context examples from different groups.\n\nLimitations                                               Stoica, and Eric P. Xing. 2023. Vicuna: An open-\n                                                        source chatbot impressing gpt-4 with 90%* chatgpt\nFirstly, this work discusses the generalization abil-       quality.\nity of prompts while ignoring the effect of other\n                                           Hyung Won Chung, Le Hou, Shayne Longpre, Bar-LLM inputs such as in-context examples. The\n                                                                     ret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nchoice of in-context examples might also affect                                                Wang, Mostafa Dehghani, Siddhartha Brahma, et al.\nthe robustness of LLMs. Future work can look into      2022. Scaling instruction-finetuned language models.\nthe generalization issue of the prompt in combina-      arXiv preprint arXiv:2210.11416.\ntion with in-context examples. Secondly, this work\n                                               Leyang Cui, Yu Wu, Shujie Liu, Yue Zhang, and Ming\nassumes the availability of the inputs {xt} of the      Zhou. 2020. Mutual: A dataset for multi-turn dia-\ntarget group. It is under-explored how to achieve      logue reasoning. arXiv preprint arXiv:2004.04494.\ngeneralized prompt optimization to completely un-\n                                                  Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihanseen groups without {xt}. To improve the robust-\n                                               Wang, Han Guo, Tianmin Shu, Meng Song, Eric P\nness on these groups, we believe it is helpful to                                                      Xing, and Zhiting Hu. 2022. Rlprompt: Optimizing\nextend this work toward robust prompt optimiza-       discrete text prompts with reinforcement learning.\ntion on multiple heterogeneous groups. Thirdly,      arXiv preprint arXiv:2205.12548.\nwe acknowledge that the scope of our research\n                                                   Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nis limited to black-box LLMs capable of under-                                                            Kristina Toutanova. 2019. BERT: Pre-training of\nstanding instructions, where gradient-free prompt      deep bidirectional transformers for language under-\noptimization with instructing LLM is a suitable       standing. In Proceedings of the 2019 Conference of\nchoice. For smaller LMs without instruction under-      the North American Chapter of the Association for\n                                                     Computational Linguistics: Human Language Tech-\nstanding abilities, e.g., BERT (Devlin et al., 2019)\n                                                            nologies, Volume 1 (Long and Short Papers), pages\nand T5 (Raffel et al., 2020), they are generally not      4171–4186, Minneapolis, Minnesota. Association for\nblack-box and are more advantageous to utilize      Computational Linguistics.\ngradient-based prompt optimization methods.\n                                                   Shizhe Diao, Zhichao Huang, Ruijia Xu, Xuechun Li,\n                                                Yong Lin, Xiao Zhou, and Tong Zhang. 2022. Black-Acknowledgements\n                                                   box prompt learning for pre-trained language models.\n                                                        arXiv preprint arXiv:2201.08531.This work is supported by NExT Research Center,\nand the National Natural Science Foundation of                                               Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel\nChina (62272437). We thank the reviewers for      Stanovsky, Sameer Singh, and Matt Gardner. 2019.\ntheir constructive feedback.                           Drop: A reading comprehension benchmark re-\n                                                           quiring discrete reasoning over paragraphs. arXiv\n                                                             preprint arXiv:1903.00161.\nReferences                                                  Tianyu Gao, Adam Fisch, and Danqi Chen. 2021.\nYonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi,     Making pre-trained language models better few-shot\n   et al. 2020.  Piqa: Reasoning about physical com-       learners. In Proceedings of the 59th Annual Meet-\n  monsense in natural language. In Proceedings of the       ing of the Association for Computational Linguistics\n  AAAI conference on artificial intelligence, volume 34,     and the 11th International Joint Conference on Natu-\n  pages 7432–7439.                                          ral Language Processing (Volume 1: Long Papers),\n                                                      pages 3816–3830.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\n   Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind    Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang.\n   Neelakantan, Pranav Shyam, Girish Sastry, Amanda      2022. Ppt: Pre-trained prompt tuning for few-shot\n   Askell, et al. 2020. Language models are few-shot       learning. In Proceedings of the 60th Annual Meet-\n   learners. Advances in neural information processing       ing of the Association for Computational Linguistics\n   systems, 33:1877–1901.                              (Volume 1: Long Papers), pages 8410–8423.\n\nXuanting Chen, Junjie Ye, Can Zu, Nuo Xu, Rui Zheng,   Chulaka Gunasekara, Jonathan K Kummerfeld, Lazaros\n  Minlong Peng, Jie Zhou, Tao Gui, Qi Zhang, and      Polymenakos, and Walter Lasecki. 2019. Dstc7 task\n  Xuanjing Huang. 2023. How robust is gpt-3.5 to pre-       1: Noetic end-to-end response selection. In Proceed-\n   decessors? a comprehensive study on language un-      ings of the First Workshop on NLP for Conversational\n   derstanding tasks. arXiv preprint arXiv:2303.00293.      AI, pages 60–67.\n\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,   Xu Guo, Boyang Li, and Han Yu. 2022. Improving\n  Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan       the sample efficiency of prompt tuning with domain\n  Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion       adaptation. arXiv preprint arXiv:2210.02952.\n\nBairu Hou, Joe O’Connor, Jacob Andreas, Shiyu Chang,   Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish\n  and Yang Zhang. 2022. Promptboosting: Black-box      Sabharwal. 2018. Can a suit of armor conduct elec-\n   text classification with ten forward passes.  arXiv        tricity? a new dataset for open book question answer-\n   preprint arXiv:2212.09257.                                 ing. arXiv preprint arXiv:1809.02789.\n\nShengding Hu, Ning Ding, Huadong Wang, Zhiyuan    Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,\n   Liu, Jingang Wang, Juanzi Li, Wei Wu, and Maosong      Jason Weston, and Douwe Kiela. 2020. Adversarial\n  Sun. 2022. Knowledgeable prompt-tuning: Incor-        nli: A new benchmark for natural language under-\n   porating knowledge into prompt verbalizer for text       standing. In Proceedings of the 58th Annual Meet-\n   classification.  In Proceedings of the 60th Annual       ing of the Association for Computational Linguistics,\n  Meeting of the Association for Computational Lin-      pages 4885–4901.\n   guistics (Volume 1: Long Papers), pages 2225–2240.                                                OpenAI. 2023. Gpt-4 technical report.\n\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-   Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\n   taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-       Carroll Wainwright, Pamela Mishkin, Chong Zhang,\n  guage models are zero-shot reasoners. arXiv preprint      Sandhini Agarwal, Katarina Slama, Alex Ray, et al.\n  arXiv:2205.11916.                                   2022. Training language models to follow instruc-\n                                                              tions with human feedback.  Advances in Neural\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021.      Information Processing Systems, 35:27730–27744.\n  The power of scale for parameter-efficient prompt\n   tuning. In Proceedings of the 2021 Conference on    Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit\n  Empirical Methods in Natural Language Processing,      Bansal. 2022. Grips: Gradient-free, edit-based in-\n  pages 3045–3059.                                           struction search for prompting large language models.\n                                                        arXiv preprint arXiv:2203.07281.\nXiang Lisa Li and Percy Liang. 2021. Prefix-tuning:\n                                                 Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chen-  Optimizing continuous prompts for generation. In\n                                                  guang Zhu, and Michael Zeng. 2023.  Automatic  Proceedings of the 59th Annual Meeting of the Asso-\n                                                  prompt optimization with\" gradient descent\" and   ciation for Computational Linguistics and the 11th\n                                              beam search. arXiv preprint arXiv:2305.03495.   International Joint Conference on Natural Language\n  Processing (Volume 1: Long Papers), pages 4582–                                                Chengwei Qin, Shafiq Joty, Qian Li, and Ruochen Zhao.\n  4597.                                                      2023. Learning to initialize: Can meta learning im-\n                                                      prove cross-task generalization in prompt tuning?\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris                                                        arXiv preprint arXiv:2302.08143.\n   Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian\n  Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-   Guanghui Qin and Jason Eisner. 2021. Learning how\n  mar, et al. 2022.  Holistic evaluation of language       to ask: Querying lms with mixtures of soft prompts.\n  models. arXiv preprint arXiv:2211.09110.                In Proceedings of the 2021 Conference of the North\n                                                  American Chapter of the Association for Computa-\nJiachang Liu, Dinghan Shen, Yizhe Zhang, William B       tional Linguistics: Human Language Technologies,\n  Dolan, Lawrence Carin, and Weizhu Chen. 2022.      pages 5203–5212.\n  What makes good in-context examples for gpt-3?\n   In Proceedings of Deep Learning Inside Out (Dee-   Colin Raffel, Noam Shazeer, Adam Roberts, Katherine\n  LIO 2022): The 3rd Workshop on Knowledge Extrac-      Lee, Sharan Narang, Michael Matena, Yanqi Zhou,\n   tion and Integration for Deep Learning Architectures,     Wei Li, and Peter J Liu. 2020. Exploring the limits\n  pages 100–114.                                         of transfer learning with a unified text-to-text trans-\n                                                           former. The Journal of Machine Learning Research,\nRyan Lowe, Nissan Pow, Iulian Serban, and Joelle      21(1):5485–5551.\n   Pineau. 2015. The ubuntu dialogue corpus: A large\n                                                        Laria Reynolds and Kyle McDonell. 2021. Prompt pro-\n   dataset for research in unstructured multi-turn dia-\n                                               gramming for large language models: Beyond the  logue systems. arXiv preprint arXiv:1506.08909.\n                                                        few-shot paradigm.  In Extended Abstracts of the\n                                                  2021 CHI Conference on Human Factors in Comput-\nAndrew L. Maas, Raymond E. Daly, Peter T. Pham,\n                                                          ing Systems, pages 1–7.  Dan Huang, Andrew Y. Ng, and Christopher Potts.\n  2011. Learning word vectors for sentiment analysis.   Ohad Rubin, Jonathan Herzig, and Jonathan Berant.\n   In Proceedings of the 49th Annual Meeting of the      2022. Learning to retrieve prompts for in-context\n  Association for Computational Linguistics: Human                                                              learning.  In Proceedings of the 2022 Conference\n  Language Technologies, pages 142–150, Portland,       of the North American Chapter of the Association\n  Oregon, USA. Association for Computational Lin-       for Computational Linguistics: Human Language\n   guistics.                                                Technologies, pages 2655–2671.\n\nR Thomas McCoy, Ellie Pavlick, and Tal Linzen. 2019.   Maarten Sap, Hannah Rashkin, Derek Chen, Ronan\n  Right for the wrong reasons: Diagnosing syntac-      LeBras, and Yejin Choi. 2019.  Socialiqa: Com-\n   tic heuristics in natural language inference. arXiv      monsense reasoning about social interactions. arXiv\n   preprint arXiv:1902.01007.                               preprint arXiv:1904.09728.\n\nTimo Schick and Hinrich Schütze. 2021a. Exploiting    Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen,\n   cloze-questions for few-shot text classification and      Runkai Zheng, Yidong Wang, Linyi Yang, Hao-\n   natural language inference. In Proceedings of the      jun Huang, Wei Ye, Xiubo Geng,  et  al. 2023.\n  16th Conference of the European Chapter of the Asso-    On  the robustness of  chatgpt:  An  adversarial\n   ciation for Computational Linguistics: Main Volume,     and out-of-distribution perspective. arXiv preprint\n  pages 255–269.                                       arXiv:2302.12095.\n\nTimo Schick and Hinrich Schütze. 2021b. It’s not just                                                 Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\n   size that matters: Small language models are also few-                                            Ed Chi, and Denny Zhou. 2022a. Self-consistency\n   shot learners. In Proceedings of the 2021 Conference                                                    improves chain of thought reasoning in language\n   of the North American Chapter of the Association                                                       models. arXiv preprint arXiv:2203.11171.\n   for Computational Linguistics: Human Language\n  Technologies, pages 2339–2352.\n                                                Yizhong Wang, Swaroop Mishra, Pegah Alipoormo-\nAlessandro Stolfo, Zhijing Jin, Kumar Shridhar, Bern-       labashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva\n  hard Schölkopf, and Mrinmaya Sachan. 2022. A      Naik, Arjun Ashok, Arut Selvan Dhanasekaran, An-\n   causal framework to quantify the robustness of math-      jana Arunkumar, David Stap, et al. 2022b. Super-\n   ematical reasoning with language models.  arXiv       naturalinstructions: Generalization via declarative\n   preprint arXiv:2210.12023.                                instructions on 1600+ nlp tasks. In Proceedings of\n                                                             the 2022 Conference on Empirical Methods in Natu-\nYusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan,       ral Language Processing, pages 5085–5109.\n  Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan\n   Liu, Peng Li, Juanzi Li, et al. 2022. On transferabil-   Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\n   ity of prompt tuning for natural language processing.     Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.\n   In Proceedings of the 2022 Conference of the North      Chain of thought prompting elicits reasoning in large\n  American Chapter of the Association for Computa-      language models. arXiv preprint arXiv:2201.11903.\n   tional Linguistics: Human Language Technologies,\n  pages 3949–3969.                                                Adina Williams, Nikita Nangia, and Samuel Bowman.\n                                                      2018. A broad-coverage challenge corpus for sen-Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing\n                                                          tence understanding through inference. In Proceed-  Huang, and Xipeng Qiu. 2022. Black-box tuning for\n                                                          ings of the 2018 Conference of the North American   language-model-as-a-service. In International Con-\n                                                    Chapter of the Association for Computational Lin-   ference on Machine Learning, pages 20841–20855.\n                                                                 guistics: Human Language Technologies, Volume 1  PMLR.\n                                                    (Long Papers), pages 1112–1122.\nWeng Lam Tam, Xiao Liu, Kaixuan Ji, Lilong Xue,\n  Xingjian Zhang, Yuxiao Dong, Jiahua Liu, Maodi    Linyi Yang, Shuibai Zhang, Libo Qin, Yafu Li, Yi-\n  Hu, and Jie Tang. 2022. Parameter-efficient prompt     dong Wang, Hanmeng Liu, Jindong Wang, Xing\n   tuning makes generalized and calibrated neural text      Xie, and Yue Zhang. 2022. Glue-x: Evaluating nat-\n   retrievers. arXiv preprint arXiv:2207.07087.               ural language understanding models from an out-\n                                                               of-distribution generalization perspective.  arXiv\nRuixiang Tang, Dehan Kong, Longtao Huang, and Hui                                                             preprint arXiv:2211.08073.\n  Xue. 2023. Large language models can be lazy learn-\n   ers: Analyze shortcuts in in-context learning. arXiv\n                                              Wentao Ye, Mingfeng Ou, Tianyi Li, Xuetao Ma, Yi-\n   preprint arXiv:2305.17256.\n                                                         fan Yanggong, Sai Wu, Jie Fu, Gang Chen, Junbo\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier      Zhao, et al. 2023a. Assessing hidden risks of llms:\n   Martinet, Marie-Anne Lachaux, Timothée Lacroix,    An empirical study on robustness, consistency, and\n   Baptiste Rozière, Naman Goyal,  Eric Hambro,       credibility. arXiv preprint arXiv:2305.10235.\n   Faisal Azhar, et al. 2023.  Llama: Open and effi-\n   cient foundation language models. arXiv preprint   Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei\n  arXiv:2302.13971.                                Huang, and Yongbin Li. 2023b.  Large language\n                                                  models are versatile decomposers: Decompose evi-\nNirali Vaghani and Mansi Thummar. 2023. BFlipkart      dence and questions for table-based reasoning. arXiv\n  product reviews with sentiment dataset. https://       preprint arXiv:2301.13808.\n  www.kaggle.com/dsv/4940809.\n                                                      Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schu-Tu Vu, Brian Lester, Noah Constant, Rami Al-Rfou, and\n                                                     urmans, and Joseph E Gonzalez. 2023.  Tempera:  Daniel Cer. 2021. Spot: Better frozen model adap-\n                                                           Test-time prompt editing via reinforcement learning.   tation through soft prompt transfer. arXiv preprint\n                                                           In The Eleventh International Conference on Learn-  arXiv:2110.07904.\n                                                          ing Representations.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\n   Hill, Omer Levy, and Samuel R Bowman. 2018.   Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.\n   Glue: A multi-task benchmark and analysis platform       Character-level convolutional networks for text classi-\n   for natural language understanding. arXiv preprint        fication. Advances in neural information processing\n  arXiv:1804.07461.                                       systems, 28.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,                   # Train&Val  # Test N Shot K Prompt\n  Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy                                                             Yelp          650000      150    36      6\n  Ba. 2023. Large language models are human-level                                                                       Flipkart        75138\n  prompt engineers.  In The Eleventh International    IMDB         25000\n  Conference on Learning Representations.              Amazon       100000\n\nKaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen      SocialIQA      33410       150    36      6\n  Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei     PIQA         16113\n  Ye, Neil Zhenqiang Gong, Yue Zhang, et al. 2023.     OpenbookQA   4957\n  Promptbench: Towards evaluating the robustness of     Number        2000        150    36      6\n   large language models on adversarial prompts. arXiv      Spans         2000\n   preprint arXiv:2306.04528.                                            MNLI         392702      1000   16      4\n                                               ANLI         45460\nA  Appendix\n                                              RTE          2490        277    16      4\n                                          HANS         30000       1000\nA.1  Dataset Details\n                                              DSTC7        43824       150    9       9\nFor each dataset, we use the original training set      Ubuntu Dialog  94107\nto split into training and validation sets, and ran-     MuTual        4783\ndomly sample a subset from the original validation\n                                                     Table 10:  Statistics for the train, validation and testset as our test set as sometimes the labels for the\n                                                                  splits for each dataset, and the values of shot number\noriginal test set are not available. Following the\n                             N and prompt number K for each task. The Train&Val\nofficial implementation of APE 3, we split the orig-                                                          are further split into 1000 training samples and the rest\ninal training set with 1000 training samples, and                                                         as validation samples.\nthe rest as validation samples. For MNLI, we sam-\nple the same number of matched and mismatched\nvalidation data as the test set. For ANLI, we use   prompts by LLM for further selection. For each\nR2. For Yelp and Flipkart, we assign the review    task, we try the value of N as 9, 16, 25, 36, and\nscores of 0 and 1 as negative, 3 as neutral, and  K as N’s factors, to ensure obtaining effective\n4, 5 as positive. For multi-turn dialog reasoning,   prompts, where APE is not very parameter sensi-\nwe select the instances of MuTual within 5 dialog     tive. Moreover, we ablate the Monte Carlo search\nturns, Ubuntu and DSTC7 within 7 dialog turns,    since it is optional and not significant for our tasks.\nand reduce the number of choices to 4 for all three     Given the randomness of the backbone LLM,\ndatasets. We show an example of LLM input for   we set the temperature of the LLM as 0, top p as\neach task in Table 11, and the dataset statistics in    1.0. We set the max tokens for prompt generation\nTable 10.                                          as 100 to try to ensure no truncation, and keep\n                                                      other LLM parameters the same as the official APE\nA.2  Additional Implementation Details for                                                 implementation. The parameters N and K are\n     Preliminary Experiments                                          shown in Table 10.\nThe APE performs prompt optimization by itera-\n                                            A.3  Additional Details and Results for thetively generating and selecting the prompts lever-\n                                                    Exploration on the Factors Affectingaging LLM. For prompt generation, it utilizes a\n                                            Prompt Robustness.meta prompt to instruct LLM to infer prompts from\ngiven input-output examples. Then, the generated   Calculation of Q1 Metrics.  The label distribu-\nprompts are evaluated on validation data to select    tion shift quantifies the divergence of the label\nthe prompts with good task performance. After    distributions between two groups for classification\nthat, APE leverages LLM to perform Monte Carlo    tasks, calculated by the KL divergence of their label\nsearch by iteratively paraphrasing the current effec-    distributions,\ntive prompts and performing evaluation on them to\nobtain optimized prompts.                                    DKL = X Prs(y)log(Prs(y)  Following  the  official  implementation,  for                              Prt(y))\n                                                           y∈Y\nprompt generation, the sampled N-shot training\ndata are divided into K  splits to generate K                                            where Y is the label space of the task, and Prs(y)\n   3https://github.com/keirp/automatic_prompt_      and Prt(y) denote the probability of the label y in\nengineer/tree/main.                                  the source and target groups, respectively.\n\nDataset         Input Example                                                                       Labels\n\n  Yelp            Dr. Goldberg offers everything I look for in a general practitioner. He’s nice and easy to talk   positive, negative, neutral\n                   to without being patronizing; he’s always on time in seeing his patients...\n\n  OpenbookQA  The sun is responsible for (A) puppies learning new tricks (B) children growing up and  A, B, C, D\n                   getting old (C) flowers wilting in a vase (D) plants sprouting, blooming and wilting.\n\n MNLI         Premise: One of our number will carry out your instructions minutely. Hypothesis: A   entailment, neutral, contra-\n              member of my team will execute your orders with immense precision.                        diction\n\n HANS         Sentence 1: The doctors supported the scientist. Sentence 2: The scientist supported the   entailment,\n                   doctors.                                                                          non−entailment\n\n DSTC7         S: Hello! A: Hello! S: I’m wondering for next semester what class should I take. A: Given  A, B, C, D\n                your experience, I suggest you take EECS 280. S: Do you know what the size of that class\n                    is? Answer Choices: (A) EECS 481 covers dealing with structuring principles, pragmatic\n                  aspects of the production of software systems, design methodologies and informal analysis.\n                 (B) The class size is normally around 167 students. (C) Based on the classes you’ve taken,\n                     this class shouldn’t be extremely demanding. (D) This course has a discussion section.\n\n  Number        Question: How many in percent weren’t 45 to 64? Context: In the city, the year 2010   e.g., 78.9\n                  population was spread out with 26.3% under the age of 18, 13.6% from 18 to 24, 30.7% from\n               25 to 44, 21.1% from 45 to 64, and 7.2% who were 65 years of age or older. The median age\n               was 32 years. For every 100 females, there were 92.5 males. For every 100 females age 18\n                and over, there were 88.4 males.\n\nTable 11: Dataset examples for each task. The output for classification tasks is one of the Labels, while for Number\nthe output is a string of numerical value.\n\n\n  The input similarity quantifies the n-gram simi-     For both metrics, the n-gram(·) is calculated\nlarity of the input corpuses of the two groups. Sup-   as both word 1-gram and character 4-gram using\npose that we sample M inputs from the source    scikit-learn.\nand target groups respectively, denoted as xs =\n{xs1, ..., xsM } and xt = {xt1, ..., xtM }, we calcu-\nlate the Spearman’s rank order correlation between\nthe bag-of-word vectors of xs and xt,          Q1 Metrics for More Tasks.  Table 12 and Ta-\n                                                      ble 13 show the two Q1 metric results for common-\n                    cov(Vs, Vt)             ρ =                              sense QA and Dialog tasks. Linking the results\n                    δ(Vs)δ(Vt)                                                 with the generalization performance in Table 1 and\nwhere Vs and Vt denotes the ranked bag-of-word   Table 2, we have the following observations. 1)\nvectors of xs and xt on the vocabulary of xt.        For each target group of the commonsense QA\n                                                         task, the largest value for input similarity coheres\nCalculation of Q2 Metrics.  We sample the same                                                with the best generalization performance, but the\namount of inputs from SocialIQA, PIQA and Open-                                                    smallest value of label distribution shifts does not\nbookQA, and denote the input corpuses as x1, x2                                                         correlate to the best generalization performance. 2)\nand x3.  Firstly, we calculate the proportion of                                              For the Dialog groups, the zero label distribution\nunique n-grams for each group against the num-                                                           shifts and the close input similarities cohere with\nber of all n-grams for the three corpuses as                                                      the subtle generalization performance difference on\n            |n-grams(xi)|                         each target group. 3) The evaluation metrics cannot\n                                      i = 1, 2, 3                                              be compared across target groups nor across tasks.       |n-grams({x1, x2, x3})|,\n                                                                e.g., the source group SocialIQA performs better\nwhere n-gram(·) returns the set of unique n-grams,                                           on PIQA than OpenbookQA (cf. Table 2), but the\nand the braces denotes mixing the inputs.                                                    input similarity is higher for OpenbookQA. Also,\n  Secondly, we think the source group that has                                        MuTual has smaller input similarity with Ubuntu\nalready covered a larger proportion of n-grams of                                                     (input similarity is 0.56, and generalization per-\nthe target group may promote better generaliza-                                             formance is 74.7) but better generalization perfor-\ntion, and we calculate the proportion of n-gram                                          mance than PIQA generalizing to SocialIQA (input\ncoverage between the source and target groups as                                                        similarity is 0.57, and generalization performance\n          |n-grams(xs) ∩n-grams(xt)|                 is 68.9) (cf. Section 2). These findings reveals the\n                 |n-grams(xt)|                       benefits and limitations of the Q1 metrics.\n\nTarget                          SocialIQA    PIQA     OpenbookQA    ference for Vicuna models. We present the meta\n   Source\n                                             prompt of APE and APE-ut, the initial prompt for\n   SocialIQA                    -               2.44       0.27\n   PIQA                   0.38               -           0.59        APO, the human-written prompts, the revised ver-\n   OpenbookQA            1.59            3.17          -             sions by PromptPerfect here.\n\n                      (a) Commonsense QA\n                 Target                                              • APE meta prompt:\n                          Mutual    DSTC7     Ubuntu Dialog\n   Source                                                               I provide my friend with an instruction. Based\n   Mutual                        -          0          0               on the instruction, I gave him several inputs,\n   DSTC7               0               -           0\n   Ubuntu Dialog          0          0               -               and he generated the corresponding outputs.\n                                                Here are the input-output examples:[DEMO].                           (b) Dialog\n                                                    Please briefly illustrate the instruction and\nTable 12: Results for label distribution shifts. Smaller        describe the output format. The instruction is\nvalue indicates smaller distribution shift.  Bold font         to\nindicates the smallest value for each column.\n\n                                                                 • APE-ut meta prompt:\n                 Target                          SocialIQA    PIQA     OpenbookQA            I provide my friend with an instruction. Based\n   Source\n                                              on the instruction,  I gave him several in-\n   SocialIQA                    -               0.59       0.62\n   PIQA                   0.57               -           0.69                puts, and he generated the corresponding\n   OpenbookQA            0.61            0.67          -                  outputs.  Here are the input-output exam-\n                      (a) Commonsense QA                       ples:[Source]. Here are also some unlabeled\n                 Target                                       examples. Please consider these examples as\n                       MuTual    DSTC7     Ubuntu Dialog\n   Source                                                 well for prompt generation:[Unlabeled Tar-\n   MuTual                                     -                                          0.55                                                      0.56                get].Please briefly illustrate the instruction   DSTC7                            0.56            -                                                      0.56\n   Ubuntu Dialog           0.57         0.57            -               and describe the output format. The instruc-\n                           (b) Dialog                              tion is to\n\nTable 13: Results for input similarity.  Larger value        • APO initial Prompts:\nindicates smaller distribution shifts. Bold font indicates                                                    For Yelp: Provide a sentiment analysis of the\nthe largest value for each column.\n                                                       following text. Answer Positive Neutral or\n                                                      Negative as labels.\n                                                   For SocialIQA: Give answer to the followingA.4  Details for Baseline Implementation\n                                                          multi choice question. Provide only the single\nFor all compared methods, the LLM parameters          letter as labels.\nsuch as temperature, top p, max tokens are the        For Number: Answer the following question\nsame as in Appendix A.2. The implementation and        based on the context which involves numerical\nresults for APE follow the preliminary experiments         calculation. Provide only the numerical value\nas illustrated in Appendix A.2 and Section 2. For         that directly answers the question.\nAPO, we follow the original parameter setting ex-\ncept for number of optimization step as 1 because        • Human Prompts:\nthe three tasks do not need multi-round optimiza-       For sentiment analysis: Provide a sentiment\ntion. For GPO, the value K is unchanged from         analysis of a given input text. The output for-\nAPE. The consistency threshold for GPO are 0.83       mat is a single word indicating whether the\n(5 out of 6 prompts) for sentiment analysis and com-        sentiment is positive, negative, or neutral.\nmonsense QA, and 0.33 (2 out of 6 prompts) for        For commonsense QA: Give answer to the fol-\nDROP. Note that APE and APO are not designed        lowing multi choice question which involves\nto utilize the unlabeled target group data so we       commonsense knowledge. Provide only the\nonly observe the direct generalization performance,         single letter (a, b, c, or d) as labels.\nwhile APE-ut and GPO utilize the N-shot source        For DROP: Answer the following question\ngroup data and N-shot target group data. All of       based on the context which involves numer-\nthe above methods do not need to apply Monte          ical reasoning. Provide only the direct answer\nCarlo search following the official implementation         the question, which can be a numerical value\nof APE. We use one 32GB GPU to perform in-        or a short string.\n\n• PromptPerfect:                              Table 2.\n     For sentiment analysis: Your task is to perform\n    a sentiment analysis on a given input text and      Yelp      Provide feedback on various experiences, such as\n                                                                                   dining, shopping, and service. The output format is\n     provide a single word indicating whether the              a sentiment analysis, where the input is analyzed\n     sentiment is positive, negative, or neutral. The                  to determine whether the experience was positive,\n     input text may contain any language or style                  negative, or neutral. The output is a single word\n                                                                                  indicating the sentiment of the experience.\n     of writing. Please ensure that your analysis                                                                        Flipkart   Provide a sentiment analysis of customer reviews.\n     takes into account the overall tone and con-              The input consists of a customer review of a prod-\n      text of the text.Your response should be con-                   uct, and the output is a binary classification of the\n     cise and clear, providing a single word that                 sentiment as either positive or negative.\n                                           GPO      provide a sentiment analysis of a given text. The\n     accurately reflects the sentiment of the input                 output format is a single word indicating whether the\n      text. If there are multiple sentiments present                 sentiment is positive, negative, or neutral.\n     in the text, please choose the one that best     Number  Answer a specific question based on a given context.\n     represents the overall feeling conveyed by the              The output format is a numerical value that directly\n                                                                       answers the question asked.\n     author.Please note that your analysis should\n                                                            Spans    Answer a specific question based on a given context.\n     take into account all relevant factors, such              The output format is a single word or phrase that di-\n     as tone, language use, and content. Your re-                   rectly answers the question asked.\n     sponse should also be flexible enough to allow    GPO     Answer   questions   based   on   given   con-\n                                                                                           text  information.     The  output  format   is\n     for various types of input texts.                                                                  a numerical value or a single word answer.\n     For commonsense QA: Please choose the best\n    answer for the following multiple choice ques-   Table 14: Case study on the prompts optimized by APE\n      tion. Choose the one answer that best fits the    from a source group, and GPO.\n     given scenario. Please provide only the single\n      letter (a, b, c, or d) as labels.\n    For DROP: Your task is to answer a numeri-         K   Flipkart Ensemble\n     cal question based on a given context involv-                                                          3    81.2 ± 1.3\n     ing numerical reasoning. Please provide a               6    84.5 ± 2.0\n     direct answer to the question, which can be               9    85.8 ± 1.9\n    a numerical value or a short string.Please               12   85.2 ± 1.8\n     note that your response should be concise               18   85.3 ± 1.4\n    and directly answer the question. The ques-\n     tion may involve various numerical data, such    Table 15: Generalization performance of GPO on Flip-\n                                                             kart with different numbers of candidate prompts K.     as percentages, averages, or counts.  You\n     should focus on identifying the relevant in-\n     formation and providing a clear and accurate\n                                            A.6  Study on the Impact of the Number of\n     answer.Additionally, please ensure that your\n                                                 Candidate Prompts\n     response is flexible enough to allow for var-\n     ious relevant and creative answers based on  We examine the effect of varying the number of\n     the context provided.                          candidate prompts K on GPO performance in our\n                                                 36-shot sentiment analysis task. We test the K\nA.5  Case Study                                                    values in {3, 6, 9, 12, 18}. The results on the target\nWe present a case study by presenting the best   group Flipkart are shown in Table 15. We observe\nprompt among the five runs for sentiment analysis    that the generalization performance stabilizes as K\nand DROP as shown in Table 14. We can observe    reaches a specific value, in this case is 6, indicating\nthat the optimized prompt for a single group often    that further generating more prompts are unlikely\ncontains group-specific background information as    to yield significant improvements in performance.\nhighlighted by underline which may hinder robust\nprompt generalization. On the contrary, the opti-\nmized prompts of GPO are more general and thus\nperforms well on both groups. Note that for Spans,\nthe optimized prompt is also general enough and\nthus can generalize well to Number as shown in",
"headers": [
"arXiv:2305.13954v3  [cs.CL]  5 Feb 2024",
"Robust Prompt Optimization for Large Language Models Against",
"Distribution Shifts",
"Moxin Li",
", Wenjie Wang",
", Fuli Feng",
", Yixin Cao",
", Jizhi Zhang",
"Tat-Seng Chua",
"National University of Singapore,",
"University of Science and Technology of China",
"Institute of Dataspace, Hefei, Anhui, China,",
"Singapore Management University",
"limoxin@u.nus.edu, wangwenjie@u.nus.edu, fulifeng93@gmail.com,",
"caoyixin2011@gmail.com, cdzhangjizhi@mail.ustc.edu.cn,",
"dcscts@nus.edu.sg",
"Abstract",
"1",
"Introduction",
"2",
"Preliminary Experiments",
"3",
"Robust Prompt Optimization",
"4",
"Experiments",
"6",
"Conclusion",
"5",
"Related Work",
"Limitations",
"Acknowledgements",
"References",
"A",
"Appendix"
],
"tables": [
"|Prompt Optimization|Col2|\n|---|---|\n|**update**<br>**[Prompt]**<br>Light weight laptop<br>with new amazing<br>features, battery<br>life is awesome.<br>**LLM**<br>**Prompt**<br>Provide a sentiment<br>analysis of a given<br>input text ...<br>Provide feedback<br>on various products<br>or experiences ...<br>!\"<br>y<br>**Accuracy = 78%**<br>**Training Samples**<br>**feedback**<br>**Step 1**<br>**Step n**|**update**<br>**[Prompt]**<br>Light weight laptop<br>with new amazing<br>features, battery<br>life is awesome.<br>**LLM**<br>**Prompt**<br>Provide a sentiment<br>analysis of a given<br>input text ...<br>Provide feedback<br>on various products<br>or experiences ...<br>!\"<br>y<br>**Accuracy = 78%**<br>**Training Samples**<br>**feedback**<br>**Step 1**<br>**Step n**|\n|**update**<br>**[Prompt]**<br>Light weight laptop<br>with new amazing<br>features, battery<br>life is awesome.<br>**LLM**<br>**Prompt**<br>Provide a sentiment<br>analysis of a given<br>input text ...<br>Provide feedback<br>on various products<br>or experiences ...<br>!\"<br>y<br>**Accuracy = 78%**<br>**Training Samples**<br>**feedback**<br>**Step 1**<br>**Step n**|**Deployment**|\n|||\n|Task-specific<br>optimized prompt|Task-specific<br>optimized prompt|",
"|Target<br>Source|MNLI|ANLI|\n|---|---|---|\n|MNLI<br>ANLI|73.4_ ±_ 1.0<br>73.3_ ±_ 1.3|45.4_ ±_ 1.9<br>46.0_ ±_ 1.5|",
"|Target<br>Source|Yelp|Flipkart|IMDB|Amazon|\n|---|---|---|---|---|\n|Yelp<br>Flipkart<br>IMDB<br>Amazon|**79.7**_ ±_** 0.7**<br>69.1_ ±_ 8.7<br>71.1_ ±_ 8.2<br>75.5_ ±_ 1.5|78.4_ ±_ 1.9<br>**85.1**_ ±_** 2.9**<br>76.9_ ±_ 13.4<br>**85.6**_ ±_** 2.1**|87.1_ ±_ 1.9<br>85.2_ ±_ 9.4<br>**91.9**_ ±_** 0.9**<br>**91.5**_ ±_** 0.8**|88.4_ ±_ 1.9<br>85.9_ ±_ 12.5<br>90.4_ ±_ 5.2<br>**93.5**_ ±_** 1.4**|",
"|Target<br>Source|RTE|HANS|\n|---|---|---|\n|RTE<br>HANS|78.3_ ±_ 0.8<br>79.0_ ±_ 0.8|67.2_ ±_ 1.1<br>68.4_ ±_ 1.8|",
"|Target<br>Source|SocialIQA|PIQA|OpenbookQA|\n|---|---|---|---|\n|SocialIQA<br>PIQA<br>OpenbookQA|75.6_ ±_ 1.4<br>68.9_ ±_ 6.9<br>**79.9**_ ±_** 1.0**|82.0_ ±_ 6.0<br>83.6_ ±_ 2.9<br>**84.5**_ ±_** 1.6**|71.2_ ±_ 5.2<br>69.2_ ±_ 5.1<br>**80.1**_ ±_** 2.4**|",
"|Target<br>Source|DSTC7|Ubuntu Dialog|MuTual|\n|---|---|---|---|\n|DSTC7<br>Ubuntu Dialog<br>MuTual|58.4_ ±_ 0.8<br>56.9_ ±_ 1.3<br>52.2_ ±_ 4.4|78.9_ ±_ 0.3<br>78.7_ ±_ 0.5<br>74.7_ ±_ 6.0|74.2_ ±_ 2.2<br>74.4_ ±_ 2.1<br>76.7_ ±_ 3.4|",
"|Target<br>Source|Number|Spans|\n|---|---|---|\n|Number<br>Spans|51.9_ ±_ 2.8<br>**57.7**_ ±_** 2.9**|20.1_ ±_ 1.3<br>**63.1**_ ±_** 2.2**|",
"|Target<br>Source|Yelp Flipkart IMDB Amazon|\n|---|---|\n|Yelp<br>Flipkart<br>IMDB<br>Amazon|-<br>0.33<br>1.62<br>1.62<br>0.30<br>-<br>0.57<br>0.56<br>**0.25**<br>0.29<br>-<br>**0**<br>**0.25**<br>**0.27**<br>**0**<br>-|",
"|(a)|The n-gram diversity.|\n|---|---|\n|Source<br>Target|SocialIQA<br>PIQA<br>OpenbookQA|\n|SocialIQA<br>PIQA<br>OpenbookQA|-<br>0.39<br>0.38<br>0.47<br>-<br>**0.46**<br>**0.51**<br>**0.52**<br>-|",
"|a) Label distribution bution shifts.|shifts. Smaller values indicate less distr|\n|---|---|\n|Source<br>Target|Yelp<br>Flipkart<br>IMDB<br>Amazon|\n|Yelp<br>Flipkart<br>IMDB<br>Amazon|-<br>0.65<br>0.73<br>0.76<br>0.59<br>-<br>0.55<br>0.63<br>0.70<br>0.63<br>-<br>**0.81**<br>**0.71**<br>**0.70**<br>**0.78**<br>-|",
"|Target<br>Source|SocialIQA PIQA OpenbookQA|\n|---|---|\n|SocialIQA<br>PIQA<br>OpenbookQA|-<br>0.51<br>0.51<br>0.60<br>-<br>**0.58**<br>**0.66**<br>**0.64**<br>-|",
"|Col1|Yelp (Source) Flipkart (Target)|SocialIQA (Source) OpenbookQA (Target)|Number (Source) Spans (Target)|\n|---|---|---|---|\n|Human<br>PromptPerfect<br>GPO best|**78.7**<br>80.0<br>77.3<br>83.3<br>**78.7**<br>**84.5**|71.3<br>60.0<br>74.7<br>64.0<br>**78.9**<br>**79.7**|**54.9**<br>**37.1**<br>54.0<br>26.9<br>52.2<br>27.7|",
"|90<br>85<br>racy<br>80|Col2|Col3|\n|---|---|---|\n|80<br>85<br>90<br>racy|||\n|80<br>85<br>90<br>racy|||\n|80<br>85<br>90<br>racy|||",
"|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|||||\n|||||",
"|Col1|Col2|Col3|\n|---|---|---|\n||||\n||||\n||||",
"|Target<br>Source|SocialIQA PIQA OpenbookQA|\n|---|---|\n|SocialIQA<br>PIQA<br>OpenbookQA|-<br>**2.44**<br>**0.27**<br>**0.38**<br>-<br>0.59<br>1.59<br>3.17<br>-|",
"|Target<br>Source|Mutual DSTC7 Ubuntu Dialog|\n|---|---|\n|Mutual<br>DSTC7<br>Ubuntu Dialog|-<br>0<br>0<br>0<br>-<br>0<br>0<br>0<br>-|",
"|Target<br>Source|SocialIQA PIQA OpenbookQA|\n|---|---|\n|SocialIQA<br>PIQA<br>OpenbookQA|-<br>0.59<br>0.62<br>0.57<br>-<br>**0.69**<br>**0.61**<br>**0.67**<br>-|",
"|Target<br>Source|MuTual DSTC7 Ubuntu Dialog|\n|---|---|\n|MuTual<br>DSTC7<br>Ubuntu Dialog|-<br>0.55<br>0.56<br>0.56<br>-<br>0.56<br>0.57<br>0.57<br>-|",
"|Table 2.|Col2|\n|---|---|\n|Yelp<br>Flipkart<br>GPO|_Provide feedback on various experiences, such as_<br>_dining, shopping, and service. The output format is_<br>_a sentiment analysis, where the input is analyzed_<br>_to determine whether the experience was positive,_<br>_negative, or neutral. The output is a single word_<br>_indicating the sentiment of the experience._<br>_Provide a sentiment analysis of customer reviews._<br>_The input consists of a customer review of a prod-_<br>_uct, and the output is a binary classification of the_<br>_sentiment as either positive or negative._<br>_provide a sentiment analysis of a given text. The_<br>_output format is a single word indicating whether the_<br>_sentiment is positive, negative, or neutral._|\n|Number<br>Spans<br>GPO|_Answer a specific question based on a given context._<br>_The output format is a numerical value that directly_<br>_answers the question asked._<br>_Answer a specific question based on a given context._<br>_The output format is a single word orphrase that di-_<br>_rectly answers the question asked._<br>_Answer_<br>_questions_<br>_based_<br>_on_<br>_given_<br>_con-_<br>_text_<br>_information._<br>_The_<br>_output_<br>_format_<br>_is_<br>_a numerical value or a single word answer._|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/test/2305.13954v3.pdf"
}