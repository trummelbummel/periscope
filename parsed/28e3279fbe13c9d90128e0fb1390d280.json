{
"text": "ProAPO: Progressively Automatic Prompt Optimization for Visual Classification\n\n\n                        Xiangyan Qu12   Gaopeng Gou12‚Ä†  Jiamin Zhuang12   Jing Yu3\n                       Kun Song4   Qihao Wang12   Yili Li12  Gang Xiong12\n                  1Institute of Information Engineering, Chinese Academy of Sciences   2School of Cyber Security, Chinese Academy of Sciences\n                     3School of Information Engineering, Minzu University of China   4University of Science and Technology Beijing\n                     {quxiangyan, gougaopeng, zhuangjiamin}@iie.ac.cn, jing.yu@muc.edu.cn\n\n             songkun@xs.ustb.edu.cn, wangqihao22@mails.ucas.ac.cn, {liyili, xionggang}@iie.ac.cn\n2025\n                          Abstract                                els classify images by computing the similarity between the\n                                                               image and the prompt (a human-readable natural language)\n           Vision-language models (VLMs) have made  significant     associated with a category. The prediction is the categoryMar\n           progress in image classification by training with large-scale     with the highest similarity to the query image. Their perfor-\n           paired image-text data.  Their performances largely de-    mance highly relies on prompt quality, especially in fine-12\n          pend on the prompt quality.  While recent methods show     grained categories.  Finding the optimal prompts for the\n            that visual descriptions generated by large language mod-     downstream task becomes an urgent challenge [39, 55, 83].\n             els (LLMs) enhance the generalization of VLMs, class-       Recent works have made efforts to improve prompt qual-\n             specific prompts may be inaccurate or lack discrimination      ity [4, 19, 58]. Manual prompt engineering [9, 58, 76]\n          due to the hallucination in LLMs. In this paper, we aim to       is a standard approach, writing several templates to in-\n             find visually discriminative prompts for fine-grained cate-     clude task-specific information,  e.g., ‚Äúa photo of a[cs.CV]           gories with minimal supervision and no human-in-the-loop.    {class}, a type of bird.‚Äù  for bird recognition.\n         An evolution-based algorithm is proposed to progressively     However, designing templates requires domain expertise,\n           optimize language prompts from task-specific templates to     making it costly and challenging to scale [39, 42, 43, 55,\n             class-specific descriptions.  Unlike optimizing templates,      83].  Moreover, the template may lack details to recog-\n            the search space shows an explosion in class-specific can-     nize fine-grained categories as only the class name provides\n           didate prompts. This increases prompt generation costs, it-      the distinct information in prompts [42, 55, 83]. Prompt\n            erative times, and the overfitting problem. To this end, we     tuning methods [6, 82, 83, 85] introduce a set of learn-\n               first introduce several simple yet effective edit-based and     able tokens in the prompt to represent task-specific con-\n           evolution-based operations to generate diverse candidate       text, optimizing through gradient updates. While improving\n          prompts by one-time query of LLMs. Then, two sampling      the performance of VLMs, they require additional training\n            strategies are proposed to find a better initial search point     and lack interpretability [39, 43, 61].  In contrast, LLM-\n          and reduce traversed categories, saving iteration costs.     generated description methods [42, 43, 55, 60, 73, 87]\n           Moreover, we apply a novel fitness score with entropy con-     leverage the implicit knowledge of large language models\n             straints to mitigate overfitting.  In a challenging one-shot    (LLMs) [4, 51] to generate descriptions with class-specific\n          image classification setting, our method outperforms ex-      details, enhancing generalization ability of VLMs. How-arXiv:2502.19844v3\n             isting textual prompt-based methods and improves LLM-      ever, due to the hallucination in LLMs [28, 59], generated\n           generated description methods across 13 datasets. Mean-      descriptions are suboptimal due to inaccurate, e.g., ‚Äúfeet‚Äù\n            while, we demonstrate that our optimal prompts improve      for the food Peking Duck, or lack discrimination for fine-\n           adapter-based methods and transfer effectively across dif-     grained recognition, e.g., the same descriptions ‚Äúhooked\n            ferent backbones. Our code is available at here.            bill‚Äù and ‚Äúwebbed feet‚Äù appear in Laysan Albatross\n                                                                and Sooty Albatross (see Fig. 1(a)), or exhibit non-visual\n           1. Introduction                                               descriptions, e.g., ‚Äústrong smell‚Äù for Jackfruit. To this\n                                                                         end, we propose the following key questions:\n           In recent years, vision-language models (VLMs) [1, 30, 36,\n                                                   How can we find the optimal class-specific prompts that\n           46, 58, 68, 78, 79] pre-trained on large-scale paired image-\n                                                                       are visually discriminative for fine-grained categories with\n             text data, such as CLIP [58], have shown strong general-\n                                                                  minimal supervision and no human intervention?\n            ization on various image classification tasks. These mod-\n                                                                           Inspired by recent automatic prompt optimization (APO)\n                ‚Ä†Corresponding author                                    methods [21, 56, 64, 84] in language tasks, we aim to opti-\n\nLaysan Albatross                 Natural Language Prompt Search Space\n                                                       ‚Ä¢   white with black wings\n                                                       ‚Ä¢   a seabird                                  task-specific template\n                                                       ‚Ä¢   long, webbed feet                              template: ùëö   domain: ùëõ\n                                                       ‚Ä¢                                      a                                             long,                                         hooked                                                                               bill                     A photo of +  a bird: +\n                                                       ‚Ä¢                                                  flight                                             over                                                   the ocean\n                                                                        Laysan Albatross. +  It has white with black wings.\n                            Sooty Albatross                           class name: ùëü               description: ùë†\n                                                       ‚Ä¢   large, dark-colored bird\n                                                       ‚Ä¢   white band around its neck                  class-specific description\n                                                       ‚Ä¢  webbed feet\n                                                       ‚Ä¢   long, hooked bill               Number of task-specificÔºöùëö√ó ùëõ.\n                                                       ‚Ä¢   a species of albatross            Number of class-specificÔºöùëö√ó ùëõ√ó ùëü√ó ùë†.\n                    (a) Issues in generated descriptions.           (b) Explosion in the number of prompts.                (c) Overfitting in evaluation metric.\n\nFigure 1. Issues of optimizing class-specific prompts. (a) Due to the hallucination in LLMs, generated descriptions may be inaccurate\nand lack discrimination between fine-grained categories (see red words). (b) Compared to task-specific templates, we see an explosion in\nthe number of class-specific prompts (see red rectangle). This leads to higher generation costs, iteration times, and the overfitting problem.\n(c) Overfitting problem: Multiple candidate prompts have the same best training accuracy but variable and low test results (see red circle).\n\nmize class-specific prompts by an evolution-based process,      ‚Ä¢ We propose an evolution-based algorithm to progres-\nremoving confused prompts while retaining discriminative        sively optimize prompts from  task-specific  to  class-\nones. We consider an approximate zero-shot setting, i.e.,        specific levels with one-shot supervision and no human\none-shot classification, where minimal supervision is intro-        intervention.  It solves issues of inaccuracy and lack of\nduced to evaluate the prompt quality. However, previous        discrimination in LLM-generated descriptions.\nAPO methods focus solely on task-specific template opti-      ‚Ä¢ We address challenges in class-specific prompt optimiza-\nmization. In contrast, except for templates, a class-specific        tion by an offline generation algorithm to reduce LLM\nprompt also contains a description associated with visual       querying costs, an entropy-constrained fitness score to\ndetails in a category, as shown in Fig. 1(b). Compared with       prevent overfitting, and two sampling strategies to find an\ntemplates, class-specific optimization introduces new chal-       optimal initial point and reduce iteration times.\nlenges due to the expanded search space (see Fig. 1(b)),      ‚Ä¢ Extensive experiments on thirteen datasets show that our\nwhich leads to: (1) High generation costs. As the search       proposed ProAPO consistently outperforms SOTA textual\nspace grows,  it is costly and time-consuming to generate       prompt-based methods and improves description-based\nclass-specific prompts exclusively with LLMs at each iter-      methods in a challenging one-shot supervision.  More-\nation.  (2) Long iteration times.  Evaluating each candi-        over, our optimal prompts improve adapter-based meth-\ndate prompt in the search space may exponentially increase       ods and transfer effectively across different backbones.\nthe iteration time, which is impractical in this scenario. (3)\nOverfitting problem. As shown in Fig. 1(c), multiple can-     2. Related Work\ndidate prompts achieve variable and low test results (from\n63.6% to 64.3%) at the best training accuracy.                Adaptation of VLMs for image classification tasks. In-\n  To address these issues, we propose a Progressively      spired by successes in VLMs, recent works aim to adapt\nAutomatic Prompt Optimization (ProAPO) algorithm to     them for image classification tasks.  Some works  uti-\niteratively optimize prompts from task-specific to class-      lize lightweight linear layers [29, 38, 52, 58, 66, 69, 89],\nspecific levels.  In each iteration, we use several edited-     adapters [18, 42], visual prompting [2, 31, 50], or cache\nbased (i.e., add, remove, and replace) and evolution-based     models [70, 80, 86] to enhance visual features.  Other\noperators (i.e., crossover, and mutation) to generate diverse     works aim to improve the quality of prompts.  Manual\ncandidate prompts from a prompt library. We query LLMs     prompt engineering [9, 37, 58] applies task-specific in-\nto generate this library in the initialization stage. Compared     formation in prompt templates to enhance performance.\nto querying LLMs at each iteration, these simple opera-     However, templates need to be hand-written and lack fine-\ntions can effectively save generation costs. Then, we intro-     grained details [39, 42, 43, 55, 83]. Prompt tuning meth-\nduce a novel fitness score to evaluate generated candidate     ods  [6, 12, 25, 32, 33, 35, 40, 65, 82, 83, 85] learn\nprompts and retain several top-scoring ones for the next it-      task-specific context by a set of learnable tokens. How-\neration generation. An entropy constraint is added to the      ever, they need additional training and lack interpretabil-\nscore to increase the soft prediction score and reduce over-      ity [39, 43, 61].  In contrast, LLM-generated description\nfitting. After several iterations, we return the best prompt     methods [42‚Äì44, 47, 55, 57, 60, 62, 73, 87] exploit implicit\nfor classification. To reduce iteration times in class-specific     knowledge in LLMs to generate visual descriptions for each\ndescriptions, we propose a prompt sampling strategy to find      category. They enrich semantics in prompts and offer inter-\na better initial point in the search space and a group sam-      pretable predictions.  In this work, we aim to further im-\npling strategy to explore a few salient classes instead of all     prove description quality through an evolution process.\nfor optimization. Our key contributions are:                LLM-generated description methods apply class-specific\n\ndescriptions to language prompts to adapt VLMs for classi-     Algorithm 1 Our Progressively Automatic Prompt Opti-\nfication. DCLIP [43] and CuPL [55] design prompts such as     mization (ProAPO) for visual classification, which itera-\n‚ÄúWhat does a {class} look like?‚Äù  to instruct      tively refines prompts from task-specific to class-specific.\nLLMs to generate category descriptions. GPT4Vis [73] and                                                       Require: D ‚Üê{(x, y)}n: training samples, F : D √ó P ‚Üí\nVDT [42] use GPT-4 [51] for rich and diverse descriptions.        R: score function\nSome work utilizes LLM-generated hierarchy labels [49] or                                                                                     1: Initialize Template: Ut ‚Üê{P0}\ndescriptions [60] to recognize images from coarse to fine-                                                                                     2: Build Template Library: Bt ‚Üê{d1, ¬∑ ¬∑ ¬∑ , dn}\ngrained levels. However, due to the hallucination in LLMs,                                                                                     3: Iterative Optimization: Ut ‚ÜêAPO(D, F, Ut, Bt)\ngenerated descriptions might be inaccurate, non-visual, and            ‚àó                                                                                     4: P t ‚Üêarg maxP ‚ààUt F(D, P)\nlack discrimination [43, 60, 61]. To this end, we propose                                                                                     5: Initialize Description: Uc ‚Üê{ ÀÜP0}, initializing with\nProAPO to iteratively remove ambiguous and retain dis-            ‚àó                                           P t and prompt sampling strategy\ncriminative prompts.  Moreover, category names, ignored                                                                                     6: Group Sampling: Sample S groups by class salience\nin previous methods, are equally crucial for improving ac-                                                                                     7: for s = 1 to S do\ncuracy and are introduced in our optimization.                                                                                     8:   Build Description Library: Bs ‚Üê{ÀÜd1, ¬∑ ¬∑ ¬∑ , ÀÜdq}\nAutomatic prompt optimization aims to automatically                                                                                     9:    Iterative Optimization: Uc ‚ÜêAPO(D, F, Uc, Bs)\nfind optimal prompts for language tasks, overcoming the                                                                             10: end for\ntime-consuming issue in manual prompt methods [5]. Early                                                                             11: P ‚àó‚Üêarg maxP ‚ààUc F(D, P)\nmethods [11, 54, 64] generate discrete prompts by filling                                                           ‚àó                                                                             12: return candidate prompt with the highest score P\ntemplates with trigger tokens, iteratively refining prompts\nby mining, generation, or paraphrasing.  Recently, chat-\nbased LLMs have been applied as prompt engineers [17, 20,     Algorithm 2 Automatic Prompt Optimization (APO) algo-\n21, 56, 75, 84], using a meta-prompt with task information     rithm for VLMs - Lines 3 and 9 of Alg. 1, APO(D, F, U, B).\nto find optimal prompt design. PN [39] is the first to instruct                                                       Require: D ‚Üê{(x, y)}n: training samples, F : D √ó P ‚Üí\nLLMs to optimize templates on multimodal tasks, which        R: score function, U  : candidate prompt set, B: tem-\nfeeds visual feedback of the best and worst templates to                                                                       plate or description library\nguide. However, these methods only optimize task-specific                                                                                     1: Initialize Evaluation Score: S ‚Üê{F(D, P)}P ‚ààU\ntemplates. iCM [22] is somewhat similar to ours, optimiz-                                                                                     2: for t = 1 to T do\ning class-specific prompts with chat-based LLMs. How-                                                                                     3:   Ug ‚Üê‚àÖ\never, it uses the whole validation set as supervision. In con-                                                                                     4:    for all P ‚ààU do\ntrast, we optimize prompts with one-shot supervision and                                                                                     5:     Edit-based Generate: Ug ‚ÜêUg ‚à™GEN(P, B)\npropose solutions to solve high generation costs, long itera-                                                                                     6:   end for\ntion times, and overfitting in class-specific optimization.                                                                                     7:   Evaluate: Sg ‚Üê{F(D, P ‚Ä≤)}P ‚Ä≤‚ààUg\n                                                                                     8:   Update: U ‚Üê{U, Ug} and S ‚Üê{S, Sg}, retaining\n3. Method                                                                      the top-k of candidate prompts with high scores\nOur ProAPO algorithm is shown in Fig. 2 and summarized         9:   Evolution-based Generate: Ue ‚ÜêEVO(U, B)\nin Alg. 1. We first describe iterative optimization in tem-       10:   Evaluate: Se ‚Üê{F(D, P ‚Ä≤)}P ‚Ä≤‚ààUe\nplates (Sec. 3.1). For each iteration, candidates are gener-       11:   Update: U ‚Üê{U, Ue} and S ‚Üê{S, Se}, retaining\nated by several operators (Sec. 3.2) and then evaluated by            the top-k of candidate prompts with high scores\na fitness score (Sec. 3.3). Afterward, similar iterative opti-       12: end for\nmization is applied in descriptions, where we introduce two       13: return the latest candidate prompt set U\nsampling strategies to save iteration costs (Sec. 3.4).\n   Preliminaries. Given an image, CLIP [58] predicts by     introduced in Sec. 3.3 to evaluate the candidate prompt P\nselecting the highest similarity between the image and cat-     on a limited training set D = {(x, y)}n with one-shot su-\negory prompt. The category prompt is a human-readable      pervision, where x is an image and y is its label. Finally,\nnatural language associated with a category, which contains    we use a test set to evaluate optimized prompts. Our goal\na template, e.g., ‚Äúa photo of a bird:  {class}.       is to refine prompts in the natural language space to achieve\n{description}.‚Äù, and class-specific descriptions, e.g.,      superior performance in per training sample (x, y):\nclass name ‚ÄúLaysan Albatross‚Äù and its descriptions       \\ arg ax   _ P F (\\m ath al {D},  P) = \\arg max _P\\mathbb{E}_{(x,y)}[F(\\{(x,y)P)].(1)\n‚ÄúIt has white with black wings.‚Äù. Some cat-        m                c\negories may use multiple prompts with varied templates                                                               3.1. Automatic Template Optimization\nor descriptions,  i.e., prompt ensembling. We denote the\nprompt set that includes all categories in the task as a can-    To mitigate issues of semantic ambiguity caused by class\ndidate prompt P. A score function F  : D √ó P ‚ÜíR is     names, we first iteratively optimize the template to provide\n\nupdate             evaluate       group                         update             evaluate √ó ùë∫\n                          Score         VLM              sampling            Score         VLM\n                                               iterative optimization                                                      iterative optimization\n\n               initial     GEN & EVO generate  candidate        best      initial        GEN & EVO generate  candidate          best optimized\n          template        Operator            template              description          Operator            description            prompts\n\n\n                                                           prompt                        Template    one-time                                         Description   one-time\n                         Library      query  LLM               sampling          Library      query  LLM\n\nFigure 2. Overview of our ProAPO algorithm. We progressively refine prompts from task-specific (green lines) to class-specific (brown\nlines) levels. Specifically, we first explore the best template by an iterative optimization process (Sec. 3.1). For each iteration, ProAPO\ngenerates a set of candidate templates by several operators (Sec. 3.2) and filters/refines templates by a fitness score (Sec. 3.3). After several\niterations, we choose the top-scoring template for description initialization. Subsequently, we introduce two sampling strategies to find a\nbetter initial point and reduce traversed categories (Sec. 3.4). Similar iterative optimization is then applied to class-specific descriptions.\n\nbetter task-specific contextual information.                  Algorithm 3 Edit-based prompt generation algorithm  -\n  Template initialization offers a candidate prompt P0 as     Line 5 of Alg. 2, GEN(P, B).\na starting point in the language search space (Line 1 of\n                                                       Require: P ‚Üê{ÀÜd1, ¬∑ ¬∑ ¬∑ , ÀÜdi}: a candidate prompt, B ‚ÜêAlg. 1).  Similar to PN [39], we use ‚Äúa photo of a\n                                                               {d1, ¬∑ ¬∑ ¬∑ , dj}: template or description library\n{class}.‚Äù filling with class names in the dataset as P0.\n                                                                                     1: Ug ‚Üê‚àÖ\n   Building template library aims to provide a set of tem-\n                                                                                     2: for m = 1 to M do\nplates (Line 2 of Alg. 1) for subsequent prompt genera-\n                                                                                     3:   dadd ‚ÜêSelect(B)\ntion. We denote template library as Bt = {d1, ¬∑ ¬∑ ¬∑ , dn},\n                                                                                     4:   Padd ‚ÜêP ‚à™{dadd}                ‚ñ∑Add\nwhere d is a single template. Similar to PN [39], we can in-\n                                                                                     5:    ddel ‚ÜêSelect(P)\nstruct LLMs with a one-time query to generate a set of tem-\n                                                                                     6:    Pdel ‚ÜêP \\ {ddel}                    ‚ñ∑Delete\nplates as the library. Pre-defined templates, e.g., Template-\n                                                                                     7:   din ‚ÜêSelect(B)\n80 provided in CLIP [58], can also be used.  Inspired by\n                                                                                     8:    dout ‚ÜêSelect(P)\ndescription-based methods [42, 61], we also supplement\n                                                                                     9:   Prep ‚Üê(P ‚à™{din}) \\ {dout}         ‚ñ∑Replace\ntemplates with dataset domain information generated by\n                                                                             10:   Ug ‚ÜêUg ‚à™{Padd, Pdel, Prep}LLMs, such as ‚Äúflower‚Äù for FLO and ‚Äúbird‚Äù for CUB.\n                                                                             11: end for\n   Iterative optimization. Automatic prompt optimization\n                                                                             12: return the generated candidate prompt set Ug\n(APO) algorithm is introduced to refine template set Ut by\nan evolution-based process (Line 3 of Alg. 1). As summa-\nrized in Alg. 2, each iteration of APO contains the process      erator samples an element from a given prompt set. Three\nof: (1) Generate new candidate prompts Ug and Ue by     operations are then applied to P in each iteration: (1) Add\nseveral edit-based (Lines 4-6) and evolution-based (Line 9)     a new element dadd to P. (2) Remove an existing element\noperations based on the set U and library B. (2) Evaluate      ddel from P. (3) Replace an element dout in P with a new\neach new candidate prompt (Lines 7 and 10) by a score     element din in B.  These new candidates are ensembled\nfunction. We regard this score as an implied ‚Äúgradient‚Äù. (3)     around the current high-score candidate P, which makes\nUpdate the prompt set U based on score (Lines 8 and 11).     them more likely to succeed. Moreover, selecting elements\nThis process retains the top-k of prompts with high scores to     from the library ensures differences between generated can-\nexplore the search space around the current best candidates.      didates. After M-times steps, we return the latest set Ug.\nFinally, we return the latest candidate set U.                     Evolution-based generation is introduced to improve\n                                                             search efficiency over random steps, as shown in Alg. 4. In-\n3.2. Prompt Generation by Several Operators                                                                spired by widely used Generic Algorithm [23, 27, 45], we\nDue to the explosion of class-specific prompts, it is costly     introduce crossover and mutation operators to enhance can-\nand time-intensive to generate new prompts exclusively      didate generation. Crossover operator aims to find the opti-\nwith LLMs like previous methods [22, 39]. To this end,     mal direction quickly by combining high-scoring candidate\nwe introduce edit-based and evolution-based operators to     prompts. We randomly take the concatenation of two can-\ngenerate diverse candidate prompts from the library.             didates Pc1 and Pc2 sampled from the current optimal set\n   Edit-based generation is introduced to create a set of     U, yielding a new candidate Pc. Mutation operator aims to\nnew candidate prompts by several simple arithmetic opera-     prevent convergence to local optima by introducing varia-\ntors. As shown in Alg. 3, we iteratively operate a candidate      tions. We randomly add new elements selected from library\nprompt P with the library B, where ÀÜd in P and d in B de-   B into the candidate Pc, yielding mutation candidate Pm.\nnotes a single template or description. The Select(¬∑) op-     After N-times steps, we return the generated set Ue.\n\nAlgorithm 4 Evolution-based generation algorithm - Line    Pt‚àó and high-score descriptions (Line 5 of Alg. 1). Simi-\n9 of Alg. 2, EVO(U, B).                                              lar to description-based methods [43, 55], we instruct LLM\n                                                                   to generate a set of visual descriptions for each class. Be-Require: U ‚Üê{P1, ¬∑ ¬∑ ¬∑ , Pn}: candidate prompt set, B ‚Üê\n                                                                     sides, we replace the class name with its synonyms gener-    {d1, ¬∑ ¬∑ ¬∑ , dj}: template or description library\n                                                              ated by LLMs to increase the number of descriptions. To  1: Ue ‚Üê‚àÖ\n                                                              obtain a better initial point, we randomly sample descrip-  2: for n = 1 to N do\n                                                                   tions of each category to obtain multiple candidate prompts  3:   Pc1 ‚ÜêSelect(U)\n                                                      and select the one with the highest score as ÀÜP0.  It ensures  4:   Pc2 ‚ÜêSelect(U)\n                                                                     that subsequent optimization is around candidates with rel-  5:   Pc ‚ÜêPc1 ‚à™Pc2                    ‚ñ∑Crossover\n                                                                    atively high scores. More details are shown in Appendix B.  6:    Pall ‚ÜêB ‚à™Pc\n                                                Group sampling  strategy aims  to  explore  several  7:  Pm ‚ÜêRANDOMSELECT(Pall, len(Pc)) ‚ñ∑Mutation\n                                                                      salient categories into groups for optimization (Line 6 of  8:   Ue ‚ÜêUe ‚à™{Pc, Pm}\n                                                           Alg. 1). We consider two ways to sample categories. First,  9: end for\n                                             we select the groups with the lowest top-nwst accuracy 10: return the generated candidate prompt set Ue\n                                                      and its misclassified categories. Moreover, we also choose\n                                                                      salient groups by the category with the top-nsln result gains\n3.3. Score Functions\n                                                                       after adding descriptions and its misclassified categories. In\nTo measure candidate prompts, we introduce a fitness score      the end, We use S = nwst + nsln groups for optimization.\nto approximately obtain the ‚Äúgradient‚Äù used for optimiza-    More details are shown in Appendix C. In Sec. 4.4, exper-\ntion. It contains the accuracy and an entropy constraint.        iments show that optimizing these selected categories can\n   Accuracy.  Given an image x, we obtain a prediction      effectively improve performance and save costs.\npred(x) that yields the highest cosine similarity:                 Building Library and Iterative Optimization for De-\n                  c                                         scriptions. In Lines 7-10 of Alg. 1, we iteratively optimize\n           s( x,   f  }{|D(c)|}  \\sum      _{d\n                             )  &= \\                                      the class-specific description in selected groups. Similar to\n                    rac {1                             template optimization, we first build the description library,\n         \\in D( c )} \\te {cos }(I(x),c),T(d)).\\text{pred}(x)&=\\argmaxs(x,                    (3)     which contains visual descriptions for categories in the spe-\n                    xt                                               cific group. Then, we apply APO algorithm to refine de-\nwhere D(c) ‚ààP is a set with all prompts describing the cat-      scriptions automatically. After several iterations, we use the\negory c in candidate prompt P, and C is the entire category     candidate P ‚àówith the highest score as the final prompt.\nin the dataset. I and T are image encoder and text encoder,\nrespectively. The accuracy is formulated as follows:            4. Experiments\n              \\ t ext {Acc} = \\mathb b    {E}_{(x,y)\\in\\mathcal{D}}[\\mathbb{I}(\\text{pred}(x)y)],         (4)\n                                                             Datasets.  Following prompt tuning [82, 83] and LLM-\nwhere D is the training set and I(¬∑) is an indicator function.                                                            generated description works [43], we evaluate our ProAPO\n  Entropy constrain. Previous methods [22, 39] only use                                                    on thirteen downstream tasks, including ImageNet-1K (IN-\naccuracy as the evaluation metric. However, the overfitting                                                  1K) [10], Caltech101 [15] (object recognition), Standford-\nproblem appears as shown in Fig. 1(c). To this end, we in-                                                         Cars [34], CUB200-2011 [71] (bird classification), DTD [8]\nclude a simple entropy constrain, which penalizes the model                                                                  (Textures), EuroSAT (ESAT) [26] (satellite images), FGV-\nto predict a higher probabilistic score in the true label y:                                                             CAircraft [41], Flowers102 [48], Food101 [3], Oxford-\n            H                   = \\mathb b {E}_{( x, y)\\in\\mathcal{D}}[-\\log(s(x,y))].          (5)     Pets [53], Places365 [81], SUN397 [74] (scene recogni-\nThe final score is formulated as follows:                            tion), UCF101 [67] (human action).\n                                                     Implementation details.  In the default setting, we use\n               F( \\m a thc a l   {D},P)\\text{Acc}H.\\label{eq:score_function}              (6)\n                                                            template-80 pre-defined in CLIP [58] as the template li-\nwhere Œ± is a scalar to balance them. In Sec. 4.4, we empiri-                                                              brary and CuPL [55] as the description library for search-\ncally show that this score effectively reduces overfitting.                                                             ing the hyperparameters in a fixed language space. Dataset\n                                                    domain and synonym labels are generated by LLMs. This\n3.4. Sampling Strategy for Initialization\n                                                                    setting ensures a one-time query of LLMs, and no human\nAfter exploring the best template, we continue to opti-      intervention is required.  If not explicitly stated, we set it-\nmize the class-specific descriptions. To save iteration costs,      eration times T = 4 in both template and description op-\nwe introduce a prompt sampling strategy to find a better      timization, generated number M = N = 8, Œ± = 1e3,\nstart point and a grouping sampling strategy to select some     nwst = nsln = log(|C|) for all datasets, where |C| is the\nsalient categories instead of all for iterative optimization.      number of classes. All results are average with four seeds.\n  Prompt sampling strategy aims to initialize the class-     Besides, our ProAPO is implemented in PyTorch and runs\nspecific candidate prompt ÀÜP0 with the optimized template     with an RTX 3090 GPU. More details are shown in Supp.4.\n\n(11)        (13)\n          Module           TF        IN-1K              Caltech        Cars      CUB      DTD        ESAT        FGVC      FLO        Food        Pets            Places      SUN      UCF      Avg      Avg\n\n                                                             ResNet-50 Backbone\n          CLIP (a photo of a {})  ‚úì   57.9   84.5   53.9   44.7   38.8   28.6   15.9   60.2   74.0   83.2   38.2   58.0   56.9   55.6   53.4\n\n           prompt tuning methods\n         CoOp [83]           ‚úó    57.2   87.5   55.6      -    44.4   50.6   9.6   68.1   74.3   85.9      -    60.3   61.9   59.6      -\n         PLOT [6]            ‚úó    59.5   89.8   56.6      -    46.6   54.1   17.9   71.7   77.7   87.5      -    62.5   64.5   62.6      -\n           ProGrad [85]         ‚úó    57.8   88.7   58.4      -    46.1   56.3   18.8   73.2   76.0   88.4      -    60.5   65.6   62.7      -\n\n            automatic prompt optimization methods\n         PN [39]          ‚úì   59.6   89.1   56.2      -    44.8   49.0   18.1   67.2   78.3   88.1      -    61.0   60.2   61.1      -\n         ProAPO (ours)      ‚úì   61.5   90.3   58.0   50.7   52.3   51.7   21.1   75.1   81.8   88.7   41.8   63.7   66.0   64.6   61.8\n\n                                                                ViT-B/32 Backbone\n          CLIP (a photo of a {})  ‚úì   62.1   91.2   60.4   51.7   42.9   43.9   20.2   66.0   83.2   86.8   39.9   62.1   60.9   61.8   59.3\n\n            hand-engineered methods\n            Template-80 [58]     ‚úì   63.5   91.6   60.4   51.2   42.8   52.6   19.5   66.1   84.2   87.4   41.6   63.5   62.9   63.1   60.6\n            FILIP-8 [76]       ‚úì   63.8   91.4   60.7   52.7   43.4   54.3   18.9   67.0   84.6   87.5   41.2   63.9   65.0   63.7   61.1\n           DEFILIP-6 [9]      ‚úì   62.5   91.0   59.9   51.1   41.3   46.4   18.8   66.5   84.3   87.5   40.2   62.3   63.6   62.2   59.6\n\n             description-based methods\n          DCLIP [43]        ‚úì   63.3   92.7   59.4   52.7   44.1   38.4   19.4   66.1   83.9   88.1   41.2   65.0   65.8   62.4   60.0\n             Waffle [61]        ‚úì   63.3   92.1   59.3   52.9   43.2   51.6   19.6   66.3   84.9   87.7   41.5   65.0   64.5   63.4   60.9\n          CuPL [55]        ‚úì   64.4   92.9   60.7   53.3   50.6   50.5   20.9   69.5   84.2   87.0   43.1   66.3   66.4   64.9   62.3\n          GPT4Vis [73]       ‚úì   63.5   93.1   61.4   52.7   48.5   47.0   21.4   69.8   84.3   88.1   42.7   64.2   65.7   64.3   61.7\n           AdaptCLIP [62]     ‚úì   63.3   92.7   59.7   53.6   47.4   51.3   20.8   67.2   84.2   87.6   41.9   66.1   66.5   64.2   61.7\n         ProAPO w/ DCLIP   ‚úì   64.1   93.2   60.6   53.6   48.2   59.4   22.6   71.5   84.2   88.7   42.7   66.0   68.0   66.0   63.3\n         ProAPO (ours)      ‚úì   64.7   94.4   61.7   55.4   53.5   63.0   23.0   74.3   85.3   91.0   43.3   66.6   69.0   67.9   65.0\n\nTable 1. Comparison of our ProAPO with SOTA textual prompt-based methods. We report the top-1 accuracy (%) on the test set. The\nbest and second best results of the same backbone for each dataset are bolded and underlined, respectively. Avg (11) and Avg (13) denote\naverage results across 11 datasets (excluding CUB [71] and Places [81]) and all 13 datasets. TF denotes training-free approaches.\n\n4.1. Comparison with SOTA Methods                          tails.  Our ProAPO also outperforms description-based\n                                                         methods, even with DCLIP as initialization. We improve\nCompared methods. We compare our results with state-     performances of DCLIP and CuPL by 3.3% and 2.7% on av-\nof-the-art (SOTA) textual prompt-based methods, includ-     erage across thirteen datasets. Notably, it improves DCLIP\ning vanilla CLIP with ‚Äúa photo of a {}‚Äù template,     and CuPL by 5.4% and 4.8% on FLO and by 21% and\nprompt tuning methods [6, 83, 85], hand-engineered meth-    12.5% on ESAT, confirming that iterative optimization of\nods (i.e., best templates released by [9, 58, 76]), LLM-      class-specific prompts enhances fine-grained recognition.\ngenerated description methods [43, 55, 61, 62, 73], and        Critical analysis. On datasets like ImageNet [10], Cal-\nautomatic prompt optimization methods [39]. We test our     tech [15], Places [81], and SUN [74], performance gains\nProAPO on two popular backbones (ResNet50 [24] and      are relatively small. We attribute this to two reasons: First,\nViT-B/32 [13]). Prompt tuning and automatic prompt opti-      datasets like ImageNet and Caltech contain coarse-grained\nmization methods are evaluated under one-shot supervision.      categories.  The differences between categories have be-\n   Results.  In Tab. 1, we see that our ProAPO consis-    come clearer with LLM-generated descriptions, eliminat-\ntently outperforms previous prompt-based methods across     ing the need for our method. Second, fine-grained datasets,\ndiverse datasets on ResNet50 and ViT-B/32 backbones.     such as Places and SUN for scene recognition, are easily\nOur optimized prompts improve vanilla CLIP by an av-     confusing between different images, limiting performance\nerage of 8.4% (from 53.4% to 61.8%) on ResNet50 and     from only textual side optimization. In Sec. 4.2, we show\n5.7% (from 59.3% to 65.0%) on ViT-B/32.  Moreover,      that adapter-based methods with our optimized prompt im-\nour training-free ProAPO surpasses gradient-based prompt-     prove performance again after addressing issues of image\ntuning methods (CoOp, PLOT, ProGrad) by at least 1.9%     confusion. Moreover, we observe that the language search\naverage accuracy in eleven datasets.   It shows optimiz-     space impacts performance. Since CuPL has better descrip-\ning prompts in a natural language space is more effective      tions than DCLIP, our ProAPO with CuPL performs well.\nin low-shot tasks. Compared to template-optimized meth-\n                                                               4.2. More Benefits by Optimal Promptsods (i.e., PN and hand-engineered methods), our ProAPO\nachieves remarkable performance on fine-grained datasets,     Transfer to adapter-based methods. In Fig. 3, we show\ne.g., CUB, FLO, ESAT, and UCF. This is because class-      the results of popular adapter-based methods [18, 70, 80,\nspecific descriptions provide fine-grained discriminative de-     86] with different prompt initialization, i.e., SOTA method\n\n75.0                                            77.5                                                        70     PN                                             67       Baseline\n                                                                                                                                                      Best                                                                                                                                                                  Single                                                                                                                                                         Template*                                                                                                                                                                          66                                                                                                                                                                                  w/                                                                                                                                            ATO                                                                                                           set                                                                                                                   68     72.5                                                     75.0                                                                                                        ATO                                                                                                                                                                             (ours)                                                                                                                                                                                  w/                                                                                                                                                               ProAPO                                                                                                                                                                          65                                                                                                                                                      Best                                                                                                                                            Ensemble                                                                                                                                                            Template*                                                                                                                                              test                                                     72.5     70.0                                                                                                                   66                                                                                                                                                                          64                                                                                                                                                                                                                   (13)                                                                       on\n                                                     70.0 (11)                                                     (11)     67.5                                  Tip                                  w/                               CuPL                                                                       CLIP-A                                                                                   w/                                                                                                                                                              Avg 6362                                                     67.5                                Tip-X                                    w/                                 CuPL                                                                                    Tip-F                                                                                 w/                                                                       CuPL     65.0                                                                                                                   62 Avg                                        Avg                                                                                                                                                                          61                        APE                                   w/                                CuPL                                                                   APE-T                                                                                  w/                                                                        CuPL                                                     65.0                                                                         CuPL                                        Accuracy 64\n                                                                                                                                                                          60     62.5                        Tip w/ ProAPO         62.5                   CLIP-A w/ ProAPO                 60\n                                    w/                                  ProAPO                                                                                    Tip-F                                                                                 w/                                                                          ProAPO     60.0                       Tip-X                                                                                                                   58   Avg (11)    ImageNet    UCF      FLO          59  DCLIP  GPT4Vis AdaptCLIP  CuPL                                                     60.0                        APE w/                                 ProAPO                                                                   APE-T                                                                                  w/                                                                           ProAPO     57.5                                                                                                                                 Datasets                                    Methods\n          1 2   4       8              16           1 2   4       8              16\n                 Shots Number                          Shots Number                                      (a)                                   (b)\n                                                                  Figure 5. Performance improvement analysis. (a) Analysis of      (a) Training-free methods.           (b) Fine-tuning methods.\n                                                                       the effect of single vs. ensemble prompts. * denotes results eval-\nFigure 3. Results of adapter-based methods with different ini-\n                                                                   uated in the test set. ATO is our automatic template optimization\ntial prompts. Solid and dotted lines denote prompt initialization\n                                                                      algorithm. (b) Results of previous description-based methods with\nwith ProAPO and CuPL, respectively.\n                                                            prompt optimization by our ATO and ProAPO algorithms.\n\n\n                        Source            Target                                                     Removed Prompts                    Retained Prompts\n                                                                                                                                                                                                                                ‚Ä¢   Laysan Albatross, a type of seabird.            ‚Ä¢   The Laysan Albatross  is a white bird\n      Module    Shots  RN50  RN101  ViT-B/32  ViT-B/16                                                                            ‚Ä¢  A Laysan albatross in mid-flight over        with a yellow head.\n                                                                                                                                                   the ocean.                                               ‚Ä¢   The Moli is a large seabird with a white      CLIP [58]    0     57.9     60.6     61.9      66.6                                                                                  Albatross                                  ‚Ä¢   Laysan albatrosses are large birds with       body and wings flecked with black.\n                                                                                                                                              long wings and a long hooked bill.            ‚Ä¢  A Laysan Albatross  is a seabird with\n      CoOp [83]   16     63.0     20.6     31.7      39.5                                                                                 ‚Ä¢   The Laysan albatross has a slim build        white feathers, a yellow beak, and\n                                                                                                                               and long wings.                             black eyes.     PN [39]      1     59.9     60.7     62.2      67.0                                                       Laysan\n      ProAPO     1     61.5     62.1     64.6      69.9                                                                                 ‚Ä¢‚Ä¢  ASootySootyalbatrossesAlbatross inareflightlargetheblackocean.and       ‚Ä¢   TheblackSootybird Albatrosswith a wingspanis a darkof brown3-3.   or\n                                                                                                                                                white birds with long wings and a       ‚Ä¢   The Sooty Albatross is a type of bird                                                                                                                                                                                                                                                                                                                                                                     Albatross                        long hooked bill.                               that is all black with a white belly.Table 2. Results of prompt transfer from ResNet-50 to other                                                        ‚Ä¢   Sooty  albatrosses  are a  species  of       ‚Ä¢   Sooty Albatrosses have black, white\narchitectures. We report the top-1 accuracy in ImageNet-1K.                             Sooty                                  ‚Ä¢   seabirdSooty Albatrossthat haveis darka specieplumage.of albatross.        underparts,white crescentandarounda blacktheheadeye. with a\n\n                          Avg (13)\n                                                                  Figure 6.  Qualitative analysis of class-specific prompt opti-\n               CuPL  5.1   -0.3   3.0    3.1    2.4    1.2    1.0    0.5      4            mization by ProAPO. Shaded red and blue words denote com-\n         Model                                            mon and discriminative descriptions in two confused categories.\n               RN50  8.4    2.6    4.8    4.9    4.2    3.8    2.4    1.7      2\n                                                               4.3. Performance Improvement Analysis           Source                                                         0              7.3    2.9    5.7    5.0    4.1    3.6    2.4    1.5                              ViT-B/32\n                                                                   2           In this section, we analyze the key reasons for the perfor-\n                                                  mance improvement of our ProAPO.           RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP\n                                Target Model                                                  Prompt ensembling is better than a single prompt.\nFigure 4. Results of prompt transfer to different backbones.    Compared to PN [39], we utilize prompt ensembling instead\nThe value denotes performance gains compared to vanilla VLMs.                                                              of a single prompt to optimize the template and descrip-\nOur optimized prompts of ResNet50 and ViT-B/32 are reported.\n                                                                        tion. To evaluate the effectiveness of prompt ensembling,\nCuPL [55] and our ProAPO. Adapter-based methods with    we use Template-80 [58] as the template library and denote\nProAPO (solid lines) consistently surpass those with CuPL      the prompts searched by the test set as the upper bound.\n(dotted lines).   It reveals that high-quality prompts make    As shown in Fig. 5(a), we observe that ensemble templates\nadapters perform better. Even in low shots, training with     have a higher upper bound than the single template, consis-\nProAPO achieves notable performance gains, which verifies      tent with prior work [9, 43, 76]. Similarly, we observe that\nits effectiveness. As the number of shots increases, adapters     our optimized templates achieve higher performance than\nfurther improve results by enhancing image features.        PN [39], even better than the best single template, further\n                                                                verifying the effectiveness of our method.Transfer to different backbones.   In Tab. 2, we  re-\nport accuracy in ImageNet across  different backbones,         Iterative optimization improves prompt quality.  In\nwith prompts optimized on a source backbone (ResNet50)      Fig. 6, we show the changes in descriptions with our\nadapted to target backbones (ResNet101, ViT-B/32, ViT-    ProAPO. After iterative optimization, common descriptions\nB/16). We observe that CoOp [83] obtains a significant drop     such as ‚Äúflight over ocean‚Äù and ‚Äúlong wings\nin accuracy on target backbones while our ProAPO main-    and hooked bill‚Äù are removed.  Discriminative de-\ntains performance. It verifies that discrete prompts searched      scriptions are also retained in candidate prompts,  e.g.,\nin natural language spaces transfer better than continuous    ‚Äúwhite body‚Äù  for  Laysan  Albatross,  and ‚Äúblack\nprompts. ProAPO also outperforms PN, which reveals the    underpants‚Äù for Sooty Albatross. As such, we see a\neffectiveness of class-specific optimization. Moreover, we     notable improvement in description-based methods [43, 55,\nachieve stable performance gains compared to CuPL [55]     62, 73] with our ATO and ProAPO in Fig. 5(b) by at least\nfrom source to target models in Fig. 4.  It further verifies    2.7% average in thirteen datasets. It further verifies the ef-\nthat ProAPO transfers easily across different backbones.         fectiveness of our progressive optimization.\n\nComponent                                                                                ImageNet                                 ImageNet\n                                                                                                                                                        PCCs:                                                                                                                                                                                    0.932                                                                                                             PCCs:                                                                                                                                0.7195                                                                                                                                                                                         64.5                                                                                                                                  64.5        Add             Del  Rep  Cross  Mut  IN-1K                                              Avg                                                                 (11)  Avg                                                                            (13)                  set                                                                                                                                                                               Best Acc:                                                                                                                                                                                            64.7                                                                                                                             Best Acc:                                                                                                                             64.0¬±0.2                       set                                                                                                                                                                                         64.0                                                                                                                                  64.0                                                                                                                                                                                                              test                                                                                                                                                test     CLIP            (Baseline)                                                 62.1                                                           61.8                                                                      59.3                                                                                                                                                                                         63.5\n                                                                        on 63.5                           on 63.0\n      edit-based               generation\n                                                                                                                                                                                         62.5       ‚úì    a)                                                 63.8                                                           66.0                                                                      63.3                                                                                                                                  62.5                                                                                                                                                                                         62.0       ‚úì           ‚úì    b)                                                 64.6                                                           66.4                                                                      63.8                                                                                                                                                                                                                                                                                               Accuracy 63.0                                                                                                                                  62.0                                                                                                             Accuracy                                                                                                                                                                                         61.5       ‚úì               ‚úì    c)                                                 64.4                                                           66.5                                                                      63.8\n    d)  ‚úì   ‚úì   ‚úì                      64.6      66.7       64.0                                64.0 64.5 65.0Accuracy65.5 66.0on train66.5 set67.0 67.5 68.0          -9.2  -9.0  -8.8Fitness-8.5score-8.2 on-8.0train-7.8set -7.5  -7.2\n      evolution-based                     generation                                                                                             (a) Previous score function.             (b) Our fitness score\n    e)  ‚úì   ‚úì               ‚úì    ‚úì             64.6      67.3       64.5\n    f)  ‚úì   ‚úì   ‚úì         ‚úì     64.7      67.1       64.3            Figure 7. Effect of different score functions. Higher PCC val-\n    g)  ‚úì   ‚úì   ‚úì    ‚úì    ‚úì     64.7      67.9       65.0\n                                                                 ues mean stronger correlations between training metrics and test\n   Table 3. Ablation of edit- and evolution-based operators.          results. Best Acc is the test result when achieving the best score.\n\n                                                                                                                 68                               68                               68\n     Module (ViT-B/32)        IN-1K  Avg (11)  Avg (13)   Times\n                                                                                                                   set 67                             set 67                             set 67\n     a) w/o prompt sampling      64.4      67.3       64.5     12 min                            test 66                                       test 66                                       test 66\n     b) w/o group sampling       64.8      68.1       65.2    306 min             on 65                    on 65                    on 65\n     c) w/o sampling strategies    64.5      67.2       64.4    302 min                      64                               64                               64\n                                                                                                                                                                                   63                 Avg (11)                                                                                                                 63                 Avg (11)        Accuracy                                                                                                                                                 63                Avg (11)         Accuracy     ProAPO (full model)         64.7      67.9       65.0     15 min                                                       Accuracy\n                                                                                                                 62                 Avg (13)      62                Avg (13)      62                 Avg (13)\n         Table 4. Ablation of two sampling strategies.                           61 0 1 2 3 4 5 6 7 8 9 16    61 0  1  2  4  8 16 32 64 128    61 0  2  4  6  8  10 12 14\n                                                                                          (a) Iteration times T.  (b) Generated numbers  (c) Sampling groups S\n4.4. Ablation Study\n                                                                  Figure 8. The effect of hyperparameter analysis. The hyperpa-\nAre both GEN and EVO algorithms necessary? In Tab. 3,      rameter value set to 0 denotes the result of CuPL [55].\nwe ablate edit- and evolution-based operators.  For edit-\n                                                                the number of iterations increases, we see a consistent per-based operators, we observe that the model with add, delete,\n                                                       formance improvement compared to the baseline CuPL. Itand replace operations achieves a higher result in row d).\n                                                           demonstrates that iterative optimization improves promptAfter introducing evolution-based operators, i.e., crossover\n                                                                      quality. Stable results are achieved when T ‚â•4.operator to combine advantages of high-scoring candidates,\n                                       How many generated prompts to use? In Fig. 8(b), weand mutation operator to avoid locally optimal solutions,\n                                                  show the effect of generated numbers in GEN and EVO al-we see an increase in performance in rows e)-g).  It con-\n                                                             gorithm, where we set M = N. Similarly, progressive im-firms that evolution-based operators make the model search\n                                                        provements are seen as generated numbers increase. We seethe optimal prompt faster with limited iterations.\n                                                          a reliable result when M = N ‚â•8. It reveals the effective-Does sample strategies degrade performance? In Tab. 4,\n                                                            ness of generating diverse candidates by our algorithm.we ablate two sampling strategies for description optimiza-\n                                                 Are more sampling groups better? In Fig. 8(c), we showtion. Without the prompt sampling, we see a slight decrease\n                                                                the effect of the number of salient groups S in the groupin times while results drop in row a). It verifies the effective-\n                                                         sampling strategy. We see a notable improvement whenness of the prompt sampling in finding a better initial point.\n                                          S = 2. As the number of groups S increases, it achievesWithout the group sampling to select salient categories for\n                                                                   stable results when S ‚â•8.   It verifies that optimizingoptimization, we observe a notable increase in time costs\n                                                                 several salient categories can achieve comparable perfor-(from 15 min to 300+ min, 20 times) yet similar results in\n                                                    mances with all categories and save iteration costs.row b) and the full model.  It reveals that group sampling\nsimultaneously improves performance and efficiency.\n                                                          5. ConclusionWhich score function is better? In Fig. 7, we compare the\ndifferent score functions, i.e., accuracy (used in PN [39])   We propose an evolution-based algorithm for VLMs to\nand our fitness score, to evaluate the quality of the candidate     progressively refine prompts from task-specific to class-\nprompt. PCCs (Pearson Correlation Coefficients) are intro-      specific levels. To save generation costs, ProAPO uses sev-\nduced to evaluate the linear relationship between training      eral edit- and evolution-based operators to create candidate\nmetrics and test performance. The high PCC values mean     prompts with a prompt library. Results show that our fitness\na strong correlation. We see that the model with our fit-     score mitigates overfitting in class-specific prompts. We\nness score achieves stable and high test results compared     empirically verify that two sampling strategies improve per-\nto previous score functions when achieving the best score.     formance and save iteration times. Extensive experiments\nBesides, a higher PPC value further verifies that our fitness     on thirteen datasets reveal that ProAPO consistently out-\nscore effectively alleviates the overfitting problem.             performs SOTA textual prompt-based methods on low-shot\n                                                                     tasks. Moreover, our method effectively improves adapter-\n4.5. Hyperparameter Sensitivity\n                                                         based and description-based methods and easily transfers\nHow many iterations of Alg. 2 to use? In Fig. 8(a), we     across different backbones. We hope ProAPO could pro-\nshow the effect of iteration times T in APO algorithm. As     vide new insight into adapting VLMs from the textual side.\n\nAcknowledgements                                                    for neon genesis. Image Vis. Comput., 149:105171, 2024.\n                                                                           14, 15\nThis work was supported by the Central Guidance for Local                                                                     [15] Li Fei-Fei, Rob Fergus, and Pietro Perona. Learning gener-\nSpecial Project (Grant No. Z231100005923044).                                                                                  ative visual models from few training examples: An incre-\n                                                                     mental bayesian approach tested on 101 object categories. In\nReferences                                          CVPRW, page 178, 2004. 5, 6, 12, 14, 18\n                                                                     [16] Chun-Mei Feng, Kai Yu, Yong Liu, Salman Khan, and\n [1] Jean-Baptiste Alayrac, Jeff Donahue, and Pauline Luc et al.\n                                                       Wangmeng Zuo. Diverse data augmentation with diffusions\n     Flamingo: a visual language model for few-shot learning. In\n                                                                                for effective test-time prompt tuning. In ICCV, pages 2704‚Äì\n     NeurIPS, 2022. 1, 14\n                                                                     2714, 2023. 16\n [2] Hyojin Bahng, Ali Jahanian, Swami Sankaranarayanan, and\n                                                                     [17] Chrisantha Fernando, Dylan Banarse, Henryk Michalewski,      Phillip Isola.  Visual prompting: Modifying pixel space to\n                                                           Simon Osindero, and Tim Rockt¬®aschel.   Promptbreeder:     adapt pre-trained models. CoRR, abs/2203.17274, 2022. 2\n                                                                                  Self-referential self-improvement via prompt evolution.  In\n [3] Lukas Bossard, Matthieu Guillaumin, and Luc Van Gool.\n                                                           ICML, 2024. 3\n     Food-101 - mining discriminative components with random\n                                                                     [18] Peng Gao, Shijie Geng, Renrui Zhang, Teli Ma, Rongyao      forests. In ECCV, pages 446‚Äì461, 2014. 5, 12, 14, 18\n                                                                      Fang,  Yongfeng Zhang, Hongsheng  Li,  and Yu Qiao.\n [4] Tom B. Brown, Benjamin Mann, and Nick Ryder et al. Lan-\n                                                                             Clip-adapter:  Better vision-language models with feature\n     guage models are few-shot learners. In NeurIPS, 2020.  1,\n                                                                              adapters. IJCV, 132(2):581‚Äì595, 2024. 2, 6, 21\n    14\n                                                                     [19] Tianyu Gao, Adam Fisch, and Danqi Chen.  Making pre-\n [5] Kaiyan Chang, Songcheng Xu, Chenglong Wang, Yingfeng\n                                                                              trained language models better few-shot learners.  In ACL,\n     Luo, Tong Xiao, and Jingbo Zhu.   Efficient prompting\n                                                                    pages 3816‚Äì3830, 2021. 1\n     methods for large language models: A survey.  CoRR,\n     abs/2404.01077, 2024. 3                                        [20] Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song,\n                                                   Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu Yang.  Con- [6] Guangyi Chen, Weiran Yao, Xiangchen Song, Xinyue Li,\n                                                                          necting large language models with evolutionary algorithms    Yongming Rao, and Kun Zhang.  PLOT: prompt learning\n                                                                              yields powerful prompt optimizers. In ICLR, 2024. 3     with optimal transport for vision-language models. In ICLR,\n     2023. 1, 2, 6                                                    [21] Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song,\n                                                   Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu Yang.  Con- [7] Mehdi Cherti, Romain Beaumont, Ross Wightman, Mitchell\n                                                                          necting large language models with evolutionary algorithms     Wortsman, Gabriel Ilharco, Cade Gordon, Christoph Schuh-\n                                                                              yields powerful prompt optimizers. In ICLR, 2024. 1, 3    mann, Ludwig Schmidt, and Jenia Jitsev. Reproducible scal-\n     ing laws for contrastive language-image learning. In CVPR,      [22] Songhao Han, Le Zhuo, Yue Liao, and Si Liu. Llms as visual\n     pages 2818‚Äì2829, 2023. 14, 15                                         explainers: Advancing image classification with evolving vi-\n                                                                             sual descriptions. CoRR, abs/2311.11904, 2023. 3, 4, 5, 16, [8] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy\n                                                              17    Mohamed, and Andrea Vedaldi. Describing textures in the\n     wild. In CVPR, pages 3606‚Äì3613, 2014. 5, 12, 14, 17, 18        [23] Frederick Hayes-Roth. Review of ‚Äùadaptation in natural and\n [9] Yufeng Cui, Lichen Zhao, Feng Liang, Yangguang Li, and              artificial systems by john h. holland‚Äù, the u. of michigan\n     Jing Shao. Democratizing contrastive language-image pre-            press, 1975. SIGART Newsl., 53:15, 1975. 4\n      training: A CLIP benchmark of data, model, and supervi-      [24] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\n      sion. CoRR, abs/2203.05796, 2022. 1, 2, 6, 7, 12, 14               Deep residual learning for image recognition.  In CVPR,\n[10]  Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,          pages 770‚Äì778, 2016. 6\n     and Li Fei-Fei. Imagenet: A large-scale hierarchical image      [25] Xuehai He, Diji Yang, Weixi Feng, Tsu-Jui Fu, Arjun R.\n     database. In CVPR, pages 248‚Äì255, 2009. 5, 6, 12, 14, 18            Akula, Varun Jampani, Pradyumna Narayana, Sugato Basu,\n[11] Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan          William Yang Wang, and Xin Wang. CPL: counterfactual\n    Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing,          prompt learning for vision and language models. In EMNLP,\n     and Zhiting Hu. Rlprompt: Optimizing discrete text prompts          pages 3407‚Äì3418, 2022. 2\n     with reinforcement learning. In EMNLP, pages 3369‚Äì3391,      [26] Patrick Helber, Benjamin Bischke, Andreas Dengel, and\n     2022. 3                                                 Damian Borth. Eurosat: A novel dataset and deep learning\n[12] Mohammad Mahdi Derakhshani, Enrique Sanchez, Adrian          benchmark for land use and land cover classification. IEEE J.\n      Bulat, Victor Guilherme Turrisi da Costa, Cees G. M. Snoek,             Sel. Top. Appl. Earth Obs. Remote. Sens., 12(7):2217‚Äì2226,\n     Georgios Tzimiropoulos, and Brais Mart¬¥ƒ±nez.  Variational           2019. 5, 12, 14, 17, 18\n     prompt tuning improves generalization of vision-language      [27] John H. Holland. Adaptation in Natural and Artificial Sys-\n     models. CoRR, abs/2210.02390, 2022. 2                             tems: An Introductory Analysis with Applications to Biology,\n[13] Alexey Dosovitskiy, Lucas Beyer, and Alexander Kolesnikov           Control, and Artificial Intelligence. MIT Press, 1992. 4\n      et al. An image is worth 16x16 words: Transformers for      [28] Lei Huang, Weijiang Yu, and Weitao Ma et al. A sur-\n     image recognition at scale. In ICLR, 2021. 6                       vey on hallucination in large language models:  Princi-\n[14] Yuxin Fang, Quan Sun, Xinggang Wang, Tiejun Huang, Xin-             ples, taxonomy, challenges, and open questions.  CoRR,\n     long Wang, and Yue Cao. EVA-02: A visual representation           abs/2311.05232, 2023. 1\n\n[29] Yunshi Huang, Fereshteh Shakeri, Jose Dolz, Malik Boudiaf,      [44] Muhammad Jehanzeb Mirza, Leonid Karlinsky, Wei Lin,\n    Houda Bahig, and Ismail Ben Ayed. LP++: A surprisingly           Sivan Doveh, Jakub Micorek, Mateusz Kozinski, Hilde\n     strong linear probe for few-shot CLIP.  In CVPR, pages          Kuehne, and Horst Possegger. Meta-prompting for automat-\n     23773‚Äì23782, 2024. 2                                              ing zero-shot visual recognition with llms. In ECCV, pages\n[30] Chao Jia, Yinfei Yang, and Ye Xia et al. Scaling up visual          370‚Äì387, 2024. 2\n     and vision-language representation learning with noisy text      [45] Melanie Mitchell.  An introduction to genetic algorithms.\n     supervision. In ICML, pages 4904‚Äì4916, 2021. 1, 14            MIT Press, 1998. 4\n[31] Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie,      [46] Norman Mu, Alexander Kirillov, David A. Wagner, and\n     Serge J. Belongie, Bharath Hariharan, and Ser-Nam Lim. Vi-           Saining Xie. SLIP: self-supervision meets language-image\n      sual prompt tuning. In ECCV, pages 709‚Äì727, 2022. 2                  pre-training. In ECCV, pages 529‚Äì544, 2022. 1, 14\n[32] Muhammad  Uzair  Khattak,  Hanoona  Abdul  Rasheed,      [47] M. Naeem, M. Ali Khan, Y. Xian, M. Afzal, D. Stricker,\n    Muhammad Maaz, Salman H. Khan, and Fahad Shahbaz           L. Van Gool, and F. Tombari. I2mvformer: Large language\n     Khan. Maple: Multi-modal prompt learning. In CVPR, pages         model generated multi-view document supervision for zero-\n     19113‚Äì19122. IEEE, 2023. 2, 16                                     shot image classification.  In CVPR, pages 15169‚Äì15179,\n[33] Muhammad Uzair Khattak, Syed Talal Wasim, Muzammal           2023. 2\n     Naseer, Salman Khan, Ming-Hsuan Yang, and Fahad Shah-      [48] Maria-Elena Nilsback and Andrew Zisserman. Automated\n     baz Khan.  Self-regulating prompts:  Foundational model           flower classification over a large number of classes.   In\n     adaptation without forgetting. In ICCV, pages 15144‚Äì15154,         ICVGIP, pages 722‚Äì729, 2008. 5, 12, 14, 15, 17, 18\n     2023. 2, 16                                                     [49] Zachary Novack, Julian J. McAuley, Zachary Chase Lipton,\n[34] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei.          and Saurabh Garg.  Chils:  Zero-shot image classification\n    3d object representations for fine-grained categorization. In           with hierarchical label sets. In ICML, pages 26342‚Äì26362,\n    ICCV, pages 554‚Äì561, 2013. 5, 12, 14, 18                           2023. 3\n[35] Feng Li, Qing Jiang, Hao Zhang, Tianhe Ren, Shilong Liu,      [50] Changdae Oh, Hyeji Hwang, Hee Young Lee, YongTaek\n    Xueyan Zou, Huaizhe Xu, Hongyang Li, Jianwei Yang,          Lim, Geunyoung Jung, Jiyoung Jung, Hosik Choi, and\n    Chunyuan Li, Lei Zhang, and Jianfeng Gao.  Visual in-         Kyungwoo Song.  Blackvip: Black-box visual prompting\n     context prompting. In CVPR. IEEE, 2024. 2                            for robust transfer learning. In CVPR, pages 24224‚Äì24235,\n[36] Junnan Li, Dongxu Li, Caiming Xiong, and Steven C. H.           2023. 2\n     Hoi. BLIP: bootstrapping language-image pre-training for      [51] OpenAI. GPT-4 technical report. CoRR, abs/2303.08774,\n      unified vision-language understanding and generation.  In           2023. 1, 3, 14\n    ICML, pages 12888‚Äì12900, 2022. 1, 14                         [52] Yassine Ouali, Adrian Bulat, Brais Mart¬¥ƒ±nez, and Georgios\n[37] Yangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui, Wanli           Tzimiropoulos.  Black box few-shot adaptation for vision-\n     Ouyang, Jing Shao, Fengwei Yu, and Junjie Yan.   Su-          language models. In ICCV, pages 15488‚Äì15500, 2023. 2\n     pervision exists everywhere: A data efficient contrastive      [53] Omkar M. Parkhi, Andrea Vedaldi, Andrew Zisserman, and\n     language-image pre-training paradigm.  In ICLR, 2022.  2,          C. V. Jawahar. Cats and dogs. In CVPR, pages 3498‚Äì3505,\n    14                                                              2012. 5, 12, 14, 18\n[38] Yili Li, Jing Yu, Keke Gai, Bang Liu, Gang Xiong, and Qi      [54] Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal.\n    Wu.  T2vindexer: A generative video indexer for efficient           Grips:   Gradient-free,  edit-based  instruction  search  for\n     text-video retrieval. In ACM MM, pages 3955‚Äì3963. ACM,          prompting large language models.  In EACL, pages 3827‚Äì\n     2024. 2                                                         3846, 2023. 3\n[39] Shihong Liu, Samuel Yu, Zhiqiu Lin, Deepak Pathak, and      [55] Sarah M. Pratt, Ian Covert, Rosanne Liu, and Ali Farhadi.\n    Deva Ramanan. Language models as black-box optimizers         What does a platypus look like?  generating customized\n      for vision-language models. In CVPR, pages 12687‚Äì12697,          prompts for zero-shot image classification. In ICCV, pages\n     2024. 1, 2, 3, 4, 5, 6, 7, 8, 12, 17, 21, 24                           15645‚Äì15655, 2023. 1, 2, 3, 5, 6, 7, 8, 13, 14, 15, 16, 17, 21,\n[40] Yuning Lu, Jianzhuang Liu, Yonggang Zhang, Yajing Liu,           24, 25\n     and Xinmei Tian. Prompt distribution learning.  In CVPR,      [56] Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang\n     pages 5196‚Äì5205, 2022. 2                                       Zhu, and Michael Zeng.  Automatic prompt optimization\n[41] Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew B.           with ‚Äùgradient descent‚Äù and beam search. In EMNLP, pages\n     Blaschko, and Andrea Vedaldi.  Fine-grained visual classi-          7957‚Äì7968, 2023. 1, 3\n      fication of aircraft. CoRR, abs/1306.5151, 2013. 5, 12, 14,      [57] Xiangyan Qu, Jing Yu, Keke Gai, Jiamin Zhuang, Yuan-\n    18                                                      min Tang, Gang Xiong, Gaopeng Gou, and Qi Wu. Visual-\n[42] Mayug Maniparambil, Chris Vorster, Derek Molloy, Noel           semantic decomposition and partial alignment for document-\n     Murphy, Kevin McGuinness, and Noel E. O‚ÄôConnor.  En-          based zero-shot learning.  In ACM MM, pages 4581‚Äì4590.\n     hancing CLIP with GPT-4: harnessing visual descriptions as        ACM, 2024. 2\n     prompts. In ICCV, pages 262‚Äì271, 2023. 1, 2, 3, 4, 12           [58] Alec Radford, Jong Wook Kim, and Chris Hallacy et al.\n[43] Sachit Menon and Carl Vondrick.  Visual classification via          Learning transferable visual models from natural language\n     description from large language models. In ICLR, 2023. 1,            supervision. In ICML, pages 8748‚Äì8763, 2021. 1, 2, 3, 4, 5,\n      2, 3, 5, 6, 7, 13, 14, 17, 21, 25                                             6, 7, 12, 14, 15, 16\n\n[59] Vipula Rawte, Swagata Chakraborty, and Agnibh Pathak et      [74] Jianxiong Xiao, James Hays, Krista A. Ehinger, Aude Oliva,\n       al. The troubling emergence of hallucination in large lan-          and Antonio Torralba. SUN database:  Large-scale scene\n     guage models - an extensive definition, quantification, and           recognition from abbey to zoo. In CVPR, pages 3485‚Äì3492,\n      prescriptive remediations. In EMNLP, 2023. 1                       2010. 5, 6, 12, 14, 18\n[60] Zhiyuan Ren, Yiyang Su, and Xiaoming Liu.   Chatgpt-      [75] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,\n     powered hierarchical comparisons for image classification.         Quoc V. Le, Denny Zhou, and Xinyun Chen. Large language\n     In NeurIPS, 2023. 1, 2, 3                                       models as optimizers. In ICLR, 2024. 3\n[61] Karsten Roth, Jae-Myung Kim, A. Sophia Koepke, Oriol      [76] Lewei Yao, Runhui Huang, and Lu Hou et al. FILIP: fine-\n     Vinyals, Cordelia Schmid, and Zeynep Akata.   Waffling           grained interactive language-image pre-training.  In ICLR.\n     around for performance: Visual classification with random          OpenReview.net, 2022. 1, 6, 7, 12, 14\n     words and broad concepts.  In ICCV, pages 15700‚Äì15711,      [77] Yuhang Zang, Wei Li, Kaiyang Zhou, Chen Huang, and\n     2023. 1, 2, 3, 4, 6, 12                                      Chen Change Loy.  Unified vision and language prompt\n[62] Oindrila Saha, Grant Van Horn, and Subhransu Maji. Im-            learning. CoRR, abs/2210.07225, 2022. 16\n     proved zero-shot classification by adapting vlms with text      [78] Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and\n      descriptions. In CVPR, pages 17542‚Äì17552, 2024. 2, 6, 7,          Lucas Beyer. Sigmoid loss for language image pre-training.\n     13, 14, 17, 21, 25                                                    In ICCV, pages 11941‚Äì11952, 2023. 1, 14, 15\n[63] Jameel Abdul Samadh, Hanan Gani, Noor Hussein, Muham-      [79] Hao Zhang, Hongyang Li, Feng Li, Tianhe Ren, Xueyan\n    mad Uzair Khattak, Muzammal Naseer, Fahad Shahbaz          Zou, Shilong Liu, Shijia Huang, Jianfeng Gao, Leizhang,\n     Khan, and Salman H. Khan. Align your prompts: Test-time         Chunyuan  Li,  and  Jainwei  Yang.     Llava-grounding:\n     prompting with distribution alignment for zero-shot general-         Grounded visual chat with large multimodal models.  In\n      ization. In NeurIPS, 2023. 16                              ECCV, pages 19‚Äì35, 2024. 1\n[64] Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric      [80] Renrui Zhang, Wei Zhang, Rongyao Fang, Peng Gao, Kun-\n     Wallace, and Sameer Singh. Autoprompt: Eliciting knowl-          chang Li, Jifeng Dai, Yu Qiao, and Hongsheng Li.  Tip-\n     edge from language models with automatically generated            adapter: Training-free adaption of CLIP for few-shot clas-\n     prompts. In EMNLP, 2020. 1, 3                                             sification. In ECCV, pages 493‚Äì510, 2022. 2, 6, 21\n[65] Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom      [81] Bolei Zhou, `Agata Lapedriza, Aditya Khosla, Aude Oliva,\n     Goldstein, Anima Anandkumar, and Chaowei Xiao.  Test-          and Antonio Torralba. Places: A 10 million image database\n     time prompt tuning for zero-shot generalization in vision-            for scene recognition. IEEE TPAMI, 40(6):1452‚Äì1464, 2018.\n     language models. In NeurIPS, 2022. 2, 16                                5, 6, 12, 14, 15, 17, 18, 25\n[66] Kun Song, Huimin Ma, Bochao Zou, Huishuai Zhang, and      [82] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Zi-\n     Weiran Huang. Fd-align: Feature discrimination alignment          wei Liu.  Conditional prompt learning for vision-language\n      for fine-tuning pre-trained models in few-shot learning.  In           models. In CVPR, pages 16795‚Äì16804, 2022. 1, 2, 5, 16\n     NeurIPS, 2023. 2                                               [83] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei\n[67] Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah.            Liu. Learning to prompt for vision-language models. IJCV,\n    UCF101: A dataset of 101 human actions classes from          130(9):2337‚Äì2348, 2022. 1, 2, 5, 6, 7, 14, 16, 18, 19\n     videos in the wild. CoRR, abs/1212.0402, 2012. 5, 12, 14,      [84] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran\n     15, 17, 18                                                                  Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large lan-\n[68] Quan Sun, Yuxin Fang, Ledell Wu, Xinlong Wang, and Yue          guage models are human-level prompt engineers. In ICLR,\n     Cao. EVA-CLIP: improved training techniques for CLIP at           2023. 1, 3\n      scale. CoRR, abs/2303.15389, 2023. 1, 14                       [85] Beier Zhu, Yulei Niu, Yucheng Han, Yue Wu, and Hanwang\n[69] Yuwei Tang, Zhenyi Lin, Qilong Wang, Pengfei Zhu, and          Zhang. Prompt-aligned gradient for prompt tuning. In ICCV,\n     Qinghua Hu. Amu-tuning: Effective logit bias for clip-based          pages 15613‚Äì15623, 2023. 1, 2, 6\n     few-shot learning. In CVPR, pages 23323‚Äì23333, 2024. 2        [86] Xiangyang Zhu, Renrui Zhang, Bowei He, Aojun Zhou,\n[70] Vishaal Udandarao, Ankush Gupta, and Samuel Albanie.         Dong Wang, Bin Zhao, and Peng Gao.  Not all features\n     Sus-x: Training-free name-only transfer of vision-language            matter: Enhancing few-shot CLIP with adaptive prior refine-\n     models. In ICCV, pages 2725‚Äì2736, 2023. 2, 6, 21                   ment. In ICCV, pages 2605‚Äì2615, 2023. 2, 6, 16, 21\n[71] Catherine Wah, Steve Branson, Peter Welinder, Pietro Per-      [87] Yuhan Zhu, Yuyang  Ji, Zhiyu Zhao, Gangshan Wu, and\n     ona, and Serge Belongie. The caltech-ucsd birds-200-2011          Limin Wang. AWT: transferring vision-language models via\n      dataset. california institute of technology, 2011. 5, 6, 12, 14,           augmentation, weighting, and transportation.  In NeurIPS,\n     15, 17, 18, 25                                                    2024. 1, 2, 16\n[72] Dongsheng Wang, Miaoge Li, Xinyang Liu, Mingsheng Xu,      [88] Yuhan Zhu, Guozhen Zhang, Chen Xu, Haocheng Shen,\n    Bo Chen, and Hanwang Zhang. Tuning multi-mode token-          Xiaoxin Chen, Gangshan Wu, and Limin Wang.  Efficient\n      level prompt alignment across modalities. In NeurIPS, 2023.            test-time prompt tuning for vision-language models. CoRR,\n    16                                                               abs/2408.05775, 2024. 16\n[73] Wenhao Wu, Huanjin Yao, Mengxi Zhang, Yuxin Song,      [89] Jiamin Zhuang, Jing Yu, Yang Ding, Xiangyan Qu, and Yue\n     Wanli Ouyang, and Jingdong Wang.    Gpt4vis:  What          Hu. Towards fast and accurate image-text retrieval with self-\n     can GPT-4 do for zero-shot visual recognition?   CoRR,           supervised fine-grained alignment. IEEE TMM, 26:1361‚Äì\n     abs/2311.15732, 2023. 1, 2, 3, 6, 7, 13, 14, 17, 21, 25                1372, 2024. 2\n\nWe  first describe detailed processes of building the     vious description-based methods [42, 61], we query LLMs\nprompt library and sampling strategies in our method:           to generate dataset domain information to provide task-\n‚Ä¢ Appendix A: Details of building prompt library.                specific context. For this purpose, we use the prompt:\n‚Ä¢ Appendix B: Details of prompt sampling strategy.\n                                                               ‚ÄúHi, ChatGPT! I would like your help in generating‚Ä¢ Appendix C: Details of group sampling strategy.\n                                                                   dataset domain  information  for image  classification   Then, we show more experiments to show the effective-\n                                                          based on the dataset paper. A few words are good. Pleaseness of our ProAPO:\n                                                                   return directly without explanation.‚Ä¢ Appendix D: More implementation details.\n‚Ä¢ Appendix E: Results on different backbones.\n                                             {uploaded PDF}.‚Äù‚Ä¢ Appendix F: More comparisons with SOTA methods.\n‚Ä¢ Appendix G.1: Ablation of progressive optimization.\n                                                           Here, {uploaded PDF} represents the uploading of the\n‚Ä¢ Appendix G.2: More ablation of operators.\n                                                          paper of the dataset to LLMs. Generated dataset domain\n‚Ä¢ Appendix G.3: More ablation of group sampling.\n                                                             information is summarized in Tab. 5.\n‚Ä¢ Appendix G.4: Ablation of cost computation.\n‚Ä¢ Appendix H.1: Effect of shot numbers.\n                                                                     Dataset     Domain Information\n‚Ä¢ Appendix H.2: Effect of scalar Œ± in score function.\n‚Ä¢ Appendix H.3:  Effect of sampled numbers in prompt       IN-1K [10]    real scenario; natural scene\n  sampling.                                                            Caltech [15]   object; everyday objects; common items\n                                                                      Cars [34]       car; vehicles; auto-mobile\n‚Ä¢ Appendix H.4: Effect of quality of prompt library.\n                                               CUB [71]      bird; wildlife; ornithology\n‚Ä¢ Appendix I: More qualitative results.\n                                               DTD [8]       textures; patterns; surface; material\n  We also provide detailed results for experiments appear-                                                     ESAT [26]    land cover; remote sensing; satellite photo; satellite\ning in the main paper:                                                              imagery; aerial or satellite images; centered satel-\n‚Ä¢ Appendix J.1:  Results of transfering to adapter-based                               lite photo\n  methods.                                        FGVC [41]     aircraft; airplane; plane; airliner\n‚Ä¢ Appendix J.2: Results of transferring to different back-      FLO [48]      flower; floral; botanical; bloom\n  bones.                                                      Food [3]       food; dishes; cuisine; nourishment\n‚Ä¢ Appendix K.1: Analysis of single vs ensemble prompts.          Pets [53]       pet; domestic animals; breed; dog or cat\n                                                                           Places [81]    place; scene\n‚Ä¢ Appendix K.2: Improvement by iterative optimization.\n                                                SUN [74]      place; scene\n‚Ä¢ Appendix L.1: Ablation of edit and evolution operators.\n                                                 UCF [67]      action; human action; human activities; person do-\n‚Ä¢ Appendix L.2: Ablation of two sampling strategies.                             ing\n‚Ä¢ Appendix L.3: Ablation of different score functions.\n                                                                        Table 5. Generated dataset domain information.\nA. Details of Building Prompt Library\n                                                   Adding dataset domain to templates. We supplement\nA.1. Details of Building Template Library\n                                                             templates with dataset domain information in the follow-\nThe template library aims to collect a set of templates that     ing four ways: (1) Add ‚Äúa type of {domain}‚Äù.  (2) Re-\nprovide task-specific contextual information, which can ad-     place ‚Äú{class}‚Äù with ‚Äú{domain}:{class}‚Äù.  (3) Re-\ndress issues of semantic ambiguity caused by class names.     place ‚Äúphoto‚Äù with ‚Äú{domain}‚Äù. (4) Replace ‚Äúphoto‚Äù with\nIt contains processes for collecting templates, generating    ‚Äú{domain} photo‚Äù. Taking ‚Äúa photo of a {class}‚Äù as an\ndataset domains, and adding dataset domains to templates.      example, we modify the templates with the above four ways\n   Collecting templates. We utilize two ways to collect      to add dataset domain information as follows:\ntemplates.  First, pre-defined templates, such as Template-\n                                                                       1. a photo of a {class}, a type of {domain}.80 [58], FILIP-8 [76], and DEFILIP-6 [9] can be used. Sec-\n                                                                       2. a photo of a {domain}: {class}.ond, similar to PN [39], we query LLMs to create diverse\n                                                                       3. a {domain} of a {class}.templates by the following prompt:\n                                                                       4. a {domain} photo of a {class}.\n ‚ÄúHi, ChatGPT! I would like your help to prompt for\n                                                           Here, {class} and {domain} denote category name and image  classification  using CLIP. As  a  human-level\n                                                                 dataset domain information, respectively. prompt engineer, your task is to create a set of Templates\n  like the following for visual classification. For example:                                                       A.2. Details of Building Description Library\n\n a photo of a {}.‚Äù                                            Description Library aims to provide a set of visual descrip-\n                                                                   tions for each category, enhancing visual semantics for fine-\n  Generating dataset domain by LLMs. Inspired by pre-     grained recognition in prompts.  It contains processes for\n\ngenerating visual descriptions and category synonyms and      instruct LLM to generate visual descriptions for each cate-\nintegrating descriptions with the best templates.               gory by several prompts, which are summarized in Tab. 6.\n                                                              Integrating descriptions with the best templates. We\n  Method         Prompts                                   use the following prompt to integrate descriptions with tem-\n DCLIP [43]      Q: What are useful visual features for distin-        plates: ‚Äú{template}. {description.}‚Äù.\n                    guishing a {class} in a photo?                     After the above processes, we collect diverse visual de-\n                 A: There are several useful visual features to        scriptions for each category c, denoted as VD(c). For each\n                           tell there is a {class} in a photo:               group iteration, we select the descriptions for categories in\n  CuPL-Base [55]   Describe what a {class} looks like.               the specific group as the description library. Moreover, the\n                   Describe a {class}.                        prompt sampling strategy also utilizes these descriptions for\n                What are the identifying characteristics of a        class-specific initialization.\n                {class}?\n  CuPL-Full [55]    Describe what a {class} looks like.           B. Details of Prompt Sampling Strategy\n             How can you identify a {class}?\n                What does a {class} look like?               The detailed prompt sampling strategy is summarized in\n                   Describe an image from  the  internet  of a       Alg. 5.  Visual descriptions of each class VD(c) are col-\n               {class}                                       lected by the above process (see Appendix A.2). We utilize\n            A caption of an image of a {class}:               the candidate prompt P t‚àó with the best templates as an ini-\n  GPT4Vis [73]      I want you to act as an image description expert.         tial point. The RANDOMSAMPLE(¬∑) operator denotes ran-\n                          I will give you a word and your task is to give      domly selecting a set of elements from a given set. We ran-\n              me 20 sentences to describe the word.  Your      domly sample descriptions for each category to create mul-\n                     description must accurately revolve around this\n                                                                         tiple candidate prompts (Lines 2-8).  After Tsample-times                 word and be as objective, detailed and diverse\n                     as possible. In addition, the subject of your de-        steps, we select the candidate prompt ÀÜP0 with the highest\n                      scription is a some kind of object photograph.       score for description initialization (Line 9).  It ensures that\n                   Output the sentences in a json format which key       subsequent optimization is around the optimal initial point.\n                          is the the word and the value is a list composed\n                                        We set Tsample = 32 for all datasets in the default setting.\n                     of these sentences. Do not provide any expla-\n                      nations. The first word is ‚Äú{class}‚Äù.\n                                                     Algorithm 5 Prompt Sampling Strategy.\n  AdaptCLIP [62]  What  characteristics  can  be  used  to  dif-\n                       ferentiate {class} from  other {domain}      Require: D ‚Üê{(x, y)}n: training samples, F : D √ó P ‚Üí\n                   based on just a photo?  Provide an exhaus-         R: score function, C: class labels, VD(c): visual de-\n                        tive  list of  all  attributes  that can be used                                  ‚àó\n                                                                       scriptions of class c, Pt : the prompt candidate with the                      to identify the {domain} uniquely.   Texts\n                   should  be  of  the  form ‚Äú{domain}  with            best template\n                                                                            ‚àó\n               {characteristic}‚Äù.                                   1: U ‚Üê{Pt }\n                                                                                     2: for i = 1 to Tsample do\n     Table 6. Prompts for generating visual descriptions.                3:   Pi ‚ÜêPt‚àó\n                                                                                     4:    for all class c ‚ààC do\n  Generating category synonym.  Except for descrip-         5:     Pi ‚ÜêPi ‚à™RANDOMSAMPLE(VD(c))\ntions, we also replace class names from the dataset with         6:   end for\ntheir synonyms to create diverse class-specific prompts. For         7:  U ‚ÜêU ‚à™{Pi}\nthis purpose, we use the following prompt to ask LLMs to         8: end for\ngenerate category synonyms:                                                9: ÀÜP0 ‚Üêarg maxP ‚ààU F(D, P)\n                                                                             10: return the candidate prompt with the highest score ÀÜP0\n ‚ÄúHi, ChatGPT! I would like your help in generating\n category synonyms.  As a {domain} expert,  I will\n provide you with a category name.  Your task  is to\n provide synonyms for the current category.   If  it has     C. Details of Group Sampling Strategy\n  subclasses, return them as well.  Please return directly\n                                                  The detailed group sampling strategy  is summarized in\n without explanation.\n                                                           Alg. 6. It contains processes of obtaining misclassified cat-\n                                                               egories and selecting the worst and salient groups.\n User: I want to give the synonyms of {class}.\n                                                      Obtaining misclassified categories.   In Lines 1-8 of\n  Assistant: ‚Äù\n                                                           Alg. 6, we collect misclassified set for each category by\n  Generating visual descriptions for each category.    MISCLASS(¬∑) operator. Given an image x, if the prediction\nSimilar to previous description methods [43, 55, 62, 73], we     pred(x) is not its corresponding label y, we will add pred(x)\n\nAlgorithm 6 Group Sampling Strategy.                 D. More Implementation Details\nRequire: D ‚Üê{(x, y)}n: training samples, F : D √ó P ‚Üí                                                       D.1. Hyperparameter Settings\n   R: score function, C: class labels, VD(c): visual de-\n    scriptions of class c, Pt‚àó : prompt candidate with the     In Tab. 7, we show the searched hyperparameter settings for\n    best template, pred(x): prediction for image x               thirteen datasets.  All results are average with four seeds.\n  1: for all class c ‚ààC do                                  Except for 1, 2, 3 as seeds like CoOp [83], we add 42 as our\n  2:   MISCLASS(c) ‚Üê‚àÖ                                      fourth seed to further evaluate the stability of our method. In\n  3: end for                                                    the default setting, we use the same LLMs as the description\n  4: for all training sample (x, y) ‚ààD do                     methods, i.e., GPT-3 [4] for CuPL [55] and DCLIP [43],\n  5:     if pred(x) Ã∏= y then                             GPT-4 [51] for GPT4Vis [73] and AdaptCLIP [62].\n  6:     MISCLASS(y) ‚ÜêMISCLASS(y) ‚à™{pred(x)}\n  7:   end if                                                    Dataset     T M  N   Œ±    nwst   nsln   Tsample\n  8: end for\n                                                         IN-1K [10]    4   8   8   1e3    4     4      32\n  9: for all class c ‚ààC do\n                                                                    Caltech [15]   2   8   8   1e2    2     2      32\n 10:    Select Class Images: DATA(c) ‚Üê{(x, y)  | y =                                                                 Cars [34]     4   8   8   1e4    4     4      32\n      c}(x,y)‚ààD                                           CUB [71]     4   8   8   1e2    4     4      32                                                      ‚àó\n 11:   Compute Accuracy: ACC(c) ‚ÜêF(DATA(c), Pt )      DTD [8]      4   8   8   1e3    4     4      32                                  ‚àó\n 12:  Add Descriptions: Pc ‚ÜêPt ‚à™VD(c)                ESAT [26]    4   8   8   1e3    3     3      32\n 13:   Compute  Accuracy  Gain:   ACCGAIN(c) ‚Üê                                             FGVC [41]   4   8   8   1e3    4     4      32\n     F(DATA(c), Pc) ‚àíACC(c)                                               FLO [48]     4   8   8   1e3    4     4      32\n 14: end for                                                          Food [3]      4   8   8   1e3    2     2      32\n 15: Sort Class by Accuracy: Cwst, retaining the classes        Pets [53]     2   8   8   1e4    2     2      32\n    with the lowest top-nwst accuracy                              Places [81]    4   8   8   1e2    3     3      32\n 16: Sort Class by Accuracy Gain:  Csln, retaining the     SUN [74]     2   8   8   1e4    4     4      32\n    classes with the top-nsln accuracy gain                UCF [67]     4   8   8   1e3    3     3      32\n 17: Initialize Group Set: G ‚Üê‚àÖ\n 18: for all class c ‚ààCwst do                                        Table 7. Hyperparameters settings for thirteen datasets.\n 19:   G ‚ÜêG ‚à™{MISCLASS(y)}\n 20: end for                                             D.2. More Related Work\n 21: for all class c ‚ààCsln do                                                          Large-scale vision-language models like CLIP [58] have\n 22:   G ‚ÜêG ‚à™{MISCLASS(y)}\n                                                  shown promising performance on various tasks. They align\n 23: end for\n                                                                 visual and textual spaces to a joint space via training on\n 24: return sampled groups G\n                                                               millions of image-text pairs from the web. Other work [1,\n                                                                     9, 14, 30, 36, 37, 46, 68, 76] has furthered this paradigm\nto the misclassified set for category y. In fact, we also ab-      to learn more accurate semantic alignment in joint space.\nlate the K-means clustering algorithm to group categories     In this work, we advance VLMs for downstream tasks by\n(in Appendix G.3). Results show that the misclassified set     progressively learning optimal class-specific prompts with\nachieves better performance than the K-means algorithm.      minimal supervision and no human intervention.\nSelecting the worst groups aims to select categories with\nthe lowest top-nwst accuracy and corresponding misclassi-    E. Results on Different Backbones\nfied categories. We first compute the accuracy for each cat-\negory in Line 11. Then, we sort the categories by accuracy      Settings.  In Tab. 8, we show results of our ProAPO in\nand retain the top-nwst worst categories in Line 15. Finally,      different backbones, including ResNet50, ResNet101, ViT-\nnwst groups are added to the set G in Lines 18-20.             B/32, ViT-B/16, ViT-L/14 for CLIP [58], ViT-B/32 for\nSelecting the salient groups aims to select categories with    OpenCLIP [7], ViT-B/16 for EVA02 [14], and ViT-B/16 for\nthe top-nsln performance gains and its misclassified cate-     SigLIP [78]. We compare our ProAPO with vanilla VLMs\ngories after adding descriptions. In Line 13, we compute     and the SOTA description method CuPL [55].\nthe accuracy gains after adding the descriptions. Then, we        Results. We see that our ProAPO consistently improves\nsort the categories by accuracy gain and retain the top-nsln      vanilla CLIP and CuPL in thirteen datasets across all back-\naccuracy gain categories in Line 16. At last, nsln groups     bones. Compared to vanilla VLMs, our ProAPO enhances\nare added to the set G in Lines 21-23.                      them by at least 3.4% average accuracy in thirteen datasets.\n   Finally, we collect S = nwst + nsln groups for subse-     Moreover, we see notable performance improvement on\nquent description optimization.                                  several fine-grained datasets, such as DTD [8], ESAT [26],\n\nModule                                          IN-1K             Caltech       Cars     CUB      DTD         ESAT        FGVC      FLO        Food       Pets           Places     SUN     UCF       (11)Avg       (13)Avg\n\n  CLIP [58] - ResNet50      57.9  84.5  53.9  44.7   38.8    28.6   15.9   60.2   74.0  83.2  38.2  58.0  56.9   55.6   53.4\n  CuPL [55]                61.2  88.3  55.3  48.7   49.5    38.2   18.9   67.0   80.1  86.1  41.2  63.1  63.3   61.1   58.5\n  ProAPO (ours)           61.5  90.3  58.0  50.7   52.3    51.7   21.1   75.1   81.8  88.7  41.8  63.7  66.0   64.6   61.8\n ‚àÜ                  + 3.6 + 5.8 + 4.1 + 6.0 + 13.5 + 23.1 + 5.2 + 14.9 + 7.8 + 5.5 + 3.6 + 5.7 + 9.1 + 9.0 + 8.4\n\n  CLIP [58] - ResNet101    61.4  89.9  63.3  49.6   40.3    31.7   18.3   64.3   83.4  86.9  37.9  59.0  61.2   60.0   57.5\n  CuPL [55]                61.4  91.0  61.2  45.3   49.7    28.7   18.6   59.0   82.7  86.6  40.6  62.3  56.4   59.8   57.2\n  ProAPO (ours)           63.6  92.3  64.4  52.2   51.6    45.9   21.2   69.6   84.9  89.6  40.6  63.5  64.0   64.6   61.8\n ‚àÜ                  + 2.2 + 2.4 + 1.1 + 2.6 + 11.3 + 14.2 + 2.9  + 5.3  + 1.5 + 2.7 + 2.7 + 4.5 + 2.8 + 4.6 + 4.3\n\n  CLIP [58] - ViT-B/32      62.1  91.2  60.4  51.7   42.9    43.9   20.2   66.0   83.2  86.8  39.9  62.1  60.9   61.8   59.3\n  CuPL [55]                64.4  92.9  60.7  53.3   50.6    50.5   20.9   69.5   84.2  87.0  43.1  66.3  66.4   64.9   62.3\n  ProAPO (ours)           64.7  94.4  61.7  55.4   53.5    63.0   23.0   74.3   85.3  91.0  43.3  66.6  69.0   67.9   65.0\n ‚àÜ                  + 2.6 + 3.2 + 1.3 + 3.7 + 10.6 + 19.1 + 2.8  + 8.3  + 2.1 + 4.2 + 3.4 + 4.5 + 8.1 + 6.1 + 5.7\n\n  CLIP [58] - ViT-B/16      66.9  93.2  65.5  55.3   44.3    51.0   24.4   70.6   88.4  89.0  40.8  62.5  67.7   65.8   63.0\n  CuPL [55]                69.6  94.3  66.1  57.2   53.8    55.7   26.6   73.9   88.9  91.2  43.4  69.0  70.3   69.0   66.1\n  ProAPO (ours)           69.9  95.2  67.7  59.0   55.8    65.3   28.3   82.7   89.5  92.7  43.8  68.9  73.1   71.7   68.6\n ‚àÜ                  + 3.0 + 2.0 + 2.2 + 3.7 + 11.5 + 14.3 + 3.9 + 12.1 + 1.1 + 3.7 + 3.0 + 6.4 + 5.4 + 5.9 + 5.6\n\n  CLIP [58] - ViT-L/14      73.5  95.1  76.8  62.5   52.1    61.5   33.4   79.5   93.1  93.3  40.7  67.6  75.0   72.8   69.5\n  CuPL [55]                76.7  96.2  77.6  61.4   62.6    62.4   36.1   79.7   93.4  93.8  43.8  73.2  78.3   75.5   71.9\n  ProAPO (ours)           76.8  97.1  78.8  65.1   64.8    74.3   38.3   87.3   93.9  94.6  44.4  73.4  80.1   78.1   74.5\n ‚àÜ                  + 3.3 + 2.0 + 2.0 + 2.6 + 12.7 + 12.8 + 4.9  + 7.8  + 0.8 + 1.3 + 3.7 + 5.3 + 5.1 + 5.8 + 5.0\n\n  OpenCLIP [7] - ViT-B/32  66.2  94.7  88.2  65.6   51.3    49.4   23.0   71.2   82.4  90.7  41.5  68.1  65.0   68.2   65.9\n  CuPL [55]                66.7  94.4  86.6  65.9   62.4    50.1   25.5   69.5   81.7  90.8  43.3  69.1  65.8   69.3   67.1\n  ProAPO (ours)           67.0  95.8  88.7  67.3   65.1    66.0   27.5   81.8   83.2  91.9  43.4  69.7  70.2   73.3   70.6\n ‚àÜ                  + 0.8 + 1.1 + 0.5 + 1.7 + 13.8 + 16.6 + 4.5 + 10.6 + 0.8 + 1.2 + 1.9 + 1.6 + 5.2 + 5.1 + 4.7\n\n  EVA02 [14] - ViT-B/16    74.6  97.2  79.2  60.8   49.7    68.0   24.6   75.6   89.5  92.2  42.9  70.7  68.6   71.8   68.7\n  CuPL [55]                75.4  96.7  79.2  61.8   59.1    61.7   27.5   75.2   89.3  92.1  44.0  72.5  71.9   72.8   69.7\n  ProAPO (ours)           75.5  97.0  80.0  62.8   61.3    74.2   29.7   89.1   89.6  93.5  44.5  72.5  75.2   76.2   72.7\n ‚àÜ                  + 0.9   -0.2  + 0.8 + 2.0 + 11.6  + 6.2  + 5.1 + 13.5 + 0.1 + 1.3 + 1.6 + 1.8 + 6.6 + 4.4 + 4.0\n\n   SigLIP [78] - ViT-B/16    75.8  97.3  90.5  62.3   62.8    44.6   43.6   85.5   91.5  94.1  41.6  69.5  74.9   75.5   71.8\n  CuPL [55]                76.0  98.0  90.5  63.0   64.9    42.8   45.1   87.0   90.7  94.5  43.5  69.9  73.4   75.7   72.3\n  ProAPO (ours)           76.4  98.3  91.7  66.2   69.1    55.8   47.1   93.3   92.2  94.9  44.3  71.7  75.9   78.8   75.2\n ‚àÜ                  + 0.6 + 1.0 + 1.2 + 3.9  + 6.3  + 11.2 + 3.5  + 7.8  + 0.7 + 0.8 + 2.7 + 2.2 + 1.0 + 3.3 + 3.4\n\nTable 8. Results of our ProAPO on different backbones. Avg (11) and Avg (13) denote average results across 11 datasets (excluding\nCUB [71] and Places [81]) and all 13 datasets, respectively. ‚àÜdenotes performance gains compared to vanilla VLMs.\n\nFLO [48], and UCF [67].   It further verifies that class-     4.7%, and from CLIP [58] to EVA02 [14] to SigLIP [78],\nspecific descriptions provide helpful knowledge for fine-      the gain is from 5.6% to 4.0% to 3.4%. We argue that\ngrained recognition. Besides, iterative optimization by our      the model with the higher result has more knowledge,\nProAPO also enhances the description method CuPL.         which may be affected less by prompt quality. Overall, our\n                                              ProAPO continues to improve the performance of VLMs.  More interesting findings. We find that as the back-\nbones of VLMs become larger, the performance improve-\nment by ProAPO gradually decreases. For example, from    F. More Comparisons with SOTA Methods\nViT-B/32 to ViT-B/16 to ViT-L/14, the gain for CLIP is\nfrom 5.7% to 5.6% to 5.0%. Moreover, similar results ap-     In this section, we compare our ProAPO with more SOTA\npear in different models with the same backbone, i.e., the     prompt tuning methods. These methods adapt VLMs from\nvanilla model with better results achieves a lower perfor-     both visual and textual views.\nmance increase.  For example, from CLIP [58] to Open-       Comparison of test-time prompt tuning methods.\nCLIP [7] on ViT-B/32 backbone, the gain is from 5.7% to     In Tab. 9, our ProAPO outperforms SOTA test-time prompt\n\n(11)\n              Module (ViT-B/16)            IN-1K           Caltech      Cars     DTD      ESAT      FGVC     FLO      Food      Pets     SUN     UCF    Avg\n\n                  Vanilla CLIP [58]      66.9  93.2  65.5  44.3  51.0  24.4  70.6  88.4  89.0  62.5  67.7  65.8\n\n                                            Test-Time Prompt Tuning Methods\n\n            TPT [65]              69.0  94.2  66.9  47.8  42.4  24.8  69.0  84.7  87.8  65.5  68.0  65.5\n               DiffTPT [16]          70.3  92.5  67.0  47.0  43.1  25.6  70.1  87.2  88.2  65.7  68.2  65.9\n                PromptAlign [63]      71.4  94.0  68.5  47.2  47.9  24.8  72.4  86.7  90.8  67.5  69.5  67.3\n                 Self-TPT-v [88]        73.0  94.7  68.8  49.4  51.9  27.6  71.8  85.4  91.3  68.2  69.5  68.3\n\n                                            Vector-based Prompt Tuning Methods\n\n            UPT [77]              69.6  93.7  67.6  45.0  66.5  28.4  75.0  84.2  82.9  68.8  72.0  68.5\n            CoCoOp [82]          69.4  93.8  67.2  48.5  55.3  12.7  72.1  85.7  91.3  68.3  70.3  66.8\n             MaPLe [32]           69.6  92.6  66.6  52.1  71.8  26.7  83.3  80.5  89.1  64.8  71.8  69.9\n            ALIGN [72]           69.8  94.0  68.3  54.1  53.2  29.6  81.3  85.3  91.4  69.1  74.4  70.1\n              PromptSRC [33]       68.1  93.7  69.4  56.2  73.1  27.7  85.9  84.9  92.0  69.7  74.8  72.3\n\n                                                Description-Based Methods\n\n               w/o adapters\n             CuPL [55]             69.6  94.3  66.1  53.8  55.7  26.6  73.9  88.9  91.2  69.0  70.3  69.0\n               AWT-text [87]         68.9  95.2  66.0  52.0  52.6  26.1  74.5  89.4  91.2  68.4  69.8  68.6\n            ProAPO (ours)        69.9  95.2  67.7  55.8  65.3  28.3  82.7  89.5  92.7  68.9  73.1  71.7\n            ProAPO w/ AWT-text  69.4  95.3  67.8  54.3  67.1  27.4  82.1  89.6  93.2  68.5  73.1  71.6\n\n                w/ adapters\n              AWT-Adapter [87]     72.1  95.1  73.4  59.4  76.3  33.9  85.6  85.9  92.9  72.7  78.4  75.1\n            ProAPO w/ APE [86]  71.3  95.8  70.9  60.6  72.4  33.2  91.4  89.9  93.4  71.0  77.6  75.2\n\nTable 9. Comparison of our ProAPO with more SOTA methods under one-shot supervision. Avg (11) denote average results across\n11 datasets.\n\n\ntuning methods on 11 datasets. Notably, we adapt VLMs     mented visual and textual views to adapt VLMs, we com-\nsolely from the textual view, while TPT methods introduce     pare ProAPO with AWT under the augmented textual view\ntextual and visual views (i.e., augmented images), which      for a fair comparison.  In Tab. 9, the result shows our\nfurther verifies the effectiveness of our method.            ProAPO improves AWT-text by 6.1% on average, verifying\n                                                                     that our progressive optimization improves prompt quality.  Comparison of vector-based prompt-tuning methods\n                                                              In addition, we introduce a common adapter-based methodSince recent prompt-tuning methods adapt VLMs using\n                                                                   to our ProAPO and compare it with AWT-Adapter in theboth visual and textual views, we combine ProAPO with an\n                                                            one-shot setting. We see that our ProAPO achieves compa-adapter (i.e., APE [86]) for a fair comparison. (1) Higher\n                                                                 rable results. These results suggest that ProAPO and AWTperformance in low-shot. In Tab. 9, ProAPO consistently\n                                                                are complementary.outperforms these methods, which verifies that optimiz-\ning prompts in natural language is more effective in low-\nshot tasks.  (2) Better transferability and interpretabil-                                                   Comparison of iCM [22]. iCM is somewhat similar\nity. Unlike vector-based prompt-tuning methods that search                                                                   to ours, optimizing class-specific prompts with chat-based\nin a continuous space, ProAPO benefits from the discrete                                               LLMs. However, it uses the whole validation set as super-\nnature of natural language, leading to better interpretabil-                                                                   vision.  In Tab. 10, we see that our ProAPO outperforms\nity and easily transfers across different backbones (shown                                          iCM significantly even under the one-shot supervision. This\nin Tab. 2). (3) Lower performance in high-shot. However,                                                                              is because our ProAPO address challenges in class-specific\nin Tab. 15, ProAPO shows a sub-optimal result compared to                                                      prompt optimization by an offline generation algorithm to\nCoOp [83] in high-shot settings. This is due to the limited                                                          reduce LLM querying costs, an entropy-constrained fitness\nlanguage search space and iteration steps.                                                              score to prevent overfitting, and two sampling strategies to\n  Comparison of AWT [87]. First, since AWT uses aug-      find an optimal initial point and reduce iteration times.\n\nModule (ViT-B/32)        IN-1K   Caltech  CUB  DTD  ESAT  FLO  SUN  UCF  Avg (8)\n\n                Vanilla CLIP                  62.1      91.2     51.7    42.9    43.9    66.0   62.1   60.9     60.1\n\n                                           Automatic Prompt Optimization Methods\n\n           iCM [22] (w/ validation set)    64.5      92.7     56.1    51.4    56.3    72.2   66.2   67.0     65.8\n           ProAPO (w/ 1-shot)           64.7      94.4     55.4    53.5    63.0    74.3   66.6   69.0     67.6\n\n\n              Table 10. Comparison of our ProAPO with iCM [22]. Avg (8) denotes average results across 8 datasets.\n\n                                                                                                                                                                                                              (11)        (13)\n  Module (ResNet50)                   IN-1K              Caltech        Cars      CUB      DTD        ESAT        FGVC      FLO        Food        Pets            Places      SUN      UCF      Avg      Avg\n\n   Vanilla CLIP               57.9   84.5   53.9   44.7   38.8   28.6   15.9   60.2   74.0   83.2   38.2   58.0   56.9   55.6   53.4\n\n                                               Template Optimization Methods\n\n  PN [39]                    59.6   89.1   56.2    -      44.8   49.0   18.1   67.2   78.3   88.1    -      61.0   60.2   61.1    -\n  ATO (w/o dataset domain)   60.4   88.9   56.8   47.0   45.0   43.7   17.9   67.4   79.9   87.8   40.0   61.2   61.5   61.0   58.3\n  ATO                       61.3   89.4   57.4   49.2   45.4   46.4   18.4   68.1   80.5   88.5   40.2   61.8   63.9   61.9   59.3\n\n                                                  Description Optimization Methods\n\n  ProAPO (w/o synonyms)    61.5   89.7   58.3   49.7   46.6   46.8   20.5   74.6   81.0   88.8   40.9   62.3   64.8   63.2   60.4\n  ProAPO (ours)             61.5   90.3   58.0   50.7   52.3   51.7   21.1   75.1   81.8   88.7   41.8   63.7   66.0   64.6   61.8\n\n\nTable 11. Ablation of template and description optimization. Avg (11) and Avg (13) denote average results across 11 datasets (excluding\nCUB [71] and Places [81]) and all 13 datasets, respectively. ATO denotes our automatic template optimization algorithm.\n\nG. More Ablation Results                          G.2. More Ablation of Operators\n\nG.1. Ablation of Template and Description Opti-    To further explore whether each operator has a role in\n     mization                                             searching the optimal result, we show the number of each\n                                                              operator causing the new optimal score during the itera-\nIn Tab. 11, we ablate key components in template and de-                                                                   tions in Tab. 12. We see that each operator in iterative op-\nscription optimization on the ResNet50 backbone.                                                                timization may generate a better prompt. It further demon-\n   (1) Ablation of Template Optimization.  In the main                                                                       strates that each operator is helpful in ProAPO. Notably,\npaper (Sec. 4.3), we show that prompt ensembling is better                                                                the crossover operator has the highest times to update the\nthan a single prompt. Moreover, dataset domain informa-                                                           optimal score, which demonstrates that it makes the model\ntion also plays a significant role in template optimization.                                                             search for the optimal prompt faster with limited iterations.\nWithout domain information, we see a performance drop in\nour ATO by an average of 1.0% (from 58.3% to 59.3 %) on     G.3. More Ablation of Group Sampling\nthirteen datasets. This is because domain information pro-     In Tab. 13, we ablate how to select categories in the group\nvides contextual information, which can mitigate issues of     sampling strategy. We consider the settings for optimiz-\nsemantic ambiguity caused by class names.                    ing all categories in one group, selecting random categories\n   (2) Ablation of Description Optimization. Without la-     and the best categories with their misclassified categories\nbel synonyms to increase description diversity, a perfor-      in groups.  In rows a)-c) of Tab. 13, we see notable per-\nmance degradation appears by an average of 1.4% (from     formance degradation compared to full ProAPO. It further\n60.4% to 61.8%) on thirteen datasets.  It verifies the effec-     demonstrates that optimizing salient and worst groups can\ntiveness of optimization class names, which are usually ig-     achieve comparable results with all categories and save iter-\nnored in previous description methods [43, 55, 62, 73].          ation costs. Moreover, we also consider replacing misclas-\n   (3) Template VS Description Optimization.  Com-      sified categories with a K-Means clustering algorithm. A\npared with template optimization, we see a notable per-     performance drop appears in row d), which verifies the ef-\nformance improvement with description optimization, es-      fectiveness of selecting misclassified categories in groups.\npecially in CUB [71], DTD [8], ESAT [26], FLO [48],\n                                                     G.4. Ablation of Cost Computationand UCF [67] datasets.   It demonstrates that optimizing\nclass-specific prompts can find discriminative information     In Tab. 14, we detail the time each process consumes on\nfor fine-grained classification.                              ImageNet. Compared to previous LLM-generated descrip-\n\nDataset     Add  Del  Rep  Cross  Mut   Total       H.2. Effect of Scalar in Score Function\n\n   IN-1K [10]     3     4     5      5      2     19          In Tab. 16, we show the effect of Œ± in Eq. (6). We see that\n   Caltech [15]    5     5     6      12      3     31         performance improves as the Œ± increases. This is because\n   Cars [34]      7     8     5      8      3     31          the entropy constraint provides more information to select\n  CUB [71]      9     4     10      6      2     31          better candidate prompts. We see a stable result when Œ± ‚àà\n  DTD [8]       5     3     8      8      2     26          [5e2, 5e3], which means a better trade-off between accuracy\n  ESAT [26]     2     4     6      8      1     21                                                      and entropy constraint. However, a high Œ± may be biased to\n  FGVC [41]     6     2     6      5      3     22\n                                                                the train set, thus harming the performance.\n  FLO [48]      5     3     11      5      4     28\n   Food [3]       5     3     4      5      2     19\n                                                     H.3. Effect of Sampled Numbers in Prompt Sam-   Pets [53]       4     2     5      6      2     19\n                                                            pling Strategy   Places [81]     3     2     8      12      4     29\n  SUN [74]      4     2     3      5      2     16          In Fig. 9, we show the effect of sampled numbers Tsample of\n  UCF [67]      5     6     8      6      2     27         Alg. 5. The Tsample = 0 means that the prompt sampling\n  Sum         63    48    85     91     32    319          strategy is not used. As the number of Tsample increases,\n                                             we see a slight performance gain when Tsample < 4. After\nTable 12. Number of times for each operator that update the     Tsample ‚â•4, a consistent improvement appears because the\noptimal score. Total denotes the total number of iterations when       initial search point achieves a higher score than the baseline.\nachieving the highest score.                        We achieve stable results when Tsample ‚â•32.\n\ntion methods, we similarly query LLMs one-time to gener-\nate descriptions (i.e., process of building prompt library). In             68\naddition, we introduce iterative processes to refine prompts           set                                                                       67\nand two sampling strategies to save costs. With a few ad-               test\nditional costs (15 min v.s. 60 min), our ProAPO improves       on 66\nprevious methods by at least 2.7% on average. This further\n                                                                       65\nverifies the efficiency of our method.\n                                                                                               Avg (11)                                                                                                                                                                                             Accuracy 64\n                                                                                               Avg (13)\n                                                                       63                                                                          0    1    2    4    8   16   32   64  128\nH. More Hyperparameter Analysis\n                                                                           Figure 9. Effect of sampled numbers Tsample.\n\nH.1. Effect of Shot Numbers\n                                                     H.4. Effect of Quality of Prompt Library\nIn Tab. 15, we show the effect of the number of training\n                                                              In Fig. 10 and Fig. 11, we analyze two key factors affect-samples per category. Specifically, we conduct experiments\n                                                             ing the prompt library: LLM-query prompts and generatedwith 1, 2, 4, 8, and 16 shots. Moreover, we introduce the\n                                                                  descriptions. Our ProAPO improves prompt quality evenperformance of the optimal prompt searched in the test set\n                                                         under a small number of query prompts and descriptions,as the upper bound of ProAPO. Compared with CoOp [83],\n                                                           demonstrating its effectiveness in a limited prompt library.ProAPO achieves remarkable performance when shots ‚â§2,\nwhich demonstrates the effectiveness of our method under\nlow-shot settings. Since we only adapt VLMs in a training-\nfree way, the performance increases finitely as the training            61\nsamples increase. We attribute two key directions for fur-\nther performance improvement in high-shot settings. First,                                                                                                                                                                                                  Accuracy 60our result is still far from the upper bound (66.1 % in 16\nshots VS 67.2 % for the upper bound). We need to improve\nthe prompt generation algorithm and the score function to            59                                                                                                                                                                                                  ImageNetfind better candidate prompts within the limited iterations.                                     ProAPO\nSecond, the upper bound of our ProAPO is much smaller                                          w/o ProAPO                                                                58\nthan the prompt tuning method. We need to use a larger                                                                   0      1      2      3      4      5\nnatural language search space (e.g., more diverse descrip-\n                                                                       Figure 10. Effect of Number of LLM-query Prompts.\ntions, or more query times of LLMs) to further increase the\nupper bound of the optimal result.\n\n(11)        (13)\n  Module (ViT-B/32)                                   IN-1K              Caltech        Cars      CUB      DTD        ESAT        FGVC      FLO        Food        Pets            Places      SUN      UCF      Avg      Avg   Times\n\n  CuPL                            64.4   92.9   60.7   53.3   50.6   50.5   20.9   69.5   84.2   87.0   43.1   66.3   66.4   64.9   62.3        -\n\n  a) w/ all categories in one group   64.5   93.3   60.9   53.5   51.6   52.2   22.2   70.8   84.5   87.9   42.3   66.7   69.4   65.8   63.1  20 min\n  b) w/ random selected group      64.3   93.7   61.8   55.2   48.7   59.5   22.6   72.9   85.2   90.8   42.6   65.4   68.4   66.7   63.9   15 min\n  c) w/ performance best group     64.1   93.0   61.2   54.4   47.4   56.8   20.7   68.2   85.1   88.6   42.4   65.0   65.4   65.0   62.5   15 min\n  d) w/ K-Means algorithm         64.6   93.8   61.8   55.1   49.4   59.6   22.8   74.0   85.3   90.7   42.7   65.4   69.0   67.0   64.2   17 min\n\n  ProAPO (full model)             64.7   94.4   61.7   55.4   53.5   63.0   23.0   74.3   85.3   91.0   43.3   66.6   69.0   67.9   65.0   15 min\n\nTable 13. More ablation of group sampling strategy. We ablate the ways for selecting salient groups. Times denotes the time that\nProAPO runs on ImageNet with the default setting.\n\n\n Process  Build Library  Sample Strategy  Template Optim.  Description Optim.      Œ±          0    1e1   1e2   5e2   1e3   5e3   1e4   1e5\n Times      60 min         3 min             1.6 min            10.4 min\n                                                            Avg (13)   62.3   63.4   64.4   64.9   65.0   64.8   63.7   63.1\n\n Table 14. Computation cost analysis in the ImageNet dataset.\n                                                                      Table 16. Effect of Œ± value in Eq.6 across 13 datasets.\n\n\n\n                                                                61\n Dataset  Module   TF Number of training samples UB          (RN50)          1    2    4    8    16                                                     Accuracy 60\n        CoOp [83]  ‚úó   59.6  62.3  66.8  69.9  73.4     -\n Avg (11)\n        ProAPO  ‚úì   64.6  65.0  65.4  65.8  66.1  67.2              59                                                                                                                                                                                                 ImageNet                                                                                      ProAPO        CoOp [83]  ‚úó   57.2  57.8  60.0  61.6  63.0     -\n IN-1K                                                                                                 w/o ProAPO        ProAPO  ‚úì   61.5  61.6  61.5  61.6  61.6  61.7              58\n        CoOp [83]  ‚úó   87.5  87.9  89.6  90.2  91.8     -                   0     20     40     60     80    100\n Caltech\n        ProAPO  ‚úì   90.3  90.4  90.6  90.7  91.0  91.1           Figure 11. Effect of Number of Generated Descriptions.\n        CoOp [83]  ‚úó   55.6  58.3  62.6  68.4  73.4     -\n Cars        ProAPO  ‚úì   58.0  58.5  58.8  58.9  59.1  60.8        I. More Qualitative Results\n        CoOp [83]  ‚úó   44.4  45.2  53.5  60.0  63.6     -         In Fig. 12, we show more examples of the changes in de- DTD\n        ProAPO  ‚úì   52.3  52.7  53.0  53.4  53.6              scriptions with our ProAPO, including images of animals,\n        CoOp [83]  ‚úó   50.6  61.5  70.2  76.7  83.5     -         flowers, and textures.  Similarly, we see that common de-\n ESAT\n        ProAPO  ‚úì   51.7  53.5  55.6  57.4  58.3  62.2        scriptions are removed and discriminative ones are retained\n                                                                   for fine-grained categories, which further verifies the effec-        CoOp [83]  ‚úó   9.6  18.7  21.9  26.1  31.3     -\n FGVC        ProAPO  ‚úì   21.1  21.0  21.2  21.2  21.3  21.5        tiveness of our progressive optimization.\n        CoOp [83]  ‚úó   68.1  77.5  86.2  91.2  94.5     -\n FLO\n        ProAPO  ‚úì   75.1  75.6  76.4  76.7  77.8  79.1\n        CoOp [83]  ‚úó   74.3  72.5  73.3  71.8  74.7     -\n Food\n        ProAPO  ‚úì   81.8  82.0  82.1  82.2  82.3  82.9\n        CoOp [83]  ‚úó   85.9  82.6  86.7  85.3  87.0     -\n Pets\n        ProAPO  ‚úì   88.7  89.4  89.5  89.8  89.9  91.0\n        CoOp [83]  ‚úó   60.3  59.5  63.5  65.5  69.3     -\n SUN\n        ProAPO  ‚úì   63.7  63.8  63.8  63.8  63.9  64.5\n        CoOp [83]  ‚úó   61.9  64.1  67.0  71.9  75.7     -\n UCF\n        ProAPO  ‚úì   66.0  66.8  67.1  68.1  68.9  71.4\n\nTable 15. Scaling up to more shots. Avg (11) denotes average\nresults across 11 datasets. TF denotes training-free approaches.\nUB denotes upper bound evaluated on the test set.\n\nRemoved Prompts                  Retained Prompts\n                       Gull                                    ‚Ä¢  AitsCaliforniaback and Gullwings.is white with gray on          ‚Ä¢   Californiablack headGulland isbill.a white bird with a\n                                                                    ‚Ä¢   The California Gull is a white bird with          ‚Ä¢   The California Gull is a white and gray\n                                             a light gray back and wings.                      bird with a black head.\n                                                                    ‚Ä¢  A  California  Gull  is a medium-sized,          ‚Ä¢   The California Gull is a medium sized\n                                             white-headed gull with a light gray            gull with a white and black head, a                                                          California                         back and wings.                               gray back, and a black wingtips.\n\n                                                                    ‚Ä¢  An image of a Glaucous winged Gull, a          ‚Ä¢   The Glaucous winged Gull has a white\n                       Gull                                    ‚Ä¢   typeA Glaucousof bird.winged Gull on the beach.            ‚Ä¢  headGlaucous-wingedand body withGullgrayiswings.a medium-\n                                                                    ‚Ä¢   The Glaucous winged Gull  is a large,           sized gull with a white head and body,\n                                              white bird with grey wings.                    grey wings, and a yellow beak.                                            Glaucous-                                         ‚Ä¢   This species of gull has a slate-gray          ‚Ä¢   The Glaucous-Winged Gull has a white                                   winged                                            back and wings, and white underparts.        head and a yellow beak.\n\n\n                                                                    ‚Ä¢    Fire lily is a beautiful orange flower.              ‚Ä¢  A fire lily flower is typically a deep red\n                                                                    ‚Ä¢  A  fire  lily flower has long, pointed           color with yellow spots.\n                                                                                                                                          ‚Ä¢  A  fire  lily  is a type of flower that  is                       Lily                             petals that are red or orange in color.\n                                                                    ‚Ä¢   The fire lily is a type of flower that is          bright red with yellow spots.\n                                                                                                                                          ‚Ä¢  A  fire   lily  (scientific  name:  Crinum                       Fire                              native to South America.\n                                                                    ‚Ä¢  A  fire  lily flower  is  typically red or          amabile) is a type of  lily that is deep\n                                            orange and has six petals.                     red with long thin petals.\n\n                                                                    ‚Ä¢   The tiger  lily  is a member of the  lily          ‚Ä¢  A  tiger  lily  is a type of flower with\n                                                      family, a beautiful flower.                     orange or red petals and black spots.\n                                                                    ‚Ä¢   The tiger lily is a flower that is red with          ‚Ä¢   Tiger lily flowers are large, orange-red                       Lily\n                                            orange stripes.                                  flowers with black spots.\n                                                                    ‚Ä¢   The tiger lily (Lilium columbianum) is a          ‚Ä¢   Tiger lily (Lilium columbianum) flowers                             Tiger                            species  of   lily  that   is  native  to           are orange with black spots and have\n                                                 northwestern North America.                    long, trumpet-shaped petals.\n\n\n                                                                    ‚Ä¢   Birman cats are medium to large in size,          ‚Ä¢   Birmans are characterized by their deep\n                                                  with long, silky fur and big, blue eyes.           blue eyes and white gloves in paws.\n                                                                    ‚Ä¢  A Birman is a medium- to long-haired          ‚Ä¢   They have a pointed coloration, with\n                                                   cat with a  silky coat and a dense          darker fur on the face, ears,  tail, and                                   Birman                           undercoat.                                            legs, contrasting with their lighter body.\n                                                                    ‚Ä¢   Birman cats are medium to large in size,          ‚Ä¢   Birman cats are medium-sized with a\n                                                  with long, silky fur.                        compact body and medium-length fur.\n\n                                                                    ‚Ä¢   Ragdoll cats are large and muscular,          ‚Ä¢  A Ragdoll  is characterized by its blue\n                                                  with long, fluffy fur.                               eyes, medium-long coat, and its floppy,\n                                                                    ‚Ä¢   Ragdoll cats are large, gentle cats with           rag-doll-like nature.\n                                              semi-long fur.                                            ‚Ä¢   Feature  in Ragdolls a pointed  color\n                                                                    ‚Ä¢  A Ragdoll  is a medium-sized to large           pattern with soft, blended shades on                                         Ragdoll                                                      cat that has long, silky fur.                        their body, but often lack the precise\n                                                                    ‚Ä¢   Ragdoll cats are large, longhaired cats.          white markings seen in Birmans.\n\n\n                                                                     ‚Ä¢   Crosshatched material is made up of a          ‚Ä¢  A crosshatched texture  is a series of\n                                                      series of intersecting lines, usually in a           intersecting lines that create a pattern\n                                                      criss-cross pattern.                               of squares or diamonds.\n                                                                     ‚Ä¢  A crosshatched surface has a series of          ‚Ä¢  A crosshatched object is one that has a\n                                                       intersecting diagonal lines.                         series of parallel lines intersecting each\n                                                                     ‚Ä¢   Crosshatched textures usually have a          other to form a series of small squares                                                                       Crosshatched                                                      crisscross pattern.                            or diamonds.\n\n                                                                     ‚Ä¢  A surface that is interlaced has a criss-          ‚Ä¢   Interlaced  surfaces have a wavy or\n                                                 crossing pattern.                              zigzag appearance.\n                                                                     ‚Ä¢  An interlaced texture looks like a series          ‚Ä¢   Interlaced material looks like a series of\n                                                      of lines that cross over each other.              horizontal lines that are slightly offset\n                                                                     ‚Ä¢  A surface that is interlaced has a series         from each other.                                                          Interlaced                            of lines that are crossed by a series of          ‚Ä¢   Interlaced textures are scanned images\n                                                other parallel lines.                                into even and odd scan lines.\n\n\nFigure 12. Qualitative analysis of class-specific prompt optimization by ProAPO. Shaded red and blue words denote common and\ndiscriminative descriptions in two confused categories.\n\nJ. Detailed Results of More Benefits by Opti-     combine advantages of high-scoring candidates, and mu-\n   mal Prompts                                              tation operator to avoid locally optimal solutions, we see\n                                                       an increase in performance in rows e)-g).  It confirms that\nJ.1. Transfer to Adapter-based Methods                 evolution-based operators make the model search the opti-\nIn Fig. 13 and   Fig. 14, we show the detailed results     mal prompt faster with limited iterations.\nof popular training-free and training adapter-based meth-\n                                                         L.2. Ablation of Two Sampling Strategies\nods [18, 70, 80, 86] with different prompt initialization,\ni.e., SOTA method CuPL [55] and our ProAPO. Adapter-     In Tab. 20, we show detailed ablation results of two sam-\nbased methods with ProAPO (solid lines) consistently sur-     pling strategies.  Without the prompt sampling, we see a\npass those with CuPL (dotted lines).  It reveals that high-      slight decrease in times while results drop in row a). It ver-\nquality prompts make adapters perform better. Even in low       ifies the effectiveness of the prompt sampling. Without the\nshots, training with ProAPO achieves notable performance     group sampling to select salient categories for optimization,\ngains, which further verifies its effectiveness.              we observe a notable increase in time costs (from 15 min to\n                                                  300+ min, 20 times) yet similar results in row b) and the\nJ.2. Transfer to Different Backbones                          full model.  It reveals that group sampling simultaneously\nIn Fig. 15, we show detailed results of transferring prompts     improves performance and efficiency.\nfrom source to target models in thirteen datasets. Our opti-\n                                                         L.3. Ablation of Different Score Functions\nmized prompts of ResNet50 and ViT-B/32 are reported. We\nsee that ProAPO achieves stable performance gains com-     In Tab. 21, we show detailed ablation results of score\npared to CuPL [55], which verifies that ProAPO transfers      functions. Accuracy obtains the worst result as the score\neasily across different backbones.                              function due to the overfitting problem.  Our full model\n                                                          with accuracy and entropy constraints as the score func-\nK. Detailed Results of Performance Improve-      tion achieves the SOTA result. The score function with only\n   ment Analysis                                      accuracy or entropy constraint achieves suboptimal results,\n                                                             suggesting a trade-off process between them.\nK.1. Analysis of the Effect of Single VS Ensemble\n     Prompts\n\nIn Tab. 17, we show detailed results of the effect of single vs\nensemble prompts. Compared to PN [39], we utilize prompt\nensembling instead of a single prompt to optimize the tem-\nplate and description. We observe that ensemble templates\nhave a higher upper bound than the single template. Simi-\nlarly, our optimized templates achieve higher performance\nthan PN [39], even better than the best single template, fur-\nther verifying the effectiveness of our method.\n\nK.2. Performance Improvement  of  Description\n     Methods by ProAPO\n\nIn Tab. 18, we show detailed results of description meth-\nods [43, 55, 62, 73] with our ATO and ProAPO. We see\na notable improvement in description methods by at least\n2.7% average in thirteen datasets. It further verifies the ef-\nfectiveness of our progressive optimization.\n\nL. Detailed Results of Ablation Study\n\nL.1. Ablation of Edit- and Evolution-based Opera-\n      tors\n\nIn Tab. 19, we show detailed ablation results of edit- and\nevolution-based operators. For edit-based operators, we ob-\nserve that the model with add, delete, and replace opera-\ntions achieves a higher result in row d).  After introduc-\ning evolution-based operators,  i.e., crossover operator to\n\n93             63.5                                                                                               70\n             63.0                                      92                                       68\n             62.5                                      91                                       66          (11)                                                                                                                                                Tip w/ CuPL                                           Tip w/ CuPL       (11) 90                         Tip w/ CuPL        (11) 64             62.0\n        Avg                           Tip-X w/ CuPL   Avg                          Tip-X w/ CuPL    Avg                          Tip-X w/ CuPL             61.5                 APE w/ CuPL        89                  APE w/ CuPL         62                  APE w/ CuPL\n                                           Tip w/ ProAPO                                    Tip w/ ProAPO                                     Tip w/ ProAPO                                                                                               60             61.0                       Tip-X w/ ProAPO     88                        Tip-X w/ ProAPO                                 Tip-X w/ ProAPO\n                               APE w/ ProAPO                         APE w/ ProAPO       58                  APE w/ ProAPO\n             60.5                                      87\n                 1 2   4       8              16         1 2   4       8               16         1 2   4       8               16\n                        Shots Number                         Shots Number                          Shots Number\n\n                                (a) ImageNet.                                        (b) Caltech.                                             (c) Cars.\n                                                     32                                       80\n            65                                       30                                       75\n                                                     28\n            60                                                                                 70          (11)                                                              (11) 26                                          Tip w/ CuPL                                                                                             Tip w/ CuPL        (11) 65                         Tip w/ CuPL\n        Avg 55                       Tip-X w/ CuPL    Avg 24                       Tip-X w/ CuPL    Avg                          Tip-X w/ CuPL\n                              APE w/ CuPL                            APE w/ CuPL         60                  APE w/ CuPL\n                                          Tip w/ ProAPO        22                         Tip w/ ProAPO                                     Tip w/ ProAPO            50\n                                       Tip-X w/ ProAPO      20                       Tip-X w/ ProAPO      55                       Tip-X w/ ProAPO\n                              APE w/ ProAPO                          APE w/ ProAPO                          APE w/ ProAPO\n            45                                       18                                       50\n                1 2   4       8               16         1 2   4       8               16         1 2   4       8               16\n                       Shots Number                          Shots Number                          Shots Number\n\n                                (d) DTD.                                             (e) FGVC.                                                  (f) ESAT.\n             92.5\n                                                     82\n             90.0                                                                               90\n                                                     81             87.5                                                                                               89\n          (11) 85.0                                           (11) 80                                             (11)\n             82.5                        Tip w/ CuPL                                       Tip w/ CuPL          88                         Tip w/ CuPL\n        Avg 80.0                       Tip-XAPE w/w/CuPLCuPL   Avg 79                        Tip-XAPE w/w/CuPLCuPL    Avg 87                       Tip-XAPE w/w/CuPLCuPL\n                                                     78             77.5                        Tip w/ ProAPO                                    Tip w/ ProAPO                                     Tip w/ ProAPO\n                                        Tip-X w/ ProAPO                                Tip-X w/ ProAPO      86                       Tip-X w/ ProAPO             75.0                                      77                               APE w/ ProAPO                         APE w/ ProAPO                          APE w/ ProAPO\n             72.5                                                                               85\n                 1 2   4       8              16         1 2   4       8               16         1 2   4       8               16\n                        Shots Number                         Shots Number                          Shots Number\n\n                                 (g) FLO.                                            (h) Food.                                                       (i) Pets.\n            70                                       76\n                                                     74\n            68                                                     72\n          (11)                                                              (11) 70            66                         Tip w/ CuPL                                                                                             Tip w/ CuPL\n        Avg                          Tip-X w/ CuPL    Avg 68                       Tip-X w/ CuPL\n            64                  APE w/ CuPL                            APE w/ CuPL\n                                          Tip w/ ProAPO        66                         Tip w/ ProAPO\n                                       Tip-X w/ ProAPO      64                       Tip-X w/ ProAPO            62                  APE w/ ProAPO                          APE w/ ProAPO\n                                                     62\n                1 2   4       8               16         1 2   4       8               16\n                       Shots Number                          Shots Number\n\n                                         (j) SUN.                                             (k) UCF.\n\nFigure 13.  Results of training-free adapter-based methods with different initial prompts.  Solid and dotted lines denote prompt\ninitialization with ProAPO and CuPL, respectively. We see that our ProAPO consistently improves adapter-based methods.\n\n77.5\n            66                                       93                                             75.0\n            65                                                                                             72.5                                                     92\n          (11) 64                    CLIP-A w/ CuPL     (11) 91                    CLIP-A w/ CuPL      (11) 70.067.5                   CLIP-A w/ CuPL\n                                         Tip-F                                         w/                                      CuPL                                                                                                                                       w/                                                                                                                     CuPL                                                                                       w/                                                                             CuPL        Avg                                              Avg                          Tip-F                                                                                     Avg 65.0                       Tip-F            63                                APE-T                                           w/                                       CuPL                                                                                                                  APE-T                                                                                                                                        w/                                                                         APE-T                                                                                         w/                                                                              CuPL                                                     90                                                                  CuPL                                  CLIP-A w/ ProAPO                            CLIP-A w/ ProAPO       62.5                   CLIP-A w/ ProAPO\n            62                        Tip-F w/ ProAPO                                                                                            Tip-F w/ ProAPO         60.0                       Tip-F w/ ProAPO                                                     89                                APE-T w/ ProAPO                           APE-T w/ ProAPO                            APE-T w/ ProAPO\n            61                                                                                             57.5\n                1 2   4       8               16         1 2   4       8               16           1 2   4       8              16\n                       Shots Number                          Shots Number                           Shots Number\n\n                                (a) ImageNet.                                        (b) Caltech.                                             (c) Cars.\n            70                                       40\n                                                                                               85\n            65                                       35                                       80\n          (11) 60                                             (11) 30                                             (11) 75                                  CLIP-A w/ CuPL                              CLIP-A w/ CuPL                              CLIP-A w/ CuPL\n        Avg 55                        Tip-F w/ CuPL      Avg                          Tip-F w/ CuPL      Avg 70                        Tip-F w/ CuPL                                APE-T w/ CuPL        25                   APE-T w/ CuPL                             APE-T w/ CuPL\n            50                    CLIP-A w/ ProAPO                            CLIP-A w/ ProAPO      65                    CLIP-A w/ ProAPO\n                                         Tip-F w/ ProAPO        20                        Tip-F w/ ProAPO                                   Tip-F w/ ProAPO\n                                APE-T w/ ProAPO                           APE-T w/ ProAPO       60                   APE-T w/ ProAPO            45\n                1 2   4       8               16         1 2   4       8               16         1 2   4       8               16\n                       Shots Number                          Shots Number                          Shots Number\n\n                                (d) DTD.                                             (e) FGVC.                                                  (f) ESAT.\n                                                                                               91            95                                       82\n                                                                                               90                                                     81            90\n                                                                                               89\n          (11)                                               (11) 80                                             (11)\n            85                    CLIP-A w/ CuPL                              CLIP-A w/ CuPL        88                    CLIP-A w/ CuPL\n        Avg                          Tip-F w/ CuPL      Avg 79                        Tip-F w/ CuPL      Avg                          Tip-F w/ CuPL\n                                APE-T w/ CuPL                                                                         APE-T w/ CuPL        87                   APE-T w/ CuPL            80                                                     78                                  CLIP-A w/ ProAPO                            CLIP-A w/ ProAPO                            CLIP-A w/ ProAPO\n                                         Tip-F w/ ProAPO                                   Tip-F w/ ProAPO        86                        Tip-F w/ ProAPO                                                     77            75                   APE-T w/ ProAPO                           APE-T w/ ProAPO                           APE-T w/ ProAPO\n                                                                                               85\n                1 2   4       8               16         1 2   4       8               16         1 2   4       8               16\n                       Shots Number                          Shots Number                          Shots Number\n\n                                 (g) FLO.                                            (h) Food.                                                       (i) Pets.\n                                                             80.0\n            72\n                                                             77.5\n            70                                                             75.0\n          (11) 68                                             (11) 72.5                                  CLIP-A w/ CuPL                               CLIP-A w/ CuPL\n        Avg 66                        Tip-F w/ CuPL      Avg 70.0                       Tip-F w/ CuPL\n                                APE-T w/ CuPL          67.5                  APE-T w/ CuPL            64                                  CLIP-A w/ ProAPO                             CLIP-A w/ ProAPO\n            62                        Tip-F w/ ProAPO         65.0                       Tip-F w/ ProAPO\n                                APE-T w/ ProAPO        62.5                  APE-T w/ ProAPO\n            60\n                1 2   4       8               16           1 2   4       8              16\n                       Shots Number                           Shots Number\n\n                                         (j) SUN.                                             (k) UCF.\n\nFigure 14. Results of training adapter-based methods with different initial prompts. Solid and dotted lines denote prompt initialization\nwith ProAPO and CuPL, respectively. We see that our ProAPO consistently improves adapter-based methods.\n\n4                                                              3                                                                2\n         CuPL  3.3    0.0    2.3    2.7    3.2    0.5    0.8    0.2      3          CuPL  4.0    1.1    1.7    1.1    1.1   -0.3   -0.5   0.7      2            CuPL  1.6   -2.1   0.3    0.6    0.8   -1.6   -0.1   0.0      1    Model                                                                                                       Model                                                                                                       Model\n         RN50  3.6    0.7    2.5    3.0    3.1    0.6    0.8    0.6      2          RN50  5.8    2.1    2.8    2.1    1.2    0.3   -0.2   0.9      1            RN50  4.1    0.2    0.6    1.2    1.1   -0.1   0.2    0.5      0\n     Source    3.4    0.1    2.6    2.6    3.0    0.4    0.9    0.6                                                              1      Source    5.5    1.7    3.2    1.4    1.5    0.5   -0.4   0.7                                                                                                                               0        Source    3.2    0.7    1.3    1.2    1.3   -0.1   0.1    0.4                   ViT-B/32                                                                                                                                                                                         1                                                              0                    ViT-B/32                                                        1                    ViT-B/32                                                        2\n        RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP              RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP               RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP\n                             Target Model                                                       Target Model                                                        Target Model\n\n                      (a) ImageNet                                         (b) Caltech                                              (c) Cars\n                                                            4                                                                                                                                  5\n     CuPL  4.3   -4.3   1.6    1.9   -1.1   0.3    1.0    0.7                           CuPL 10.6   9.4    7.7    9.5   10.5  11.1   9.4    2.1                          CuPL  2.9    0.3    0.7    2.2    2.7    2.5    2.9    1.5      4\n                                                            2         Model                                                         10       Model                                                         3Model\n                                                                                                                       RN50 13.5   9.5   10.6  12.9  11.4  13.5  12.3   3.2     RN50  6.0    0.3    3.0    2.4    1.4    0.5    0.6    1.9                                                                                                                                                                                                                                      RN50  5.2    1.1    1.8    3.7    4.4    4.7    3.3    2.8      2                                                                                                                             5                                                            0Source    4.5    1.6    3.7    3.0    1.5    0.7    1.2    1.6                         Source    12.7  10.6  10.6  11.3   11.7  13.2  10.6   2.9                        Source    3.4    2.1    2.8    3.2    4.0    3.6    3.8    2.6      1          ViT-B/32                                                        2                        ViT-B/32                                                      0                           ViT-B/32                                                      0\n      RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP                RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP                RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP\n                          Target Model                                                          Target Model                                                         Target Model\n\n                     (d) CUB                                                (e) DTD                                                    (f) FGVC\n                                                                                                                                                 10.0                                                                3\n     CuPL  9.5   -3.0   6.6    4.7    0.9    0.7   -6.3   -1.8      10             CuPL  6.6   -5.3   3.5    3.3    0.2   -1.7   -0.4   1.5       7.5              CuPL  6.4   -0.7   1.0    0.5    0.3   -0.7   -0.2   -0.8      2Model                                                                                                                                                                                                                            Model                                                                                                                Model     RN50 23.1  12.0  13.9   9.3    9.4   11.4   -3.6   3.6      5                                                                                                                                                                                                                                           RN50  7.8    0.6    2.0    1.1    0.9    0.7    0.0    0.5      1                                                                                                                          RN50 14.9   -1.2   8.3    9.4    7.2    8.2    9.6    4.3       5.0\n                                                            0Source    21.5   7.1   19.1  14.1  10.2  15.1   -1.7   2.2                                                                                                                                       Source    11.1   6.3    8.3    9.4    5.7    6.3    8.0    3.0       2.50.0          Source    7.7    1.3    2.1    1.1    0.7    0.9    0.1    0.5          ViT-B/32                                                        5                        ViT-B/32                                                                                                                                                                                                                               ViT-B/32                                                      0 1\n      RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP                 RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP                 RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP\n                          Target Model                                                          Target Model                                                          Target Model\n\n                     (g) ESAT                                             (h) FLO                                                         (i) Food\n     CuPL  3.3   -0.3   0.2    2.2    0.5    0.1   -0.1   0.4      4              CuPL  2.8    2.7    3.2    2.6    3.1    1.8    1.1    1.9      3            CuPL  5.0    3.3    4.2    6.5    5.6    1.0    1.8    0.4      54                                                                                                            Model                                                                                                                                                                                                                       ModelModel\n                                                                                                                                                                                                                                      RN50  5.7    3.6    3.9    7.1    4.9    1.3    1.4    1.1      3                                                                                                                      RN50  3.6    2.4    3.3    2.9    3.4    1.4    1.2    2.5      2     RN50  5.5    2.7    3.5    3.7    1.2    1.0    0.8    0.5      2\n                                                                                                                                                                                             2                                                            0                                                                                                                                 Source                                                                                                                                                                                                                                                                  SourceSource                                                                                                                                                   5.7    3.4    4.5    7.2    4.7    1.2    1.5    1.3        5.2    2.3    4.2    3.6    1.4    1.0    0.8    0.2                                                                             3.2    2.4    3.4    2.8    3.3    1.9    1.3    2.5      1                                                                                                                                                                                             1                                                                                                                                                                                                                                           ViT-B/32                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ViT-B/32          ViT-B/32                                                             2\n      RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP                RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP               RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP\n                          Target Model                                                         Target Model                                                        Target Model\n\n                           (j) Pets                                              (k) Places                                                        (l) SUN\n                                                                                                                  7.5       CuPL  5.4   -0.2   3.1    3.2    2.7    1.1    1.0    0.2      6                                                                   CuPL  6.0   -4.8   5.5    2.6    3.3    0.8    3.3   -1.5                                                                                                                                                              Model                                                           Model                                                                    5.0                                                                                                                                                                          RN50  9.0    2.8    5.1    5.2    4.5    4.2    2.7    1.6      4                                                                   RN50  9.1   -0.1   6.2    4.0    4.0    4.8    4.8   -0.3       2.5\n                                                                                                                  0.0   Source    7.9    3.0    6.1    5.3    4.3    4.0    2.6    1.3                                                                       Source    6.9   -2.2   8.1    3.8    3.6    2.0    4.6    0.0                                                                                                                                     ViT-B/32                                                                   2.5           ViT-B/32                                                      20\n                                      RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP              RN50  RN101 ViT-B/32 ViT-B/16 ViT-L/14 OpenCLIP EVA02  SigLIP\n                                                                Target Model                                                      Target Model\n\n                                        (m) UCF                                        (n) Avg (11)\n\nFigure 15. Results of prompt transfer to different backbones. The value denotes performance gains compared to vanilla VLMs. Our\noptimized prompts of ResNet50 and ViT-B/32 are reported. We see that we achieve stable performance gains compared to CuPL [55].\n\n                                                                                                                                                                                                               (11)\n                Module (ResNet50)             IN-1K              Caltech        Cars      DTD        ESAT        FGVC      FLO        Food        Pets      SUN      UCF      Avg\n\n                CLIP (a photo of a {})   57.9   84.5   53.9   38.8   28.6   15.9   60.2   74.0   83.2   58.0   56.9   55.6\n\n                                                                Single Prompt\n\n             PN [39]                59.6   89.1   56.2   44.8   49.0   18.1   67.2   78.3   88.1   61.0   60.2   61.1\n                   Best Single*            60.2   89.2   57.9   45.0   46.0   18.3   68.1   81.8   88.3   61.5   62.6   61.7\n\n                                                     Ensemble Prompt\n\n            ATO (ours)             61.3   89.2   57.9   45.4   44.7   18.2   68.1   81.8   88.5   61.8   63.9   61.9\n                   Best Ensemble*         61.5   90.0   58.4   47.0   49.1   18.7   69.9   82.2   89.4   62.1   64.8   63.0\n\nTable 17. Analysis of the effect of single vs ensemble prompts. * denotes results evaluated in the test set. ATO is our automatic template\noptimization algorithm. We see that our optimized templates achieve higher results than PN [39], even better than the best single template.\n\n(11)         (13)\n  Module (ViT-B/32)      IN-1K                Caltech         Cars       CUB       DTD         ESAT           FGVC       FLO         Food         Pets              Places       SUN       UCF       Avg       Avg\n\n   Vanilla CLIP         62.1   91.2   60.4   51.7   42.9   43.9     20.2   66.0   83.2   86.8   39.9   62.1   60.9    61.8    59.3\n\n  DCLIP [43]          63.3   92.7   59.4   52.7   44.1   38.4     19.4   66.1   83.9   88.1   41.2   65.0   65.8    62.4    60.0\n  + ATO              63.8   93.0   60.3   52.5   46.5   54.1     21.8   68.9   84.0   88.4   41.5   65.4   66.0    64.7    62.0\n  + ProAPO           64.1   93.2   60.6   53.6   48.2   59.4     22.6   71.5   84.2   88.7   42.7   66.0   68.0    66.0    63.3\n ‚àÜ               + 0.8  + 0.5  + 1.2  + 0.9  + 4.1  + 21.0  + 3.2  + 5.4  + 0.3  + 0.6  + 1.5  + 1.0  + 2.2  + 3.6  + 3.3\n\n  CuPL-base [55]      64.0   92.3   60.1   54.3   47.2   42.4     21.7   68.7   84.3   88.8   42.0   66.2   66.7    63.8    61.4\n  + ATO              64.2   93.3   60.9   54.8   47.8   53.1     22.2   70.4   84.9   89.2   42.3   65.5   67.4    65.3    62.8\n  + ProAPO           64.4   94.2   61.8   55.9   48.1   62.1     23.2   74.4   85.4   91.0   42.7   65.6   68.6    67.2    64.4\n ‚àÜ               + 0.4  + 1.9  + 1.7  + 1.6  + 0.9  + 19.7  + 1.5  + 5.7  + 1.1  + 2.2  + 0.7   -0.6   + 1.9  + 3.4  + 3.0\n\n   CuPL-full [55]       64.4   92.9   60.7   53.3   50.6   50.5     20.9   69.5   84.2   87.0   43.1   66.3   66.4    64.9    62.3\n  + ATO              64.5   93.7   61.0   54.0   52.0   58.7     22.1   70.5   84.6   89.2   43.2   66.4   67.5    66.4    63.6\n  + ProAPO           64.7   94.4   61.7   55.4   53.5   63.0     23.0   74.3   85.3   91.0   43.3   66.6   69.0    67.9    65.0\n ‚àÜ               + 0.3  + 1.5  + 1.0  + 2.1  + 2.9  + 12.5  + 2.1  + 4.8  + 1.1  + 4.0  + 0.2  + 0.3  + 2.6  + 3.0  + 2.7\n\n  GPT4Vis [73]        63.5   93.1   61.4   52.7   48.5   47.0     21.4   69.8   84.3   88.1   42.7   64.2   65.7    64.3    61.7\n  + ATO              63.8   93.4   61.2   53.8   49.0   54.0     22.4   70.8   84.7   88.1   42.6   64.7   66.8    65.3    62.7\n  + ProAPO           64.4   93.7   61.8   55.4   49.3   62.6     23.9   73.8   85.4   90.7   42.8   65.5   68.2    67.2    64.4\n ‚àÜ               + 0.9  + 0.6  + 0.4  + 2.7  + 0.8  + 15.6  + 2.5  + 4.0  + 1.1  + 2.6  + 0.1  + 1.3  + 2.5  + 2.9  + 2.7\n\n  AdaptCLIP [62]      63.3   92.7   59.7   53.6   47.4   51.3     20.8   67.2   84.2   87.6   41.9   66.1   66.5    64.2    61.7\n  + ATO              63.9   93.2   60.4   54.2   47.9   55.5     22.4   69.1   84.7   88.8   42.3   66.3   67.6    65.4    62.8\n  + ProAPO           64.4   93.7   61.8   55.5   49.6   61.6     23.3   73.8   85.4   91.0   42.6   66.5   68.6    67.2    64.5\n ‚àÜ               + 1.1  + 1.0  + 2.1  + 1.9  + 2.2  + 10.3  + 2.5  + 6.6  + 1.2  + 3.4  + 0.7  + 0.4  + 2.1  + 3.0  + 2.8\n\n\nTable 18. Performance improvement of description methods by our ProAPO. Avg (11) and Avg (13) denote average results across 11\ndatasets (excluding CUB [71] and Places [81]) and all 13 datasets, respectively. ‚àÜdenotes performance gains compared to baseline.\n\n\n\n\n\n             Component\n                                                                                                                                                                                                                                          (11)        (13)\n      Add  Del  Rep  Cross  Mut        IN-1K              Caltech        Cars      CUB      DTD        ESAT        FGVC      FLO        Food        Pets            Places      SUN      UCF      Avg      Avg\n\n   Vanilla CLIP (ViT-B/32)                    62.1   91.2   60.4   51.7   42.9   43.9   20.2   66.0   83.2   86.8   39.9   62.1   60.9   61.8   59.3\n\n   edit-based generation\n  a)  ‚úì                                  63.8   93.6   60.0   54.6   51.8   59.0   21.8   74.0   82.2   86.7   43.0   65.7   66.8   66.0   63.3\n  b)  ‚úì   ‚úì                           64.6   94.0   60.9   55.0   52.6   59.3   21.8   72.0   83.2   88.0   43.2   66.4   68.0   66.4   63.8\n  c)  ‚úì       ‚úì                    64.4   94.0   61.0   55.2   52.3   59.7   22.4   71.9   84.0   87.7   43.2   66.4   67.8   66.5   63.8\n  d)  ‚úì   ‚úì   ‚úì                    64.6   93.6   60.8   54.4   53.1   60.1   22.2   74.7   82.4   87.2   43.4   66.5   68.6   66.7   64.0\n\n   evolution-based generation\n  e)  ‚úì   ‚úì   ‚úì    ‚úì            64.6   94.3   61.2   55.0   53.2   62.6   22.9   73.9   84.3   88.0   43.1   66.8   68.5   67.3   64.5\n  f)  ‚úì   ‚úì   ‚úì         ‚úì    64.7   94.3   61.4   55.1   52.9   61.4   22.6   74.0   83.6   87.7   43.4   66.7   68.3   67.1   64.3\n  g)  ‚úì   ‚úì   ‚úì    ‚úì    ‚úì    64.7   94.4   61.7   55.4   53.5   63.0   23.0   74.3   85.3   91.0   43.3   66.6   69.0   67.9   65.0\n\n\n                                   Table 19. Ablation of edit- and evolution-based operators.\n\n(11)        (13)\nModule (ViT-B/32)                       IN-1K              Caltech        Cars      CUB      DTD        ESAT        FGVC      FLO        Food        Pets            Places      SUN      UCF      Avg      Avg    Times\n\na) w/o prompt sampling     64.4   93.8   61.8   55.4   51.8   60.0   23.2   74.0   85.1   90.7   43.0   66.0   69.3   67.3   64.5   12 min\nb) w/o group sampling      64.8   94.5   61.7   55.5   53.6   63.5   23.2   75.3   85.4   90.8   43.3   66.7   69.8   68.1   65.2  306 min\nc) w/o sampling strategies   64.5   93.4   57.4   54.8   53.6   63.2   23.4   76.8   83.8   86.9   43.3   66.1   69.7   67.2   64.4   302 min\n\nProAPO (full model)        64.7   94.4   61.7   55.4   53.5   63.0   23.0   74.3   85.3   91.0   43.3   66.6   69.0   67.9   65.0   15 min\n\n\n                                       Table 20. Ablation of two sampling strategies.\n\n\n\n\n\n                                                                                                                                                                                                               (11)        (13)\nModule (ViT-B/32)                           IN-1K              Caltech        Cars      CUB      DTD        ESAT        FGVC      FLO        Food        Pets            Places      SUN      UCF      Avg      Avg\n\na) w/ only accuracy           64.0   93.0   60.8   54.2   49.1   55.5   20.4   68.3   84.8   88.4   41.9   64.6   65.1   64.9   62.3\nb) w/ only entropy constrain   64.3   93.4   61.6   54.8   49.3   56.7   22.3   69.9   85.2   89.1   42.4   65.1   66.7   65.8   63.1\n\nProAPO (full model)          64.7   94.4   61.7   55.4   53.5   63.0   23.0   74.3   85.3   91.0   43.3   66.6   69.0   67.9   65.0\n\n\n                                      Table 21. Ablation of different score functions.",
"headers": [
"arXiv:2502.19844v3  [cs.CV]  12 Mar 2025",
"ProAPO: Progressively Automatic Prompt Optimization for Visual Classification",
"Xiangyan Qu",
"Gaopeng Gou",
"Jiamin Zhuang",
"Jing Yu",
"Kun Song",
"Qihao Wang",
"Yili Li",
"Gang Xiong",
"Abstract",
"1. Introduction",
"2. Related Work",
"3. Method",
"4. Experiments",
"5. Conclusion",
"Acknowledgements",
"References",
"A. Details of Building Prompt Library",
"B. Details of Prompt Sampling Strategy",
"C. Details of Group Sampling Strategy",
"D. More Implementation Details",
"E. Results on Different Backbones",
"F. More Comparisons with SOTA Methods",
"G. More Ablation Results",
"H. More Hyperparameter Analysis",
"I. More Qualitative Results",
"J. Detailed Results of More Benefits by Opti-",
"mal Prompts",
"K. Detailed Results of Performance Improve-",
"ment Analysis",
"L. Detailed Results of Ablation Study",
"3.1. Automatic Template Optimization",
"3.2. Prompt Generation by Several Operators",
"3.3. Score Functions",
"3.4. Sampling Strategy for Initialization",
"4.1. Comparison with SOTA Methods",
"4.2. More Benefits by Optimal Prompts",
"4.3. Performance Improvement Analysis",
"4.4. Ablation Study",
"4.5. Hyperparameter Sensitivity",
"A.1. Details of Building Template Library",
"A.2. Details of Building Description Library",
"D.1. Hyperparameter Settings",
"D.2. More Related Work",
"G.2. More Ablation of Operators",
"G.1. Ablation of Template and Description Opti-",
"mization",
"G.3. More Ablation of Group Sampling",
"G.4. Ablation of Cost Computation",
"H.2. Effect of Scalar in Score Function",
"H.3. Effect of Sampled Numbers in Prompt Sam-",
"pling Strategy",
"H.1. Effect of Shot Numbers",
"H.4. Effect of Quality of Prompt Library",
"J.1. Transfer to Adapter-based Methods",
"L.2. Ablation of Two Sampling Strategies",
"J.2. Transfer to Different Backbones",
"L.3. Ablation of Different Score Functions",
"K.1. Analysis of the Effect of Single VS Ensemble",
"Prompts",
"K.2. Performance Improvement of Description",
"Methods by ProAPO",
"L.1. Ablation of Edit- and Evolution-based Opera-",
"tors"
],
"tables": [
"|Laysan Albatross<br>‚Ä¢ white with black wings<br>‚Ä¢ a seabird<br>‚Ä¢ long, webbed feet<br>‚Ä¢ a long, hooked bill<br>‚Ä¢ flight over the ocean<br>Sooty Albatross<br>‚Ä¢ large, dark-colored bird<br>‚Ä¢ white band around its neck<br>‚Ä¢ webbed feet<br>‚Ä¢ long, hooked bill<br>‚Ä¢ a species of albatross<br>(a) Issues in generated descriptions.|Natural Language Prompt Search Space<br>task-specific template<br>template: ùëö domain: ùëõ<br>A photo of + a bird: +<br>Laysan Albatross. + It has white with black wings.<br>class name: ùëü description: ùë†<br>class-specific description<br>Number of task-specificÔºöùëö√ó ùëõ.<br>Number of class-specificÔºöùëö√ó ùëõ√ó ùëü√ó ùë†.<br>(b) Explosion in the number of prompts.|(c) Overfitting in evaluation metric.|\n|---|---|---|",
"|template: ùëö|domain: ùëõ|\n|---|---|\n|A photo of|a bird:|",
"|Number of task-specificÔºöùëö√ó ùëõ.|Col2|Col3|\n|---|---|---|\n|Number of class-specificÔºö|ùëö√ó ùëõ√ó ùëü√ó ùë†.||",
"|Module|TF|IN-1K Caltech Cars CUB DTD ESAT FGVC FLO Food Pets Places SUN UCF|Avg (11)|Avg (13)|\n|---|---|---|---|---|\n|**_ResNet-50 Backbone_**|**_ResNet-50 Backbone_**|**_ResNet-50 Backbone_**|**_ResNet-50 Backbone_**|**_ResNet-50 Backbone_**|\n|CLIP (a photo of a_ {}_)|‚úì|57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9|55.6|53.4|",
"|CoOp [83]<br>PLOT [6]<br>ProGrad [85]|‚úó<br>‚úó<br>‚úó|57.2 87.5 55.6 - 44.4 50.6 9.6 68.1 74.3 85.9 - 60.3 61.9<br>59.5 89.8 56.6 - 46.6 54.1 17.9 71.7 77.7 87.5 - 62.5 64.5<br>57.8 88.7 58.4 - 46.1 56.3 18.8 73.2 76.0 88.4 - 60.5 65.6|59.6<br>62.6<br>62.7|-<br>-<br>-|\n|---|---|---|---|---|",
"|PN [39]|‚úì|59.6 89.1 56.2 - 44.8 49.0 18.1 67.2 78.3 88.1 - 61.0 60.2|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|61.1|-|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|**ProAPO** (ours)|‚úì|**61.5**|**90.3**|58.0|**50.7**|**52.3**|51.7|**21.1**|**75.1**|**81.8**|**88.7**|**41.8**|**63.7**|**66.0**|**64.6**|**61.8**|\n|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|**_ViT-B/32 Backbone_**|\n|CLIP (a photo of a_ {}_)|‚úì|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|61.8|59.3|",
"|Template-80 [58]<br>FILIP-8 [76]<br>DEFILIP-6 [9]|‚úì<br>‚úì<br>‚úì|63.5 91.6 60.4 51.2 42.8 52.6 19.5 66.1 84.2 87.4 41.6 63.5 62.9<br>63.8 91.4 60.7 52.7 43.4 54.3 18.9 67.0 84.6 87.5 41.2 63.9 65.0<br>62.5 91.0 59.9 51.1 41.3 46.4 18.8 66.5 84.3 87.5 40.2 62.3 63.6|63.1<br>63.7<br>62.2|60.6<br>61.1<br>59.6|\n|---|---|---|---|---|",
"|description-based methods ‚úì|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|DCLIP [43]<br>‚úì<br>63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>62.4<br>60.0<br>Waffle [61]<br>‚úì<br>63.3<br>92.1<br>59.3<br>52.9<br>43.2<br>51.6<br>19.6<br>66.3<br>84.9<br>87.7<br>41.5<br>65.0<br>64.5<br>63.4<br>60.9<br>CuPL [55]<br>‚úì<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.9<br>62.3<br>GPT4Vis [73]<br>‚úì<br>63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>64.3<br>61.7<br>AdaptCLIP [62]<br>‚úì<br>63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>64.2<br>61.7<br>|\n|**ProAPO** w/ DCLIP|‚úì<br>|64.1|93.2|60.6|53.6|48.2|59.4|22.6|71.5|84.2|88.7|42.7|66.0|68.0|66.0|63.3|\n|**ProAPO** (ours)|‚úì|**64.7**|**94.4**|**61.7**|**55.4**|**53.5**|**63.0**|**23.0**|**74.3**|**85.3**|**91.0**|**43.3**|**66.6**|**69.0**|**67.9**|**65.0**|",
"|Acc<br>Fig<br>the<br>uat<br>alg<br>pro|62<br>60<br>58 Avg (11) Im<br>ure 5. Perf<br>effect of sin<br>ed in the tes<br>orithm. (b) R<br>mpt optimiz|61<br>60<br>ageNet UCF FLO 59 DCLIP<br>Datasets<br>(a)<br>ormance improvement analy<br>gle vs. ensemble prompts. *<br>t set. ATO is our automatic te<br>esults of previous description-<br>ation by our ATO and ProAPO|\n|---|---|---|\n|**Sooty Albatross Laysan Albatross**||**Removed Prompts**<br>‚Ä¢<br>Laysan Albatross,** a type of seabird**.<br>‚Ä¢<br>A Laysan albatross in** mid-flight over**<br>**the ocean**.<br>‚Ä¢<br>Laysan albatrosses are** large birds**with<br>**long wings and a long hooked bill**.<br>‚Ä¢<br>The Laysan albatross has a** slim build**<br>**and long wings**.<br>‚Ä¢<br>The<br>**with**<br>‚Ä¢<br>The<br>**bod**<br>‚Ä¢<br>A La<br>**whit**<br>**blac**<br>‚Ä¢<br>The<br>**blac**<br>‚Ä¢<br>The<br>that<br>‚Ä¢<br>Soot<br>**und**<br>**whit**<br>‚Ä¢<br>A Sooty Albatross in** flight the ocean**.<br>‚Ä¢<br>Sooty albatrosses are** large black and**<br>**white birds** with** long wings and a**<br>**long hooked bill**.<br>‚Ä¢<br>Sooty albatrosses are<br>**a**<br>**species**<br>**of**<br>**seabird**that have** dark plumage**.<br>‚Ä¢<br>Sooty Albatross is** a specie of albatross**.|\n|<br> <br>Figure 6.<br>**Qualitative analysis of class-spe**<br>**mization by ProAPO.** Shaded** red** and** blue** <br>mon and discriminative descriptions in two co<br>**4.3. Performance Improvement An**<br>In this section, we analyze the key reaso<br>mance improvement of our ProAPO.<br>**Prompt ensembling is better than**<br>Compared to PN [39], we utilize prompt e<br>of a single prompt to optimize the tem<br>tion. To evaluate the effectiveness of pr<br>we use Template-80 [58] as the template<br>the prompts searched by the test set as<br>As shown in Fig. 5(a), we observe that en<br>have a higher upper bound than the single<br>tent with prior work [9, 43, 76]. Similarl<br>our optimized templates achieve higher<br>PN [39], even better than the best single<br>verifying the effectiveness of our method<br>**Iterative optimization improves pr**<br>Fig. 6, we show the changes in desc|<br> <br>Figure 6.<br>**Qualitative analysis of class-spe**<br>**mization by ProAPO.** Shaded** red** and** blue** <br>mon and discriminative descriptions in two co<br>**4.3. Performance Improvement An**<br>In this section, we analyze the key reaso<br>mance improvement of our ProAPO.<br>**Prompt ensembling is better than**<br>Compared to PN [39], we utilize prompt e<br>of a single prompt to optimize the tem<br>tion. To evaluate the effectiveness of pr<br>we use Template-80 [58] as the template<br>the prompts searched by the test set as<br>As shown in Fig. 5(a), we observe that en<br>have a higher upper bound than the single<br>tent with prior work [9, 43, 76]. Similarl<br>our optimized templates achieve higher<br>PN [39], even better than the best single<br>verifying the effectiveness of our method<br>**Iterative optimization improves pr**<br>Fig. 6, we show the changes in desc|<br> <br>Figure 6.<br>**Qualitative analysis of class-spe**<br>**mization by ProAPO.** Shaded** red** and** blue** <br>mon and discriminative descriptions in two co<br>**4.3. Performance Improvement An**<br>In this section, we analyze the key reaso<br>mance improvement of our ProAPO.<br>**Prompt ensembling is better than**<br>Compared to PN [39], we utilize prompt e<br>of a single prompt to optimize the tem<br>tion. To evaluate the effectiveness of pr<br>we use Template-80 [58] as the template<br>the prompts searched by the test set as<br>As shown in Fig. 5(a), we observe that en<br>have a higher upper bound than the single<br>tent with prior work [9, 43, 76]. Similarl<br>our optimized templates achieve higher<br>PN [39], even better than the best single<br>verifying the effectiveness of our method<br>**Iterative optimization improves pr**<br>Fig. 6, we show the changes in desc|",
"|Source Target<br>Module Shots RN50 RN101 ViT-B/32 ViT-|Col2|Col3|\n|---|---|---|\n|CLIP [58]<br>0<br>CoOp [83]<br>16<br>PN [39]<br>1|57.9<br>60.6<br>61.9<br>66<br>**63.0**<br>20.6<br>31.7<br>39<br>59.9<br>60.7<br>62.2<br>67|57.9<br>60.6<br>61.9<br>66<br>**63.0**<br>20.6<br>31.7<br>39<br>59.9<br>60.7<br>62.2<br>67|\n|<br><br>**ProAPO**<br>1|61.5<br>**62.1**|**64.6**<br>**69**|",
"|64.5<br>Best Acc:<br>64.0<br>63.5<br>63.0<br>62.5<br>62.0<br>64.0 64.5 6|64.0¬±0.2<br>5.0 65.5 66.0 66.5 67.0 67.5 68.0|\n|---|---|",
"|b) ‚úì ‚úì<br>c) ‚úì ‚úì<br>d) ‚úì ‚úì ‚úì|64.6 66.4 63.8<br>64.4 66.5 63.8|\n|---|---|",
"|evolution-based generation ‚úì ‚úì ‚úì ‚úì|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|64.6<br>67.3<br>64.5<br>64.7<br>67.1<br>64.3|64.6<br>67.3<br>64.5<br>64.7<br>67.1<br>64.3|64.6<br>67.3<br>64.5<br>64.7<br>67.1<br>64.3|\n|g)|‚úì|‚úì|‚úì|‚úì|‚úì|**64.7**|**67.9**|**65.0**|",
"|67<br>66<br>65<br>64<br>63|Col2|67 set<br>66 test<br>65 on<br>64 curacy<br>63|Col4|Col5|Col6|Col7|67 set<br>66 test<br>65 on<br>64 curacy<br>63|Col9|\n|---|---|---|---|---|---|---|---|---|",
"|Dataset|Domain Information|\n|---|---|\n|IN-1K [10]<br>Caltech [15]<br>Cars [34]<br>CUB [71]<br>DTD [8]<br>ESAT [26]<br>FGVC [41]<br>FLO [48]<br>Food [3]<br>Pets [53]<br>Places [81]<br>SUN [74]<br>UCF [67]|real scenario; natural scene<br>object; everyday objects; common items<br>car; vehicles; auto-mobile<br>bird; wildlife; ornithology<br>textures; patterns; surface; material<br>land cover; remote sensing; satellite photo; satellite<br>imagery; aerial or satellite images; centered satel-<br>lite photo<br>aircraft; airplane; plane; airliner<br>flower; floral; botanical; bloom<br>food; dishes; cuisine; nourishment<br>pet; domestic animals; breed; dog or cat<br>place; scene<br>place; scene<br>action; human action; human activities; person do-<br>ing|",
"|Method|Prompts|\n|---|---|\n|DCLIP [43]|Q: What are useful visual features for distin-<br>guishing a_ {_class_}_ in a photo?<br>A: There are several useful visual features to<br>tell there is a_ {_class_}_ in a photo:|\n|CuPL-Base [55]|Describe what a_ {_class_}_ looks like.<br>Describe a_ {_class_}_.<br>What are the identifying characteristics of a<br>_{_class_}_?|\n|CuPL-Full [55]|Describe what a_ {_class_}_ looks like.<br>How can you identify a_ {_class_}_?<br>What does a_ {_class_}_ look like?<br>Describe an image from the internet of a<br>_{_class_}_<br>A caption of an image of a_ {_class_}_:|\n|GPT4Vis [73]|I want you to act as an image description expert.<br>I will give you a word and your task is to give<br>me 20 sentences to describe the word. Your<br>description must accurately revolve around this<br>word and be as objective, detailed and diverse<br>as possible. In addition, the subject of your de-<br>scription is a some kind of object photograph.<br>Output the sentences in a json format which key<br>is the the word and the value is a list composed<br>of these sentences. Do not provide any expla-<br>nations. The first word is ‚Äú_{_class_}_‚Äù.|\n|AdaptCLIP [62]|What characteristics can be used to dif-<br>ferentiate_ {_class_}_ from other_ {_domain_}_<br>based on just a photo?<br>Provide an exhaus-<br>tive list of all attributes that can be used<br>to identify the_ {_domain_}_ uniquely.<br>Texts<br>should be of the form ‚Äú_{_domain_}_ with<br>_{_characteristic_}_‚Äù.|",
"|Dataset|T|M|N|Œ±|n<br>wst|n<br>sln|T<br>sample|\n|---|---|---|---|---|---|---|---|\n|IN-1K [10]<br>Caltech [15]<br>Cars [34]<br>CUB [71]<br>DTD [8]<br>ESAT [26]<br>FGVC [41]<br>FLO [48]<br>Food [3]<br>Pets [53]<br>Places [81]<br>SUN [74]<br>UCF [67]|4<br>2<br>4<br>4<br>4<br>4<br>4<br>4<br>4<br>2<br>4<br>2<br>4|8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8|8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8<br>8|1e3<br>1e2<br>1e4<br>1e2<br>1e3<br>1e3<br>1e3<br>1e3<br>1e3<br>1e4<br>1e2<br>1e4<br>1e3|4<br>2<br>4<br>4<br>4<br>3<br>4<br>4<br>2<br>2<br>3<br>4<br>3|4<br>2<br>4<br>4<br>4<br>3<br>4<br>4<br>2<br>2<br>3<br>4<br>3|32<br>32<br>32<br>32<br>32<br>32<br>32<br>32<br>32<br>32<br>32<br>32<br>32|",
"|Module|IN-1K Caltech Cars CUB DTD ESAT FGVC FLO Food Pets Places SUN UCF|Avg (11)|Avg (13)|\n|---|---|---|---|\n|CLIP [58] - ResNet50<br>CuPL [55]<br>**ProAPO** (ours)<br>‚àÜ|57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>61.2<br>88.3<br>55.3<br>48.7<br>49.5<br>38.2<br>18.9<br>67.0<br>80.1<br>86.1<br>41.2<br>63.1<br>63.3<br>**61.5**<br>**90.3**<br>**58.0**<br>**50.7**<br>**52.3**<br>**51.7**<br>**21.1**<br>**75.1**<br>**81.8**<br>**88.7**<br>**41.8**<br>**63.7**<br>**66.0**<br>+ 3.6 + 5.8 + 4.1 + 6.0 + 13.5 + 23.1 + 5.2 + 14.9 + 7.8 + 5.5 + 3.6 + 5.7 + 9.1|55.6<br>61.1<br>**64.6**<br>                          + 9.0|53.4<br>58.5<br>**61.8**<br>+ 8.4|\n|CLIP [58] - ResNet101<br>CuPL [55]<br>**ProAPO** (ours)<br>‚àÜ|61.4<br>89.9<br>63.3<br>49.6<br>40.3<br>31.7<br>18.3<br>64.3<br>83.4<br>86.9<br>37.9<br>59.0<br>61.2<br>61.4<br>91.0<br>61.2<br>45.3<br>49.7<br>28.7<br>18.6<br>59.0<br>82.7<br>86.6<br>**40.6**<br>62.3<br>56.4<br>**63.6**<br>**92.3**<br>**64.4**<br>**52.2**<br>**51.6**<br>**45.9**<br>**21.2**<br>**69.6**<br>**84.9**<br>**89.6**<br>**40.6**<br>**63.5**<br>**64.0**<br>+ 2.2 + 2.4 + 1.1 + 2.6 + 11.3 + 14.2 + 2.9<br>+ 5.3<br>+ 1.5 + 2.7 + 2.7 + 4.5 + 2.8|60.0<br>59.8<br>**64.6**<br>          + 4.6|57.5<br>57.2<br>**61.8**<br>+ 4.3|\n|CLIP [58] - ViT-B/32<br>CuPL [55]<br>**ProAPO** (ours)<br>‚àÜ|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9<br>64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>**64.7**<br>**94.4**<br>**61.7**<br>**55.4**<br>**53.5**<br>**63.0**<br>**23.0**<br>**74.3**<br>**85.3**<br>**91.0**<br>**43.3**<br>**66.6**<br>**69.0**<br>+ 2.6 + 3.2 + 1.3 + 3.7 + 10.6 + 19.1 + 2.8<br>+ 8.3<br>+ 2.1 + 4.2 + 3.4 + 4.5 + 8.1|61.8<br>64.9<br>**67.9**<br>          + 6.1|59.3<br>62.3<br>**65.0**<br>+ 5.7|\n|CLIP [58] - ViT-B/16<br>CuPL [55]<br>**ProAPO** (ours)<br>‚àÜ|66.9<br>93.2<br>65.5<br>55.3<br>44.3<br>51.0<br>24.4<br>70.6<br>88.4<br>89.0<br>40.8<br>62.5<br>67.7<br>69.6<br>94.3<br>66.1<br>57.2<br>53.8<br>55.7<br>26.6<br>73.9<br>88.9<br>91.2<br>43.4<br>**69.0**<br>70.3<br>**69.9**<br>**95.2**<br>**67.7**<br>**59.0**<br>**55.8**<br>**65.3**<br>**28.3**<br>**82.7**<br>**89.5**<br>**92.7**<br>**43.8**<br>68.9<br>**73.1**<br>+ 3.0 + 2.0 + 2.2 + 3.7 + 11.5 + 14.3 + 3.9 + 12.1 + 1.1 + 3.7 + 3.0 + 6.4 + 5.4|65.8<br>69.0<br>**71.7**<br>                          + 5.9|63.0<br>66.1<br>**68.6**<br>+ 5.6|\n|CLIP [58] - ViT-L/14<br>CuPL [55]<br>**ProAPO** (ours)<br>‚àÜ|73.5<br>95.1<br>76.8<br>62.5<br>52.1<br>61.5<br>33.4<br>79.5<br>93.1<br>93.3<br>40.7<br>67.6<br>75.0<br>76.7<br>96.2<br>77.6<br>61.4<br>62.6<br>62.4<br>36.1<br>79.7<br>93.4<br>93.8<br>43.8<br>73.2<br>78.3<br>**76.8**<br>**97.1**<br>**78.8**<br>**65.1**<br>**64.8**<br>**74.3**<br>**38.3**<br>**87.3**<br>**93.9**<br>**94.6**<br>**44.4**<br>**73.4**<br>**80.1**<br>+ 3.3 + 2.0 + 2.0 + 2.6 + 12.7 + 12.8 + 4.9<br>+ 7.8<br>+ 0.8 + 1.3 + 3.7 + 5.3 + 5.1|72.8<br>75.5<br>**78.1**<br>          + 5.8|69.5<br>71.9<br>**74.5**<br>+ 5.0|\n|OpenCLIP [7] - ViT-B/32<br>CuPL [55]<br>**ProAPO** (ours)<br>‚àÜ|66.2<br>94.7<br>88.2<br>65.6<br>51.3<br>49.4<br>23.0<br>71.2<br>82.4<br>90.7<br>41.5<br>68.1<br>65.0<br>66.7<br>94.4<br>86.6<br>65.9<br>62.4<br>50.1<br>25.5<br>69.5<br>81.7<br>90.8<br>43.3<br>69.1<br>65.8<br>**67.0**<br>**95.8**<br>**88.7**<br>**67.3**<br>**65.1**<br>**66.0**<br>**27.5**<br>**81.8**<br>**83.2**<br>**91.9**<br>**43.4**<br>**69.7**<br>**70.2**<br>+ 0.8 + 1.1 + 0.5 + 1.7 + 13.8 + 16.6 + 4.5 + 10.6 + 0.8 + 1.2 + 1.9 + 1.6 + 5.2|68.2<br>69.3<br>**73.3**<br>                          + 5.1|65.9<br>67.1<br>**70.6**<br>+ 4.7|\n|EVA02 [14] - ViT-B/16<br>CuPL [55]<br>**ProAPO** (ours)<br>‚àÜ|74.6<br>**97.2**<br>79.2<br>60.8<br>49.7<br>68.0<br>24.6<br>75.6<br>89.5<br>92.2<br>42.9<br>70.7<br>68.6<br>75.4<br>96.7<br>79.2<br>61.8<br>59.1<br>61.7<br>27.5<br>75.2<br>89.3<br>92.1<br>44.0<br>72.5<br>71.9<br>**75.5**<br>97.0<br>**80.0**<br>**62.8**<br>**61.3**<br>**74.2**<br>**29.7**<br>**89.1**<br>**89.6**<br>**93.5**<br>**44.5**<br>**72.5**<br>**75.2**<br>+ 0.9<br>-0.2<br>+ 0.8 + 2.0 + 11.6<br>+ 6.2<br>+ 5.1 + 13.5 + 0.1 + 1.3 + 1.6 + 1.8 + 6.6|71.8<br>72.8<br>**76.2**<br>              + 4.4|68.7<br>69.7<br>**72.7**<br>+ 4.0|\n|SigLIP [78] - ViT-B/16<br>CuPL [55]<br>**ProAPO** (ours)<br>‚àÜ|75.8<br>97.3<br>90.5<br>62.3<br>62.8<br>44.6<br>43.6<br>85.5<br>91.5<br>94.1<br>41.6<br>69.5<br>74.9<br>76.0<br>98.0<br>90.5<br>63.0<br>64.9<br>42.8<br>45.1<br>87.0<br>90.7<br>94.5<br>43.5<br>69.9<br>73.4<br>**76.4**<br>**98.3**<br>**91.7**<br>**66.2**<br>**69.1**<br>**55.8**<br>**47.1**<br>**93.3**<br>**92.2**<br>**94.9**<br>**44.3**<br>**71.7**<br>**75.9**<br>+ 0.6 + 1.0 + 1.2 + 3.9<br>+ 6.3<br>+ 11.2 + 3.5<br>+ 7.8<br>+ 0.7 + 0.8 + 2.7 + 2.2 + 1.0|75.5<br>75.7<br>**78.8**<br>          + 3.3|71.8<br>72.3<br>**75.2**<br>+ 3.4|",
"|Module (ViT-B/16)|IN-1K Caltech Cars DTD ESAT FGVC FLO Food Pets SUN UCF|Avg (11)|\n|---|---|---|\n|Vanilla CLIP [58]<br>66.9 93.2 65.5 44.3 51.0 24.4 70.6 88.4 89.0 62.5 67.7<br>65.8|Vanilla CLIP [58]<br>66.9 93.2 65.5 44.3 51.0 24.4 70.6 88.4 89.0 62.5 67.7<br>65.8|Vanilla CLIP [58]<br>66.9 93.2 65.5 44.3 51.0 24.4 70.6 88.4 89.0 62.5 67.7<br>65.8|\n|**_Test-Time Prompt Tuning Methods_**|**_Test-Time Prompt Tuning Methods_**|**_Test-Time Prompt Tuning Methods_**|\n|TPT [65]<br>69.0 94.2 66.9 47.8 42.4 24.8 69.0 84.7 87.8 65.5 68.0<br>65.5<br>DiffTPT [16]<br>70.3 92.5 67.0 47.0 43.1 25.6 70.1 87.2 88.2 65.7 68.2<br>65.9<br>PromptAlign [63]<br>71.4 94.0 68.5 47.2 47.9 24.8 72.4 86.7 90.8 67.5 69.5<br>67.3<br>Self-TPT-v [88]<br>**73.0** 94.7 68.8 49.4 51.9 27.6 71.8 85.4 91.3 68.2 69.5<br>68.3|TPT [65]<br>69.0 94.2 66.9 47.8 42.4 24.8 69.0 84.7 87.8 65.5 68.0<br>65.5<br>DiffTPT [16]<br>70.3 92.5 67.0 47.0 43.1 25.6 70.1 87.2 88.2 65.7 68.2<br>65.9<br>PromptAlign [63]<br>71.4 94.0 68.5 47.2 47.9 24.8 72.4 86.7 90.8 67.5 69.5<br>67.3<br>Self-TPT-v [88]<br>**73.0** 94.7 68.8 49.4 51.9 27.6 71.8 85.4 91.3 68.2 69.5<br>68.3|TPT [65]<br>69.0 94.2 66.9 47.8 42.4 24.8 69.0 84.7 87.8 65.5 68.0<br>65.5<br>DiffTPT [16]<br>70.3 92.5 67.0 47.0 43.1 25.6 70.1 87.2 88.2 65.7 68.2<br>65.9<br>PromptAlign [63]<br>71.4 94.0 68.5 47.2 47.9 24.8 72.4 86.7 90.8 67.5 69.5<br>67.3<br>Self-TPT-v [88]<br>**73.0** 94.7 68.8 49.4 51.9 27.6 71.8 85.4 91.3 68.2 69.5<br>68.3|\n|**_Vector-based Prompt Tuning Methods_**|**_Vector-based Prompt Tuning Methods_**|**_Vector-based Prompt Tuning Methods_**|\n|UPT [77]<br>69.6 93.7 67.6 45.0 66.5 28.4 75.0 84.2 82.9 68.8 72.0<br>68.5<br>CoCoOp [82]<br>69.4 93.8 67.2 48.5 55.3 12.7 72.1 85.7 91.3 68.3 70.3<br>66.8<br>MaPLe [32]<br>69.6 92.6 66.6 52.1 71.8 26.7 83.3 80.5 89.1 64.8 71.8<br>69.9<br>ALIGN [72]<br>69.8 94.0 68.3 54.1 53.2 29.6 81.3 85.3 91.4 69.1 74.4<br>70.1<br>PromptSRC [33]<br>68.1 93.7 69.4 56.273.127.7 85.984.9 92.0 69.7 74.8<br>72.3|UPT [77]<br>69.6 93.7 67.6 45.0 66.5 28.4 75.0 84.2 82.9 68.8 72.0<br>68.5<br>CoCoOp [82]<br>69.4 93.8 67.2 48.5 55.3 12.7 72.1 85.7 91.3 68.3 70.3<br>66.8<br>MaPLe [32]<br>69.6 92.6 66.6 52.1 71.8 26.7 83.3 80.5 89.1 64.8 71.8<br>69.9<br>ALIGN [72]<br>69.8 94.0 68.3 54.1 53.2 29.6 81.3 85.3 91.4 69.1 74.4<br>70.1<br>PromptSRC [33]<br>68.1 93.7 69.4 56.273.127.7 85.984.9 92.0 69.7 74.8<br>72.3|UPT [77]<br>69.6 93.7 67.6 45.0 66.5 28.4 75.0 84.2 82.9 68.8 72.0<br>68.5<br>CoCoOp [82]<br>69.4 93.8 67.2 48.5 55.3 12.7 72.1 85.7 91.3 68.3 70.3<br>66.8<br>MaPLe [32]<br>69.6 92.6 66.6 52.1 71.8 26.7 83.3 80.5 89.1 64.8 71.8<br>69.9<br>ALIGN [72]<br>69.8 94.0 68.3 54.1 53.2 29.6 81.3 85.3 91.4 69.1 74.4<br>70.1<br>PromptSRC [33]<br>68.1 93.7 69.4 56.273.127.7 85.984.9 92.0 69.7 74.8<br>72.3|\n|**_Description-Based Methods_**|**_Description-Based Methods_**|**_Description-Based Methods_**|",
"|w/o adapters|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|CuPL [55]<br>AWT-text [87]|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.6 94.3 66.1 53.8 55.7 26.6 73.9 88.9 91.2 69.0 70.3<br>68.9 95.2 66.0 52.0 52.6 26.1 74.5 89.4 91.2 68.4 69.8|69.0<br>68.6|\n|**ProAPO** (ours)|69.9|95.2|67.7|55.8|65.3|28.3|82.7|89.5|92.7|68.9|73.1|71.7|\n|**ProAPO** w/ AWT-text|69.4|95.3|67.8|54.3|67.1|27.4|82.1|89.6|93.2|68.5|73.1|71.6|",
"|w/ adapters|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|AWT-Adapter [87]|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|72.195.1** 73.4** 59.4 **76.3 33.9** 85.6 85.9 92.9** 72.7 78.4**|75.1|\n|**ProAPO** w/ APE [86]|71.3|** 95.8**|70.9|**60.6**|72.4|33.2|**91.4**|** 89.9**|**  93.4**|71.0|77.6|**75.2**|",
"|Module (ViT-B/32)|IN-1K Caltech CUB DTD ESAT FLO SUN UCF|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Avg (8)|\n|---|---|---|---|---|---|---|---|---|---|\n|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|Vanilla CLIP<br>62.1<br>91.2<br>51.7<br>42.9<br>43.9<br>66.0<br>62.1<br>60.9<br>60.1|\n|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|**_Automatic Prompt Optimization Methods_**|\n|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|iCM [22] (w/ validation set)<br>64.5<br>92.7<br>**56.1**<br>51.4<br>56.3<br>72.2<br>66.2<br>67.0<br>65.8|\n|**ProAPO** (w/ 1-shot)|**64.7**|**94.4**|55.4|**53.5**|**63.0**|**74.3**|**66.6**|**69.0**|**67.6**|",
"|Module (ResNet50)|IN-1K Caltech Cars CUB DTD ESAT FGVC FLO Food Pets Places SUN UCF|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Avg (11)|Avg (13)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|Vanilla CLIP<br>57.9<br>84.5<br>53.9<br>44.7<br>38.8<br>28.6<br>15.9<br>60.2<br>74.0<br>83.2<br>38.2<br>58.0<br>56.9<br>55.6<br>53.4|\n|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|**_Template Optimization Methods_**|\n|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|PN [39]<br>59.6<br>89.1<br>56.2<br>-<br>44.8<br>49.0<br>18.1<br>67.2<br>78.3<br>88.1<br>-<br>61.0<br>60.2<br>61.1<br>-|\n|**ATO** (w/o dataset domain)|60.4|88.9|56.8|47.0|45.0|43.7|17.9|67.4|79.9|87.8|40.0|61.2|61.5|61.0|58.3|\n|**ATO**|61.3|89.4|57.4|49.2|45.4|46.4|18.4|68.1|80.5|88.5|40.2|61.8|63.9|61.9|59.3|\n|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|**_Description Optimization Methods_**|\n|**ProAPO** (w/o synonyms)|**61.5**|89.7|**58.3**|49.7|46.6|46.8|20.5|74.6|81.0|**88.8**|40.9|62.3|64.8|63.2|60.4|\n|**ProAPO** (ours)|**61.5**|**90.3**|58.0|**50.7**|**52.3**|**51.7**|**21.1**|**75.1**|**81.8**|88.7|**41.8**|**63.7**|**66.0**|**64.6**|**61.8**|",
"|Dataset|Add Del Rep Cross Mut|Total|\n|---|---|---|\n|IN-1K [10]<br>Caltech [15]<br>Cars [34]<br>CUB [71]<br>DTD [8]<br>ESAT [26]<br>FGVC [41]<br>FLO [48]<br>Food [3]<br>Pets [53]<br>Places [81]<br>SUN [74]<br>UCF [67]|3<br>4<br>5<br>5<br>2<br>5<br>5<br>6<br>12<br>3<br>7<br>8<br>5<br>8<br>3<br>9<br>4<br>10<br>6<br>2<br>5<br>3<br>8<br>8<br>2<br>2<br>4<br>6<br>8<br>1<br>6<br>2<br>6<br>5<br>3<br>5<br>3<br>11<br>5<br>4<br>5<br>3<br>4<br>5<br>2<br>4<br>2<br>5<br>6<br>2<br>3<br>2<br>8<br>12<br>4<br>4<br>2<br>3<br>5<br>2<br>5<br>6<br>8<br>6<br>2|19<br>31<br>31<br>31<br>26<br>21<br>22<br>28<br>19<br>19<br>29<br>16<br>27|\n|**Sum**|63<br>48<br>85<br>91<br>32|319|",
"|68<br>set<br>67<br>test<br>66 on<br>Accuracy<br>65<br>Avg (11)<br>64<br>Avg (13)<br>63<br>0 1 2 4 8 16 32 64 128|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|\n|---|---|---|---|---|---|---|---|---|---|---|\n|0<br>1<br>2<br>4<br>8<br>16<br>32<br>64<br>128<br>63<br>64<br>65<br>66<br>67<br>68<br>Accuracy on test set<br>Avg (11)<br>Avg (13)|||||||||||\n|0<br>1<br>2<br>4<br>8<br>16<br>32<br>64<br>128<br>63<br>64<br>65<br>66<br>67<br>68<br>Accuracy on test set<br>Avg (11)<br>Avg (13)|||||||||||\n|0<br>1<br>2<br>4<br>8<br>16<br>32<br>64<br>128<br>63<br>64<br>65<br>66<br>67<br>68<br>Accuracy on test set<br>Avg (11)<br>Avg (13)|||||||||||\n|0<br>1<br>2<br>4<br>8<br>16<br>32<br>64<br>128<br>63<br>64<br>65<br>66<br>67<br>68<br>Accuracy on test set<br>Avg (11)<br>Avg (13)|||||||||Avg (11)<br>Avg (13)|<br>|\n|0<br>1<br>2<br>4<br>8<br>16<br>32<br>64<br>128<br>63<br>64<br>65<br>66<br>67<br>68<br>Accuracy on test set<br>Avg (11)<br>Avg (13)|||||||||||",
"|61<br>Accuracy<br>60<br>ImageNet<br>59<br>ProAPO<br>w/o ProAPO<br>58<br>0 1 2 3 4 5|Col2|Col3|Col4|Col5|Col6|Col7|Col8|\n|---|---|---|---|---|---|---|---|\n|0<br>1<br>2<br>3<br>4<br>5<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO||||||||\n|0<br>1<br>2<br>3<br>4<br>5<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO||||||||\n|0<br>1<br>2<br>3<br>4<br>5<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO||||||||\n|0<br>1<br>2<br>3<br>4<br>5<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO|||||Pro<br>w/o|PO<br> ProAPO|PO<br> ProAPO|\n|0<br>1<br>2<br>3<br>4<br>5<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO||||||||\n|0<br>1<br>2<br>3<br>4<br>5<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO||||||||",
"|Module (ViT-B/32)|IN-1K Caltech Cars CUB DTD ESAT FGVC FLO Food Pets Places SUN UCF|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Avg (11)|Avg (13)|Times|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|CuPL|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4|64.9|62.3|-|\n|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|a) w/ all categories in one group<br>64.5<br>93.3<br>60.9<br>53.5<br>51.6<br>52.2<br>22.2<br>70.8<br>84.5<br>87.9<br>42.3<br>**66.7**<br>**69.4**<br>65.8<br>63.1<br>**20 min**<br>b) w/ random selected group<br>64.3<br>93.7<br>**61.8**<br>55.2<br>48.7<br>59.5<br>22.6<br>72.9<br>85.2<br>90.8<br>42.6<br>65.4<br>68.4<br>66.7<br>63.9<br>15 min<br>c) w/ performance best group<br>64.1<br>93.0<br>61.2<br>54.4<br>47.4<br>56.8<br>20.7<br>68.2<br>85.1<br>88.6<br>42.4<br>65.0<br>65.4<br>65.0<br>62.5<br>15 min<br>d) w/ K-Means algorithm<br>64.6<br>93.8<br>**61.8**<br>55.1<br>49.4<br>59.6<br>22.8<br>74.0<br>**85.3**<br>90.7<br>42.7<br>65.4<br>69.0<br>67.0<br>64.2<br>17 min|\n|**ProAPO** (full model)|**64.7**|**94.4**|61.7|**55.4**|**53.5**|**63.0**|**23.0**|**74.3**|**85.3**|**91.0**|**43.3**|66.6|69.0|**67.9**|**65.0**|15 min|",
"|Process|Build Library|Sample Strategy|Template Optim.|Description Optim.|\n|---|---|---|---|---|\n|**Times**|60 min|3 min|1.6 min|10.4 min|",
"|Œ±|0 1e1 1e2 5e2 1e3 5e3 1e4 1e5|\n|---|---|\n|**Avg (13)**<br>62.3<br>63.4<br>64.4<br>64.9<br>**65.0**<br>64.8<br>63.7<br>63.1|**Avg (13)**<br>62.3<br>63.4<br>64.4<br>64.9<br>**65.0**<br>64.8<br>63.7<br>63.1|",
"|61<br>Accuracy<br>60<br>ImageNet<br>59<br>ProAPO<br>w/o ProAPO<br>58<br>0 20 40 60 80 100|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|0<br>20<br>40<br>60<br>80<br>100<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO|||||||||\n|0<br>20<br>40<br>60<br>80<br>100<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO|||||||||\n|0<br>20<br>40<br>60<br>80<br>100<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO|||||||||\n|0<br>20<br>40<br>60<br>80<br>100<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO||||||ProA<br>w/o|PO<br> roAP||\n|0<br>20<br>40<br>60<br>80<br>100<br>58<br>59<br>60<br>61<br>ImageNet Accuracy<br>ProAPO<br>w/o ProAPO|||||||||",
"|Dataset Module TF Number of training samples UB<br>(RN50) 1 2 4 8 16|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|**Avg (11)**<br>CoOp [83]<br>‚úó<br>59.6 62.3<br>**66.8 69.9**<br>**73.4**<br>-<br>**ProAPO**<br>‚úì<br>**64.6 65.0**<br>65.4 65.8<br>66.1<br>67.2<br>|**Avg (11)**<br>CoOp [83]<br>‚úó<br>59.6 62.3<br>**66.8 69.9**<br>**73.4**<br>-<br>**ProAPO**<br>‚úì<br>**64.6 65.0**<br>65.4 65.8<br>66.1<br>67.2<br>|**Avg (11)**<br>CoOp [83]<br>‚úó<br>59.6 62.3<br>**66.8 69.9**<br>**73.4**<br>-<br>**ProAPO**<br>‚úì<br>**64.6 65.0**<br>65.4 65.8<br>66.1<br>67.2<br>|**Avg (11)**<br>CoOp [83]<br>‚úó<br>59.6 62.3<br>**66.8 69.9**<br>**73.4**<br>-<br>**ProAPO**<br>‚úì<br>**64.6 65.0**<br>65.4 65.8<br>66.1<br>67.2<br>|**Avg (11)**<br>CoOp [83]<br>‚úó<br>59.6 62.3<br>**66.8 69.9**<br>**73.4**<br>-<br>**ProAPO**<br>‚úì<br>**64.6 65.0**<br>65.4 65.8<br>66.1<br>67.2<br>|\n|**IN-1K**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|57.2 57.8 60.0<br>**61.6 63.0**<br>**61.5 61.6 61.5**<br>**61.6**<br>61.6|-<br>61.7|\n|**Caltech**<br>CoOp [83]<br>‚úó<br>87.5 87.9 89.6<br>90.2 91.8<br>-<br>**ProAPO**<br>‚úì<br>**90.3 90.4 90.6**<br>**90.7 91.0**<br>91.1|**Caltech**<br>CoOp [83]<br>‚úó<br>87.5 87.9 89.6<br>90.2 91.8<br>-<br>**ProAPO**<br>‚úì<br>**90.3 90.4 90.6**<br>**90.7 91.0**<br>91.1|**Caltech**<br>CoOp [83]<br>‚úó<br>87.5 87.9 89.6<br>90.2 91.8<br>-<br>**ProAPO**<br>‚úì<br>**90.3 90.4 90.6**<br>**90.7 91.0**<br>91.1|**Caltech**<br>CoOp [83]<br>‚úó<br>87.5 87.9 89.6<br>90.2 91.8<br>-<br>**ProAPO**<br>‚úì<br>**90.3 90.4 90.6**<br>**90.7 91.0**<br>91.1|**Caltech**<br>CoOp [83]<br>‚úó<br>87.5 87.9 89.6<br>90.2 91.8<br>-<br>**ProAPO**<br>‚úì<br>**90.3 90.4 90.6**<br>**90.7 91.0**<br>91.1|\n|**Cars**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|55.6 58.3<br>**62.6 68.4**<br>**73.4**<br>**58.0 58.5**<br>58.8 58.9<br>59.1|-<br>60.8|\n|**DTD**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|44.4 45.2<br>**53.5 60.0**<br>**63.6**<br>**52.3 52.7**<br>53.0 53.4<br>53.6|-|\n|**ESAT**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|50.6<br>**61.5 70.2**<br>**76.7**<br>**83.5**<br>**51.7**<br>53.5 55.6<br>57.4<br>58.3|-<br>62.2|\n|**FGVC**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|9.6<br>18.7<br>**21.9 26.1**<br>**31.3**<br>**21.1 21.0**<br>21.2 21.2<br>21.3|-<br>21.5|\n|**FLO**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|68.1<br>**77.5 86.2**<br>**91.2**<br>**94.5**<br>**75.1**<br>75.6 76.4<br>76.7<br>77.8|-<br>79.1|\n|**Food**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|74.3 72.5 73.3<br>71.8 74.7<br>**81.8 82.0 82.1**<br>**82.2 82.3**|-<br>82.9|\n|**Pets**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|85.9 82.6 86.7<br>85.3 87.0<br>**88.7 89.4 89.5**<br>**89.8 89.9**|-<br>91.0|\n|**SUN**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|60.3 59.5 63.5<br>**65.5 69.3**<br>**63.7 63.8 63.8**<br>63.8 63.9|-<br>64.5|\n|**UCF**|CoOp [83]<br>**ProAPO**|‚úó<br>‚úì|61.9 64.1 67.0<br>**71.9 75.7**<br>**66.0 66.8 67.1**<br>68.1 68.9|-<br>71.4|",
"|its|back|\n|---|---|",
"|a l|ight g|ray back and win|\n|---|---|---|",
"|white bi|rd with grey wing|\n|---|---|",
"|family, a|beautiful flower.|\n|---|---|",
"|white gloves in p|Col2|\n|---|---|\n|** ointed coloratio**|**  n, with**|",
"|oft, blended sha|des on|\n|---|---|",
"|series of|intersecting line|\n|---|---|\n|<br>**criss-cro**|<br>**criss-cro**|",
"|lines t|hat cross over ea|\n|---|---|",
"|of|lines|\n|---|---|\n|**other pa**|**other pa**|",
"|63.5<br>63.0<br>62.5 (11)<br>Tip w/ CuPL<br>62.0 Avg<br>Tip-X w/ CuPL<br>61.5 APE w/ CuPL<br>Tip w/ ProAPO<br>61.0 Tip-X w/ ProAPO<br>APE w/ ProAPO<br>60.5<br>1 2 4 8 16<br>Shots Number|92<br>91<br>(11)<br>90 Tip w/ CuPL<br>Tip-X w/ CuPL Avg<br>89 APE w/ CuPL<br>Tip w/ ProAPO<br>88 Tip-X w/ ProAPO<br>APE w/ ProAPO<br>87<br>1 2 4 8 16<br>Shots Number|70<br>68<br>66 (11)<br>64 Tip w/ CuPL Avg<br>Tip-X w/ CuPL<br>62 APE w/ CuPL<br>Tip w/ ProAPO<br>60<br>Tip-X w/ ProAPO<br>58 APE w/ ProAPO<br>1 2 4 8 16<br>Shots Number|Col4|Col5|Col6|Col7|Tip w/ CuPL<br>Tip-X w/ CuPL|Col9|\n|---|---|---|---|---|---|---|---|---|",
"|Col1|Tip<br>Tip-|\n|---|---|",
"|Col1|Col2|Col3|Col4|Tip w/ CuPL<br>Tip-X w/ CuPL|\n|---|---|---|---|---|",
"|APE w/ CuPL<br>Tip w/ ProAPO<br>50<br>Tip-X w/ ProAPO<br>APE w/ ProAPO<br>45<br>1 2 4 8 16<br>Shots Number|APE w/ CuPL<br>22 Tip w/ ProAPO<br>20 Tip-X w/ ProAPO<br>APE w/ ProAPO<br>18<br>1 2 4 8 16<br>Shots Number|60 APE w/ CuPL A<br>Tip w/ ProAPO<br>55 Tip-X w/ ProAPO<br>APE w/ ProAPO<br>50<br>1 2 4 8 16<br>Shots Number|\n|---|---|---|",
"|90.0<br>87.5<br>85.0 (11)<br>82.5 Tip w/ CuPL Avg<br>Tip-X w/ CuPL<br>80.0<br>APE w/ CuPL<br>77.5 Tip w/ ProAPO<br>Tip-X w/ ProAPO<br>75.0<br>APE w/ ProAPO<br>72.5<br>1 2 4 8 16<br>Shots Number|81<br>80 (11)<br>Tip w/ CuPL<br>79 Tip-X w/ CuPL Avg<br>APE w/ CuPL<br>78<br>Tip w/ ProAPO<br>77 Tip-X w/ ProAPO<br>APE w/ ProAPO<br>1 2 4 8 16<br>Shots Number|90<br>89<br>(11)<br>88 Tip w/ CuPL<br>Avg<br>Tip-X w/ CuPL<br>87 APE w/ CuPL<br>Tip w/ ProAPO<br>86 Tip-X w/ ProAPO<br>APE w/ ProAPO<br>85<br>1 2 4 8 16<br>Shots Number|Col4|Col5|Col6|Col7|Tip w/ CuPL<br>Tip-X w/ CuPL<br>APE w/ CuPL|Col9|\n|---|---|---|---|---|---|---|---|---|",
"|Col1|Tip<br>Tip-<br>APE|\n|---|---|",
"|Col1|Col2|Col3|Col4|Tip w/ CuPL<br>Tip-X w/ CuPL<br>APE w/ CuPL|\n|---|---|---|---|---|",
"|Col1|Col2|APE<br>Tip w<br>Tip-X<br>APE|\n|---|---|---|",
"|Col1|Col2|Col3|Col4|APE w/ CuPL<br>Tip w/ ProAPO<br>Tip-X w/ ProAPO<br>APE w/ ProAPO|\n|---|---|---|---|---|",
"|66<br>65<br>(11)<br>64 CLIP-A w/ CuPL<br>Avg<br>Tip-F w/ CuPL<br>63 APE-T w/ CuPL<br>CLIP-A w/ ProAPO<br>62 Tip-F w/ ProAPO<br>APE-T w/ ProAPO<br>61<br>1 2 4 8 16<br>Shots Number|93<br>92<br>(11)<br>91 CLIP-A w/ CuPL<br>Avg<br>Tip-F w/ CuPL<br>90 APE-T w/ CuPL<br>CLIP-A w/ ProAPO<br>Tip-F w/ ProAPO<br>89<br>APE-T w/ ProAPO<br>1 2 4 8 16<br>Shots Number|75.0<br>72.5<br>70.0 (11)<br>67.5 CLIP-A w/ CuPL<br>Avg<br>Tip-F w/ CuPL<br>65.0<br>APE-T w/ CuPL<br>62.5 CLIP-A w/ ProAPO<br>60.0 Tip-F w/ ProAPO<br>APE-T w/ ProAPO<br>57.5<br>1 2 4 8 16<br>Shots Number|Col4|CLIP<br>Tip-F<br>APE-|-A w/ CuPL<br>w/ CuPL<br>T w/ CuPL|\n|---|---|---|---|---|---|",
"|Col1|Col2|Col3|CLIP<br>Tip-F<br>APE-|-A w/ CuPL<br>w/ CuPL<br>T w/ CuPL|\n|---|---|---|---|---|",
"|Col1|Col2|CLIP-<br>Tip-F<br>APE-|\n|---|---|---|",
"|65<br>(11)<br>60<br>CLIP-A w/ CuPL<br>Avg<br>55 Tip-F w/ CuPL<br>APE-T w/ CuPL<br>50 CLIP-A w/ ProAPO<br>Tip-F w/ ProAPO<br>APE-T w/ ProAPO<br>45<br>1 2 4 8 16<br>Shots Number|35<br>(11)<br>30<br>CLIP-A w/ CuPL<br>Avg<br>Tip-F w/ CuPL<br>25 APE-T w/ CuPL<br>CLIP-A w/ ProAPO<br>20 Tip-F w/ ProAPO<br>APE-T w/ ProAPO<br>1 2 4 8 16<br>Shots Number|85<br>80<br>(11)<br>75<br>CLIP-A w/ CuPL<br>Avg<br>70 Tip-F w/ CuPL<br>APE-T w/ CuPL<br>65 CLIP-A w/ ProAPO<br>Tip-F w/ ProAPO<br>60 APE-T w/ ProAPO<br>1 2 4 8 16<br>Shots Number|Col4|Col5|CLIP-<br>Tip-F<br>APE-T|A w/ CuPL<br>w/ CuPL<br>w/ CuPL|\n|---|---|---|---|---|---|---|",
"|Col1|Col2|Col3|CLIP<br>Tip-F<br>APE-|-A w/ CuPL<br>w/ CuPL<br>T w/ CuPL|\n|---|---|---|---|---|",
"|Col1|Col2|CLIP-<br>Tip-F<br>APE-|\n|---|---|---|",
"|A<br>APE-T w/ CuPL<br>80<br>CLIP-A w/ ProAPO<br>Tip-F w/ ProAPO<br>75 APE-T w/ ProAPO<br>1 2 4 8 16<br>Shots Number|A<br>APE-T w/ CuPL<br>78<br>CLIP-A w/ ProAPO<br>77 Tip-F w/ ProAPO<br>APE-T w/ ProAPO<br>1 2 4 8 16<br>Shots Number|A<br>87 APE-T w/ CuPL<br>CLIP-A w/ ProAPO<br>86 Tip-F w/ ProAPO<br>APE-T w/ ProAPO<br>85<br>1 2 4 8 16<br>Shots Number|\n|---|---|---|",
"|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||CLIP<br>~~Tip-F~~<br>APE~~-~~|~~-~~A w/ CuPL<br>~~ w/ CuPL~~<br>T w/ CuPL|",
"|Col1|Col2|\n|---|---|\n||CLIP<br>~~Tip-F~~<br>APE|",
"|Module (ViT-B/32)|IN-1K Caltech Cars CUB DTD ESAT FGVC FLO Food Pets Places SUN UCF|Avg (11)|Avg (13)|\n|---|---|---|---|\n|Vanilla CLIP|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|61.8|59.3|\n|DCLIP [43]<br>+** ATO**<br>+** ProAPO**<br>‚àÜ|63.3<br>92.7<br>59.4<br>52.7<br>44.1<br>38.4<br>19.4<br>66.1<br>83.9<br>88.1<br>41.2<br>65.0<br>65.8<br>63.8<br>93.0<br>60.3<br>52.5<br>46.5<br>54.1<br>21.8<br>68.9<br>84.0<br>88.4<br>41.5<br>65.4<br>66.0<br>**64.1**<br>**93.2**<br>**60.6**<br>**53.6**<br>**48.2**<br>**59.4**<br>**22.6**<br>**71.5**<br>**84.2**<br>**88.7**<br>**42.7**<br>**66.0**<br>**68.0**<br>+ 0.8<br>+ 0.5<br>+ 1.2<br>+ 0.9<br>+ 4.1<br>+ 21.0<br>+ 3.2<br>+ 5.4<br>+ 0.3<br>+ 0.6<br>+ 1.5<br>+ 1.0<br>+ 2.2|62.4<br>64.7<br>**66.0**<br>+ 3.6|60.0<br>62.0<br>**63.3**<br>+ 3.3|\n|CuPL-base [55]<br>+** ATO**<br>+** ProAPO**<br>‚àÜ|64.0<br>92.3<br>60.1<br>54.3<br>47.2<br>42.4<br>21.7<br>68.7<br>84.3<br>88.8<br>42.0<br>**66.2**<br>66.7<br>64.2<br>93.3<br>60.9<br>54.8<br>47.8<br>53.1<br>22.2<br>70.4<br>84.9<br>89.2<br>42.3<br>65.5<br>67.4<br>**64.4**<br>**94.2**<br>**61.8**<br>**55.9**<br>**48.1**<br>**62.1**<br>**23.2**<br>**74.4**<br>**85.4**<br>**91.0**<br>**42.7**<br>65.6<br>**68.6**<br>+ 0.4<br>+ 1.9<br>+ 1.7<br>+ 1.6<br>+ 0.9<br>+ 19.7<br>+ 1.5<br>+ 5.7<br>+ 1.1<br>+ 2.2<br>+ 0.7<br>-0.6<br>+ 1.9|63.8<br>65.3<br>**67.2**<br>+ 3.4|61.4<br>62.8<br>**64.4**<br>+ 3.0|\n|CuPL-full [55]<br>+** ATO**<br>+** ProAPO**<br>‚àÜ|64.4<br>92.9<br>60.7<br>53.3<br>50.6<br>50.5<br>20.9<br>69.5<br>84.2<br>87.0<br>43.1<br>66.3<br>66.4<br>64.5<br>93.7<br>61.0<br>54.0<br>52.0<br>58.7<br>22.1<br>70.5<br>84.6<br>89.2<br>43.2<br>66.4<br>67.5<br>**64.7**<br>**94.4**<br>**61.7**<br>**55.4**<br>**53.5**<br>**63.0**<br>**23.0**<br>**74.3**<br>**85.3**<br>**91.0**<br>**43.3**<br>**66.6**<br>**69.0**<br>+ 0.3<br>+ 1.5<br>+ 1.0<br>+ 2.1<br>+ 2.9<br>+ 12.5<br>+ 2.1<br>+ 4.8<br>+ 1.1<br>+ 4.0<br>+ 0.2<br>+ 0.3<br>+ 2.6|64.9<br>66.4<br>**67.9**<br>+ 3.0|62.3<br>63.6<br>**65.0**<br>+ 2.7|\n|GPT4Vis [73]<br>+** ATO**<br>+** ProAPO**<br>‚àÜ|63.5<br>93.1<br>61.4<br>52.7<br>48.5<br>47.0<br>21.4<br>69.8<br>84.3<br>88.1<br>42.7<br>64.2<br>65.7<br>63.8<br>93.4<br>61.2<br>53.8<br>49.0<br>54.0<br>22.4<br>70.8<br>84.7<br>88.1<br>42.6<br>64.7<br>66.8<br>**64.4**<br>**93.7**<br>**61.8**<br>**55.4**<br>**49.3**<br>**62.6**<br>**23.9**<br>**73.8**<br>**85.4**<br>**90.7**<br>**42.8**<br>**65.5**<br>**68.2**<br>+ 0.9<br>+ 0.6<br>+ 0.4<br>+ 2.7<br>+ 0.8<br>+ 15.6<br>+ 2.5<br>+ 4.0<br>+ 1.1<br>+ 2.6<br>+ 0.1<br>+ 1.3<br>+ 2.5|64.3<br>65.3<br>**67.2**<br>+ 2.9|61.7<br>62.7<br>**64.4**<br>+ 2.7|\n|AdaptCLIP [62]<br>+** ATO**<br>+** ProAPO**<br>‚àÜ|63.3<br>92.7<br>59.7<br>53.6<br>47.4<br>51.3<br>20.8<br>67.2<br>84.2<br>87.6<br>41.9<br>66.1<br>66.5<br>63.9<br>93.2<br>60.4<br>54.2<br>47.9<br>55.5<br>**22.4**<br>69.1<br>84.7<br>88.8<br>42.3<br>66.3<br>67.6<br>**64.4**<br>**93.7**<br>**61.8**<br>**55.5**<br>**49.6**<br>**61.6**<br>23.3<br>**73.8**<br>**85.4**<br>**91.0**<br>**42.6**<br>**66.5**<br>**68.6**<br>+ 1.1<br>+ 1.0<br>+ 2.1<br>+ 1.9<br>+ 2.2<br>+ 10.3<br>+ 2.5<br>+ 6.6<br>+ 1.2<br>+ 3.4<br>+ 0.7<br>+ 0.4<br>+ 2.1|64.2<br>65.4<br>**67.2**<br>+ 3.0|61.7<br>62.8<br>**64.5**<br>+ 2.8|",
"|Add Del Rep Cross Mut|IN-1K Caltech Cars CUB DTD ESAT FGVC FLO Food Pets Places SUN UCF|Avg (11)|Avg (13)|\n|---|---|---|---|\n|Vanilla CLIP (ViT-B/32)|62.1<br>91.2<br>60.4<br>51.7<br>42.9<br>43.9<br>20.2<br>66.0<br>83.2<br>86.8<br>39.9<br>62.1<br>60.9|61.8|59.3|",
"|a) ‚úì<br>b) ‚úì ‚úì<br>c) ‚úì ‚úì<br>d) ‚úì ‚úì ‚úì|63.8 93.6 60.0 54.6 51.8 59.0 21.8 74.0 82.2 86.7 43.0 65.7 66.8<br>64.6 94.0 60.9 55.0 52.6 59.3 21.8 72.0 83.2 88.0 43.2 66.4 68.0<br>64.4 94.0 61.0 55.2 52.3 59.7 22.4 71.9 84.0 87.7 43.2 66.4 67.8<br>64.6 93.6 60.8 54.4 53.1 60.1 22.2 74.7 82.4 87.2 43.4 66.5 68.6|66.0<br>66.4<br>66.5<br>66.7|63.3<br>63.8<br>63.8<br>64.0|\n|---|---|---|---|",
"|evolution-based generation ‚úì ‚úì ‚úì ‚úì|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|Col18|Col19|Col20|Col21|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|e)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br>f)<br>‚úì<br>‚úì<br>‚úì<br>‚úì<br><br><br><br><br>|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|64.6<br>94.3<br>61.2<br>55.0<br>53.2<br>62.6<br>22.9<br>73.9<br>84.3<br>88.0<br>43.1<br>**66.8**<br>68.5<br>**64.7**<br>94.3<br>61.4<br>55.1<br>52.9<br>61.4<br>22.6<br>74.0<br>83.6<br>87.7<br>**43.4**<br>66.7<br>68.3|67.3<br>67.1|64.5<br>64.3|\n|g)|‚úì|‚úì|‚úì|‚úì|‚úì|**64.7**|**94.4**|**61.7**|**55.4**|**53.5**|**63.0**|**23.0**|74.3|**85.3**|**91.0**|43.3|66.6|**69.0**|**67.9**|**65.0**|",
"|Module (ViT-B/32)|IN-1K Caltech Cars CUB DTD ESAT FGVC FLO Food Pets Places SUN UCF|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Avg (11)|Avg (13)|Times|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|a) w/o prompt sampling<br>64.4<br>93.8<br>**61.8**<br>55.4<br>51.8<br>60.0<br>23.2<br>74.0<br>85.1<br>90.7<br>43.0<br>66.0<br>69.3<br>67.3<br>64.5<br>12 min<br>b) w/o group sampling<br>**64.8**<br>**94.5**<br>61.7<br>**55.5**<br>**53.6**<br>**63.5**<br>23.2<br>75.3<br>**85.4**<br>90.8<br>**43.3**<br>**66.7**<br>**69.8**<br>**68.1**<br>**65.2**<br>**306 min**<br>c) w/o sampling strategies<br>64.5<br>93.4<br>57.4<br>54.8<br>**53.6**<br>63.2<br>**23.4**<br>**76.8**<br>83.8<br>86.9<br>**43.3**<br>66.1<br>69.7<br>67.2<br>64.4<br>302 min|\n|**ProAPO** (full model)|64.7|94.4|61.7|55.4|53.5|63.0|23.0|74.3|85.3|**91.0**|**43.3**|66.6|69.0|67.9|65.0|15 min|",
"|Module (ViT-B/32)|IN-1K Caltech Cars CUB DTD ESAT FGVC FLO Food Pets Places SUN UCF|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Avg (11)|Avg (13)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|a) w/ only accuracy<br>64.0<br>93.0<br>60.8<br>54.2<br>49.1<br>55.5<br>20.4<br>68.3<br>84.8<br>88.4<br>41.9<br>64.6<br>65.1<br>64.9<br>62.3<br>b) w/ only entropy constrain<br>64.3<br>93.4<br>61.6<br>54.8<br>49.3<br>56.7<br>22.3<br>69.9<br>85.2<br>89.1<br>42.4<br>65.1<br>66.7<br>65.8<br>63.1|\n|**ProAPO** (full model)|**64.7**|**94.4**|**61.7**|**55.4**|**53.5**|**63.0**|**23.0**|**74.3**|**85.3**|**91.0**|**43.3**|**66.6**|**69.0**|**67.9**|**65.0**|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2502.19844v3.pdf"
}