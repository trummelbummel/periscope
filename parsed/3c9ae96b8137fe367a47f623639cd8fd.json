{
"text": "1\n        Instructional Prompt Optimization for Few-Shot LLM-Based\n               Recommendations on Cold-Start Users\n\n            Haowei Yang*                                  Yushang Zhao\n       Cullen College of Engineering                    McKelvey School of Engineering                                   Sitao Min\n    University of Houston, Houston, USA                  Washington University in St. Louis                         Independent Researcher\n          *Corresponding author:                                          St. Louis, USA                                    Newark, USA\n         yang38@cougarnet.uh.edu                           yushangzhao@wustl.edu                             mstzjdx@163.com,\n\n              Bo Su                                      Chao Yao                                    Wei Xu\nLuddy School of Informatics, Computing, and                  Ira A.Fulton Schools of Engineering                         Independent Researcher\n                Engineering                                  Arizona State University                              Los Altos,USA\n       Indiana University Bloomington                            Tempe, USA                               williamxw09@gmail.com\n            Bloomington, USA                             benyao2134@gmail.com\n         subo47403@gmail.com\nAbstract— The cold-start user issue further compromises the     language, reducing the need for retraining and  initial user\neffectiveness of recommender systems in limiting access to      histories.\nthe  historical  behavioral  information.  It  is  an  effective     Let ��denote a pre-trained LLM parameterized by weights θ.\npipeline to optimize instructional prompts on a few-shot large     For a cold-start user u, the recommendation task is defined as:\nlanguage model (LLM) used  in recommender  tasks. We                   ��_�= ��(�(�, ��))\nintroduce a context-conditioned prompt formulation method    Where:P   (u,  Ds)   is  the  optimized  prompt  composed\n�(�, ��) →��, where �is a cold-start user profile, ��is a      of:Instructional header I,\ncurated support set, and ��is the predicted ranked list of items.     Support set ��= {(��, ��)}_{�= 1}^{�} with exemplar users\nBased on systematic experimentation with transformer-based      ui and item rankings ri,User meta-data φ(u).\nautoregressive LLMs  (BioGPT, LLaMA-2,  GPT-4), we    The  model  performs  inference  by  transforming  token\nprovide empirical evidence that optimal exemplar injection    embeddings �(�) ∈ℝ^{�× �} into autoregressive outputs\nand  instruction  structuring can  significantly improve  the     through multi-head attention:\nprecision@k and NDCG scores of such models in low-data          ���������(�, �, �) = �������(��ᵀ/ √�_�) �\nsettings.  The  pipeline  uses  token-level  alignments  and    Where �= ��^�, �= ��^�, ����= ��^�    are\nembedding  space  regularization  with  a  greater  semantic     query, key, and value projections derived from the prompt\nfidelity. Our findings not only show that timely composition is     encoding.\nnot merely syntactic but also functional as  it  is in direct   We hypothesize that, by further engineering P to be more\ncontrol  of  attention  scales and decoder conduct  through      instructionally  rich and  structurally  aligned  with domain\ninference. This paper shows  that prompt-based adaptation     semantics, it will then be possible to guide the decoder of an\nmay be considered one of the ways to address cold-start   LLM  into a high-precision recommendation regime, even\nrecommendation issues in LLM-based pipelines.                  without the presence of H(u)[4]. To justify this, we present a\nKeywords:   Cold-Start   Recommendation,   Instructional    Prompt  Optimization  Module  (POM). We  maintain  a\nPrompting, Few-Shot Learning                              framework that enables modular prompt injection and that\n                           I. INTRODUCTION                       measures performance by increasing the prompt lengths  l\nRecommender systems face a fundamental challenge when    ∈[256, 2048]  and exemplar  densities �∈[2, 10] . We\nengaging  cold-start  users—users  for whom  there  exists     apply  this  system  to  Amazon  Reviews,  Last.fm,  and\ninsufficient   interaction   history  �(�) = ∅.     Classical    MovieLens (1M), in comparison to zero-shot, collaborative\ncollaborative filtering and matrix factorization methods are      filtering, and hybrid neural baselines (Soylu et  al., 2024).\nruined by such sparsity[1]. We encourage a paradigm shift:     Findings  indicate  that our model always becomes  better:\nthe optimization of  instructional prompts  in  the few-shot     Precision@5 by up to +18.7%,NDCG@10 by +21.3%.\nLarge Language Models (LLM) has taken place, with the     Semantic coherence (via cosine similarity in embedding space)\ncorresponding advice induction process being performed via    by +12.5%. The present paper declares that this beneficial\nthe  semantic  generalization  instead  of  the   historico-     feature of LLMs,  their  potential  to process and generate\nwidebounИ round of the wisdom of the ages[2].                   language, with the ability to cold-start user personalization\nThe cold-start problem in recommender systems has been     (without  fine-tuning),  presents an extremely  scalable and\naddressed through content-based, collaborative filtering with     enticing solution to next-generation recommendation systems\nside information, and hybrid methods, though each faces     through  their  latent reasoning  capacities, which have  the\nlimitations such  as  overspecialization,  feature engineering      potential to be directly scaffolded via instruction prompting[5].\ncosts,  and  computational  overhead[3].  Deep   learning                             II. RELATED WORK\napproaches   like  VAEs  and  GNNs  improve  low-data    The cold-start user problem has been a curse to conventional\nrepresentation learning but still rely on large prior datasets.    recommender  systems,   especially  those   that  use   the\nRecently,  large  language  models (LLMs)  offer  a new     collaborative  filtering method and matrix  factorization[6].\nparadigm  by  conditioning  recommendations  on  natural     According to these paradigms, the lack of  historical data\n\n2\nconcerning  user  interaction  (�(�) = 2 )     is  a  great     3.1 Problem Formulation\ncompromise in the personalization of recommendations. The     In the case of a cold-start user u, the objective is to create a\nfirst  attempt  at  addressing  this problem was  via  hybrid     ranked  list of items ��  with a prompt �(�, ��), where:\nrecommendation models, which contain content-based feature   ��= {(�_�, �_�)}_{�= 1}^�   is a set of support exemplar\nmetadata and  collaborative  signals[7].  Nevertheless,  these     users and assigned rankings, or Ds, and the user metadata\nmethods can precondition a high need for feature engineering     �, �(�, ��) = �∪��∪�(�) and where the joint prompt\nand are likely to experience overfitting related to the domain.        is P (u, Ds) = I 0 Ds 0 0 (u ). This is given as input to a frozen\nThe new  developments  in  deep  learning  have  led  to   LLM Mθ, which gives: ��_�= ��(�(�, ��)).\ninvestigations  related  to neural  collaborative  filtering and     3.2 Prompt Optimization Strategy\nvariational autoencoders that propose to address sparsity and     Prompts  are  optimized  as  follows:  Instructional  Header\nlearn latent representations of users and items[8]. Although     Design: Task-specific natural language instructions. Exemplar\nthese  advances  represent an  improvement,  the  cold-start      Injection: Those support  sets of examples were  carefully\nsetting is particularly difficult in the model because it requires     curated and added  in  the form of a  few-shot. Metadata\neither   pre-existing   user   profiles   or   expensive   side     Conditioning: Age,  interests,  or  domain-specific  tags  are\ninformation[9].                                                being added to provide context to the model.\nThe recent rise of Large Language Models (LLMs), which     3.3 Embedding and Attention Dynamics\ninclude  GPT-3, LLaMA-2,  and  BioGPT,  suggests new    The encoder insertion is placed E(P) in ℝ^ {n x d}, and the\nfamilies of how recommender systems might work, where any    model carries out autoregressive comparison by multi-head\nlevel of contextualized reasoning can be achieved through                                                                        attention: (Q, K, V) = softmax(QKᵀ/ √d_k with Q, K, and V\nnatural language prompts. Such models have demonstrated                                                            based on E ( P ). Prompt length and exemplar density, l and k,\nimpressive results in zero-shot and few-shot settings, which                                                                   are altered to determine performance effect.\npushed researchers to conduct experiments on prompt-based                                                                 3.4 Summary\nrecommendation schemes[10]. Semantically-aligned LLMs:                                                                      In order to guarantee reproducibility and transparency,\nInstruction-tuned LLMs  have  the  potential  of  capturing                                                                   the experimental setup was made in a way that factors the\nsemantic alignment between the metadata of items and the                                                                      specifics of  datasets, preprocessing, and assessment were\ndescription of a user, without having to use explicit histories                                                               considered  explicitly[16]. The Amazon Reviews  data  setof interactions[11].                                                               included about 3 million of the products reviews on variousInstructional  prompting  has  captured  interest  as  a  low-                                                                      categories, where text fields were pre-processed by getting ridresource  substitute  to  fine-tuning,  especially  in  few-shot                                                                 of HTML tags and other special symbols prior to generating\nscenarios. In-context learning, or prompt engineering methods,                                                                   the embedding. Last.fm included the approximate 360,000\nhave been used in areas of classification, summarization, and                                                                 user artist interactions and was centered on music preferences\nquestion answering, and only more recently in recommender                                                                 data augmented with genre metadata whereas MovieLens 1Msystems. Recent experiments in prompt design revealed that                                                               included over one million ratings with categorical features. Insyntactic changes in prompt structure may substantially affect                                                                                  all  datasets,  cold-start  splits  were  formed  retaining  nothe model performance, suggesting that prompt optimization                                                                      interaction history of test users, so no overlap was present\ncan be used as a means of control over the behavior of LLMs                                                         between training and evaluation identities[17]. The metadata\n[12].                                                             about users, such as demographic properties and tags related\nSimultaneously, other works in the few-shot recommendation                                                                      to a  particular domain,  as well  as  their  interest  clustersdomain assume training strategies where a support  set of                                                               obtained through inference, was encoded in a natural languageexemplar users can be used to adjust to new users or objects.                                                              format so that the LLMs could consume it directly.Such methods tend  to involve gradient updates or meta-                                                          Three complementary measures were used to do evaluation.\nlearning optimization, and prompt-based approaches suggest                                                     The  selection of Precision@5 was meant  to measure the\nthe use of non-parametric, inference-time adaptation [13].                                                               percentage of the best recommendations that are identical to\nThe  research  of  this  paper  can  be  understood  as  the                                                                   the ground truth that represents instant performance of thedevelopment  of  the above  lines  of  research due  to  the                                                           recommendation. The quality of ranking was measured usingimmediate and tangible result in directly leading the LLM                                                                   the   metric   of  NDCG@10   (Normalized   Discountedwithout  providing any  instructional prompts  in  cold-start                                                          Cumulative Gain), which rewards well placed relevant items\nsettings[14]. Compared to the previous approaches, which                                                                            at high rank in the list. By estimating semantic coherence as\nretrain models  or add  external modules, we  are able  to                                                                cosine similarity between the predicted items and the target\nconsider the prompt as the main vehicle of adaptation and                                                               items  embedding  vectors,  this  provided  a  latent-spaceinterject  structural information, exemplar  logic, and  user-                                                                 evaluation of thematic or contextual coherence. This third\nspecific data into the textual template[15].                                                         measure was also relevant when considering the cold-start\n                      III. METHODOLOGY                                                                 scenario as lexical similarity might not be sufficient to obtain\nWe will put forward a new Prompt Optimization Module                                                             semantic alignment [18].\n(POM) with which the large language models (LLMs) can                                      A sample of optimized instructional prompt is indicated below\ndeliver accurate suggestions to meet the cold-start users via                                                         and illustrates how instructional headers, exemplar profiles,instructional prompting.                                                         and target user metadata can be deployed:\n\n3\n   Instructional Header: “Given the following examples of\n    users and their ranked preferences, recommend the top                 Table 2: Baseline vs. Proposed Model Performance (Cold-Start Setting)                                                                                                         Dataset              Best Baseline (P@5 /         Proposed          Gain (%)\n     five items  for the target user, considering contextual                             NDCG)             (P@5 /\n     similarity and thematic relevance.                                                                     NDCG)                                                                          Amazon Reviews         43.6 / 48.3                    51.8 / 58.6       +18.7 / +21.3\n   Exemplar Section: “User A: 1) Kindle Paperwhite, 2)       Last.fm                  42.1 / 49.0                    47.5 / 55.0       +12.8 / +12.2\n   Echo Dot, 3) Fire TV Stick, 4) Audible Subscription, 5)      MovieLens 1M           41.9 / 47.1                    47.9 / 53.7       +14.2 / +14.0\n   Amazon Basics Tripod.”\n   Target User Metadata: “User Z: Age 29, interested in\n     digital reading devices, home automation, and streaming\n    accessories.”\n   This formulation has the  effect of  retaining semantics\nstructure at the same time as imposing attention over the\nmodel  to  constrain domain  relevant  exemplars[19]. The\nexemplar frequency and prompt length were parameterically\naltered to find optimum combinations and exemplar number\nof 6 to 8 produced the best tradeoff between information and\ncomputational cost.\n          IV. EXPERIMENTS AND EVALUATION\nIn order to justify ourselves, we tried the experiments with                            Figure 1. Performance Metrics across Datasets                                                                    V. RESULTS AND DISCUSSIONthree  datasets,  such  as Amazon  Reviews,  Last.fm,  and                                                     The empirical findings support the main argument of thisMovieLens 1M, which represent various types of scale. We                                                                  paper, which states that instructional-prompt optimization canalso deployed pure cold-start assumptions whereby all the test                                                          be an effective and feasible solution to the cold-start userusers had no prior interaction data within the training set.                                                                    issue  of  the LLM-based recommender  systems[22]. WeThree fine-tuning-free LLMs--BioGPT, LLaMA-2 (7B), and                                                        assume that the transformer models possess latent reasoningGPT-4--were  tested. We  based  our prompt  optimization                                                                          capabilities, but we do not change the parameters of thepipeline on applying structured prompts to the models to                                                           system to achieve the goal. We do that by transforming theintroduce recommendations. In the prompts, there was an                                                         recommendation task  into a few-shot language generationinstructional header, a support set of 2 to 10 similar user                                                              problem[23]. Not only does this lower computational expenseprofiles with item rankings, and  cold-start user metadata.                                                                    against conventional fine-tuning methods, but importantly, itPerformance was measured by Precision@5, NDCG@10, and                                                                                  is also scalable across domains and requires little by way ofsemantic coherence (cosine similarity in the embeddings of                                                                        infrastructure.the  predicted items and  ground-truth). To be  consistent,                                             Among the most interesting ones is the functional effect ofresults were averaged across five runs with non-deterministic                                                         prompt structure. The structure of the prompt to a great extentseeds [20].                                                              determines the behavior associated with that model, not onlyWe performed  better than any  baseline. On Amazon,  it                                                                      in content, but also in terms of narrative and instructionalincreased Precision@5 by 18.7% and NDCG@10 by 21.3%                                                                          specificity. The production  of  instructional  headers, hardcompared to zero-shot LLM. Prompt richness increased the                                                                        setting the objective of the ranking of the users and the itemssemantic coherence of Last.fm by 12.5 percent, and context-                                                                 of the use, seems to stabilize the levels of attention moresensitive music recommendations also improved significantly.                                                                           efficiently, making  the  relevancy and  output  consistencyIn MovieLens, with the reduced variability in metadata, our                                                                           better. This implies that the prompt is cognitive interactivepings gave us an up to 14.2 percent higher Precision@5. The                                                                      rather than  lexical  input, wherein  the immediate decoderperformance was influenced by the length of the prompt and                                                          pathways are implicitly altered in terms of the affinity towardsthe number of exemplars. Returns were shown to be positive                                                                      attention flow [24].on lengths of up  to 1024 tokens, but afterwards, returns                                                                 In addition, the exemplar density result simply underlines howbecame smaller. Working with 6 8 exemplars was the best                                            LLMs are advantaged by being exposed to similar patternssuggestion. Instructional headers turned out to be important                                                                      prior  to  the new  generation. The  sets  of  supports withtoo,  as  eliminating  them  decreased model  performance,                                                                 semantically consistent user profiles offer inductive priors thatparticularly in less instruction-tuned ones such as BioGPT                                                                  drive the model rationale, even where data of target users does[21].                                                                not  exist[25].  This  resembles  human  learning  patterns,These findings in general indicate that instructional prompt                                                       whereby exposure to familiar cases enhances decision makingengineering can indeed improve the effectiveness of LLM                                                                      in a new context. Nonetheless, too much of this advantage canrecommendations during  the  cold-start problem  scenario--                                                          be  detrimental:  dense  prompts  are  excessively  capacity-without  requiring any model  retraining--therefore,  it  is a                                                           consuming, and they can distort the signal with noise. Ourmodel-independent and scalable solution.              Table 1: Best Model Performance on Cold-Start Recommendation             finding that gains wash out with many exemplars agrees with\n  Dataset             Best Model    Precision@5  NDCG@10    Semantic Coherence       previous findings conducted on contextual learning, pointing\n  Amazon         Reviews   GPT-4                               51.8%                                            58.6%                                                         75.4%\n  Last.fm                  GPT-4                               47.5%                                            55.0%                                                         71.8%                 to an efficient domain of a few-shot conditioning[26].\n  MovieLens 1M     GPT-4       47.9%        53.7%       72.1%                        Table 3. Relative Improvements of Proposed Model over Baseline (Cold-Start Setting)\n\n4\n Dataset      Baseline      Baseline     Proposed    Proposed     Precision   NDCG@     models towards a recommendation task. It brings a paradigm\n              Precision               NDCG@                                          Precision                               NDCG@                                         @5                                                               Gain     10                                                                           Gain      transition of a parameter-based adaptation to interaction-based          @5                          10                          @5                                                 10                                                            (%)                                                                        (%)\nAmazon     43.6          48.3         51.8          58.6         18.8          21.3         conditioning, taking advantage of the flexible nature of a\nReviews\nLast.fm     42.1          49.0         47.5          55.0         12.8          12.2         natural language to perform personalization without retraining.\nMovieLe    41.9          47.1         47.9          53.7         14.3          14.0\nns 1M\n\nThe differences in performance between domains also provide\nuseful information.  Instructional prompting works well  in\ncontent-rich areas such as e-commerce and music, where the\npreferences of the user can be predicted based on a relatively\nsmall amount of metadata (e.g., age, interest tags, category of\nitems). However, in contrast, areas that are built on more\nfundamental  behavioral  cues,  such  as  long-form  content\nconsumption or multi-modal preferences, may need layers of                 Figure 3. Relative Gains in Precision@5 and NDCG@10 across datasets\nadaptation  or  hybrid   services.  Nevertheless,   in  such              VI. CONCLUSION AND FUTURE WORK\nproblematic fields, it can be seen that prompt engineering is    As shown in the present study, optimization of instructional\nuseful and brings a quantifiable advantage, clearing the way to     prompts, when made in few-shot large language models, is a\nmulti-modal prompt extensions, which will have embeddings    way  to  effectively  mitigate  the  cold-start-user  challenge\nlearned in the modality rooms involved: vision, audio, or     without  further  expenditure  of  expensive  fine-tuning  or\ngraphs[27].                                                            retraining. Our way of structuring the prompts, to integrate an\nNotably,  the  semantic  coherence  metric  offers  a new      instructional header, a collection of exemplar profiles, and\nperspective to measure the quality of a recommendation. As     user-specific metadata, demonstrated steady improvement in\nopposed to precision or NDCG, which look at the position of     Precision@5, NDCG@10, and semantic coherence  across\nan item, semantic coherence examines the latent coverage     multiple domains. These findings confirm that prompt-based\nbetween the projected and ideal output in both embedding     adaptation provides not only an accurate but also a scalable\nspaces. The fact that our method scores well on this metric    and   model-agnostic  method   of   personalization   with\nimplies that the model is not only capable of retrieving things    recommendation systems.\nof relevance to the user but also understands its thematic or    The applications of such work can be appreciated in various\nsituational grammar. Such  ability  is especially wanted  in     applied fields in which user interaction data may be limited or\nsettings of  cold-start, where no behavioral information  is     even nonexistent at the time of system onboarding. In online\navailable, and models have to depend on abstraction and      stores, streamlined suggestions based on customer actions\nanalogy[28].                                            would provide appropriate product recommendations as soon\n                                                                 as a user creates an account, so that early-life interactions and\n                                                              conversion outcomes would be increased. The approach can\n                                                          be applicable in music streaming services, whereby streams\n                                                           can be  easily customized with minimal demographics or\n                                                                 expressive preferences to create personal playlists for new\n                                                                              static users without the risk of churned users in a trial period.\n                                                     The same way, there may be dynamic prompting of the right\n                                                               course  materials,  exercises,  or  multimedia  informational\n                                                                 resources in an educational technology system, such as an\n                                                                adaptive learning system, according to learner profiles before\n                   Figure 2. Exemplar Density vs. Model Performance                    the development of adequate performance histories. Since the\nNonetheless, some constraints should be accounted for. First,                                                              suggested  approach  does  not   require  domain-specific\nprompt optimization is flexible, but it is not resistant to minor                                                                         retraining,  it has real-world benefits with respect to cross-\nchanges in words, sequence, and structure. One requirement,                                                       domain  deployments,  quick  training  in  new  markets,\nprompt instability, has been a documented restriction in the                                                          deployment on  low-resource  computation  platforms,  and\napplication of LLMs, potentially impacting stability between                                                          deployment in resource-constrained computing environments.\ninference runs[29]. Second, the selection of examples is based                        Future Work\non embedding similarity these days, so  it does not always                                                     The  current  research  findings  present  several  interesting\nmodel latent preference clusters. In the future,  it might be                                                           avenues  for  future  research. On  one  hand,  multimodal\ninteresting  to  consider  reinforcement  learning  or  active                                                          prompts  that would  allow  users  to  receive both  written\nsampling to improve the construction of the support set on-                                                                      instructions and visual or auditory setting might play a crucial\nthe-fly[30].                                                                      role in personalization in the sphere of fashion, video-on-\nWe have shown  that with a well-optimized  formulation,                                                        demand, and music recommendation. Second, more effective\ninstructional  prompting  may  become  an  effective  but                                                         prompt  adaptability  can  be  achieved by  selecting more\nlightweight tool that can be used to guide large language                                                        dynamic  examples  through  reinforcement  learning  or\n\n5\nretrieval-augmented generation that can process the changing           through    Human-Machine    Co-Adaptation.    arXiv     preprint\nuser signals online. Third, the framework could be extended           arXiv:2501.15167.\nto multilingual and low-resource languages, at which point it      [16] Huang, Sining, et al. \"Ar overlay: Training image pose estimation on                                                                                curved surface in a synthetic way.\" arXiv preprint arXiv:2409.14577\nwould be more global and applicable in areas where there is a            (2024).\nlack of recommendation data. Lastly, similar to cold-start, the      [17] Kang, Yixiao, Yukun Song, and Sining Huang. \"Tie memories to e-\npersonalization models could be constantly enhanced due to            souvenirs: Personalized souvenirs with augmented reality for interactive\nongoing optimization of prompt  structures as a  result of            learning in the museum.\" Preprints, October (2024).\nadding longitudinal feedback loops to the system. Instead of      [18] Jiang,  Haowei,  et   al.  \"Recurrent  neural  network  from  adder’s                                                                                          perspective: Carry-lookahead RNN.\" Neural Networks 144 (2021): 297-\nbeing just a peripheral instructional prompting strategy, the           306.\nlatter instructions would enable the development of a wider      [19] Cao, Jin, et al. \"Rough set improved therapy-based metaverse assisting\ntheoretical basis of the instructional prompting and make it a           system.\" 2024 IEEE International Conference on Metaverse Computing,\nprime instructional strategy in next-generation recommender           Networking, and Applications (MetaCom). IEEE, 2024.\nsystems.                                                                       [20] Xiang, A., Zhang,  J., Yang, Q., Wang,  L., & Cheng, Y. (2024).\n                                                                               Research on splicing image detection algorithms based on natural image\n                  REFERENCES                                                  statistical characteristics. arXiv preprint arXiv:2404.16296.\n                                                                                 [21] Wang,  Jingru, Wen Ding, and Xiaotong Zhu. \"Financial  analysis:[1]  Li Y, Yao Y, Lin J, et al. A Deep Learning Algorithm Based on CNN-                                                                                                 Intelligent financial data analysis system based on llm-rag.\" arXiv   LSTM Framework for Predicting Cancer Drug Sales Volume[J]. arXiv                                                                                           preprint arXiv:2504.06279 (2025).      preprint arXiv:2506.21927, 2025.\n                                                                                 [22] Yang H, Fu L, Lu Q, et al. Research on the Design of a Short Video[2]  Research  on  Low-Latency  Inference  and  Training  Efficiency                                                                        Recommendation  System  Based  on  Multimodal  Information  and     Optimization for Graph Neural Network and Large Language Model-                                                                                             Differential Privacy[J]. arXiv preprint arXiv:2504.08751, 2025.     Based Recommendation Systems\n                                                                                 [23] Lin X, Cheng Z, Yun L, et al. Enhanced Recommendation Combining[3]  Yang, Haowei,  et  al. \"Research on Model  Parallelism and Data                                                                                       Collaborative Filtering and Large Language Models[J]. arXiv preprint     Parallelism Optimization Methods in Large Language Model-Based                                                                                  arXiv:2412.18713, 2024.    Recommendation Systems.\" arXiv preprint arXiv:2506.17551 (2025).\n                                                                                 [24] Niu, Tianyue, et al. \"Decoding student cognitive abilities: a comparative[4]  Zheng Z, Liu K, Zhu X. Machine Learning-Based Prediction of Metal-                                                                                   study  of  explainable AI  algorithms  in  educational  data  mining.\"     Organic Framework Materials: A Comparative Analysis of Multiple                                                                                              Scientific Reports 15.1 (2025): 26862.     Models[J]. arXiv preprint arXiv:2507.04493, 2025.\n                                                                                 [25] Zhao, Yushang, et al. \"Meta-Learning for Cold-Start Personalization in[5]  Yuan T, Zhang X, Chen X. Machine Learning based  Enterprise                                                                           Prompt-Tuned LLMs.\" arXiv preprint arXiv:2507.16672 (2025).Yang,     Financial Audit Framework and High Risk  Identification[J]. arXiv                                                                            Haowei, et al. \"LLM-Augmented Symptom Analysis for Cardiovascular      preprint arXiv:2507.06266, 2025.                                                                                 Disease  Risk   Prediction:  A   Clinical  NLP.\"  arXiv   preprint\n[6]  Shao, Junli, et al. \"Deep Learning Model Acceleration and Optimization           arXiv:2507.11052 (2025).\n      Strategies for Real-Time Recommendation Systems.\" arXiv preprint                                                                                 [26] Yang, Zhongheng, et al. \"RLHF Fine-Tuning of LLMs for Alignment     arXiv:2506.11421 (2025).                                                                                 with Implicit User Feedback in Conversational Recommenders.\" arXiv\n[7]  Xiang, A., Qi, Z., Wang, H., Yang, Q., & Ma, D. (2024, August). A            preprint arXiv:2508.05289 (2025).\n     multimodal fusion network for student emotion recognition based on                                                                                 [27] Li J, Zhou Y. Bideeplab: An improved lightweight multi-scale feature     transformer and  tensor  product.  In 2024 IEEE 2nd  International                                                                                       fusion deeplab algorithm for facial recognition on mobile devices[J].     Conference  on  Sensors,  Electronics  and  Computer  Engineering                                                                         Computer Simulation in Application, 2025, 3(1): 57-65.    (ICSECE) (pp. 1-4). IEEE.\n                                                                                 [28] Chen, Y., Du, H., & Zhou, Y. (2025). Lightweight Network-Based[8]  Ding Y, Wu Y, Ding Z. An automatic patent literature retrieval system                                                                              Semantic Segmentation for UAVs and  Its RISC-V Implementation.     based on LLM-RAG[J]. arXiv preprint arXiv:2508.14064, 2025.                                                                                        Preprints.https://doi.org/10.20944/preprints202508.1108.v1\n[9]  Ning Z, Zeng H, Tian Z. Research on data-driven energy efficiency                                                                                 [29] Lyu, Haotian, et al. \"Self-Supervised User Embedding Alignment for     optimisation  algorithm  for  air  compressors[C]//Third  International                                                                          Cross-Domain  Recommendations   via  Multi-LLM   Co-Training.\"     Conference on Advanced  Materials and Equipment Manufacturing                                                                              Authorea Preprints (2025).   (AMEM 2024). SPIE, 2025, 13691: 1068-1075.\n                                                                                 [30] Shao, Junli, et al. \"Deep Learning Model Acceleration and Optimization[10] Ou,  Y.  \"Dynamic  Allocation  Mechanism  of  Cloud  Computing                                                                                            Strategies for Real-Time Recommendation Systems.\" arXiv preprint     Resources Driven by Neural Network.\" Frontiers in Computing and                                                                               arXiv:2506.11421 (2025).      Intelligent Systems (2023).\n[11] Wang  J, Zhang  Z, He  Y,  et  al.  Enhancing Code LLMs  with\n     Reinforcement  Learning  in  Code  Generation[J].  arXiv  preprint\n     arXiv:2412.20367, 2024.\n[12]  Wu, S., Fu, L., Chang, R., Wei, Y., Zhang, Y., Wang, Z., ... & Li, K.\n     (2025). Warehouse Robot Task Scheduling Based on Reinforcement\n     Learning to Maximize Operational Efficiency. Authorea Preprints.\n[13]  Li, K., Liu, L., Chen, J., Yu, D., Zhou, X., Li, M., ... & Li, Z. (2024,\n     November). Research on reinforcement learning based warehouse robot\n     navigation  algorithm  in complex warehouse  layout.  In 2024  6th\n      International  Conference  on  Artificial  Intelligence  and  Computer\n     Applications (ICAICA) (pp. 296-301). IEEE.\n[14] Yu, D., Liu, L., Wu, S., Li, K., Wang, C., Xie, J., ... & Ji, R. (2025,\n     March). Machine learning optimizes the  efficiency of picking and\n     packing  in  automated  warehouse  robot  systems.  In  2025 IEEE\n      International Conference on Electronics, Energy Systems and Power\n     Engineering (EESPE) (pp. 1325-1332). IEEE.\n[15]  He, Y., Wang, J., Li, K., Wang, Y., Sun, L., Yin, J., ... & Wang, X.\n     (2025).  Enhancing  Intent  Understanding  for Ambiguous  Prompts",
"headers": [
"Instructional Prompt Optimization for Few-Shot LLM-Based",
"Recommendations on Cold-Start Users"
],
"tables": [
"|Dataset|Best Baseline (P@5 /<br>NDCG)|Proposed<br>(P@5 /<br>NDCG)|Gain (%)|\n|---|---|---|---|\n|Amazon Reviews|43.6 / 48.3|51.8 / 58.6|+18.7 / +21.3|\n|Last.fm|42.1 / 49.0|47.5 / 55.0|+12.8 / +12.2|\n|MovieLens 1M|41.9 / 47.1|47.9 / 53.7|+14.2 / +14.0|",
"|Dataset|Best Model|Precision@5|NDCG@10|Semantic Coherence|\n|---|---|---|---|---|\n|Amazon Reviews|GPT-4|51.8%|58.6%|75.4%|\n|Last.fm|GPT-4|47.5%|55.0%|71.8%|\n|MovieLens 1M|GPT-4|47.9%|53.7%|72.1%|",
"|Dataset|Baseline<br>Precision<br>@5|Baseline<br>NDCG@<br>10|Proposed<br>Precision<br>@5|Proposed<br>NDCG@<br>10|Precision<br>@5 Gain<br>(%)|NDCG@<br>10 Gain<br>(%)|\n|---|---|---|---|---|---|---|\n|Amazon<br>Reviews|43.6|48.3|51.8|58.6|18.8|21.3|\n|Last.fm|42.1|49.0|47.5|55.0|12.8|12.2|\n|MovieLe<br>ns 1M|41.9|47.1|47.9|53.7|14.3|14.0|"
],
"file_path": "/Users/theresa/projects/miro_case/periscope/data/2509.09066v1.pdf"
}